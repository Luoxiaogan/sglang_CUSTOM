[2025-07-25 02:12:13] [sglang_test_framework] [INFO] SGLang Testing Framework v1.0.0 initialized with log level: DEBUG
[2025-07-25 02:12:16] [__main__] [INFO] ============================================================
[2025-07-25 02:12:16] [__main__] [INFO] SGLang Testing Framework - Routing Test
[2025-07-25 02:12:16] [__main__] [INFO] ============================================================
[2025-07-25 02:12:16] [asyncio] [DEBUG] Using selector: EpollSelector
[2025-07-25 02:12:16] [sglang_test_framework.tests.routing_test] [INFO] sglang-router is installed and available
[2025-07-25 02:12:16] [sglang_test_framework.tests.routing_test] [INFO] Launching 2 SGLang servers
[2025-07-25 02:12:16] [sglang_test_framework.core.server_manager] [INFO] Starting server worker_0 with command: python -m sglang.launch_server --model-path /data/pretrained_models/Llama-2-7b-hf --port 30001 --host 0.0.0.0 --mem-fraction-static 0.9 --max-running-requests 256 --chunked-prefill-size 8192 --max-prefill-tokens 16384 --schedule-conservativeness 1.0 --tp-size 1 --tokenizer-mode auto --dtype auto --load-format auto --log-level info --enable-metrics
[2025-07-25 02:12:16] [sglang_test_framework.core.server_manager] [INFO] Server logs will be displayed for worker_0
[2025-07-25 02:12:16] [sglang_test_framework.core.server_manager] [INFO] Starting server worker_1 with command: python -m sglang.launch_server --model-path /data/pretrained_models/Llama-2-7b-hf --port 30002 --host 0.0.0.0 --mem-fraction-static 0.9 --max-running-requests 256 --chunked-prefill-size 8192 --max-prefill-tokens 16384 --schedule-conservativeness 1.0 --tp-size 1 --tokenizer-mode auto --dtype auto --load-format auto --log-level info --enable-metrics
[2025-07-25 02:12:16] [sglang_test_framework.core.server_manager] [INFO] Server logs will be displayed for worker_1
[2025-07-25 02:12:22] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:22] server_args=ServerArgs(model_path='/data/pretrained_models/Llama-2-7b-hf', tokenizer_path='/data/pretrained_models/Llama-2-7b-hf', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=False, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='0.0.0.0', port=30001, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.9, max_running_requests=256, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=1, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=482925929, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=0, crash_dump_folder=None, show_time_cost=False, enable_metrics=True, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, api_key=None, served_model_name='/data/pretrained_models/Llama-2-7b-hf', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, dp_size=1, load_balance_method='round_robin', dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, ep_size=1, enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_moe=False, enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through_selective', hicache_io_backend='', hicache_storage_backend=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, cuda_graph_max_bs=None, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_nccl_nvls=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, enable_triton_kernel_moe=False, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, pdlb_url=None, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3)
[2025-07-25 02:12:23] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:23] server_args=ServerArgs(model_path='/data/pretrained_models/Llama-2-7b-hf', tokenizer_path='/data/pretrained_models/Llama-2-7b-hf', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=False, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='0.0.0.0', port=30002, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.9, max_running_requests=256, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=1, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=895115206, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=0, crash_dump_folder=None, show_time_cost=False, enable_metrics=True, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, api_key=None, served_model_name='/data/pretrained_models/Llama-2-7b-hf', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, dp_size=1, load_balance_method='round_robin', dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, ep_size=1, enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_moe=False, enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through_selective', hicache_io_backend='', hicache_storage_backend=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, cuda_graph_max_bs=None, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_nccl_nvls=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, enable_triton_kernel_moe=False, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, pdlb_url=None, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3)
[2025-07-25 02:12:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:29] Attention backend not explicitly specified. Use flashinfer backend by default.
[2025-07-25 02:12:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:29] Init torch distributed begin.
[2025-07-25 02:12:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:29] Init torch distributed ends. mem usage=0.00 GB
[2025-07-25 02:12:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:30] Attention backend not explicitly specified. Use flashinfer backend by default.
[2025-07-25 02:12:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:30] Init torch distributed begin.
[2025-07-25 02:12:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:30] Init torch distributed ends. mem usage=0.00 GB
[2025-07-25 02:12:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:30] Load weight begin. avail mem=78.64 GB
[2025-07-25 02:12:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[2025-07-25 02:12:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:30] Load weight begin. avail mem=78.64 GB
[2025-07-25 02:12:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[2025-07-25 02:12:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.72it/s]
[2025-07-25 02:12:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.44it/s]
[2025-07-25 02:12:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.20s/it]
[2025-07-25 02:12:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.11s/it]
[2025-07-25 02:12:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:32] Load weight end. type=LlamaForCausalLM, dtype=torch.float16, avail mem=66.07 GB, mem usage=12.57 GB.
[2025-07-25 02:12:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:32] KV Cache is allocated. #tokens: 119182, K size: 29.10 GB, V size: 29.10 GB
[2025-07-25 02:12:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:32] Memory pool end. avail mem=7.80 GB
[2025-07-25 02:12:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:33] Capture cuda graph begin. This can take up to several minutes. avail mem=7.30 GB
[2025-07-25 02:12:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:33] Capture cuda graph bs [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160]
[2025-07-25 02:12:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0]   0%|          | 0/23 [00:00<?, ?it/s]
[2025-07-25 02:12:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.43s/it]
[2025-07-25 02:12:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.32s/it]
[2025-07-25 02:12:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:33] Load weight end. type=LlamaForCausalLM, dtype=torch.float16, avail mem=66.07 GB, mem usage=12.57 GB.
[2025-07-25 02:12:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:33] KV Cache is allocated. #tokens: 119182, K size: 29.10 GB, V size: 29.10 GB
[2025-07-25 02:12:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:33] Memory pool end. avail mem=7.80 GB
[2025-07-25 02:12:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=160 avail_mem=7.30 GB):   0%|          | 0/23 [00:00<?, ?it/s]
[2025-07-25 02:12:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=160 avail_mem=7.30 GB):   4%|▍         | 1/23 [00:00<00:16,  1.36it/s]
[2025-07-25 02:12:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:33] Capture cuda graph begin. This can take up to several minutes. avail mem=7.30 GB
[2025-07-25 02:12:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:33] Capture cuda graph bs [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160]
[2025-07-25 02:12:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1]   0%|          | 0/23 [00:00<?, ?it/s]
[2025-07-25 02:12:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=152 avail_mem=7.21 GB):   4%|▍         | 1/23 [00:00<00:16,  1.36it/s]
[2025-07-25 02:12:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=152 avail_mem=7.21 GB):   9%|▊         | 2/23 [00:00<00:09,  2.24it/s]
[2025-07-25 02:12:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=144 avail_mem=7.19 GB):   9%|▊         | 2/23 [00:00<00:09,  2.24it/s]
[2025-07-25 02:12:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=144 avail_mem=7.19 GB):  13%|█▎        | 3/23 [00:01<00:07,  2.76it/s]
[2025-07-25 02:12:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=136 avail_mem=7.16 GB):  13%|█▎        | 3/23 [00:01<00:07,  2.76it/s]
[2025-07-25 02:12:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=136 avail_mem=7.16 GB):  17%|█▋        | 4/23 [00:01<00:06,  3.15it/s]
[2025-07-25 02:12:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=160 avail_mem=7.30 GB):   0%|          | 0/23 [00:00<?, ?it/s]
[2025-07-25 02:12:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=160 avail_mem=7.30 GB):   4%|▍         | 1/23 [00:00<00:17,  1.27it/s]
[2025-07-25 02:12:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=128 avail_mem=7.12 GB):  17%|█▋        | 4/23 [00:01<00:06,  3.15it/s]
[2025-07-25 02:12:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=128 avail_mem=7.12 GB):  22%|██▏       | 5/23 [00:01<00:05,  3.45it/s]
[2025-07-25 02:12:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=152 avail_mem=7.21 GB):   4%|▍         | 1/23 [00:00<00:17,  1.27it/s]
[2025-07-25 02:12:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=152 avail_mem=7.21 GB):   9%|▊         | 2/23 [00:01<00:10,  2.10it/s]
[2025-07-25 02:12:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=120 avail_mem=7.09 GB):  22%|██▏       | 5/23 [00:01<00:05,  3.45it/s]
[2025-07-25 02:12:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=120 avail_mem=7.09 GB):  26%|██▌       | 6/23 [00:01<00:04,  3.67it/s]
[2025-07-25 02:12:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=144 avail_mem=7.19 GB):   9%|▊         | 2/23 [00:01<00:10,  2.10it/s]
[2025-07-25 02:12:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=144 avail_mem=7.19 GB):  13%|█▎        | 3/23 [00:01<00:07,  2.66it/s]
[2025-07-25 02:12:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=112 avail_mem=7.05 GB):  26%|██▌       | 6/23 [00:01<00:04,  3.67it/s]
[2025-07-25 02:12:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=112 avail_mem=7.05 GB):  30%|███       | 7/23 [00:02<00:04,  3.83it/s]
[2025-07-25 02:12:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=136 avail_mem=7.16 GB):  13%|█▎        | 3/23 [00:01<00:07,  2.66it/s]
[2025-07-25 02:12:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=136 avail_mem=7.16 GB):  17%|█▋        | 4/23 [00:01<00:06,  3.04it/s]
[2025-07-25 02:12:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=104 avail_mem=7.03 GB):  30%|███       | 7/23 [00:02<00:04,  3.83it/s]
[2025-07-25 02:12:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=104 avail_mem=7.03 GB):  35%|███▍      | 8/23 [00:02<00:03,  3.94it/s]
[2025-07-25 02:12:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=128 avail_mem=7.12 GB):  17%|█▋        | 4/23 [00:01<00:06,  3.04it/s]
[2025-07-25 02:12:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=128 avail_mem=7.12 GB):  22%|██▏       | 5/23 [00:01<00:05,  3.33it/s]
[2025-07-25 02:12:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=96 avail_mem=7.00 GB):  35%|███▍      | 8/23 [00:02<00:03,  3.94it/s]
[2025-07-25 02:12:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=96 avail_mem=7.00 GB):  39%|███▉      | 9/23 [00:02<00:03,  4.02it/s]
[2025-07-25 02:12:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=120 avail_mem=7.09 GB):  22%|██▏       | 5/23 [00:01<00:05,  3.33it/s]
[2025-07-25 02:12:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=120 avail_mem=7.09 GB):  26%|██▌       | 6/23 [00:02<00:04,  3.53it/s]
[2025-07-25 02:12:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=88 avail_mem=6.98 GB):  39%|███▉      | 9/23 [00:02<00:03,  4.02it/s]
[2025-07-25 02:12:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=88 avail_mem=6.98 GB):  43%|████▎     | 10/23 [00:02<00:03,  4.05it/s]
[2025-07-25 02:12:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=112 avail_mem=7.05 GB):  26%|██▌       | 6/23 [00:02<00:04,  3.53it/s]
[2025-07-25 02:12:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=112 avail_mem=7.05 GB):  30%|███       | 7/23 [00:02<00:04,  3.67it/s]
[2025-07-25 02:12:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=80 avail_mem=6.94 GB):  43%|████▎     | 10/23 [00:02<00:03,  4.05it/s]
[2025-07-25 02:12:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=80 avail_mem=6.94 GB):  48%|████▊     | 11/23 [00:03<00:02,  4.10it/s]
[2025-07-25 02:12:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=104 avail_mem=7.03 GB):  30%|███       | 7/23 [00:02<00:04,  3.67it/s]
[2025-07-25 02:12:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=104 avail_mem=7.03 GB):  35%|███▍      | 8/23 [00:02<00:04,  3.75it/s]
[2025-07-25 02:12:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=72 avail_mem=6.91 GB):  48%|████▊     | 11/23 [00:03<00:02,  4.10it/s]
[2025-07-25 02:12:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=72 avail_mem=6.91 GB):  52%|█████▏    | 12/23 [00:03<00:02,  4.13it/s]
[2025-07-25 02:12:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=96 avail_mem=7.00 GB):  35%|███▍      | 8/23 [00:02<00:04,  3.75it/s]
[2025-07-25 02:12:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=96 avail_mem=7.00 GB):  39%|███▉      | 9/23 [00:02<00:03,  3.83it/s]
[2025-07-25 02:12:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=64 avail_mem=6.88 GB):  52%|█████▏    | 12/23 [00:03<00:02,  4.13it/s]
[2025-07-25 02:12:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=64 avail_mem=6.88 GB):  57%|█████▋    | 13/23 [00:03<00:02,  4.11it/s]
[2025-07-25 02:12:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=88 avail_mem=6.98 GB):  39%|███▉      | 9/23 [00:02<00:03,  3.83it/s]
[2025-07-25 02:12:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=88 avail_mem=6.98 GB):  43%|████▎     | 10/23 [00:03<00:03,  3.86it/s]
[2025-07-25 02:12:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=56 avail_mem=6.86 GB):  57%|█████▋    | 13/23 [00:03<00:02,  4.11it/s]
[2025-07-25 02:12:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=56 avail_mem=6.86 GB):  61%|██████    | 14/23 [00:03<00:02,  4.13it/s]
[2025-07-25 02:12:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=80 avail_mem=6.94 GB):  43%|████▎     | 10/23 [00:03<00:03,  3.86it/s]
[2025-07-25 02:12:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=80 avail_mem=6.94 GB):  48%|████▊     | 11/23 [00:03<00:03,  3.90it/s]
[2025-07-25 02:12:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=48 avail_mem=6.84 GB):  61%|██████    | 14/23 [00:03<00:02,  4.13it/s]
[2025-07-25 02:12:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=48 avail_mem=6.84 GB):  65%|██████▌   | 15/23 [00:04<00:01,  4.17it/s]
[2025-07-25 02:12:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=40 avail_mem=6.83 GB):  65%|██████▌   | 15/23 [00:04<00:01,  4.17it/s]
[2025-07-25 02:12:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=40 avail_mem=6.83 GB):  70%|██████▉   | 16/23 [00:04<00:01,  4.19it/s]
[2025-07-25 02:12:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=72 avail_mem=6.91 GB):  48%|████▊     | 11/23 [00:03<00:03,  3.90it/s]
[2025-07-25 02:12:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=72 avail_mem=6.91 GB):  52%|█████▏    | 12/23 [00:03<00:02,  3.89it/s]
[2025-07-25 02:12:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=32 avail_mem=6.78 GB):  70%|██████▉   | 16/23 [00:04<00:01,  4.19it/s]
[2025-07-25 02:12:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=32 avail_mem=6.78 GB):  74%|███████▍  | 17/23 [00:04<00:01,  4.22it/s]
[2025-07-25 02:12:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=64 avail_mem=6.88 GB):  52%|█████▏    | 12/23 [00:03<00:02,  3.89it/s]
[2025-07-25 02:12:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=64 avail_mem=6.88 GB):  57%|█████▋    | 13/23 [00:03<00:02,  3.88it/s]
[2025-07-25 02:12:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=24 avail_mem=6.78 GB):  74%|███████▍  | 17/23 [00:04<00:01,  4.22it/s]
[2025-07-25 02:12:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=24 avail_mem=6.78 GB):  78%|███████▊  | 18/23 [00:04<00:01,  4.23it/s]
[2025-07-25 02:12:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=56 avail_mem=6.86 GB):  57%|█████▋    | 13/23 [00:03<00:02,  3.88it/s]
[2025-07-25 02:12:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=56 avail_mem=6.86 GB):  61%|██████    | 14/23 [00:04<00:02,  3.93it/s]
[2025-07-25 02:12:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=16 avail_mem=6.76 GB):  78%|███████▊  | 18/23 [00:04<00:01,  4.23it/s]
[2025-07-25 02:12:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=16 avail_mem=6.76 GB):  83%|████████▎ | 19/23 [00:05<00:00,  4.24it/s]
[2025-07-25 02:12:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=48 avail_mem=6.84 GB):  61%|██████    | 14/23 [00:04<00:02,  3.93it/s]
[2025-07-25 02:12:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=48 avail_mem=6.84 GB):  65%|██████▌   | 15/23 [00:04<00:02,  3.89it/s]
[2025-07-25 02:12:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=8 avail_mem=6.75 GB):  83%|████████▎ | 19/23 [00:05<00:00,  4.24it/s]
[2025-07-25 02:12:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=8 avail_mem=6.75 GB):  87%|████████▋ | 20/23 [00:05<00:00,  4.20it/s]
[2025-07-25 02:12:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=40 avail_mem=6.83 GB):  65%|██████▌   | 15/23 [00:04<00:02,  3.89it/s]
[2025-07-25 02:12:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=40 avail_mem=6.83 GB):  70%|██████▉   | 16/23 [00:04<00:01,  3.93it/s]
[2025-07-25 02:12:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=4 avail_mem=6.73 GB):  87%|████████▋ | 20/23 [00:05<00:00,  4.20it/s]
[2025-07-25 02:12:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=4 avail_mem=6.73 GB):  91%|█████████▏| 21/23 [00:05<00:00,  4.20it/s]
[2025-07-25 02:12:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=32 avail_mem=6.78 GB):  70%|██████▉   | 16/23 [00:04<00:01,  3.93it/s]
[2025-07-25 02:12:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=32 avail_mem=6.78 GB):  74%|███████▍  | 17/23 [00:04<00:01,  3.97it/s]
[2025-07-25 02:12:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=2 avail_mem=6.72 GB):  91%|█████████▏| 21/23 [00:05<00:00,  4.20it/s]
[2025-07-25 02:12:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=2 avail_mem=6.72 GB):  96%|█████████▌| 22/23 [00:05<00:00,  4.21it/s]
[2025-07-25 02:12:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=24 avail_mem=6.78 GB):  74%|███████▍  | 17/23 [00:04<00:01,  3.97it/s]
[2025-07-25 02:12:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=24 avail_mem=6.78 GB):  78%|███████▊  | 18/23 [00:05<00:01,  4.00it/s]
[2025-07-25 02:12:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=1 avail_mem=6.70 GB):  96%|█████████▌| 22/23 [00:05<00:00,  4.21it/s]
[2025-07-25 02:12:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=1 avail_mem=6.70 GB): 100%|██████████| 23/23 [00:06<00:00,  4.22it/s]
[2025-07-25 02:12:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=1 avail_mem=6.70 GB): 100%|██████████| 23/23 [00:06<00:00,  3.82it/s]
[2025-07-25 02:12:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:39] Capture cuda graph end. Time elapsed: 6.05 s. mem usage=0.61 GB. avail mem=6.69 GB.
[2025-07-25 02:12:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:39] max_total_num_tokens=119182, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=256, context_len=4096, available_gpu_mem=6.69 GB
[2025-07-25 02:12:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=16 avail_mem=6.76 GB):  78%|███████▊  | 18/23 [00:05<00:01,  4.00it/s]
[2025-07-25 02:12:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=16 avail_mem=6.76 GB):  83%|████████▎ | 19/23 [00:05<00:00,  4.01it/s]
[2025-07-25 02:12:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:39] INFO:     Started server process [1876953]
[2025-07-25 02:12:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:39] INFO:     Waiting for application startup.
[2025-07-25 02:12:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:39] INFO:     Application startup complete.
[2025-07-25 02:12:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:39] INFO:     Uvicorn running on http://0.0.0.0:30001 (Press CTRL+C to quit)
[2025-07-25 02:12:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=8 avail_mem=6.75 GB):  83%|████████▎ | 19/23 [00:05<00:00,  4.01it/s]
[2025-07-25 02:12:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=8 avail_mem=6.75 GB):  87%|████████▋ | 20/23 [00:05<00:00,  4.02it/s]
[2025-07-25 02:12:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=4 avail_mem=6.73 GB):  87%|████████▋ | 20/23 [00:05<00:00,  4.02it/s]
[2025-07-25 02:12:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=4 avail_mem=6.73 GB):  91%|█████████▏| 21/23 [00:05<00:00,  3.94it/s]
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=2 avail_mem=6.72 GB):  91%|█████████▏| 21/23 [00:05<00:00,  3.94it/s]
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=2 avail_mem=6.72 GB):  96%|█████████▌| 22/23 [00:06<00:00,  3.97it/s]
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=1 avail_mem=6.70 GB):  96%|█████████▌| 22/23 [00:06<00:00,  3.97it/s]
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=1 avail_mem=6.70 GB): 100%|██████████| 23/23 [00:06<00:00,  4.00it/s]
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=1 avail_mem=6.70 GB): 100%|██████████| 23/23 [00:06<00:00,  3.63it/s]
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:40] Capture cuda graph end. Time elapsed: 6.38 s. mem usage=0.61 GB. avail mem=6.69 GB.
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:40] max_total_num_tokens=119182, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=256, context_len=4096, available_gpu_mem=6.69 GB
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:40] INFO:     127.0.0.1:56300 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:40] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0,
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:40] INFO:     Started server process [1876955]
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:40] INFO:     Waiting for application startup.
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:40] INFO:     Application startup complete.
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:40] INFO:     Uvicorn running on http://0.0.0.0:30002 (Press CTRL+C to quit)
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:40] INFO:     127.0.0.1:41444 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:40] INFO:     127.0.0.1:56324 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] Server worker_1 started successfully in 24.0s
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] Server worker_0 started successfully in 24.0s
[2025-07-25 02:12:40] [sglang_test_framework.tests.routing_test] [INFO] Launching router with policy: cache_aware
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] Starting router with command: python -m sglang_router.launch_router --worker-urls http://0.0.0.0:30001 http://0.0.0.0:30002 --port 30000 --host 0.0.0.0 --policy cache_aware --cache-threshold 0.5 --balance-abs-threshold 32 --balance-rel-threshold 1.0001 --eviction-interval 60 --max-tree-size 16777216
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:40] INFO:     127.0.0.1:56338 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:40] INFO:     127.0.0.1:41446 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:40] INFO:     127.0.0.1:41450 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:12:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:40] INFO:     127.0.0.1:56352 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:12:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:41] INFO:     127.0.0.1:56308 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:41] The server is fired up and ready to roll!
[2025-07-25 02:12:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:41] INFO:     127.0.0.1:41464 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-07-25 02:12:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:41] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0,
[2025-07-25 02:12:41] [sglang_test_framework.core.server_manager] [INFO] Router started successfully in 1.0s
[2025-07-25 02:12:41] [sglang_test_framework.tests.routing_test] [INFO] Warming up servers with 10 requests
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] RequestSender session created with connection pool limit=100
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [INFO] Generating 10 requests from dataset 'random'...
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [INFO] Generating random requests with input_len=128, output_len=16, range_ratio=0.1
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [INFO] Successfully generated 10 random requests
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [INFO] Setting all requests to arrive immediately (infinite rate)
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_0 to http://0.0.0.0:30000/generate at 1753380761.590476
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_0 with payload: {'text': 'Random prompt 0 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 14, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_1 to http://0.0.0.0:30000/generate at 1753380761.5922358
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_1 with payload: {'text': 'Random prompt 1 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 17, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_2 to http://0.0.0.0:30000/generate at 1753380761.5931387
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_2 with payload: {'text': 'Random prompt 2 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 16, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_3 to http://0.0.0.0:30000/generate at 1753380761.5939436
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_3 with payload: {'text': 'Random prompt 3 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 15, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_4 to http://0.0.0.0:30000/generate at 1753380761.5947273
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_4 with payload: {'text': 'Random prompt 4 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 15, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_5 to http://0.0.0.0:30000/generate at 1753380761.5954707
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_5 with payload: {'text': 'Random prompt 5 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 15, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_6 to http://0.0.0.0:30000/generate at 1753380761.5962143
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_6 with payload: {'text': 'Random prompt 6 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 15, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_7 to http://0.0.0.0:30000/generate at 1753380761.5969224
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_7 with payload: {'text': 'Random prompt 7 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 16, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_8 to http://0.0.0.0:30000/generate at 1753380761.597643
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_8 with payload: {'text': 'Random prompt 8 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 15, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_9 to http://0.0.0.0:30000/generate at 1753380761.598401
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_9 with payload: {'text': 'Random prompt 9 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 15, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:41] INFO:     127.0.0.1:56360 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:41] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0,
[2025-07-25 02:12:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:41] INFO:     127.0.0.1:56370 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_1
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_1
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_3
[2025-07-25 02:12:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:41] INFO:     127.0.0.1:56380 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_3
[2025-07-25 02:12:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:41] INFO:     127.0.0.1:56382 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_5
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_5
[2025-07-25 02:12:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:41] INFO:     127.0.0.1:56388 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_7
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_7
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_9
[2025-07-25 02:12:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:41] Prefill batch. #new-seq: 3, #new-token: 97, #cached-token: 3, token usage: 0.00, #running-req: 1, #queue-req: 0,
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_9
[2025-07-25 02:12:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:41] INFO:     127.0.0.1:41482 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_0
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_0
[2025-07-25 02:12:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:41] INFO:     127.0.0.1:41486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_2
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_2
[2025-07-25 02:12:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:41] INFO:     127.0.0.1:41494 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_4
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_4
[2025-07-25 02:12:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:41] INFO:     127.0.0.1:41508 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_6
[2025-07-25 02:12:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:41] INFO:     127.0.0.1:41510 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_6
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_8
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_8
[2025-07-25 02:12:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:41] Prefill batch. #new-seq: 1, #new-token: 30, #cached-token: 4, token usage: 0.00, #running-req: 4, #queue-req: 0,
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_5 received DONE after 16 chunks
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_5 completed: 47 chars, 16 chunks, TTFT=97.6ms
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_9 received DONE after 16 chunks
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_9 completed: 60 chars, 16 chunks, TTFT=235.7ms
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_3 received DONE after 16 chunks
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_3 completed: 45 chars, 16 chunks, TTFT=98.9ms
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_7 received DONE after 17 chunks
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_7 completed: 64 chars, 17 chunks, TTFT=96.1ms
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_1 received DONE after 18 chunks
[2025-07-25 02:12:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_1 completed: 41 chars, 18 chunks, TTFT=78.3ms
[2025-07-25 02:12:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:42] Prefill batch. #new-seq: 5, #new-token: 156, #cached-token: 5, token usage: 0.00, #running-req: 1, #queue-req: 0,
[2025-07-25 02:12:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:42] INFO:     127.0.0.1:41470 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:42] The server is fired up and ready to roll!
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_0 received DONE after 15 chunks
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_0 completed: 44 chars, 15 chunks, TTFT=856.4ms
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_4 received DONE after 16 chunks
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_4 completed: 47 chars, 16 chunks, TTFT=851.7ms
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_8 received DONE after 16 chunks
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_8 completed: 45 chars, 16 chunks, TTFT=849.2ms
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_6 received DONE after 16 chunks
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_6 completed: 45 chars, 16 chunks, TTFT=850.7ms
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_2 received DONE after 17 chunks
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_2 completed: 64 chars, 17 chunks, TTFT=853.6ms
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] RequestSender session closed
[2025-07-25 02:12:42] [sglang_test_framework.tests.routing_test] [INFO] Warmup complete: 10/10 successful
[2025-07-25 02:12:42] [sglang_test_framework.core.metrics_collector] [INFO] Started metrics collection
[2025-07-25 02:12:42] [sglang_test_framework.core.metrics_collector] [INFO] Started metrics collection
[2025-07-25 02:12:42] [sglang_test_framework.core.metrics_collector] [INFO] Started metrics collection
[2025-07-25 02:12:42] [sglang_test_framework.tests.routing_test] [INFO] Starting test with 1000 requests
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] RequestSender session created with connection pool limit=100
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [INFO] Generating 1000 requests from dataset 'random'...
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [INFO] Generating random requests with input_len=512, output_len=128, range_ratio=0.5
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [INFO] Generated 1000/1000 random requests
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [INFO] Successfully generated 1000 random requests
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [INFO] Generating Poisson arrivals with rate=50.0 req/s
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [INFO] Total test duration: 20.0 seconds
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_0 to http://0.0.0.0:30000/generate at 1753380762.9582384
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_0 with payload: {'text': 'Random prompt 0 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_1 to http://0.0.0.0:30000/generate at 1753380762.9592478
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_1 with payload: {'text': 'Random prompt 1 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_2 to http://0.0.0.0:30000/generate at 1753380762.9597566
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_2 with payload: {'text': 'Random prompt 2 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_3 to http://0.0.0.0:30000/generate at 1753380762.9602044
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_3 with payload: {'text': 'Random prompt 3 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_4 to http://0.0.0.0:30000/generate at 1753380762.9606364
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_4 with payload: {'text': 'Random prompt 4 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_5 to http://0.0.0.0:30000/generate at 1753380762.961053
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_5 with payload: {'text': 'Random prompt 5 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_6 to http://0.0.0.0:30000/generate at 1753380762.9616702
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_6 with payload: {'text': 'Random prompt 6 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_7 to http://0.0.0.0:30000/generate at 1753380762.9621482
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_7 with payload: {'text': 'Random prompt 7 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 173, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_8 to http://0.0.0.0:30000/generate at 1753380762.9626052
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_8 with payload: {'text': 'Random prompt 8 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 96, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_9 to http://0.0.0.0:30000/generate at 1753380762.963004
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_9 with payload: {'text': 'Random prompt 9 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_10 to http://0.0.0.0:30000/generate at 1753380762.963417
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_10 with payload: {'text': 'Random prompt 10 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_11 to http://0.0.0.0:30000/generate at 1753380762.9637876
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_11 with payload: {'text': 'Random prompt 11 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_12 to http://0.0.0.0:30000/generate at 1753380762.9641676
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_12 with payload: {'text': 'Random prompt 12 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_13 to http://0.0.0.0:30000/generate at 1753380762.964665
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_13 with payload: {'text': 'Random prompt 13 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_14 to http://0.0.0.0:30000/generate at 1753380762.9650383
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_14 with payload: {'text': 'Random prompt 14 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 154, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_15 to http://0.0.0.0:30000/generate at 1753380762.9654245
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_15 with payload: {'text': 'Random prompt 15 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 182, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_16 to http://0.0.0.0:30000/generate at 1753380762.9657917
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_16 with payload: {'text': 'Random prompt 16 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_17 to http://0.0.0.0:30000/generate at 1753380762.9661586
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_17 with payload: {'text': 'Random prompt 17 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 137, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_18 to http://0.0.0.0:30000/generate at 1753380762.9665492
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_18 with payload: {'text': 'Random prompt 18 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 181, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_19 to http://0.0.0.0:30000/generate at 1753380762.9669015
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_19 with payload: {'text': 'Random prompt 19 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_20 to http://0.0.0.0:30000/generate at 1753380762.9673502
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_20 with payload: {'text': 'Random prompt 20 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_21 to http://0.0.0.0:30000/generate at 1753380762.9677072
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_21 with payload: {'text': 'Random prompt 21 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 102, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_22 to http://0.0.0.0:30000/generate at 1753380762.9680567
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_22 with payload: {'text': 'Random prompt 22 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 182, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_23 to http://0.0.0.0:30000/generate at 1753380762.9684086
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_23 with payload: {'text': 'Random prompt 23 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_24 to http://0.0.0.0:30000/generate at 1753380762.9687524
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_24 with payload: {'text': 'Random prompt 24 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_25 to http://0.0.0.0:30000/generate at 1753380762.969095
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_25 with payload: {'text': 'Random prompt 25 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_26 to http://0.0.0.0:30000/generate at 1753380762.9694595
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_26 with payload: {'text': 'Random prompt 26 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 174, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_27 to http://0.0.0.0:30000/generate at 1753380762.970959
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_27 with payload: {'text': 'Random prompt 27 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_28 to http://0.0.0.0:30000/generate at 1753380762.9713652
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_28 with payload: {'text': 'Random prompt 28 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 105, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_29 to http://0.0.0.0:30000/generate at 1753380762.9717236
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_29 with payload: {'text': 'Random prompt 29 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_30 to http://0.0.0.0:30000/generate at 1753380762.972063
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_30 with payload: {'text': 'Random prompt 30 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_31 to http://0.0.0.0:30000/generate at 1753380762.9724102
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_31 with payload: {'text': 'Random prompt 31 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_32 to http://0.0.0.0:30000/generate at 1753380762.9727495
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_32 with payload: {'text': 'Random prompt 32 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_33 to http://0.0.0.0:30000/generate at 1753380762.9731688
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_33 with payload: {'text': 'Random prompt 33 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 79, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_34 to http://0.0.0.0:30000/generate at 1753380762.973523
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_34 with payload: {'text': 'Random prompt 34 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_35 to http://0.0.0.0:30000/generate at 1753380762.9738448
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_35 with payload: {'text': 'Random prompt 35 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_36 to http://0.0.0.0:30000/generate at 1753380762.974162
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_36 with payload: {'text': 'Random prompt 36 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_37 to http://0.0.0.0:30000/generate at 1753380762.9744825
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_37 with payload: {'text': 'Random prompt 37 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_38 to http://0.0.0.0:30000/generate at 1753380762.9749427
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_38 with payload: {'text': 'Random prompt 38 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_39 to http://0.0.0.0:30000/generate at 1753380762.9753077
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_39 with payload: {'text': 'Random prompt 39 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 104, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_40 to http://0.0.0.0:30000/generate at 1753380762.975733
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_40 with payload: {'text': 'Random prompt 40 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_41 to http://0.0.0.0:30000/generate at 1753380762.97605
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_41 with payload: {'text': 'Random prompt 41 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_42 to http://0.0.0.0:30000/generate at 1753380762.976384
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_42 with payload: {'text': 'Random prompt 42 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 105, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_43 to http://0.0.0.0:30000/generate at 1753380762.9766703
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_43 with payload: {'text': 'Random prompt 43 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_44 to http://0.0.0.0:30000/generate at 1753380762.9769742
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_44 with payload: {'text': 'Random prompt 44 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_45 to http://0.0.0.0:30000/generate at 1753380762.9772875
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_45 with payload: {'text': 'Random prompt 45 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_46 to http://0.0.0.0:30000/generate at 1753380762.9776697
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_46 with payload: {'text': 'Random prompt 46 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_47 to http://0.0.0.0:30000/generate at 1753380762.977991
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_47 with payload: {'text': 'Random prompt 47 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_48 to http://0.0.0.0:30000/generate at 1753380762.9783118
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_48 with payload: {'text': 'Random prompt 48 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_49 to http://0.0.0.0:30000/generate at 1753380762.978607
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_49 with payload: {'text': 'Random prompt 49 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_50 to http://0.0.0.0:30000/generate at 1753380762.9788964
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_50 with payload: {'text': 'Random prompt 50 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_51 to http://0.0.0.0:30000/generate at 1753380762.979203
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_51 with payload: {'text': 'Random prompt 51 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 132, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_52 to http://0.0.0.0:30000/generate at 1753380762.979505
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_52 with payload: {'text': 'Random prompt 52 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_53 to http://0.0.0.0:30000/generate at 1753380762.9798663
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_53 with payload: {'text': 'Random prompt 53 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_54 to http://0.0.0.0:30000/generate at 1753380762.9801555
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_54 with payload: {'text': 'Random prompt 54 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_55 to http://0.0.0.0:30000/generate at 1753380762.980444
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_55 with payload: {'text': 'Random prompt 55 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_56 to http://0.0.0.0:30000/generate at 1753380762.9807217
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_56 with payload: {'text': 'Random prompt 56 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_57 to http://0.0.0.0:30000/generate at 1753380762.9810042
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_57 with payload: {'text': 'Random prompt 57 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_58 to http://0.0.0.0:30000/generate at 1753380762.9812927
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_58 with payload: {'text': 'Random prompt 58 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_59 to http://0.0.0.0:30000/generate at 1753380762.981643
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_59 with payload: {'text': 'Random prompt 59 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_60 to http://0.0.0.0:30000/generate at 1753380762.981951
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_60 with payload: {'text': 'Random prompt 60 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_61 to http://0.0.0.0:30000/generate at 1753380762.9822402
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_61 with payload: {'text': 'Random prompt 61 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_62 to http://0.0.0.0:30000/generate at 1753380762.9825194
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_62 with payload: {'text': 'Random prompt 62 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_63 to http://0.0.0.0:30000/generate at 1753380762.9827929
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_63 with payload: {'text': 'Random prompt 63 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_64 to http://0.0.0.0:30000/generate at 1753380762.9830692
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_64 with payload: {'text': 'Random prompt 64 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 118, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_65 to http://0.0.0.0:30000/generate at 1753380762.9833431
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_65 with payload: {'text': 'Random prompt 65 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_66 to http://0.0.0.0:30000/generate at 1753380762.983711
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_66 with payload: {'text': 'Random prompt 66 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 95, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_67 to http://0.0.0.0:30000/generate at 1753380762.9839966
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_67 with payload: {'text': 'Random prompt 67 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_68 to http://0.0.0.0:30000/generate at 1753380762.9842706
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_68 with payload: {'text': 'Random prompt 68 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_69 to http://0.0.0.0:30000/generate at 1753380762.9845407
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_69 with payload: {'text': 'Random prompt 69 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 101, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_70 to http://0.0.0.0:30000/generate at 1753380762.9848127
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_70 with payload: {'text': 'Random prompt 70 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 102, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_71 to http://0.0.0.0:30000/generate at 1753380762.9850795
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_71 with payload: {'text': 'Random prompt 71 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_72 to http://0.0.0.0:30000/generate at 1753380762.98544
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_72 with payload: {'text': 'Random prompt 72 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_73 to http://0.0.0.0:30000/generate at 1753380762.9857402
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_73 with payload: {'text': 'Random prompt 73 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 66, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_74 to http://0.0.0.0:30000/generate at 1753380762.9860132
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_74 with payload: {'text': 'Random prompt 74 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_75 to http://0.0.0.0:30000/generate at 1753380762.9862986
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_75 with payload: {'text': 'Random prompt 75 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_76 to http://0.0.0.0:30000/generate at 1753380762.9865935
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_76 with payload: {'text': 'Random prompt 76 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 113, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_77 to http://0.0.0.0:30000/generate at 1753380762.9868648
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_77 with payload: {'text': 'Random prompt 77 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_78 to http://0.0.0.0:30000/generate at 1753380762.9871275
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_78 with payload: {'text': 'Random prompt 78 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_79 to http://0.0.0.0:30000/generate at 1753380762.9874644
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_79 with payload: {'text': 'Random prompt 79 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_80 to http://0.0.0.0:30000/generate at 1753380762.9877222
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_80 with payload: {'text': 'Random prompt 80 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_81 to http://0.0.0.0:30000/generate at 1753380762.9879863
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_81 with payload: {'text': 'Random prompt 81 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_82 to http://0.0.0.0:30000/generate at 1753380762.9882507
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_82 with payload: {'text': 'Random prompt 82 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_83 to http://0.0.0.0:30000/generate at 1753380762.9885142
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_83 with payload: {'text': 'Random prompt 83 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_84 to http://0.0.0.0:30000/generate at 1753380762.9887612
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_84 with payload: {'text': 'Random prompt 84 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_85 to http://0.0.0.0:30000/generate at 1753380762.9890716
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_85 with payload: {'text': 'Random prompt 85 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 124, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_86 to http://0.0.0.0:30000/generate at 1753380762.9893363
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_86 with payload: {'text': 'Random prompt 86 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_87 to http://0.0.0.0:30000/generate at 1753380762.989584
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_87 with payload: {'text': 'Random prompt 87 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_88 to http://0.0.0.0:30000/generate at 1753380762.9898367
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_88 with payload: {'text': 'Random prompt 88 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_89 to http://0.0.0.0:30000/generate at 1753380762.990082
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_89 with payload: {'text': 'Random prompt 89 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_90 to http://0.0.0.0:30000/generate at 1753380762.990345
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_90 with payload: {'text': 'Random prompt 90 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_91 to http://0.0.0.0:30000/generate at 1753380762.9905949
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_91 with payload: {'text': 'Random prompt 91 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_92 to http://0.0.0.0:30000/generate at 1753380762.9909112
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_92 with payload: {'text': 'Random prompt 92 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_93 to http://0.0.0.0:30000/generate at 1753380762.9911625
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_93 with payload: {'text': 'Random prompt 93 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_94 to http://0.0.0.0:30000/generate at 1753380762.9914167
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_94 with payload: {'text': 'Random prompt 94 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_95 to http://0.0.0.0:30000/generate at 1753380762.991662
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_95 with payload: {'text': 'Random prompt 95 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_96 to http://0.0.0.0:30000/generate at 1753380762.9919093
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_96 with payload: {'text': 'Random prompt 96 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_97 to http://0.0.0.0:30000/generate at 1753380762.9921556
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_97 with payload: {'text': 'Random prompt 97 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_98 to http://0.0.0.0:30000/generate at 1753380762.9924688
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_98 with payload: {'text': 'Random prompt 98 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_99 to http://0.0.0.0:30000/generate at 1753380762.9927177
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_99 with payload: {'text': 'Random prompt 99 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_100 to http://0.0.0.0:30000/generate at 1753380762.992954
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_100 with payload: {'text': 'Random prompt 100 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_101 to http://0.0.0.0:30000/generate at 1753380762.993136
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_101 with payload: {'text': 'Random prompt 101 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_102 to http://0.0.0.0:30000/generate at 1753380762.9933045
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_102 with payload: {'text': 'Random prompt 102 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_103 to http://0.0.0.0:30000/generate at 1753380762.9934447
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_103 with payload: {'text': 'Random prompt 103 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_104 to http://0.0.0.0:30000/generate at 1753380762.993582
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_104 with payload: {'text': 'Random prompt 104 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_105 to http://0.0.0.0:30000/generate at 1753380762.9937277
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_105 with payload: {'text': 'Random prompt 105 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_106 to http://0.0.0.0:30000/generate at 1753380762.9938667
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_106 with payload: {'text': 'Random prompt 106 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_107 to http://0.0.0.0:30000/generate at 1753380762.994001
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_107 with payload: {'text': 'Random prompt 107 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_108 to http://0.0.0.0:30000/generate at 1753380762.9947474
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_108 with payload: {'text': 'Random prompt 108 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_109 to http://0.0.0.0:30000/generate at 1753380762.9949033
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_109 with payload: {'text': 'Random prompt 109 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 84, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_110 to http://0.0.0.0:30000/generate at 1753380762.9950335
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_110 with payload: {'text': 'Random prompt 110 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_111 to http://0.0.0.0:30000/generate at 1753380762.9951696
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_111 with payload: {'text': 'Random prompt 111 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_112 to http://0.0.0.0:30000/generate at 1753380762.9953132
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_112 with payload: {'text': 'Random prompt 112 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_113 to http://0.0.0.0:30000/generate at 1753380762.9954507
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_113 with payload: {'text': 'Random prompt 113 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_114 to http://0.0.0.0:30000/generate at 1753380762.9955828
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_114 with payload: {'text': 'Random prompt 114 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_115 to http://0.0.0.0:30000/generate at 1753380762.9957154
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_115 with payload: {'text': 'Random prompt 115 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 138, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_116 to http://0.0.0.0:30000/generate at 1753380762.9958465
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_116 with payload: {'text': 'Random prompt 116 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 76, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_117 to http://0.0.0.0:30000/generate at 1753380762.995983
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_117 with payload: {'text': 'Random prompt 117 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_118 to http://0.0.0.0:30000/generate at 1753380762.996116
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_118 with payload: {'text': 'Random prompt 118 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 98, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_119 to http://0.0.0.0:30000/generate at 1753380762.996258
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_119 with payload: {'text': 'Random prompt 119 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_120 to http://0.0.0.0:30000/generate at 1753380762.9964457
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_120 with payload: {'text': 'Random prompt 120 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 178, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_121 to http://0.0.0.0:30000/generate at 1753380762.9965842
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_121 with payload: {'text': 'Random prompt 121 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_122 to http://0.0.0.0:30000/generate at 1753380762.996718
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_122 with payload: {'text': 'Random prompt 122 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 174, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_123 to http://0.0.0.0:30000/generate at 1753380762.9968512
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_123 with payload: {'text': 'Random prompt 123 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_124 to http://0.0.0.0:30000/generate at 1753380762.99698
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_124 with payload: {'text': 'Random prompt 124 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_125 to http://0.0.0.0:30000/generate at 1753380762.9971113
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_125 with payload: {'text': 'Random prompt 125 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 135, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_126 to http://0.0.0.0:30000/generate at 1753380762.9972472
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_126 with payload: {'text': 'Random prompt 126 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_127 to http://0.0.0.0:30000/generate at 1753380762.9973934
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_127 with payload: {'text': 'Random prompt 127 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_128 to http://0.0.0.0:30000/generate at 1753380762.997528
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_128 with payload: {'text': 'Random prompt 128 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 112, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_129 to http://0.0.0.0:30000/generate at 1753380762.9976552
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_129 with payload: {'text': 'Random prompt 129 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_130 to http://0.0.0.0:30000/generate at 1753380762.9977813
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_130 with payload: {'text': 'Random prompt 130 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_131 to http://0.0.0.0:30000/generate at 1753380762.9979095
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_131 with payload: {'text': 'Random prompt 131 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_132 to http://0.0.0.0:30000/generate at 1753380762.9980752
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_132 with payload: {'text': 'Random prompt 132 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_133 to http://0.0.0.0:30000/generate at 1753380762.9982028
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_133 with payload: {'text': 'Random prompt 133 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_134 to http://0.0.0.0:30000/generate at 1753380762.9983358
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_134 with payload: {'text': 'Random prompt 134 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_135 to http://0.0.0.0:30000/generate at 1753380762.9984682
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_135 with payload: {'text': 'Random prompt 135 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_136 to http://0.0.0.0:30000/generate at 1753380762.9985905
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_136 with payload: {'text': 'Random prompt 136 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 173, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_137 to http://0.0.0.0:30000/generate at 1753380762.998722
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_137 with payload: {'text': 'Random prompt 137 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_138 to http://0.0.0.0:30000/generate at 1753380762.9988508
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_138 with payload: {'text': 'Random prompt 138 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_139 to http://0.0.0.0:30000/generate at 1753380762.9989734
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_139 with payload: {'text': 'Random prompt 139 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_140 to http://0.0.0.0:30000/generate at 1753380762.999105
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_140 with payload: {'text': 'Random prompt 140 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_141 to http://0.0.0.0:30000/generate at 1753380762.999241
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_141 with payload: {'text': 'Random prompt 141 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_142 to http://0.0.0.0:30000/generate at 1753380762.999369
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_142 with payload: {'text': 'Random prompt 142 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_143 to http://0.0.0.0:30000/generate at 1753380762.9994974
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_143 with payload: {'text': 'Random prompt 143 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 136, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_144 to http://0.0.0.0:30000/generate at 1753380762.999663
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_144 with payload: {'text': 'Random prompt 144 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 98, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_145 to http://0.0.0.0:30000/generate at 1753380762.999792
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_145 with payload: {'text': 'Random prompt 145 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_146 to http://0.0.0.0:30000/generate at 1753380762.9999156
[2025-07-25 02:12:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_146 with payload: {'text': 'Random prompt 146 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_147 to http://0.0.0.0:30000/generate at 1753380763.0000489
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_147 with payload: {'text': 'Random prompt 147 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_148 to http://0.0.0.0:30000/generate at 1753380763.000183
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_148 with payload: {'text': 'Random prompt 148 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 173, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_149 to http://0.0.0.0:30000/generate at 1753380763.0003147
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_149 with payload: {'text': 'Random prompt 149 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_150 to http://0.0.0.0:30000/generate at 1753380763.0004387
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_150 with payload: {'text': 'Random prompt 150 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_151 to http://0.0.0.0:30000/generate at 1753380763.0005724
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_151 with payload: {'text': 'Random prompt 151 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 171, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_152 to http://0.0.0.0:30000/generate at 1753380763.0007017
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_152 with payload: {'text': 'Random prompt 152 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_153 to http://0.0.0.0:30000/generate at 1753380763.0008304
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_153 with payload: {'text': 'Random prompt 153 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_154 to http://0.0.0.0:30000/generate at 1753380763.0009549
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_154 with payload: {'text': 'Random prompt 154 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_155 to http://0.0.0.0:30000/generate at 1753380763.0010822
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_155 with payload: {'text': 'Random prompt 155 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 160, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_156 to http://0.0.0.0:30000/generate at 1753380763.0012178
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_156 with payload: {'text': 'Random prompt 156 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 84, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_157 to http://0.0.0.0:30000/generate at 1753380763.0013928
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_157 with payload: {'text': 'Random prompt 157 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_158 to http://0.0.0.0:30000/generate at 1753380763.0015192
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_158 with payload: {'text': 'Random prompt 158 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_159 to http://0.0.0.0:30000/generate at 1753380763.0016522
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_159 with payload: {'text': 'Random prompt 159 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_160 to http://0.0.0.0:30000/generate at 1753380763.0017817
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_160 with payload: {'text': 'Random prompt 160 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_161 to http://0.0.0.0:30000/generate at 1753380763.001907
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_161 with payload: {'text': 'Random prompt 161 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_162 to http://0.0.0.0:30000/generate at 1753380763.0020335
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_162 with payload: {'text': 'Random prompt 162 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_163 to http://0.0.0.0:30000/generate at 1753380763.0021658
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_163 with payload: {'text': 'Random prompt 163 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 159, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_164 to http://0.0.0.0:30000/generate at 1753380763.0022953
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_164 with payload: {'text': 'Random prompt 164 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_165 to http://0.0.0.0:30000/generate at 1753380763.0024197
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_165 with payload: {'text': 'Random prompt 165 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_166 to http://0.0.0.0:30000/generate at 1753380763.0025542
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_166 with payload: {'text': 'Random prompt 166 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 171, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_167 to http://0.0.0.0:30000/generate at 1753380763.002681
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_167 with payload: {'text': 'Random prompt 167 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 129, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_168 to http://0.0.0.0:30000/generate at 1753380763.0028024
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_168 with payload: {'text': 'Random prompt 168 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_169 to http://0.0.0.0:30000/generate at 1753380763.002972
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_169 with payload: {'text': 'Random prompt 169 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 101, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_170 to http://0.0.0.0:30000/generate at 1753380763.0030966
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_170 with payload: {'text': 'Random prompt 170 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_171 to http://0.0.0.0:30000/generate at 1753380763.0032277
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_171 with payload: {'text': 'Random prompt 171 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_172 to http://0.0.0.0:30000/generate at 1753380763.003358
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_172 with payload: {'text': 'Random prompt 172 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_173 to http://0.0.0.0:30000/generate at 1753380763.0034819
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_173 with payload: {'text': 'Random prompt 173 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_174 to http://0.0.0.0:30000/generate at 1753380763.0036154
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_174 with payload: {'text': 'Random prompt 174 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_175 to http://0.0.0.0:30000/generate at 1753380763.003738
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_175 with payload: {'text': 'Random prompt 175 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_176 to http://0.0.0.0:30000/generate at 1753380763.0038638
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_176 with payload: {'text': 'Random prompt 176 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_177 to http://0.0.0.0:30000/generate at 1753380763.0039933
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_177 with payload: {'text': 'Random prompt 177 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_178 to http://0.0.0.0:30000/generate at 1753380763.0041218
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_178 with payload: {'text': 'Random prompt 178 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_179 to http://0.0.0.0:30000/generate at 1753380763.0042558
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_179 with payload: {'text': 'Random prompt 179 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_180 to http://0.0.0.0:30000/generate at 1753380763.0043805
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_180 with payload: {'text': 'Random prompt 180 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 187, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_181 to http://0.0.0.0:30000/generate at 1753380763.004558
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_181 with payload: {'text': 'Random prompt 181 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_182 to http://0.0.0.0:30000/generate at 1753380763.0047262
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_182 with payload: {'text': 'Random prompt 182 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_183 to http://0.0.0.0:30000/generate at 1753380763.0048566
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_183 with payload: {'text': 'Random prompt 183 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_184 to http://0.0.0.0:30000/generate at 1753380763.0049868
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_184 with payload: {'text': 'Random prompt 184 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_185 to http://0.0.0.0:30000/generate at 1753380763.0051177
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_185 with payload: {'text': 'Random prompt 185 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_186 to http://0.0.0.0:30000/generate at 1753380763.0052555
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_186 with payload: {'text': 'Random prompt 186 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_187 to http://0.0.0.0:30000/generate at 1753380763.0053802
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_187 with payload: {'text': 'Random prompt 187 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_188 to http://0.0.0.0:30000/generate at 1753380763.0055025
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_188 with payload: {'text': 'Random prompt 188 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_189 to http://0.0.0.0:30000/generate at 1753380763.005632
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_189 with payload: {'text': 'Random prompt 189 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_190 to http://0.0.0.0:30000/generate at 1753380763.0057592
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_190 with payload: {'text': 'Random prompt 190 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_191 to http://0.0.0.0:30000/generate at 1753380763.0058923
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_191 with payload: {'text': 'Random prompt 191 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 139, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_192 to http://0.0.0.0:30000/generate at 1753380763.006022
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_192 with payload: {'text': 'Random prompt 192 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_193 to http://0.0.0.0:30000/generate at 1753380763.0061967
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_193 with payload: {'text': 'Random prompt 193 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_194 to http://0.0.0.0:30000/generate at 1753380763.0063198
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_194 with payload: {'text': 'Random prompt 194 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 70, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_195 to http://0.0.0.0:30000/generate at 1753380763.0064452
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_195 with payload: {'text': 'Random prompt 195 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_196 to http://0.0.0.0:30000/generate at 1753380763.0065758
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_196 with payload: {'text': 'Random prompt 196 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_197 to http://0.0.0.0:30000/generate at 1753380763.0067046
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_197 with payload: {'text': 'Random prompt 197 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_198 to http://0.0.0.0:30000/generate at 1753380763.0068362
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_198 with payload: {'text': 'Random prompt 198 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 160, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_199 to http://0.0.0.0:30000/generate at 1753380763.0069604
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_199 with payload: {'text': 'Random prompt 199 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_200 to http://0.0.0.0:30000/generate at 1753380763.007088
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_200 with payload: {'text': 'Random prompt 200 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_201 to http://0.0.0.0:30000/generate at 1753380763.0072188
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_201 with payload: {'text': 'Random prompt 201 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_202 to http://0.0.0.0:30000/generate at 1753380763.0073445
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_202 with payload: {'text': 'Random prompt 202 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_203 to http://0.0.0.0:30000/generate at 1753380763.0074704
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_203 with payload: {'text': 'Random prompt 203 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 105, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_204 to http://0.0.0.0:30000/generate at 1753380763.0075986
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_204 with payload: {'text': 'Random prompt 204 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_205 to http://0.0.0.0:30000/generate at 1753380763.0077734
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_205 with payload: {'text': 'Random prompt 205 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_206 to http://0.0.0.0:30000/generate at 1753380763.0079012
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_206 with payload: {'text': 'Random prompt 206 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_207 to http://0.0.0.0:30000/generate at 1753380763.0080283
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_207 with payload: {'text': 'Random prompt 207 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 121, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_208 to http://0.0.0.0:30000/generate at 1753380763.0081577
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_208 with payload: {'text': 'Random prompt 208 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_209 to http://0.0.0.0:30000/generate at 1753380763.0082912
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_209 with payload: {'text': 'Random prompt 209 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_210 to http://0.0.0.0:30000/generate at 1753380763.0084198
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_210 with payload: {'text': 'Random prompt 210 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_211 to http://0.0.0.0:30000/generate at 1753380763.008543
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_211 with payload: {'text': 'Random prompt 211 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_212 to http://0.0.0.0:30000/generate at 1753380763.008673
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_212 with payload: {'text': 'Random prompt 212 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_213 to http://0.0.0.0:30000/generate at 1753380763.0088003
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_213 with payload: {'text': 'Random prompt 213 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_214 to http://0.0.0.0:30000/generate at 1753380763.0089266
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_214 with payload: {'text': 'Random prompt 214 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_215 to http://0.0.0.0:30000/generate at 1753380763.009051
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_215 with payload: {'text': 'Random prompt 215 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_216 to http://0.0.0.0:30000/generate at 1753380763.0091739
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_216 with payload: {'text': 'Random prompt 216 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_217 to http://0.0.0.0:30000/generate at 1753380763.0093563
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_217 with payload: {'text': 'Random prompt 217 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_218 to http://0.0.0.0:30000/generate at 1753380763.0094874
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_218 with payload: {'text': 'Random prompt 218 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_219 to http://0.0.0.0:30000/generate at 1753380763.0096078
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_219 with payload: {'text': 'Random prompt 219 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_220 to http://0.0.0.0:30000/generate at 1753380763.0097399
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_220 with payload: {'text': 'Random prompt 220 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_221 to http://0.0.0.0:30000/generate at 1753380763.0098717
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_221 with payload: {'text': 'Random prompt 221 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_222 to http://0.0.0.0:30000/generate at 1753380763.0099952
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_222 with payload: {'text': 'Random prompt 222 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_223 to http://0.0.0.0:30000/generate at 1753380763.0101209
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_223 with payload: {'text': 'Random prompt 223 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_224 to http://0.0.0.0:30000/generate at 1753380763.010257
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_224 with payload: {'text': 'Random prompt 224 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 118, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_225 to http://0.0.0.0:30000/generate at 1753380763.010383
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_225 with payload: {'text': 'Random prompt 225 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_226 to http://0.0.0.0:30000/generate at 1753380763.010507
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_226 with payload: {'text': 'Random prompt 226 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_227 to http://0.0.0.0:30000/generate at 1753380763.0106382
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_227 with payload: {'text': 'Random prompt 227 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_228 to http://0.0.0.0:30000/generate at 1753380763.0107667
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_228 with payload: {'text': 'Random prompt 228 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_229 to http://0.0.0.0:30000/generate at 1753380763.0109448
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_229 with payload: {'text': 'Random prompt 229 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_230 to http://0.0.0.0:30000/generate at 1753380763.0110688
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_230 with payload: {'text': 'Random prompt 230 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 178, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_231 to http://0.0.0.0:30000/generate at 1753380763.0112007
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_231 with payload: {'text': 'Random prompt 231 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_232 to http://0.0.0.0:30000/generate at 1753380763.0113356
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_232 with payload: {'text': 'Random prompt 232 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 91, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_233 to http://0.0.0.0:30000/generate at 1753380763.0114598
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_233 with payload: {'text': 'Random prompt 233 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_234 to http://0.0.0.0:30000/generate at 1753380763.0115821
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_234 with payload: {'text': 'Random prompt 234 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_235 to http://0.0.0.0:30000/generate at 1753380763.0117104
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_235 with payload: {'text': 'Random prompt 235 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_236 to http://0.0.0.0:30000/generate at 1753380763.0118375
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_236 with payload: {'text': 'Random prompt 236 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_237 to http://0.0.0.0:30000/generate at 1753380763.011959
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_237 with payload: {'text': 'Random prompt 237 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_238 to http://0.0.0.0:30000/generate at 1753380763.0120854
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_238 with payload: {'text': 'Random prompt 238 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_239 to http://0.0.0.0:30000/generate at 1753380763.012222
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_239 with payload: {'text': 'Random prompt 239 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_240 to http://0.0.0.0:30000/generate at 1753380763.0123575
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_240 with payload: {'text': 'Random prompt 240 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_241 to http://0.0.0.0:30000/generate at 1753380763.012535
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_241 with payload: {'text': 'Random prompt 241 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_242 to http://0.0.0.0:30000/generate at 1753380763.0126646
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_242 with payload: {'text': 'Random prompt 242 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_243 to http://0.0.0.0:30000/generate at 1753380763.0127935
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_243 with payload: {'text': 'Random prompt 243 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_244 to http://0.0.0.0:30000/generate at 1753380763.0129206
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_244 with payload: {'text': 'Random prompt 244 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_245 to http://0.0.0.0:30000/generate at 1753380763.0130427
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_245 with payload: {'text': 'Random prompt 245 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_246 to http://0.0.0.0:30000/generate at 1753380763.0131667
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_246 with payload: {'text': 'Random prompt 246 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_247 to http://0.0.0.0:30000/generate at 1753380763.0133007
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_247 with payload: {'text': 'Random prompt 247 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_248 to http://0.0.0.0:30000/generate at 1753380763.013428
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_248 with payload: {'text': 'Random prompt 248 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 182, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_249 to http://0.0.0.0:30000/generate at 1753380763.013555
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_249 with payload: {'text': 'Random prompt 249 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_250 to http://0.0.0.0:30000/generate at 1753380763.0136843
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_250 with payload: {'text': 'Random prompt 250 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_251 to http://0.0.0.0:30000/generate at 1753380763.0138183
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_251 with payload: {'text': 'Random prompt 251 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_252 to http://0.0.0.0:30000/generate at 1753380763.013943
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_252 with payload: {'text': 'Random prompt 252 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 79, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_253 to http://0.0.0.0:30000/generate at 1753380763.0146859
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_253 with payload: {'text': 'Random prompt 253 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_254 to http://0.0.0.0:30000/generate at 1753380763.014821
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_254 with payload: {'text': 'Random prompt 254 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_255 to http://0.0.0.0:30000/generate at 1753380763.0149474
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_255 with payload: {'text': 'Random prompt 255 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_256 to http://0.0.0.0:30000/generate at 1753380763.0150743
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_256 with payload: {'text': 'Random prompt 256 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_257 to http://0.0.0.0:30000/generate at 1753380763.0152102
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_257 with payload: {'text': 'Random prompt 257 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_258 to http://0.0.0.0:30000/generate at 1753380763.0153415
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_258 with payload: {'text': 'Random prompt 258 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_259 to http://0.0.0.0:30000/generate at 1753380763.0154665
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_259 with payload: {'text': 'Random prompt 259 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 138, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_260 to http://0.0.0.0:30000/generate at 1753380763.0155878
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_260 with payload: {'text': 'Random prompt 260 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 98, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_261 to http://0.0.0.0:30000/generate at 1753380763.0157228
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_261 with payload: {'text': 'Random prompt 261 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_262 to http://0.0.0.0:30000/generate at 1753380763.015854
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_262 with payload: {'text': 'Random prompt 262 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 104, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_263 to http://0.0.0.0:30000/generate at 1753380763.015976
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_263 with payload: {'text': 'Random prompt 263 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_264 to http://0.0.0.0:30000/generate at 1753380763.0161037
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_264 with payload: {'text': 'Random prompt 264 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_265 to http://0.0.0.0:30000/generate at 1753380763.0162811
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_265 with payload: {'text': 'Random prompt 265 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_266 to http://0.0.0.0:30000/generate at 1753380763.016409
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_266 with payload: {'text': 'Random prompt 266 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_267 to http://0.0.0.0:30000/generate at 1753380763.0165343
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_267 with payload: {'text': 'Random prompt 267 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_268 to http://0.0.0.0:30000/generate at 1753380763.016664
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_268 with payload: {'text': 'Random prompt 268 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_269 to http://0.0.0.0:30000/generate at 1753380763.0167892
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_269 with payload: {'text': 'Random prompt 269 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 101, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_270 to http://0.0.0.0:30000/generate at 1753380763.0169177
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_270 with payload: {'text': 'Random prompt 270 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_271 to http://0.0.0.0:30000/generate at 1753380763.0170572
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_271 with payload: {'text': 'Random prompt 271 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 174, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_272 to http://0.0.0.0:30000/generate at 1753380763.0171962
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_272 with payload: {'text': 'Random prompt 272 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_273 to http://0.0.0.0:30000/generate at 1753380763.0173247
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_273 with payload: {'text': 'Random prompt 273 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_274 to http://0.0.0.0:30000/generate at 1753380763.0174563
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_274 with payload: {'text': 'Random prompt 274 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_275 to http://0.0.0.0:30000/generate at 1753380763.017582
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_275 with payload: {'text': 'Random prompt 275 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_276 to http://0.0.0.0:30000/generate at 1753380763.0177104
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_276 with payload: {'text': 'Random prompt 276 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 95, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_277 to http://0.0.0.0:30000/generate at 1753380763.017879
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_277 with payload: {'text': 'Random prompt 277 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_278 to http://0.0.0.0:30000/generate at 1753380763.0180025
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_278 with payload: {'text': 'Random prompt 278 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 82, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_279 to http://0.0.0.0:30000/generate at 1753380763.0181322
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_279 with payload: {'text': 'Random prompt 279 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_280 to http://0.0.0.0:30000/generate at 1753380763.0182626
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_280 with payload: {'text': 'Random prompt 280 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_281 to http://0.0.0.0:30000/generate at 1753380763.0183926
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_281 with payload: {'text': 'Random prompt 281 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 154, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_282 to http://0.0.0.0:30000/generate at 1753380763.0185208
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_282 with payload: {'text': 'Random prompt 282 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 136, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_283 to http://0.0.0.0:30000/generate at 1753380763.0186436
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_283 with payload: {'text': 'Random prompt 283 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_284 to http://0.0.0.0:30000/generate at 1753380763.018768
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_284 with payload: {'text': 'Random prompt 284 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_285 to http://0.0.0.0:30000/generate at 1753380763.0188944
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_285 with payload: {'text': 'Random prompt 285 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_286 to http://0.0.0.0:30000/generate at 1753380763.019018
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_286 with payload: {'text': 'Random prompt 286 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_287 to http://0.0.0.0:30000/generate at 1753380763.019148
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_287 with payload: {'text': 'Random prompt 287 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_288 to http://0.0.0.0:30000/generate at 1753380763.0192785
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_288 with payload: {'text': 'Random prompt 288 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_289 to http://0.0.0.0:30000/generate at 1753380763.0194483
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_289 with payload: {'text': 'Random prompt 289 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_290 to http://0.0.0.0:30000/generate at 1753380763.0195808
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_290 with payload: {'text': 'Random prompt 290 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_291 to http://0.0.0.0:30000/generate at 1753380763.0197072
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_291 with payload: {'text': 'Random prompt 291 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_292 to http://0.0.0.0:30000/generate at 1753380763.0198271
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_292 with payload: {'text': 'Random prompt 292 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 137, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_293 to http://0.0.0.0:30000/generate at 1753380763.0199575
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_293 with payload: {'text': 'Random prompt 293 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_294 to http://0.0.0.0:30000/generate at 1753380763.0200825
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_294 with payload: {'text': 'Random prompt 294 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_295 to http://0.0.0.0:30000/generate at 1753380763.0202117
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_295 with payload: {'text': 'Random prompt 295 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_296 to http://0.0.0.0:30000/generate at 1753380763.0203419
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_296 with payload: {'text': 'Random prompt 296 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_297 to http://0.0.0.0:30000/generate at 1753380763.0204728
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_297 with payload: {'text': 'Random prompt 297 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_298 to http://0.0.0.0:30000/generate at 1753380763.020596
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_298 with payload: {'text': 'Random prompt 298 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_299 to http://0.0.0.0:30000/generate at 1753380763.0207226
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_299 with payload: {'text': 'Random prompt 299 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 154, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_300 to http://0.0.0.0:30000/generate at 1753380763.0208507
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_300 with payload: {'text': 'Random prompt 300 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_301 to http://0.0.0.0:30000/generate at 1753380763.0210207
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_301 with payload: {'text': 'Random prompt 301 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_302 to http://0.0.0.0:30000/generate at 1753380763.0211482
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_302 with payload: {'text': 'Random prompt 302 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_303 to http://0.0.0.0:30000/generate at 1753380763.021276
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_303 with payload: {'text': 'Random prompt 303 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_304 to http://0.0.0.0:30000/generate at 1753380763.021402
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_304 with payload: {'text': 'Random prompt 304 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_305 to http://0.0.0.0:30000/generate at 1753380763.0215292
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_305 with payload: {'text': 'Random prompt 305 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_306 to http://0.0.0.0:30000/generate at 1753380763.0216572
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_306 with payload: {'text': 'Random prompt 306 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_307 to http://0.0.0.0:30000/generate at 1753380763.0217798
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_307 with payload: {'text': 'Random prompt 307 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_308 to http://0.0.0.0:30000/generate at 1753380763.0219057
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_308 with payload: {'text': 'Random prompt 308 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_309 to http://0.0.0.0:30000/generate at 1753380763.0220287
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_309 with payload: {'text': 'Random prompt 309 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_310 to http://0.0.0.0:30000/generate at 1753380763.0221543
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_310 with payload: {'text': 'Random prompt 310 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_311 to http://0.0.0.0:30000/generate at 1753380763.022294
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_311 with payload: {'text': 'Random prompt 311 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 179, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_312 to http://0.0.0.0:30000/generate at 1753380763.0224266
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_312 with payload: {'text': 'Random prompt 312 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_313 to http://0.0.0.0:30000/generate at 1753380763.0225925
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_313 with payload: {'text': 'Random prompt 313 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_314 to http://0.0.0.0:30000/generate at 1753380763.0227175
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_314 with payload: {'text': 'Random prompt 314 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_315 to http://0.0.0.0:30000/generate at 1753380763.0228417
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_315 with payload: {'text': 'Random prompt 315 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_316 to http://0.0.0.0:30000/generate at 1753380763.0229664
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_316 with payload: {'text': 'Random prompt 316 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 131, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_317 to http://0.0.0.0:30000/generate at 1753380763.0230906
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_317 with payload: {'text': 'Random prompt 317 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_318 to http://0.0.0.0:30000/generate at 1753380763.0232227
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_318 with payload: {'text': 'Random prompt 318 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_319 to http://0.0.0.0:30000/generate at 1753380763.0233548
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_319 with payload: {'text': 'Random prompt 319 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_320 to http://0.0.0.0:30000/generate at 1753380763.0234797
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_320 with payload: {'text': 'Random prompt 320 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 96, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_321 to http://0.0.0.0:30000/generate at 1753380763.023606
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_321 with payload: {'text': 'Random prompt 321 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 84, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_322 to http://0.0.0.0:30000/generate at 1753380763.0237327
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_322 with payload: {'text': 'Random prompt 322 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_323 to http://0.0.0.0:30000/generate at 1753380763.0238578
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_323 with payload: {'text': 'Random prompt 323 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_324 to http://0.0.0.0:30000/generate at 1753380763.0239797
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_324 with payload: {'text': 'Random prompt 324 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_325 to http://0.0.0.0:30000/generate at 1753380763.024155
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_325 with payload: {'text': 'Random prompt 325 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_326 to http://0.0.0.0:30000/generate at 1753380763.024286
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_326 with payload: {'text': 'Random prompt 326 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_327 to http://0.0.0.0:30000/generate at 1753380763.0244167
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_327 with payload: {'text': 'Random prompt 327 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_328 to http://0.0.0.0:30000/generate at 1753380763.0245476
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_328 with payload: {'text': 'Random prompt 328 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_329 to http://0.0.0.0:30000/generate at 1753380763.0246756
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_329 with payload: {'text': 'Random prompt 329 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_330 to http://0.0.0.0:30000/generate at 1753380763.0247982
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_330 with payload: {'text': 'Random prompt 330 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 135, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_331 to http://0.0.0.0:30000/generate at 1753380763.0249279
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_331 with payload: {'text': 'Random prompt 331 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_332 to http://0.0.0.0:30000/generate at 1753380763.0250547
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_332 with payload: {'text': 'Random prompt 332 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_333 to http://0.0.0.0:30000/generate at 1753380763.0251849
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_333 with payload: {'text': 'Random prompt 333 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_334 to http://0.0.0.0:30000/generate at 1753380763.0253162
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_334 with payload: {'text': 'Random prompt 334 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_335 to http://0.0.0.0:30000/generate at 1753380763.025444
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_335 with payload: {'text': 'Random prompt 335 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_336 to http://0.0.0.0:30000/generate at 1753380763.0255656
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_336 with payload: {'text': 'Random prompt 336 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_337 to http://0.0.0.0:30000/generate at 1753380763.0257392
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_337 with payload: {'text': 'Random prompt 337 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_338 to http://0.0.0.0:30000/generate at 1753380763.025863
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_338 with payload: {'text': 'Random prompt 338 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_339 to http://0.0.0.0:30000/generate at 1753380763.025988
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_339 with payload: {'text': 'Random prompt 339 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_340 to http://0.0.0.0:30000/generate at 1753380763.0261152
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_340 with payload: {'text': 'Random prompt 340 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_341 to http://0.0.0.0:30000/generate at 1753380763.026246
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_341 with payload: {'text': 'Random prompt 341 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_342 to http://0.0.0.0:30000/generate at 1753380763.0263724
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_342 with payload: {'text': 'Random prompt 342 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_343 to http://0.0.0.0:30000/generate at 1753380763.0265746
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_343 with payload: {'text': 'Random prompt 343 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_344 to http://0.0.0.0:30000/generate at 1753380763.026702
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_344 with payload: {'text': 'Random prompt 344 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 159, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_345 to http://0.0.0.0:30000/generate at 1753380763.026829
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_345 with payload: {'text': 'Random prompt 345 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 118, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_346 to http://0.0.0.0:30000/generate at 1753380763.026955
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_346 with payload: {'text': 'Random prompt 346 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_347 to http://0.0.0.0:30000/generate at 1753380763.0270793
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_347 with payload: {'text': 'Random prompt 347 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_348 to http://0.0.0.0:30000/generate at 1753380763.027216
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_348 with payload: {'text': 'Random prompt 348 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_349 to http://0.0.0.0:30000/generate at 1753380763.027386
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_349 with payload: {'text': 'Random prompt 349 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_350 to http://0.0.0.0:30000/generate at 1753380763.0275156
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_350 with payload: {'text': 'Random prompt 350 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_351 to http://0.0.0.0:30000/generate at 1753380763.0276465
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_351 with payload: {'text': 'Random prompt 351 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 138, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_352 to http://0.0.0.0:30000/generate at 1753380763.0277739
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_352 with payload: {'text': 'Random prompt 352 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_353 to http://0.0.0.0:30000/generate at 1753380763.0279067
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_353 with payload: {'text': 'Random prompt 353 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_354 to http://0.0.0.0:30000/generate at 1753380763.0280395
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_354 with payload: {'text': 'Random prompt 354 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_355 to http://0.0.0.0:30000/generate at 1753380763.0281656
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_355 with payload: {'text': 'Random prompt 355 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_356 to http://0.0.0.0:30000/generate at 1753380763.0282955
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_356 with payload: {'text': 'Random prompt 356 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 179, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_357 to http://0.0.0.0:30000/generate at 1753380763.0284233
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_357 with payload: {'text': 'Random prompt 357 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 118, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_358 to http://0.0.0.0:30000/generate at 1753380763.0285525
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_358 with payload: {'text': 'Random prompt 358 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_359 to http://0.0.0.0:30000/generate at 1753380763.028678
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_359 with payload: {'text': 'Random prompt 359 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_360 to http://0.0.0.0:30000/generate at 1753380763.028805
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_360 with payload: {'text': 'Random prompt 360 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 181, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_361 to http://0.0.0.0:30000/generate at 1753380763.0289736
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_361 with payload: {'text': 'Random prompt 361 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 91, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_362 to http://0.0.0.0:30000/generate at 1753380763.0290973
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_362 with payload: {'text': 'Random prompt 362 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_363 to http://0.0.0.0:30000/generate at 1753380763.0292299
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_363 with payload: {'text': 'Random prompt 363 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_364 to http://0.0.0.0:30000/generate at 1753380763.0293534
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_364 with payload: {'text': 'Random prompt 364 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_365 to http://0.0.0.0:30000/generate at 1753380763.0294805
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_365 with payload: {'text': 'Random prompt 365 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_366 to http://0.0.0.0:30000/generate at 1753380763.0296118
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_366 with payload: {'text': 'Random prompt 366 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_367 to http://0.0.0.0:30000/generate at 1753380763.029747
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_367 with payload: {'text': 'Random prompt 367 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 180, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_368 to http://0.0.0.0:30000/generate at 1753380763.029869
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_368 with payload: {'text': 'Random prompt 368 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_369 to http://0.0.0.0:30000/generate at 1753380763.0299945
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_369 with payload: {'text': 'Random prompt 369 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_370 to http://0.0.0.0:30000/generate at 1753380763.0301185
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_370 with payload: {'text': 'Random prompt 370 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_371 to http://0.0.0.0:30000/generate at 1753380763.03025
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_371 with payload: {'text': 'Random prompt 371 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_372 to http://0.0.0.0:30000/generate at 1753380763.0303743
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_372 with payload: {'text': 'Random prompt 372 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 173, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_373 to http://0.0.0.0:30000/generate at 1753380763.0305493
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_373 with payload: {'text': 'Random prompt 373 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_374 to http://0.0.0.0:30000/generate at 1753380763.0306768
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_374 with payload: {'text': 'Random prompt 374 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 96, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_375 to http://0.0.0.0:30000/generate at 1753380763.030802
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_375 with payload: {'text': 'Random prompt 375 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_376 to http://0.0.0.0:30000/generate at 1753380763.0309298
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_376 with payload: {'text': 'Random prompt 376 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 121, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_377 to http://0.0.0.0:30000/generate at 1753380763.0310593
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_377 with payload: {'text': 'Random prompt 377 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_378 to http://0.0.0.0:30000/generate at 1753380763.0311894
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_378 with payload: {'text': 'Random prompt 378 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 110, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_379 to http://0.0.0.0:30000/generate at 1753380763.0313125
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_379 with payload: {'text': 'Random prompt 379 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_380 to http://0.0.0.0:30000/generate at 1753380763.0314393
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_380 with payload: {'text': 'Random prompt 380 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_381 to http://0.0.0.0:30000/generate at 1753380763.0315711
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_381 with payload: {'text': 'Random prompt 381 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_382 to http://0.0.0.0:30000/generate at 1753380763.0317018
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_382 with payload: {'text': 'Random prompt 382 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_383 to http://0.0.0.0:30000/generate at 1753380763.0318441
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_383 with payload: {'text': 'Random prompt 383 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_384 to http://0.0.0.0:30000/generate at 1753380763.0319757
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_384 with payload: {'text': 'Random prompt 384 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_385 to http://0.0.0.0:30000/generate at 1753380763.032142
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_385 with payload: {'text': 'Random prompt 385 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_386 to http://0.0.0.0:30000/generate at 1753380763.0322714
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_386 with payload: {'text': 'Random prompt 386 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_387 to http://0.0.0.0:30000/generate at 1753380763.0323982
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_387 with payload: {'text': 'Random prompt 387 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_388 to http://0.0.0.0:30000/generate at 1753380763.0325246
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_388 with payload: {'text': 'Random prompt 388 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_389 to http://0.0.0.0:30000/generate at 1753380763.0326526
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_389 with payload: {'text': 'Random prompt 389 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_390 to http://0.0.0.0:30000/generate at 1753380763.0327764
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_390 with payload: {'text': 'Random prompt 390 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_391 to http://0.0.0.0:30000/generate at 1753380763.0329025
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_391 with payload: {'text': 'Random prompt 391 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_392 to http://0.0.0.0:30000/generate at 1753380763.033028
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_392 with payload: {'text': 'Random prompt 392 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_393 to http://0.0.0.0:30000/generate at 1753380763.0331511
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_393 with payload: {'text': 'Random prompt 393 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 131, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_394 to http://0.0.0.0:30000/generate at 1753380763.0332851
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_394 with payload: {'text': 'Random prompt 394 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_395 to http://0.0.0.0:30000/generate at 1753380763.033411
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_395 with payload: {'text': 'Random prompt 395 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_396 to http://0.0.0.0:30000/generate at 1753380763.0335386
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_396 with payload: {'text': 'Random prompt 396 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_397 to http://0.0.0.0:30000/generate at 1753380763.0342479
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_397 with payload: {'text': 'Random prompt 397 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 96, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_398 to http://0.0.0.0:30000/generate at 1753380763.0343783
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_398 with payload: {'text': 'Random prompt 398 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_399 to http://0.0.0.0:30000/generate at 1753380763.0345016
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_399 with payload: {'text': 'Random prompt 399 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 154, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_400 to http://0.0.0.0:30000/generate at 1753380763.0346293
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_400 with payload: {'text': 'Random prompt 400 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_401 to http://0.0.0.0:30000/generate at 1753380763.0347612
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_401 with payload: {'text': 'Random prompt 401 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_402 to http://0.0.0.0:30000/generate at 1753380763.0348916
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_402 with payload: {'text': 'Random prompt 402 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_403 to http://0.0.0.0:30000/generate at 1753380763.0350192
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_403 with payload: {'text': 'Random prompt 403 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_404 to http://0.0.0.0:30000/generate at 1753380763.035147
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_404 with payload: {'text': 'Random prompt 404 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_405 to http://0.0.0.0:30000/generate at 1753380763.035276
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_405 with payload: {'text': 'Random prompt 405 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_406 to http://0.0.0.0:30000/generate at 1753380763.0354028
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_406 with payload: {'text': 'Random prompt 406 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_407 to http://0.0.0.0:30000/generate at 1753380763.0355246
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_407 with payload: {'text': 'Random prompt 407 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_408 to http://0.0.0.0:30000/generate at 1753380763.035651
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_408 with payload: {'text': 'Random prompt 408 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 139, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_409 to http://0.0.0.0:30000/generate at 1753380763.0358207
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_409 with payload: {'text': 'Random prompt 409 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_410 to http://0.0.0.0:30000/generate at 1753380763.0359447
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_410 with payload: {'text': 'Random prompt 410 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_411 to http://0.0.0.0:30000/generate at 1753380763.036074
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_411 with payload: {'text': 'Random prompt 411 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_412 to http://0.0.0.0:30000/generate at 1753380763.0362031
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_412 with payload: {'text': 'Random prompt 412 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_413 to http://0.0.0.0:30000/generate at 1753380763.0363312
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_413 with payload: {'text': 'Random prompt 413 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_414 to http://0.0.0.0:30000/generate at 1753380763.0364575
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_414 with payload: {'text': 'Random prompt 414 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 132, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_415 to http://0.0.0.0:30000/generate at 1753380763.0365827
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_415 with payload: {'text': 'Random prompt 415 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_416 to http://0.0.0.0:30000/generate at 1753380763.036707
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_416 with payload: {'text': 'Random prompt 416 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_417 to http://0.0.0.0:30000/generate at 1753380763.0368319
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_417 with payload: {'text': 'Random prompt 417 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_418 to http://0.0.0.0:30000/generate at 1753380763.0369573
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_418 with payload: {'text': 'Random prompt 418 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_419 to http://0.0.0.0:30000/generate at 1753380763.0370798
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_419 with payload: {'text': 'Random prompt 419 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_420 to http://0.0.0.0:30000/generate at 1753380763.0372128
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_420 with payload: {'text': 'Random prompt 420 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 104, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_421 to http://0.0.0.0:30000/generate at 1753380763.0373867
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_421 with payload: {'text': 'Random prompt 421 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 129, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_422 to http://0.0.0.0:30000/generate at 1753380763.0375123
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_422 with payload: {'text': 'Random prompt 422 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_423 to http://0.0.0.0:30000/generate at 1753380763.0376365
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_423 with payload: {'text': 'Random prompt 423 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_424 to http://0.0.0.0:30000/generate at 1753380763.0377579
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_424 with payload: {'text': 'Random prompt 424 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_425 to http://0.0.0.0:30000/generate at 1753380763.0378776
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_425 with payload: {'text': 'Random prompt 425 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_426 to http://0.0.0.0:30000/generate at 1753380763.0380042
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_426 with payload: {'text': 'Random prompt 426 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_427 to http://0.0.0.0:30000/generate at 1753380763.0381324
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_427 with payload: {'text': 'Random prompt 427 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_428 to http://0.0.0.0:30000/generate at 1753380763.0382607
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_428 with payload: {'text': 'Random prompt 428 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_429 to http://0.0.0.0:30000/generate at 1753380763.0383847
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_429 with payload: {'text': 'Random prompt 429 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_430 to http://0.0.0.0:30000/generate at 1753380763.0385063
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_430 with payload: {'text': 'Random prompt 430 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_431 to http://0.0.0.0:30000/generate at 1753380763.0386343
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_431 with payload: {'text': 'Random prompt 431 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_432 to http://0.0.0.0:30000/generate at 1753380763.0387576
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_432 with payload: {'text': 'Random prompt 432 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_433 to http://0.0.0.0:30000/generate at 1753380763.0389323
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_433 with payload: {'text': 'Random prompt 433 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_434 to http://0.0.0.0:30000/generate at 1753380763.0390666
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_434 with payload: {'text': 'Random prompt 434 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 82, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_435 to http://0.0.0.0:30000/generate at 1753380763.0391967
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_435 with payload: {'text': 'Random prompt 435 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_436 to http://0.0.0.0:30000/generate at 1753380763.0393202
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_436 with payload: {'text': 'Random prompt 436 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_437 to http://0.0.0.0:30000/generate at 1753380763.0394418
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_437 with payload: {'text': 'Random prompt 437 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 154, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_438 to http://0.0.0.0:30000/generate at 1753380763.0395718
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_438 with payload: {'text': 'Random prompt 438 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_439 to http://0.0.0.0:30000/generate at 1753380763.0396972
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_439 with payload: {'text': 'Random prompt 439 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 150, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_440 to http://0.0.0.0:30000/generate at 1753380763.0398178
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_440 with payload: {'text': 'Random prompt 440 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_441 to http://0.0.0.0:30000/generate at 1753380763.039945
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_441 with payload: {'text': 'Random prompt 441 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 76, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_442 to http://0.0.0.0:30000/generate at 1753380763.0400918
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_442 with payload: {'text': 'Random prompt 442 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 150, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_443 to http://0.0.0.0:30000/generate at 1753380763.0402174
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_443 with payload: {'text': 'Random prompt 443 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 121, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_444 to http://0.0.0.0:30000/generate at 1753380763.0403488
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_444 with payload: {'text': 'Random prompt 444 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_445 to http://0.0.0.0:30000/generate at 1753380763.0405202
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_445 with payload: {'text': 'Random prompt 445 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_446 to http://0.0.0.0:30000/generate at 1753380763.0406506
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_446 with payload: {'text': 'Random prompt 446 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_447 to http://0.0.0.0:30000/generate at 1753380763.0407765
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_447 with payload: {'text': 'Random prompt 447 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 171, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_448 to http://0.0.0.0:30000/generate at 1753380763.0408988
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_448 with payload: {'text': 'Random prompt 448 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_449 to http://0.0.0.0:30000/generate at 1753380763.0410247
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_449 with payload: {'text': 'Random prompt 449 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_450 to http://0.0.0.0:30000/generate at 1753380763.0411496
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_450 with payload: {'text': 'Random prompt 450 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_451 to http://0.0.0.0:30000/generate at 1753380763.0412903
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_451 with payload: {'text': 'Random prompt 451 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_452 to http://0.0.0.0:30000/generate at 1753380763.041419
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_452 with payload: {'text': 'Random prompt 452 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_453 to http://0.0.0.0:30000/generate at 1753380763.0415432
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_453 with payload: {'text': 'Random prompt 453 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 137, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_454 to http://0.0.0.0:30000/generate at 1753380763.0416667
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_454 with payload: {'text': 'Random prompt 454 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_455 to http://0.0.0.0:30000/generate at 1753380763.0417926
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_455 with payload: {'text': 'Random prompt 455 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_456 to http://0.0.0.0:30000/generate at 1753380763.0419161
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_456 with payload: {'text': 'Random prompt 456 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_457 to http://0.0.0.0:30000/generate at 1753380763.042084
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_457 with payload: {'text': 'Random prompt 457 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_458 to http://0.0.0.0:30000/generate at 1753380763.0422187
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_458 with payload: {'text': 'Random prompt 458 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_459 to http://0.0.0.0:30000/generate at 1753380763.0423424
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_459 with payload: {'text': 'Random prompt 459 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_460 to http://0.0.0.0:30000/generate at 1753380763.0424693
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_460 with payload: {'text': 'Random prompt 460 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_461 to http://0.0.0.0:30000/generate at 1753380763.0425959
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_461 with payload: {'text': 'Random prompt 461 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_462 to http://0.0.0.0:30000/generate at 1753380763.0427163
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_462 with payload: {'text': 'Random prompt 462 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_463 to http://0.0.0.0:30000/generate at 1753380763.0428402
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_463 with payload: {'text': 'Random prompt 463 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_464 to http://0.0.0.0:30000/generate at 1753380763.042965
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_464 with payload: {'text': 'Random prompt 464 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_465 to http://0.0.0.0:30000/generate at 1753380763.043096
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_465 with payload: {'text': 'Random prompt 465 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 70, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_466 to http://0.0.0.0:30000/generate at 1753380763.0432231
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_466 with payload: {'text': 'Random prompt 466 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_467 to http://0.0.0.0:30000/generate at 1753380763.0433455
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_467 with payload: {'text': 'Random prompt 467 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_468 to http://0.0.0.0:30000/generate at 1753380763.043475
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_468 with payload: {'text': 'Random prompt 468 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_469 to http://0.0.0.0:30000/generate at 1753380763.0436492
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_469 with payload: {'text': 'Random prompt 469 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_470 to http://0.0.0.0:30000/generate at 1753380763.0437717
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_470 with payload: {'text': 'Random prompt 470 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 137, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_471 to http://0.0.0.0:30000/generate at 1753380763.0438979
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_471 with payload: {'text': 'Random prompt 471 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 159, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_472 to http://0.0.0.0:30000/generate at 1753380763.0440204
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_472 with payload: {'text': 'Random prompt 472 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_473 to http://0.0.0.0:30000/generate at 1753380763.0441492
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_473 with payload: {'text': 'Random prompt 473 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_474 to http://0.0.0.0:30000/generate at 1753380763.044277
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_474 with payload: {'text': 'Random prompt 474 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_475 to http://0.0.0.0:30000/generate at 1753380763.044405
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_475 with payload: {'text': 'Random prompt 475 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_476 to http://0.0.0.0:30000/generate at 1753380763.044531
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_476 with payload: {'text': 'Random prompt 476 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_477 to http://0.0.0.0:30000/generate at 1753380763.0446513
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_477 with payload: {'text': 'Random prompt 477 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_478 to http://0.0.0.0:30000/generate at 1753380763.0447822
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_478 with payload: {'text': 'Random prompt 478 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_479 to http://0.0.0.0:30000/generate at 1753380763.0449085
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_479 with payload: {'text': 'Random prompt 479 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_480 to http://0.0.0.0:30000/generate at 1753380763.0450313
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_480 with payload: {'text': 'Random prompt 480 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_481 to http://0.0.0.0:30000/generate at 1753380763.0452151
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_481 with payload: {'text': 'Random prompt 481 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 79, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_482 to http://0.0.0.0:30000/generate at 1753380763.0453448
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_482 with payload: {'text': 'Random prompt 482 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_483 to http://0.0.0.0:30000/generate at 1753380763.0454683
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_483 with payload: {'text': 'Random prompt 483 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_484 to http://0.0.0.0:30000/generate at 1753380763.0455928
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_484 with payload: {'text': 'Random prompt 484 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_485 to http://0.0.0.0:30000/generate at 1753380763.0457141
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_485 with payload: {'text': 'Random prompt 485 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_486 to http://0.0.0.0:30000/generate at 1753380763.0458384
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_486 with payload: {'text': 'Random prompt 486 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_487 to http://0.0.0.0:30000/generate at 1753380763.045966
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_487 with payload: {'text': 'Random prompt 487 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_488 to http://0.0.0.0:30000/generate at 1753380763.046094
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_488 with payload: {'text': 'Random prompt 488 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_489 to http://0.0.0.0:30000/generate at 1753380763.0462236
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_489 with payload: {'text': 'Random prompt 489 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 121, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_490 to http://0.0.0.0:30000/generate at 1753380763.0463521
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_490 with payload: {'text': 'Random prompt 490 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_491 to http://0.0.0.0:30000/generate at 1753380763.0464761
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_491 with payload: {'text': 'Random prompt 491 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 112, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_492 to http://0.0.0.0:30000/generate at 1753380763.0466
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_492 with payload: {'text': 'Random prompt 492 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_493 to http://0.0.0.0:30000/generate at 1753380763.0467746
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_493 with payload: {'text': 'Random prompt 493 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_494 to http://0.0.0.0:30000/generate at 1753380763.046894
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_494 with payload: {'text': 'Random prompt 494 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_495 to http://0.0.0.0:30000/generate at 1753380763.0470135
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_495 with payload: {'text': 'Random prompt 495 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 150, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_496 to http://0.0.0.0:30000/generate at 1753380763.0471392
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_496 with payload: {'text': 'Random prompt 496 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_497 to http://0.0.0.0:30000/generate at 1753380763.0472689
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_497 with payload: {'text': 'Random prompt 497 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_498 to http://0.0.0.0:30000/generate at 1753380763.0473962
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_498 with payload: {'text': 'Random prompt 498 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 113, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_499 to http://0.0.0.0:30000/generate at 1753380763.0475214
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_499 with payload: {'text': 'Random prompt 499 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_500 to http://0.0.0.0:30000/generate at 1753380763.0476508
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_500 with payload: {'text': 'Random prompt 500 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_501 to http://0.0.0.0:30000/generate at 1753380763.0477726
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_501 with payload: {'text': 'Random prompt 501 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_502 to http://0.0.0.0:30000/generate at 1753380763.0478992
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_502 with payload: {'text': 'Random prompt 502 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_503 to http://0.0.0.0:30000/generate at 1753380763.0480251
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_503 with payload: {'text': 'Random prompt 503 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_504 to http://0.0.0.0:30000/generate at 1753380763.0481553
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_504 with payload: {'text': 'Random prompt 504 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 113, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_505 to http://0.0.0.0:30000/generate at 1753380763.0483325
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_505 with payload: {'text': 'Random prompt 505 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_506 to http://0.0.0.0:30000/generate at 1753380763.0484521
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_506 with payload: {'text': 'Random prompt 506 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 138, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_507 to http://0.0.0.0:30000/generate at 1753380763.0485785
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_507 with payload: {'text': 'Random prompt 507 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 132, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_508 to http://0.0.0.0:30000/generate at 1753380763.0487034
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_508 with payload: {'text': 'Random prompt 508 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_509 to http://0.0.0.0:30000/generate at 1753380763.048825
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_509 with payload: {'text': 'Random prompt 509 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_510 to http://0.0.0.0:30000/generate at 1753380763.048949
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_510 with payload: {'text': 'Random prompt 510 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_511 to http://0.0.0.0:30000/generate at 1753380763.049082
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_511 with payload: {'text': 'Random prompt 511 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_512 to http://0.0.0.0:30000/generate at 1753380763.0492063
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_512 with payload: {'text': 'Random prompt 512 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_513 to http://0.0.0.0:30000/generate at 1753380763.049329
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_513 with payload: {'text': 'Random prompt 513 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 66, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_514 to http://0.0.0.0:30000/generate at 1753380763.0494535
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_514 with payload: {'text': 'Random prompt 514 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 89, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_515 to http://0.0.0.0:30000/generate at 1753380763.0495832
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_515 with payload: {'text': 'Random prompt 515 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_516 to http://0.0.0.0:30000/generate at 1753380763.0497074
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_516 with payload: {'text': 'Random prompt 516 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_517 to http://0.0.0.0:30000/generate at 1753380763.0498753
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_517 with payload: {'text': 'Random prompt 517 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 179, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_518 to http://0.0.0.0:30000/generate at 1753380763.0500002
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_518 with payload: {'text': 'Random prompt 518 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 95, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_519 to http://0.0.0.0:30000/generate at 1753380763.0501306
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_519 with payload: {'text': 'Random prompt 519 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_520 to http://0.0.0.0:30000/generate at 1753380763.050267
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_520 with payload: {'text': 'Random prompt 520 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_521 to http://0.0.0.0:30000/generate at 1753380763.0503964
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_521 with payload: {'text': 'Random prompt 521 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_522 to http://0.0.0.0:30000/generate at 1753380763.050526
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_522 with payload: {'text': 'Random prompt 522 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_523 to http://0.0.0.0:30000/generate at 1753380763.050651
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_523 with payload: {'text': 'Random prompt 523 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_524 to http://0.0.0.0:30000/generate at 1753380763.050779
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_524 with payload: {'text': 'Random prompt 524 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_525 to http://0.0.0.0:30000/generate at 1753380763.0509014
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_525 with payload: {'text': 'Random prompt 525 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_526 to http://0.0.0.0:30000/generate at 1753380763.0510273
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_526 with payload: {'text': 'Random prompt 526 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 100, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_527 to http://0.0.0.0:30000/generate at 1753380763.0511544
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_527 with payload: {'text': 'Random prompt 527 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_528 to http://0.0.0.0:30000/generate at 1753380763.051284
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_528 with payload: {'text': 'Random prompt 528 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_529 to http://0.0.0.0:30000/generate at 1753380763.0514617
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_529 with payload: {'text': 'Random prompt 529 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_530 to http://0.0.0.0:30000/generate at 1753380763.0515852
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_530 with payload: {'text': 'Random prompt 530 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 104, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_531 to http://0.0.0.0:30000/generate at 1753380763.0517128
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_531 with payload: {'text': 'Random prompt 531 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_532 to http://0.0.0.0:30000/generate at 1753380763.051839
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_532 with payload: {'text': 'Random prompt 532 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_533 to http://0.0.0.0:30000/generate at 1753380763.0519757
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_533 with payload: {'text': 'Random prompt 533 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_534 to http://0.0.0.0:30000/generate at 1753380763.0520978
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_534 with payload: {'text': 'Random prompt 534 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_535 to http://0.0.0.0:30000/generate at 1753380763.0522325
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_535 with payload: {'text': 'Random prompt 535 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_536 to http://0.0.0.0:30000/generate at 1753380763.052363
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_536 with payload: {'text': 'Random prompt 536 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_537 to http://0.0.0.0:30000/generate at 1753380763.052489
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_537 with payload: {'text': 'Random prompt 537 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_538 to http://0.0.0.0:30000/generate at 1753380763.0526097
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_538 with payload: {'text': 'Random prompt 538 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_539 to http://0.0.0.0:30000/generate at 1753380763.0527341
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_539 with payload: {'text': 'Random prompt 539 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 131, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_540 to http://0.0.0.0:30000/generate at 1753380763.052946
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_540 with payload: {'text': 'Random prompt 540 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_541 to http://0.0.0.0:30000/generate at 1753380763.0536869
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_541 with payload: {'text': 'Random prompt 541 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_542 to http://0.0.0.0:30000/generate at 1753380763.0538251
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_542 with payload: {'text': 'Random prompt 542 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 137, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_543 to http://0.0.0.0:30000/generate at 1753380763.0539453
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_543 with payload: {'text': 'Random prompt 543 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_544 to http://0.0.0.0:30000/generate at 1753380763.0540686
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_544 with payload: {'text': 'Random prompt 544 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 187, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_545 to http://0.0.0.0:30000/generate at 1753380763.054199
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_545 with payload: {'text': 'Random prompt 545 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_546 to http://0.0.0.0:30000/generate at 1753380763.0543206
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_546 with payload: {'text': 'Random prompt 546 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_547 to http://0.0.0.0:30000/generate at 1753380763.0544438
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_547 with payload: {'text': 'Random prompt 547 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_548 to http://0.0.0.0:30000/generate at 1753380763.054573
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_548 with payload: {'text': 'Random prompt 548 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 70, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_549 to http://0.0.0.0:30000/generate at 1753380763.054695
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_549 with payload: {'text': 'Random prompt 549 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_550 to http://0.0.0.0:30000/generate at 1753380763.0548208
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_550 with payload: {'text': 'Random prompt 550 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_551 to http://0.0.0.0:30000/generate at 1753380763.0549474
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_551 with payload: {'text': 'Random prompt 551 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_552 to http://0.0.0.0:30000/generate at 1753380763.0550675
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_552 with payload: {'text': 'Random prompt 552 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_553 to http://0.0.0.0:30000/generate at 1753380763.0552387
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_553 with payload: {'text': 'Random prompt 553 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_554 to http://0.0.0.0:30000/generate at 1753380763.0553703
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_554 with payload: {'text': 'Random prompt 554 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_555 to http://0.0.0.0:30000/generate at 1753380763.0554938
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_555 with payload: {'text': 'Random prompt 555 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 91, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_556 to http://0.0.0.0:30000/generate at 1753380763.0556138
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_556 with payload: {'text': 'Random prompt 556 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_557 to http://0.0.0.0:30000/generate at 1753380763.0557365
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_557 with payload: {'text': 'Random prompt 557 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_558 to http://0.0.0.0:30000/generate at 1753380763.0558639
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_558 with payload: {'text': 'Random prompt 558 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_559 to http://0.0.0.0:30000/generate at 1753380763.0559876
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_559 with payload: {'text': 'Random prompt 559 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 179, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_560 to http://0.0.0.0:30000/generate at 1753380763.056112
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_560 with payload: {'text': 'Random prompt 560 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_561 to http://0.0.0.0:30000/generate at 1753380763.0562418
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_561 with payload: {'text': 'Random prompt 561 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_562 to http://0.0.0.0:30000/generate at 1753380763.0563672
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_562 with payload: {'text': 'Random prompt 562 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_563 to http://0.0.0.0:30000/generate at 1753380763.0564847
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_563 with payload: {'text': 'Random prompt 563 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_564 to http://0.0.0.0:30000/generate at 1753380763.0566065
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_564 with payload: {'text': 'Random prompt 564 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_565 to http://0.0.0.0:30000/generate at 1753380763.0567813
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_565 with payload: {'text': 'Random prompt 565 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 118, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_566 to http://0.0.0.0:30000/generate at 1753380763.056909
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_566 with payload: {'text': 'Random prompt 566 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_567 to http://0.0.0.0:30000/generate at 1753380763.0570326
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_567 with payload: {'text': 'Random prompt 567 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 76, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_568 to http://0.0.0.0:30000/generate at 1753380763.0571566
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_568 with payload: {'text': 'Random prompt 568 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_569 to http://0.0.0.0:30000/generate at 1753380763.0572877
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_569 with payload: {'text': 'Random prompt 569 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_570 to http://0.0.0.0:30000/generate at 1753380763.0574234
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_570 with payload: {'text': 'Random prompt 570 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 139, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_571 to http://0.0.0.0:30000/generate at 1753380763.0575492
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_571 with payload: {'text': 'Random prompt 571 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_572 to http://0.0.0.0:30000/generate at 1753380763.0576758
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_572 with payload: {'text': 'Random prompt 572 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_573 to http://0.0.0.0:30000/generate at 1753380763.0578022
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_573 with payload: {'text': 'Random prompt 573 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 174, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_574 to http://0.0.0.0:30000/generate at 1753380763.057927
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_574 with payload: {'text': 'Random prompt 574 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_575 to http://0.0.0.0:30000/generate at 1753380763.0580437
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_575 with payload: {'text': 'Random prompt 575 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 76, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_576 to http://0.0.0.0:30000/generate at 1753380763.0581696
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_576 with payload: {'text': 'Random prompt 576 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_577 to http://0.0.0.0:30000/generate at 1753380763.058344
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_577 with payload: {'text': 'Random prompt 577 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_578 to http://0.0.0.0:30000/generate at 1753380763.058472
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_578 with payload: {'text': 'Random prompt 578 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_579 to http://0.0.0.0:30000/generate at 1753380763.0585954
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_579 with payload: {'text': 'Random prompt 579 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_580 to http://0.0.0.0:30000/generate at 1753380763.0587318
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_580 with payload: {'text': 'Random prompt 580 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_581 to http://0.0.0.0:30000/generate at 1753380763.0588572
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_581 with payload: {'text': 'Random prompt 581 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_582 to http://0.0.0.0:30000/generate at 1753380763.0589814
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_582 with payload: {'text': 'Random prompt 582 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_583 to http://0.0.0.0:30000/generate at 1753380763.0591035
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_583 with payload: {'text': 'Random prompt 583 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_584 to http://0.0.0.0:30000/generate at 1753380763.05923
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_584 with payload: {'text': 'Random prompt 584 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_585 to http://0.0.0.0:30000/generate at 1753380763.0593522
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_585 with payload: {'text': 'Random prompt 585 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_586 to http://0.0.0.0:30000/generate at 1753380763.0594752
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_586 with payload: {'text': 'Random prompt 586 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_587 to http://0.0.0.0:30000/generate at 1753380763.059601
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_587 with payload: {'text': 'Random prompt 587 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_588 to http://0.0.0.0:30000/generate at 1753380763.0597274
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_588 with payload: {'text': 'Random prompt 588 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_589 to http://0.0.0.0:30000/generate at 1753380763.0598953
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_589 with payload: {'text': 'Random prompt 589 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_590 to http://0.0.0.0:30000/generate at 1753380763.060019
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_590 with payload: {'text': 'Random prompt 590 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_591 to http://0.0.0.0:30000/generate at 1753380763.0601478
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_591 with payload: {'text': 'Random prompt 591 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_592 to http://0.0.0.0:30000/generate at 1753380763.0602796
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_592 with payload: {'text': 'Random prompt 592 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_593 to http://0.0.0.0:30000/generate at 1753380763.0604022
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_593 with payload: {'text': 'Random prompt 593 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_594 to http://0.0.0.0:30000/generate at 1753380763.0605247
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_594 with payload: {'text': 'Random prompt 594 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_595 to http://0.0.0.0:30000/generate at 1753380763.0606518
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_595 with payload: {'text': 'Random prompt 595 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 138, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_596 to http://0.0.0.0:30000/generate at 1753380763.060776
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_596 with payload: {'text': 'Random prompt 596 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_597 to http://0.0.0.0:30000/generate at 1753380763.0608978
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_597 with payload: {'text': 'Random prompt 597 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_598 to http://0.0.0.0:30000/generate at 1753380763.0610192
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_598 with payload: {'text': 'Random prompt 598 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_599 to http://0.0.0.0:30000/generate at 1753380763.0611403
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_599 with payload: {'text': 'Random prompt 599 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 178, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_600 to http://0.0.0.0:30000/generate at 1753380763.0612686
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_600 with payload: {'text': 'Random prompt 600 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 89, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_601 to http://0.0.0.0:30000/generate at 1753380763.0614378
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_601 with payload: {'text': 'Random prompt 601 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 105, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_602 to http://0.0.0.0:30000/generate at 1753380763.0615623
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_602 with payload: {'text': 'Random prompt 602 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_603 to http://0.0.0.0:30000/generate at 1753380763.0616913
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_603 with payload: {'text': 'Random prompt 603 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_604 to http://0.0.0.0:30000/generate at 1753380763.0618086
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_604 with payload: {'text': 'Random prompt 604 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_605 to http://0.0.0.0:30000/generate at 1753380763.0619369
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_605 with payload: {'text': 'Random prompt 605 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_606 to http://0.0.0.0:30000/generate at 1753380763.0620615
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_606 with payload: {'text': 'Random prompt 606 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_607 to http://0.0.0.0:30000/generate at 1753380763.0621855
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_607 with payload: {'text': 'Random prompt 607 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_608 to http://0.0.0.0:30000/generate at 1753380763.06231
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_608 with payload: {'text': 'Random prompt 608 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_609 to http://0.0.0.0:30000/generate at 1753380763.0624337
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_609 with payload: {'text': 'Random prompt 609 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_610 to http://0.0.0.0:30000/generate at 1753380763.0625575
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_610 with payload: {'text': 'Random prompt 610 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_611 to http://0.0.0.0:30000/generate at 1753380763.0626817
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_611 with payload: {'text': 'Random prompt 611 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_612 to http://0.0.0.0:30000/generate at 1753380763.06281
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_612 with payload: {'text': 'Random prompt 612 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 132, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_613 to http://0.0.0.0:30000/generate at 1753380763.0629807
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_613 with payload: {'text': 'Random prompt 613 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_614 to http://0.0.0.0:30000/generate at 1753380763.0631075
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_614 with payload: {'text': 'Random prompt 614 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_615 to http://0.0.0.0:30000/generate at 1753380763.0632389
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_615 with payload: {'text': 'Random prompt 615 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 150, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_616 to http://0.0.0.0:30000/generate at 1753380763.0633655
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_616 with payload: {'text': 'Random prompt 616 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_617 to http://0.0.0.0:30000/generate at 1753380763.063488
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_617 with payload: {'text': 'Random prompt 617 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_618 to http://0.0.0.0:30000/generate at 1753380763.0636163
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_618 with payload: {'text': 'Random prompt 618 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 135, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_619 to http://0.0.0.0:30000/generate at 1753380763.0637395
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_619 with payload: {'text': 'Random prompt 619 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_620 to http://0.0.0.0:30000/generate at 1753380763.063867
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_620 with payload: {'text': 'Random prompt 620 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 124, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_621 to http://0.0.0.0:30000/generate at 1753380763.0639923
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_621 with payload: {'text': 'Random prompt 621 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_622 to http://0.0.0.0:30000/generate at 1753380763.0641122
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_622 with payload: {'text': 'Random prompt 622 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 136, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_623 to http://0.0.0.0:30000/generate at 1753380763.0642433
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_623 with payload: {'text': 'Random prompt 623 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 187, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_624 to http://0.0.0.0:30000/generate at 1753380763.064372
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_624 with payload: {'text': 'Random prompt 624 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_625 to http://0.0.0.0:30000/generate at 1753380763.0645401
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_625 with payload: {'text': 'Random prompt 625 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_626 to http://0.0.0.0:30000/generate at 1753380763.0646653
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_626 with payload: {'text': 'Random prompt 626 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_627 to http://0.0.0.0:30000/generate at 1753380763.0647924
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_627 with payload: {'text': 'Random prompt 627 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_628 to http://0.0.0.0:30000/generate at 1753380763.0649152
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_628 with payload: {'text': 'Random prompt 628 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 76, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_629 to http://0.0.0.0:30000/generate at 1753380763.0650384
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_629 with payload: {'text': 'Random prompt 629 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_630 to http://0.0.0.0:30000/generate at 1753380763.065159
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_630 with payload: {'text': 'Random prompt 630 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_631 to http://0.0.0.0:30000/generate at 1753380763.0652938
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_631 with payload: {'text': 'Random prompt 631 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_632 to http://0.0.0.0:30000/generate at 1753380763.0654204
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_632 with payload: {'text': 'Random prompt 632 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_633 to http://0.0.0.0:30000/generate at 1753380763.0655437
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_633 with payload: {'text': 'Random prompt 633 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_634 to http://0.0.0.0:30000/generate at 1753380763.0656688
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_634 with payload: {'text': 'Random prompt 634 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_635 to http://0.0.0.0:30000/generate at 1753380763.0657973
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_635 with payload: {'text': 'Random prompt 635 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_636 to http://0.0.0.0:30000/generate at 1753380763.0659218
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_636 with payload: {'text': 'Random prompt 636 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_637 to http://0.0.0.0:30000/generate at 1753380763.066091
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_637 with payload: {'text': 'Random prompt 637 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 84, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_638 to http://0.0.0.0:30000/generate at 1753380763.0662198
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_638 with payload: {'text': 'Random prompt 638 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_639 to http://0.0.0.0:30000/generate at 1753380763.0663462
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_639 with payload: {'text': 'Random prompt 639 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_640 to http://0.0.0.0:30000/generate at 1753380763.066468
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_640 with payload: {'text': 'Random prompt 640 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_641 to http://0.0.0.0:30000/generate at 1753380763.0665941
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_641 with payload: {'text': 'Random prompt 641 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_642 to http://0.0.0.0:30000/generate at 1753380763.0667193
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_642 with payload: {'text': 'Random prompt 642 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 131, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_643 to http://0.0.0.0:30000/generate at 1753380763.066843
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_643 with payload: {'text': 'Random prompt 643 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_644 to http://0.0.0.0:30000/generate at 1753380763.0669663
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_644 with payload: {'text': 'Random prompt 644 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_645 to http://0.0.0.0:30000/generate at 1753380763.06709
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_645 with payload: {'text': 'Random prompt 645 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_646 to http://0.0.0.0:30000/generate at 1753380763.067217
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_646 with payload: {'text': 'Random prompt 646 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_647 to http://0.0.0.0:30000/generate at 1753380763.067346
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_647 with payload: {'text': 'Random prompt 647 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_648 to http://0.0.0.0:30000/generate at 1753380763.0674684
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_648 with payload: {'text': 'Random prompt 648 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_649 to http://0.0.0.0:30000/generate at 1753380763.067642
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_649 with payload: {'text': 'Random prompt 649 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_650 to http://0.0.0.0:30000/generate at 1753380763.0677736
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_650 with payload: {'text': 'Random prompt 650 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_651 to http://0.0.0.0:30000/generate at 1753380763.0678985
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_651 with payload: {'text': 'Random prompt 651 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_652 to http://0.0.0.0:30000/generate at 1753380763.0680225
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_652 with payload: {'text': 'Random prompt 652 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 98, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_653 to http://0.0.0.0:30000/generate at 1753380763.0681477
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_653 with payload: {'text': 'Random prompt 653 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 110, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_654 to http://0.0.0.0:30000/generate at 1753380763.0682738
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_654 with payload: {'text': 'Random prompt 654 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_655 to http://0.0.0.0:30000/generate at 1753380763.068399
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_655 with payload: {'text': 'Random prompt 655 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_656 to http://0.0.0.0:30000/generate at 1753380763.0685222
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_656 with payload: {'text': 'Random prompt 656 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 135, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_657 to http://0.0.0.0:30000/generate at 1753380763.068646
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_657 with payload: {'text': 'Random prompt 657 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_658 to http://0.0.0.0:30000/generate at 1753380763.0687726
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_658 with payload: {'text': 'Random prompt 658 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_659 to http://0.0.0.0:30000/generate at 1753380763.0688925
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_659 with payload: {'text': 'Random prompt 659 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 121, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_660 to http://0.0.0.0:30000/generate at 1753380763.0690148
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_660 with payload: {'text': 'Random prompt 660 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_661 to http://0.0.0.0:30000/generate at 1753380763.069189
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_661 with payload: {'text': 'Random prompt 661 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_662 to http://0.0.0.0:30000/generate at 1753380763.069316
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_662 with payload: {'text': 'Random prompt 662 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 182, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_663 to http://0.0.0.0:30000/generate at 1753380763.0694466
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_663 with payload: {'text': 'Random prompt 663 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_664 to http://0.0.0.0:30000/generate at 1753380763.0695693
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_664 with payload: {'text': 'Random prompt 664 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_665 to http://0.0.0.0:30000/generate at 1753380763.0696924
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_665 with payload: {'text': 'Random prompt 665 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 173, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_666 to http://0.0.0.0:30000/generate at 1753380763.069813
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_666 with payload: {'text': 'Random prompt 666 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 91, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_667 to http://0.0.0.0:30000/generate at 1753380763.0699377
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_667 with payload: {'text': 'Random prompt 667 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_668 to http://0.0.0.0:30000/generate at 1753380763.0700605
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_668 with payload: {'text': 'Random prompt 668 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 79, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_669 to http://0.0.0.0:30000/generate at 1753380763.070191
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_669 with payload: {'text': 'Random prompt 669 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_670 to http://0.0.0.0:30000/generate at 1753380763.0703166
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_670 with payload: {'text': 'Random prompt 670 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 113, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_671 to http://0.0.0.0:30000/generate at 1753380763.0704443
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_671 with payload: {'text': 'Random prompt 671 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_672 to http://0.0.0.0:30000/generate at 1753380763.0705702
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_672 with payload: {'text': 'Random prompt 672 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_673 to http://0.0.0.0:30000/generate at 1753380763.070738
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_673 with payload: {'text': 'Random prompt 673 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_674 to http://0.0.0.0:30000/generate at 1753380763.0708656
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_674 with payload: {'text': 'Random prompt 674 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_675 to http://0.0.0.0:30000/generate at 1753380763.0709932
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_675 with payload: {'text': 'Random prompt 675 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_676 to http://0.0.0.0:30000/generate at 1753380763.0711179
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_676 with payload: {'text': 'Random prompt 676 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_677 to http://0.0.0.0:30000/generate at 1753380763.0712466
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_677 with payload: {'text': 'Random prompt 677 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_678 to http://0.0.0.0:30000/generate at 1753380763.0713756
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_678 with payload: {'text': 'Random prompt 678 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_679 to http://0.0.0.0:30000/generate at 1753380763.0715003
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_679 with payload: {'text': 'Random prompt 679 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_680 to http://0.0.0.0:30000/generate at 1753380763.0716302
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_680 with payload: {'text': 'Random prompt 680 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_681 to http://0.0.0.0:30000/generate at 1753380763.071754
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_681 with payload: {'text': 'Random prompt 681 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_682 to http://0.0.0.0:30000/generate at 1753380763.0718906
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_682 with payload: {'text': 'Random prompt 682 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_683 to http://0.0.0.0:30000/generate at 1753380763.07201
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_683 with payload: {'text': 'Random prompt 683 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_684 to http://0.0.0.0:30000/generate at 1753380763.0721326
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_684 with payload: {'text': 'Random prompt 684 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_685 to http://0.0.0.0:30000/generate at 1753380763.0728445
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_685 with payload: {'text': 'Random prompt 685 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 174, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_686 to http://0.0.0.0:30000/generate at 1753380763.0729754
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_686 with payload: {'text': 'Random prompt 686 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 182, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_687 to http://0.0.0.0:30000/generate at 1753380763.0731065
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_687 with payload: {'text': 'Random prompt 687 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_688 to http://0.0.0.0:30000/generate at 1753380763.0732362
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_688 with payload: {'text': 'Random prompt 688 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_689 to http://0.0.0.0:30000/generate at 1753380763.073362
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_689 with payload: {'text': 'Random prompt 689 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_690 to http://0.0.0.0:30000/generate at 1753380763.0734875
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_690 with payload: {'text': 'Random prompt 690 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_691 to http://0.0.0.0:30000/generate at 1753380763.0736127
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_691 with payload: {'text': 'Random prompt 691 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_692 to http://0.0.0.0:30000/generate at 1753380763.0737367
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_692 with payload: {'text': 'Random prompt 692 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_693 to http://0.0.0.0:30000/generate at 1753380763.0738645
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_693 with payload: {'text': 'Random prompt 693 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_694 to http://0.0.0.0:30000/generate at 1753380763.073991
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_694 with payload: {'text': 'Random prompt 694 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_695 to http://0.0.0.0:30000/generate at 1753380763.0741136
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_695 with payload: {'text': 'Random prompt 695 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_696 to http://0.0.0.0:30000/generate at 1753380763.0742452
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_696 with payload: {'text': 'Random prompt 696 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_697 to http://0.0.0.0:30000/generate at 1753380763.0744169
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_697 with payload: {'text': 'Random prompt 697 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_698 to http://0.0.0.0:30000/generate at 1753380763.0745397
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_698 with payload: {'text': 'Random prompt 698 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 187, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_699 to http://0.0.0.0:30000/generate at 1753380763.0746653
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_699 with payload: {'text': 'Random prompt 699 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_700 to http://0.0.0.0:30000/generate at 1753380763.0747907
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_700 with payload: {'text': 'Random prompt 700 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_701 to http://0.0.0.0:30000/generate at 1753380763.074916
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_701 with payload: {'text': 'Random prompt 701 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_702 to http://0.0.0.0:30000/generate at 1753380763.0750406
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_702 with payload: {'text': 'Random prompt 702 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 104, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_703 to http://0.0.0.0:30000/generate at 1753380763.075165
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_703 with payload: {'text': 'Random prompt 703 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 129, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_704 to http://0.0.0.0:30000/generate at 1753380763.0752964
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_704 with payload: {'text': 'Random prompt 704 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_705 to http://0.0.0.0:30000/generate at 1753380763.0754218
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_705 with payload: {'text': 'Random prompt 705 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_706 to http://0.0.0.0:30000/generate at 1753380763.075546
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_706 with payload: {'text': 'Random prompt 706 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_707 to http://0.0.0.0:30000/generate at 1753380763.0756745
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_707 with payload: {'text': 'Random prompt 707 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_708 to http://0.0.0.0:30000/generate at 1753380763.0758028
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_708 with payload: {'text': 'Random prompt 708 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_709 to http://0.0.0.0:30000/generate at 1753380763.0759747
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_709 with payload: {'text': 'Random prompt 709 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_710 to http://0.0.0.0:30000/generate at 1753380763.0760994
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_710 with payload: {'text': 'Random prompt 710 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_711 to http://0.0.0.0:30000/generate at 1753380763.0762293
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_711 with payload: {'text': 'Random prompt 711 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_712 to http://0.0.0.0:30000/generate at 1753380763.0763621
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_712 with payload: {'text': 'Random prompt 712 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_713 to http://0.0.0.0:30000/generate at 1753380763.0764894
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_713 with payload: {'text': 'Random prompt 713 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_714 to http://0.0.0.0:30000/generate at 1753380763.0766122
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_714 with payload: {'text': 'Random prompt 714 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_715 to http://0.0.0.0:30000/generate at 1753380763.0767367
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_715 with payload: {'text': 'Random prompt 715 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_716 to http://0.0.0.0:30000/generate at 1753380763.0768619
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_716 with payload: {'text': 'Random prompt 716 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_717 to http://0.0.0.0:30000/generate at 1753380763.0769858
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_717 with payload: {'text': 'Random prompt 717 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_718 to http://0.0.0.0:30000/generate at 1753380763.0771172
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_718 with payload: {'text': 'Random prompt 718 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_719 to http://0.0.0.0:30000/generate at 1753380763.0772429
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_719 with payload: {'text': 'Random prompt 719 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 95, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_720 to http://0.0.0.0:30000/generate at 1753380763.0773668
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_720 with payload: {'text': 'Random prompt 720 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 82, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_721 to http://0.0.0.0:30000/generate at 1753380763.077539
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_721 with payload: {'text': 'Random prompt 721 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_722 to http://0.0.0.0:30000/generate at 1753380763.077664
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_722 with payload: {'text': 'Random prompt 722 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_723 to http://0.0.0.0:30000/generate at 1753380763.0777853
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_723 with payload: {'text': 'Random prompt 723 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_724 to http://0.0.0.0:30000/generate at 1753380763.077915
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_724 with payload: {'text': 'Random prompt 724 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_725 to http://0.0.0.0:30000/generate at 1753380763.078042
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_725 with payload: {'text': 'Random prompt 725 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_726 to http://0.0.0.0:30000/generate at 1753380763.0781667
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_726 with payload: {'text': 'Random prompt 726 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 129, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_727 to http://0.0.0.0:30000/generate at 1753380763.0782897
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_727 with payload: {'text': 'Random prompt 727 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_728 to http://0.0.0.0:30000/generate at 1753380763.078414
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_728 with payload: {'text': 'Random prompt 728 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_729 to http://0.0.0.0:30000/generate at 1753380763.0785375
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_729 with payload: {'text': 'Random prompt 729 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_730 to http://0.0.0.0:30000/generate at 1753380763.078665
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_730 with payload: {'text': 'Random prompt 730 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_731 to http://0.0.0.0:30000/generate at 1753380763.0787861
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_731 with payload: {'text': 'Random prompt 731 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_732 to http://0.0.0.0:30000/generate at 1753380763.0789099
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_732 with payload: {'text': 'Random prompt 732 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 131, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_733 to http://0.0.0.0:30000/generate at 1753380763.0790794
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_733 with payload: {'text': 'Random prompt 733 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_734 to http://0.0.0.0:30000/generate at 1753380763.0792096
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_734 with payload: {'text': 'Random prompt 734 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_735 to http://0.0.0.0:30000/generate at 1753380763.0793302
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_735 with payload: {'text': 'Random prompt 735 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_736 to http://0.0.0.0:30000/generate at 1753380763.0794637
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_736 with payload: {'text': 'Random prompt 736 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_737 to http://0.0.0.0:30000/generate at 1753380763.0795827
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_737 with payload: {'text': 'Random prompt 737 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 89, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_738 to http://0.0.0.0:30000/generate at 1753380763.079699
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_738 with payload: {'text': 'Random prompt 738 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_739 to http://0.0.0.0:30000/generate at 1753380763.079828
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_739 with payload: {'text': 'Random prompt 739 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_740 to http://0.0.0.0:30000/generate at 1753380763.0799606
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_740 with payload: {'text': 'Random prompt 740 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_741 to http://0.0.0.0:30000/generate at 1753380763.0800865
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_741 with payload: {'text': 'Random prompt 741 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_742 to http://0.0.0.0:30000/generate at 1753380763.0802147
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_742 with payload: {'text': 'Random prompt 742 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_743 to http://0.0.0.0:30000/generate at 1753380763.0803406
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_743 with payload: {'text': 'Random prompt 743 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_744 to http://0.0.0.0:30000/generate at 1753380763.080461
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_744 with payload: {'text': 'Random prompt 744 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_745 to http://0.0.0.0:30000/generate at 1753380763.0806327
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_745 with payload: {'text': 'Random prompt 745 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_746 to http://0.0.0.0:30000/generate at 1753380763.0807579
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_746 with payload: {'text': 'Random prompt 746 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 66, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_747 to http://0.0.0.0:30000/generate at 1753380763.080884
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_747 with payload: {'text': 'Random prompt 747 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_748 to http://0.0.0.0:30000/generate at 1753380763.0810158
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_748 with payload: {'text': 'Random prompt 748 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_749 to http://0.0.0.0:30000/generate at 1753380763.081141
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_749 with payload: {'text': 'Random prompt 749 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 82, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_750 to http://0.0.0.0:30000/generate at 1753380763.0812695
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_750 with payload: {'text': 'Random prompt 750 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_751 to http://0.0.0.0:30000/generate at 1753380763.081395
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_751 with payload: {'text': 'Random prompt 751 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_752 to http://0.0.0.0:30000/generate at 1753380763.0815222
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_752 with payload: {'text': 'Random prompt 752 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 66, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_753 to http://0.0.0.0:30000/generate at 1753380763.0816448
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_753 with payload: {'text': 'Random prompt 753 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 95, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_754 to http://0.0.0.0:30000/generate at 1753380763.081774
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_754 with payload: {'text': 'Random prompt 754 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_755 to http://0.0.0.0:30000/generate at 1753380763.081897
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_755 with payload: {'text': 'Random prompt 755 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_756 to http://0.0.0.0:30000/generate at 1753380763.0820165
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_756 with payload: {'text': 'Random prompt 756 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 187, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_757 to http://0.0.0.0:30000/generate at 1753380763.0821915
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_757 with payload: {'text': 'Random prompt 757 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_758 to http://0.0.0.0:30000/generate at 1753380763.0823214
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_758 with payload: {'text': 'Random prompt 758 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_759 to http://0.0.0.0:30000/generate at 1753380763.0824478
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_759 with payload: {'text': 'Random prompt 759 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_760 to http://0.0.0.0:30000/generate at 1753380763.0825713
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_760 with payload: {'text': 'Random prompt 760 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_761 to http://0.0.0.0:30000/generate at 1753380763.0826952
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_761 with payload: {'text': 'Random prompt 761 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_762 to http://0.0.0.0:30000/generate at 1753380763.0828226
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_762 with payload: {'text': 'Random prompt 762 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_763 to http://0.0.0.0:30000/generate at 1753380763.0829432
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_763 with payload: {'text': 'Random prompt 763 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_764 to http://0.0.0.0:30000/generate at 1753380763.0830665
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_764 with payload: {'text': 'Random prompt 764 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_765 to http://0.0.0.0:30000/generate at 1753380763.0831988
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_765 with payload: {'text': 'Random prompt 765 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_766 to http://0.0.0.0:30000/generate at 1753380763.0833259
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_766 with payload: {'text': 'Random prompt 766 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_767 to http://0.0.0.0:30000/generate at 1753380763.0834486
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_767 with payload: {'text': 'Random prompt 767 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_768 to http://0.0.0.0:30000/generate at 1753380763.0835757
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_768 with payload: {'text': 'Random prompt 768 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 112, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_769 to http://0.0.0.0:30000/generate at 1753380763.0837452
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_769 with payload: {'text': 'Random prompt 769 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_770 to http://0.0.0.0:30000/generate at 1753380763.0838697
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_770 with payload: {'text': 'Random prompt 770 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_771 to http://0.0.0.0:30000/generate at 1753380763.0839982
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_771 with payload: {'text': 'Random prompt 771 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_772 to http://0.0.0.0:30000/generate at 1753380763.0841265
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_772 with payload: {'text': 'Random prompt 772 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 178, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_773 to http://0.0.0.0:30000/generate at 1753380763.0842519
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_773 with payload: {'text': 'Random prompt 773 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_774 to http://0.0.0.0:30000/generate at 1753380763.0843759
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_774 with payload: {'text': 'Random prompt 774 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_775 to http://0.0.0.0:30000/generate at 1753380763.0844982
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_775 with payload: {'text': 'Random prompt 775 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 104, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_776 to http://0.0.0.0:30000/generate at 1753380763.0846286
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_776 with payload: {'text': 'Random prompt 776 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_777 to http://0.0.0.0:30000/generate at 1753380763.0847557
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_777 with payload: {'text': 'Random prompt 777 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_778 to http://0.0.0.0:30000/generate at 1753380763.0848806
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_778 with payload: {'text': 'Random prompt 778 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_779 to http://0.0.0.0:30000/generate at 1753380763.0850098
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_779 with payload: {'text': 'Random prompt 779 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_780 to http://0.0.0.0:30000/generate at 1753380763.0851364
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_780 with payload: {'text': 'Random prompt 780 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_781 to http://0.0.0.0:30000/generate at 1753380763.0853112
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_781 with payload: {'text': 'Random prompt 781 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 179, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_782 to http://0.0.0.0:30000/generate at 1753380763.0854332
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_782 with payload: {'text': 'Random prompt 782 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_783 to http://0.0.0.0:30000/generate at 1753380763.0855951
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_783 with payload: {'text': 'Random prompt 783 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_784 to http://0.0.0.0:30000/generate at 1753380763.085726
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_784 with payload: {'text': 'Random prompt 784 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_785 to http://0.0.0.0:30000/generate at 1753380763.0858498
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_785 with payload: {'text': 'Random prompt 785 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 179, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_786 to http://0.0.0.0:30000/generate at 1753380763.0859811
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_786 with payload: {'text': 'Random prompt 786 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_787 to http://0.0.0.0:30000/generate at 1753380763.0861063
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_787 with payload: {'text': 'Random prompt 787 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_788 to http://0.0.0.0:30000/generate at 1753380763.0862336
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_788 with payload: {'text': 'Random prompt 788 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_789 to http://0.0.0.0:30000/generate at 1753380763.0863585
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_789 with payload: {'text': 'Random prompt 789 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_790 to http://0.0.0.0:30000/generate at 1753380763.0864878
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_790 with payload: {'text': 'Random prompt 790 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_791 to http://0.0.0.0:30000/generate at 1753380763.0866196
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_791 with payload: {'text': 'Random prompt 791 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_792 to http://0.0.0.0:30000/generate at 1753380763.0867426
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_792 with payload: {'text': 'Random prompt 792 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_793 to http://0.0.0.0:30000/generate at 1753380763.0869193
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_793 with payload: {'text': 'Random prompt 793 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_794 to http://0.0.0.0:30000/generate at 1753380763.0870426
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_794 with payload: {'text': 'Random prompt 794 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_795 to http://0.0.0.0:30000/generate at 1753380763.0871644
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_795 with payload: {'text': 'Random prompt 795 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_796 to http://0.0.0.0:30000/generate at 1753380763.0872927
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_796 with payload: {'text': 'Random prompt 796 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_797 to http://0.0.0.0:30000/generate at 1753380763.0874224
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_797 with payload: {'text': 'Random prompt 797 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_798 to http://0.0.0.0:30000/generate at 1753380763.0875454
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_798 with payload: {'text': 'Random prompt 798 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_799 to http://0.0.0.0:30000/generate at 1753380763.087668
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_799 with payload: {'text': 'Random prompt 799 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 66, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_800 to http://0.0.0.0:30000/generate at 1753380763.0877962
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_800 with payload: {'text': 'Random prompt 800 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_801 to http://0.0.0.0:30000/generate at 1753380763.0879216
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_801 with payload: {'text': 'Random prompt 801 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_802 to http://0.0.0.0:30000/generate at 1753380763.0880432
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_802 with payload: {'text': 'Random prompt 802 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_803 to http://0.0.0.0:30000/generate at 1753380763.0881805
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_803 with payload: {'text': 'Random prompt 803 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 102, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_804 to http://0.0.0.0:30000/generate at 1753380763.0883079
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_804 with payload: {'text': 'Random prompt 804 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_805 to http://0.0.0.0:30000/generate at 1753380763.0884798
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_805 with payload: {'text': 'Random prompt 805 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_806 to http://0.0.0.0:30000/generate at 1753380763.088605
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_806 with payload: {'text': 'Random prompt 806 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_807 to http://0.0.0.0:30000/generate at 1753380763.08873
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_807 with payload: {'text': 'Random prompt 807 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_808 to http://0.0.0.0:30000/generate at 1753380763.088854
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_808 with payload: {'text': 'Random prompt 808 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_809 to http://0.0.0.0:30000/generate at 1753380763.0889843
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_809 with payload: {'text': 'Random prompt 809 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_810 to http://0.0.0.0:30000/generate at 1753380763.0891068
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_810 with payload: {'text': 'Random prompt 810 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_811 to http://0.0.0.0:30000/generate at 1753380763.0892382
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_811 with payload: {'text': 'Random prompt 811 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_812 to http://0.0.0.0:30000/generate at 1753380763.0893667
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_812 with payload: {'text': 'Random prompt 812 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 98, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_813 to http://0.0.0.0:30000/generate at 1753380763.0894864
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_813 with payload: {'text': 'Random prompt 813 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_814 to http://0.0.0.0:30000/generate at 1753380763.089609
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_814 with payload: {'text': 'Random prompt 814 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_815 to http://0.0.0.0:30000/generate at 1753380763.089733
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_815 with payload: {'text': 'Random prompt 815 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_816 to http://0.0.0.0:30000/generate at 1753380763.089861
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_816 with payload: {'text': 'Random prompt 816 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 102, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_817 to http://0.0.0.0:30000/generate at 1753380763.090028
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_817 with payload: {'text': 'Random prompt 817 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_818 to http://0.0.0.0:30000/generate at 1753380763.090149
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_818 with payload: {'text': 'Random prompt 818 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_819 to http://0.0.0.0:30000/generate at 1753380763.0902781
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_819 with payload: {'text': 'Random prompt 819 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 113, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_820 to http://0.0.0.0:30000/generate at 1753380763.090403
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_820 with payload: {'text': 'Random prompt 820 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_821 to http://0.0.0.0:30000/generate at 1753380763.0905335
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_821 with payload: {'text': 'Random prompt 821 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_822 to http://0.0.0.0:30000/generate at 1753380763.0906541
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_822 with payload: {'text': 'Random prompt 822 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_823 to http://0.0.0.0:30000/generate at 1753380763.09078
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_823 with payload: {'text': 'Random prompt 823 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_824 to http://0.0.0.0:30000/generate at 1753380763.0909016
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_824 with payload: {'text': 'Random prompt 824 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_825 to http://0.0.0.0:30000/generate at 1753380763.0910227
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_825 with payload: {'text': 'Random prompt 825 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 132, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_826 to http://0.0.0.0:30000/generate at 1753380763.0911515
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_826 with payload: {'text': 'Random prompt 826 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_827 to http://0.0.0.0:30000/generate at 1753380763.091283
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_827 with payload: {'text': 'Random prompt 827 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_828 to http://0.0.0.0:30000/generate at 1753380763.0914068
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_828 with payload: {'text': 'Random prompt 828 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_829 to http://0.0.0.0:30000/generate at 1753380763.092103
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_829 with payload: {'text': 'Random prompt 829 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 101, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_830 to http://0.0.0.0:30000/generate at 1753380763.0922446
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_830 with payload: {'text': 'Random prompt 830 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_831 to http://0.0.0.0:30000/generate at 1753380763.0923681
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_831 with payload: {'text': 'Random prompt 831 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_832 to http://0.0.0.0:30000/generate at 1753380763.092496
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_832 with payload: {'text': 'Random prompt 832 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 139, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_833 to http://0.0.0.0:30000/generate at 1753380763.0926225
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_833 with payload: {'text': 'Random prompt 833 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 160, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_834 to http://0.0.0.0:30000/generate at 1753380763.0927484
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_834 with payload: {'text': 'Random prompt 834 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_835 to http://0.0.0.0:30000/generate at 1753380763.092876
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_835 with payload: {'text': 'Random prompt 835 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_836 to http://0.0.0.0:30000/generate at 1753380763.0929976
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_836 with payload: {'text': 'Random prompt 836 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_837 to http://0.0.0.0:30000/generate at 1753380763.0931258
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_837 with payload: {'text': 'Random prompt 837 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_838 to http://0.0.0.0:30000/generate at 1753380763.0932567
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_838 with payload: {'text': 'Random prompt 838 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_839 to http://0.0.0.0:30000/generate at 1753380763.0933797
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_839 with payload: {'text': 'Random prompt 839 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_840 to http://0.0.0.0:30000/generate at 1753380763.0935054
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_840 with payload: {'text': 'Random prompt 840 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 112, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_841 to http://0.0.0.0:30000/generate at 1753380763.0936775
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_841 with payload: {'text': 'Random prompt 841 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_842 to http://0.0.0.0:30000/generate at 1753380763.0938113
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_842 with payload: {'text': 'Random prompt 842 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_843 to http://0.0.0.0:30000/generate at 1753380763.0939312
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_843 with payload: {'text': 'Random prompt 843 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_844 to http://0.0.0.0:30000/generate at 1753380763.0940633
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_844 with payload: {'text': 'Random prompt 844 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_845 to http://0.0.0.0:30000/generate at 1753380763.0941963
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_845 with payload: {'text': 'Random prompt 845 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 95, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_846 to http://0.0.0.0:30000/generate at 1753380763.094319
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_846 with payload: {'text': 'Random prompt 846 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_847 to http://0.0.0.0:30000/generate at 1753380763.094443
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_847 with payload: {'text': 'Random prompt 847 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 89, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_848 to http://0.0.0.0:30000/generate at 1753380763.0945683
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_848 with payload: {'text': 'Random prompt 848 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 178, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_849 to http://0.0.0.0:30000/generate at 1753380763.0946915
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_849 with payload: {'text': 'Random prompt 849 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_850 to http://0.0.0.0:30000/generate at 1753380763.0948133
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_850 with payload: {'text': 'Random prompt 850 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 101, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_851 to http://0.0.0.0:30000/generate at 1753380763.0949373
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_851 with payload: {'text': 'Random prompt 851 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_852 to http://0.0.0.0:30000/generate at 1753380763.0950623
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_852 with payload: {'text': 'Random prompt 852 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 174, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_853 to http://0.0.0.0:30000/generate at 1753380763.095232
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_853 with payload: {'text': 'Random prompt 853 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_854 to http://0.0.0.0:30000/generate at 1753380763.0953577
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_854 with payload: {'text': 'Random prompt 854 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 182, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_855 to http://0.0.0.0:30000/generate at 1753380763.0954814
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_855 with payload: {'text': 'Random prompt 855 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 96, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_856 to http://0.0.0.0:30000/generate at 1753380763.0956044
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_856 with payload: {'text': 'Random prompt 856 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_857 to http://0.0.0.0:30000/generate at 1753380763.0957289
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_857 with payload: {'text': 'Random prompt 857 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_858 to http://0.0.0.0:30000/generate at 1753380763.0958545
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_858 with payload: {'text': 'Random prompt 858 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_859 to http://0.0.0.0:30000/generate at 1753380763.095979
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_859 with payload: {'text': 'Random prompt 859 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_860 to http://0.0.0.0:30000/generate at 1753380763.0961015
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_860 with payload: {'text': 'Random prompt 860 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_861 to http://0.0.0.0:30000/generate at 1753380763.0962348
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_861 with payload: {'text': 'Random prompt 861 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_862 to http://0.0.0.0:30000/generate at 1753380763.0963573
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_862 with payload: {'text': 'Random prompt 862 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_863 to http://0.0.0.0:30000/generate at 1753380763.0964825
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_863 with payload: {'text': 'Random prompt 863 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_864 to http://0.0.0.0:30000/generate at 1753380763.0966117
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_864 with payload: {'text': 'Random prompt 864 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_865 to http://0.0.0.0:30000/generate at 1753380763.096775
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_865 with payload: {'text': 'Random prompt 865 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_866 to http://0.0.0.0:30000/generate at 1753380763.096902
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_866 with payload: {'text': 'Random prompt 866 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 70, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_867 to http://0.0.0.0:30000/generate at 1753380763.0970275
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_867 with payload: {'text': 'Random prompt 867 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_868 to http://0.0.0.0:30000/generate at 1753380763.0971475
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_868 with payload: {'text': 'Random prompt 868 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_869 to http://0.0.0.0:30000/generate at 1753380763.0972807
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_869 with payload: {'text': 'Random prompt 869 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_870 to http://0.0.0.0:30000/generate at 1753380763.0974097
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_870 with payload: {'text': 'Random prompt 870 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_871 to http://0.0.0.0:30000/generate at 1753380763.0975327
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_871 with payload: {'text': 'Random prompt 871 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 91, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_872 to http://0.0.0.0:30000/generate at 1753380763.0976582
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_872 with payload: {'text': 'Random prompt 872 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 129, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_873 to http://0.0.0.0:30000/generate at 1753380763.0977812
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_873 with payload: {'text': 'Random prompt 873 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_874 to http://0.0.0.0:30000/generate at 1753380763.097905
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_874 with payload: {'text': 'Random prompt 874 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_875 to http://0.0.0.0:30000/generate at 1753380763.0980315
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_875 with payload: {'text': 'Random prompt 875 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_876 to http://0.0.0.0:30000/generate at 1753380763.0981536
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_876 with payload: {'text': 'Random prompt 876 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_877 to http://0.0.0.0:30000/generate at 1753380763.0983253
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_877 with payload: {'text': 'Random prompt 877 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 129, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_878 to http://0.0.0.0:30000/generate at 1753380763.0984528
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_878 with payload: {'text': 'Random prompt 878 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 102, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_879 to http://0.0.0.0:30000/generate at 1753380763.0985796
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_879 with payload: {'text': 'Random prompt 879 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 136, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_880 to http://0.0.0.0:30000/generate at 1753380763.0987034
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_880 with payload: {'text': 'Random prompt 880 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_881 to http://0.0.0.0:30000/generate at 1753380763.0988345
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_881 with payload: {'text': 'Random prompt 881 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_882 to http://0.0.0.0:30000/generate at 1753380763.0989602
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_882 with payload: {'text': 'Random prompt 882 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_883 to http://0.0.0.0:30000/generate at 1753380763.0990775
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_883 with payload: {'text': 'Random prompt 883 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_884 to http://0.0.0.0:30000/generate at 1753380763.0992074
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_884 with payload: {'text': 'Random prompt 884 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 84, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_885 to http://0.0.0.0:30000/generate at 1753380763.0993333
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_885 with payload: {'text': 'Random prompt 885 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_886 to http://0.0.0.0:30000/generate at 1753380763.0994565
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_886 with payload: {'text': 'Random prompt 886 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_887 to http://0.0.0.0:30000/generate at 1753380763.099584
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_887 with payload: {'text': 'Random prompt 887 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 96, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_888 to http://0.0.0.0:30000/generate at 1753380763.0997107
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_888 with payload: {'text': 'Random prompt 888 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_889 to http://0.0.0.0:30000/generate at 1753380763.099881
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_889 with payload: {'text': 'Random prompt 889 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_890 to http://0.0.0.0:30000/generate at 1753380763.1000054
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_890 with payload: {'text': 'Random prompt 890 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_891 to http://0.0.0.0:30000/generate at 1753380763.1001225
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_891 with payload: {'text': 'Random prompt 891 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_892 to http://0.0.0.0:30000/generate at 1753380763.1002562
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_892 with payload: {'text': 'Random prompt 892 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_893 to http://0.0.0.0:30000/generate at 1753380763.1003802
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_893 with payload: {'text': 'Random prompt 893 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_894 to http://0.0.0.0:30000/generate at 1753380763.1005044
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_894 with payload: {'text': 'Random prompt 894 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 135, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_895 to http://0.0.0.0:30000/generate at 1753380763.1006315
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_895 with payload: {'text': 'Random prompt 895 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_896 to http://0.0.0.0:30000/generate at 1753380763.100752
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_896 with payload: {'text': 'Random prompt 896 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_897 to http://0.0.0.0:30000/generate at 1753380763.100873
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_897 with payload: {'text': 'Random prompt 897 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_898 to http://0.0.0.0:30000/generate at 1753380763.1010005
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_898 with payload: {'text': 'Random prompt 898 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_899 to http://0.0.0.0:30000/generate at 1753380763.1011226
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_899 with payload: {'text': 'Random prompt 899 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_900 to http://0.0.0.0:30000/generate at 1753380763.101251
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_900 with payload: {'text': 'Random prompt 900 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 135, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_901 to http://0.0.0.0:30000/generate at 1753380763.1014214
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_901 with payload: {'text': 'Random prompt 901 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_902 to http://0.0.0.0:30000/generate at 1753380763.1015427
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_902 with payload: {'text': 'Random prompt 902 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_903 to http://0.0.0.0:30000/generate at 1753380763.1016665
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_903 with payload: {'text': 'Random prompt 903 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_904 to http://0.0.0.0:30000/generate at 1753380763.1017933
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_904 with payload: {'text': 'Random prompt 904 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 159, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_905 to http://0.0.0.0:30000/generate at 1753380763.1019192
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_905 with payload: {'text': 'Random prompt 905 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_906 to http://0.0.0.0:30000/generate at 1753380763.1020489
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_906 with payload: {'text': 'Random prompt 906 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 187, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_907 to http://0.0.0.0:30000/generate at 1753380763.1021795
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_907 with payload: {'text': 'Random prompt 907 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_908 to http://0.0.0.0:30000/generate at 1753380763.1023011
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_908 with payload: {'text': 'Random prompt 908 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_909 to http://0.0.0.0:30000/generate at 1753380763.1024199
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_909 with payload: {'text': 'Random prompt 909 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_910 to http://0.0.0.0:30000/generate at 1753380763.1025496
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_910 with payload: {'text': 'Random prompt 910 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_911 to http://0.0.0.0:30000/generate at 1753380763.1026785
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_911 with payload: {'text': 'Random prompt 911 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_912 to http://0.0.0.0:30000/generate at 1753380763.1028001
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_912 with payload: {'text': 'Random prompt 912 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_913 to http://0.0.0.0:30000/generate at 1753380763.1029704
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_913 with payload: {'text': 'Random prompt 913 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_914 to http://0.0.0.0:30000/generate at 1753380763.1030917
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_914 with payload: {'text': 'Random prompt 914 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 121, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_915 to http://0.0.0.0:30000/generate at 1753380763.1032188
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_915 with payload: {'text': 'Random prompt 915 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_916 to http://0.0.0.0:30000/generate at 1753380763.1033428
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_916 with payload: {'text': 'Random prompt 916 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_917 to http://0.0.0.0:30000/generate at 1753380763.1034677
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_917 with payload: {'text': 'Random prompt 917 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_918 to http://0.0.0.0:30000/generate at 1753380763.1036005
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_918 with payload: {'text': 'Random prompt 918 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_919 to http://0.0.0.0:30000/generate at 1753380763.1037226
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_919 with payload: {'text': 'Random prompt 919 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_920 to http://0.0.0.0:30000/generate at 1753380763.103856
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_920 with payload: {'text': 'Random prompt 920 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_921 to http://0.0.0.0:30000/generate at 1753380763.1039844
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_921 with payload: {'text': 'Random prompt 921 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 64, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_922 to http://0.0.0.0:30000/generate at 1753380763.104108
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_922 with payload: {'text': 'Random prompt 922 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_923 to http://0.0.0.0:30000/generate at 1753380763.104233
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_923 with payload: {'text': 'Random prompt 923 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 110, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_924 to http://0.0.0.0:30000/generate at 1753380763.104365
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_924 with payload: {'text': 'Random prompt 924 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_925 to http://0.0.0.0:30000/generate at 1753380763.104534
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_925 with payload: {'text': 'Random prompt 925 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 76, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_926 to http://0.0.0.0:30000/generate at 1753380763.1046562
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_926 with payload: {'text': 'Random prompt 926 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 139, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_927 to http://0.0.0.0:30000/generate at 1753380763.1047814
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_927 with payload: {'text': 'Random prompt 927 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_928 to http://0.0.0.0:30000/generate at 1753380763.104901
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_928 with payload: {'text': 'Random prompt 928 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_929 to http://0.0.0.0:30000/generate at 1753380763.1050255
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_929 with payload: {'text': 'Random prompt 929 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_930 to http://0.0.0.0:30000/generate at 1753380763.1051533
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_930 with payload: {'text': 'Random prompt 930 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 138, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_931 to http://0.0.0.0:30000/generate at 1753380763.1052783
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_931 with payload: {'text': 'Random prompt 931 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 136, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_932 to http://0.0.0.0:30000/generate at 1753380763.1054044
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_932 with payload: {'text': 'Random prompt 932 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 136, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_933 to http://0.0.0.0:30000/generate at 1753380763.1055322
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_933 with payload: {'text': 'Random prompt 933 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_934 to http://0.0.0.0:30000/generate at 1753380763.1056528
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_934 with payload: {'text': 'Random prompt 934 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_935 to http://0.0.0.0:30000/generate at 1753380763.1057744
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_935 with payload: {'text': 'Random prompt 935 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_936 to http://0.0.0.0:30000/generate at 1753380763.1059883
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_936 with payload: {'text': 'Random prompt 936 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_937 to http://0.0.0.0:30000/generate at 1753380763.1061597
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_937 with payload: {'text': 'Random prompt 937 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_938 to http://0.0.0.0:30000/generate at 1753380763.1062865
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_938 with payload: {'text': 'Random prompt 938 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_939 to http://0.0.0.0:30000/generate at 1753380763.106413
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_939 with payload: {'text': 'Random prompt 939 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_940 to http://0.0.0.0:30000/generate at 1753380763.1065388
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_940 with payload: {'text': 'Random prompt 940 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_941 to http://0.0.0.0:30000/generate at 1753380763.106663
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_941 with payload: {'text': 'Random prompt 941 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_942 to http://0.0.0.0:30000/generate at 1753380763.1067853
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_942 with payload: {'text': 'Random prompt 942 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_943 to http://0.0.0.0:30000/generate at 1753380763.1069093
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_943 with payload: {'text': 'Random prompt 943 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_944 to http://0.0.0.0:30000/generate at 1753380763.107034
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_944 with payload: {'text': 'Random prompt 944 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_945 to http://0.0.0.0:30000/generate at 1753380763.1071548
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_945 with payload: {'text': 'Random prompt 945 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_946 to http://0.0.0.0:30000/generate at 1753380763.1072824
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_946 with payload: {'text': 'Random prompt 946 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_947 to http://0.0.0.0:30000/generate at 1753380763.107404
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_947 with payload: {'text': 'Random prompt 947 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_948 to http://0.0.0.0:30000/generate at 1753380763.1075335
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_948 with payload: {'text': 'Random prompt 948 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_949 to http://0.0.0.0:30000/generate at 1753380763.1077018
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_949 with payload: {'text': 'Random prompt 949 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_950 to http://0.0.0.0:30000/generate at 1753380763.107827
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_950 with payload: {'text': 'Random prompt 950 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_951 to http://0.0.0.0:30000/generate at 1753380763.1079526
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_951 with payload: {'text': 'Random prompt 951 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_952 to http://0.0.0.0:30000/generate at 1753380763.108073
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_952 with payload: {'text': 'Random prompt 952 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_953 to http://0.0.0.0:30000/generate at 1753380763.1082017
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_953 with payload: {'text': 'Random prompt 953 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_954 to http://0.0.0.0:30000/generate at 1753380763.1083274
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_954 with payload: {'text': 'Random prompt 954 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_955 to http://0.0.0.0:30000/generate at 1753380763.1084476
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_955 with payload: {'text': 'Random prompt 955 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_956 to http://0.0.0.0:30000/generate at 1753380763.1085815
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_956 with payload: {'text': 'Random prompt 956 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_957 to http://0.0.0.0:30000/generate at 1753380763.1087022
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_957 with payload: {'text': 'Random prompt 957 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 118, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_958 to http://0.0.0.0:30000/generate at 1753380763.1088238
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_958 with payload: {'text': 'Random prompt 958 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_959 to http://0.0.0.0:30000/generate at 1753380763.108947
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_959 with payload: {'text': 'Random prompt 959 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_960 to http://0.0.0.0:30000/generate at 1753380763.109073
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_960 with payload: {'text': 'Random prompt 960 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 79, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_961 to http://0.0.0.0:30000/generate at 1753380763.109246
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_961 with payload: {'text': 'Random prompt 961 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_962 to http://0.0.0.0:30000/generate at 1753380763.1093707
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_962 with payload: {'text': 'Random prompt 962 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 171, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_963 to http://0.0.0.0:30000/generate at 1753380763.1094918
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_963 with payload: {'text': 'Random prompt 963 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 113, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_964 to http://0.0.0.0:30000/generate at 1753380763.1096117
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_964 with payload: {'text': 'Random prompt 964 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 137, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_965 to http://0.0.0.0:30000/generate at 1753380763.109736
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_965 with payload: {'text': 'Random prompt 965 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 139, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_966 to http://0.0.0.0:30000/generate at 1753380763.1098592
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_966 with payload: {'text': 'Random prompt 966 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_967 to http://0.0.0.0:30000/generate at 1753380763.1099803
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_967 with payload: {'text': 'Random prompt 967 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 110, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_968 to http://0.0.0.0:30000/generate at 1753380763.110107
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_968 with payload: {'text': 'Random prompt 968 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_969 to http://0.0.0.0:30000/generate at 1753380763.1102297
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_969 with payload: {'text': 'Random prompt 969 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_970 to http://0.0.0.0:30000/generate at 1753380763.110357
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_970 with payload: {'text': 'Random prompt 970 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_971 to http://0.0.0.0:30000/generate at 1753380763.1104822
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_971 with payload: {'text': 'Random prompt 971 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_972 to http://0.0.0.0:30000/generate at 1753380763.1106052
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_972 with payload: {'text': 'Random prompt 972 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_973 to http://0.0.0.0:30000/generate at 1753380763.111301
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_973 with payload: {'text': 'Random prompt 973 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_974 to http://0.0.0.0:30000/generate at 1753380763.1114333
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_974 with payload: {'text': 'Random prompt 974 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 102, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_975 to http://0.0.0.0:30000/generate at 1753380763.111563
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_975 with payload: {'text': 'Random prompt 975 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_976 to http://0.0.0.0:30000/generate at 1753380763.111686
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_976 with payload: {'text': 'Random prompt 976 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_977 to http://0.0.0.0:30000/generate at 1753380763.1118097
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_977 with payload: {'text': 'Random prompt 977 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_978 to http://0.0.0.0:30000/generate at 1753380763.1119306
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_978 with payload: {'text': 'Random prompt 978 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_979 to http://0.0.0.0:30000/generate at 1753380763.1120553
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_979 with payload: {'text': 'Random prompt 979 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_980 to http://0.0.0.0:30000/generate at 1753380763.1121826
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_980 with payload: {'text': 'Random prompt 980 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_981 to http://0.0.0.0:30000/generate at 1753380763.1123054
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_981 with payload: {'text': 'Random prompt 981 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_982 to http://0.0.0.0:30000/generate at 1753380763.1124332
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_982 with payload: {'text': 'Random prompt 982 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_983 to http://0.0.0.0:30000/generate at 1753380763.1125526
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_983 with payload: {'text': 'Random prompt 983 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_984 to http://0.0.0.0:30000/generate at 1753380763.1126988
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_984 with payload: {'text': 'Random prompt 984 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_985 to http://0.0.0.0:30000/generate at 1753380763.112871
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_985 with payload: {'text': 'Random prompt 985 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_986 to http://0.0.0.0:30000/generate at 1753380763.1129904
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_986 with payload: {'text': 'Random prompt 986 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_987 to http://0.0.0.0:30000/generate at 1753380763.1131165
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_987 with payload: {'text': 'Random prompt 987 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_988 to http://0.0.0.0:30000/generate at 1753380763.1132472
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_988 with payload: {'text': 'Random prompt 988 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_989 to http://0.0.0.0:30000/generate at 1753380763.113368
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_989 with payload: {'text': 'Random prompt 989 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_990 to http://0.0.0.0:30000/generate at 1753380763.113495
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_990 with payload: {'text': 'Random prompt 990 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_991 to http://0.0.0.0:30000/generate at 1753380763.1136153
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_991 with payload: {'text': 'Random prompt 991 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 84, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_992 to http://0.0.0.0:30000/generate at 1753380763.1137352
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_992 with payload: {'text': 'Random prompt 992 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_993 to http://0.0.0.0:30000/generate at 1753380763.1138582
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_993 with payload: {'text': 'Random prompt 993 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_994 to http://0.0.0.0:30000/generate at 1753380763.113986
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_994 with payload: {'text': 'Random prompt 994 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 160, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_995 to http://0.0.0.0:30000/generate at 1753380763.114107
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_995 with payload: {'text': 'Random prompt 995 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_996 to http://0.0.0.0:30000/generate at 1753380763.1142316
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_996 with payload: {'text': 'Random prompt 996 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_997 to http://0.0.0.0:30000/generate at 1753380763.1144052
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_997 with payload: {'text': 'Random prompt 997 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_998 to http://0.0.0.0:30000/generate at 1753380763.1145225
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_998 with payload: {'text': 'Random prompt 998 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_999 to http://0.0.0.0:30000/generate at 1753380763.1146472
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_999 with payload: {'text': 'Random prompt 999 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 100, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44532 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0,
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_66
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_66
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0,
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41688 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:56360 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_56
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_56
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:56370 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:56382 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41482 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_4
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_4
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_47
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_47
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41494 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:56380 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_3
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_3
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_0
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_0
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41508 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:56388 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41510 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_8
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_8
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_11
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_11
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_6
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_6
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_5
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_5
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_30
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_30
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_7
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_7
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41684 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44504 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41694 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44516 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41702 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] Prefill batch. #new-seq: 6, #new-token: 575, #cached-token: 49, token usage: 0.00, #running-req: 1, #queue-req: 0,
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44528 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41706 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44560 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_12
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_12
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_16
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_16
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_18
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_18
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_10
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_10
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44566 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] Prefill batch. #new-seq: 9, #new-token: 1056, #cached-token: 110, token usage: 0.00, #running-req: 1, #queue-req: 0,
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41716 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44572 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_23
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_23
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44586 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_26
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_26
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41726 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_20
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_20
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_37
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_37
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_17
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_17
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_9
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_9
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_15
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_15
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_29
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_29
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_21
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_21
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_25
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_25
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_24
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_24
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44596 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41728 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44610 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_22
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_22
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41730 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_27
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_27
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44580 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_28
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_28
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41746 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_35
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_35
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_2
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_2
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_14
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_14
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_39
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_39
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_38
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_38
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_48
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_48
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_36
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_36
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44654 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_32
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_32
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41754 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_44
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_44
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44658 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_31
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_31
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41766 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_45
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_45
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_33
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_33
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41776 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_43
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_43
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_34
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_34
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41784 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_78
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_78
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44688 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_82
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_82
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41790 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_51
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_51
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_41
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_41
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41800 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_54
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_54
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44712 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_55
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_55
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_42
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_42
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41804 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_61
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_61
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44734 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_46
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_46
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41816 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_63
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_63
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44738 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_52
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_52
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_64
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_64
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41820 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44742 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_69
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_69
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_1
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_1
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_68
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_68
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44750 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_95
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_95
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_72
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_72
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44762 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_53
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_53
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41854 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_70
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_70
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] Prefill batch. #new-seq: 20, #new-token: 2474, #cached-token: 90, token usage: 0.01, #running-req: 7, #queue-req: 0,
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44764 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_59
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_59
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] Prefill batch. #new-seq: 24, #new-token: 2960, #cached-token: 113, token usage: 0.01, #running-req: 10, #queue-req: 0,
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41868 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_73
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_73
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44770 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_13
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_13
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_76
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_76
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_58
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_58
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_85
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_85
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41884 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44790 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_60
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_60
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_79
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_79
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41898 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44792 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_87
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_87
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_57
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_57
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44794 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41908 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_83
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_83
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_19
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_19
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41926 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_40
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_40
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44812 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_74
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_74
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_96
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_96
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_71
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_71
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41936 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_89
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_89
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44826 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_65
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_65
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41944 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_93
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_93
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44828 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_77
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_77
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41948 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_91
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_91
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44836 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_75
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_75
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_99
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_99
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44842 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41956 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_62
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_62
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_50
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_50
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44850 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_88
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_88
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41966 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_80
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_80
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41976 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_81
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_81
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41990 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_84
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_84
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:42004 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_86
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_86
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:42020 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_90
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_90
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:42022 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_92
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_92
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:42026 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_94
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_94
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:42034 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_49
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_49
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:42036 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_67
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_67
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:42040 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_98
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_98
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:42048 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_97
[2025-07-25 02:12:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_97
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] Prefill batch. #new-seq: 24, #new-token: 2907, #cached-token: 115, token usage: 0.03, #running-req: 27, #queue-req: 0,
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] Prefill batch. #new-seq: 15, #new-token: 1906, #cached-token: 75, token usage: 0.04, #running-req: 34, #queue-req: 0,
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] Decode batch. #running-req: 49, #token: 6808, token usage: 0.06, cuda graph: True, gen throughput (token/s): 172.03, #queue-req: 0,
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] Decode batch. #running-req: 51, #token: 7256, token usage: 0.06, cuda graph: True, gen throughput (token/s): 346.57, #queue-req: 0,
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:43] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:43] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] Decode batch. #running-req: 49, #token: 8768, token usage: 0.07, cuda graph: True, gen throughput (token/s): 3779.53, #queue-req: 0,
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] Decode batch. #running-req: 51, #token: 9296, token usage: 0.08, cuda graph: True, gen throughput (token/s): 3903.54, #queue-req: 0,
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_73 received DONE after 67 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_73 completed: 255 chars, 67 chunks, TTFT=615.7ms
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] INFO:     127.0.0.1:44764 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_100
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_100
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_49 received DONE after 67 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_49 completed: 69 chars, 67 chunks, TTFT=630.5ms
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] INFO:     127.0.0.1:42034 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_47 received DONE after 68 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_47 completed: 265 chars, 68 chunks, TTFT=298.8ms
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_101
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_101
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] INFO:     127.0.0.1:56382 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_102
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_102
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_19 received DONE after 68 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_19 completed: 272 chars, 68 chunks, TTFT=641.7ms
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] INFO:     127.0.0.1:41908 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_103
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_103
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_13 received DONE after 69 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_13 completed: 276 chars, 69 chunks, TTFT=644.0ms
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_30 received DONE after 69 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_30 completed: 71 chars, 69 chunks, TTFT=268.3ms
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] INFO:     127.0.0.1:41508 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] INFO:     127.0.0.1:44860 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_105
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_105
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_104
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_104
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] Prefill batch. #new-seq: 2, #new-token: 280, #cached-token: 10, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_72 received DONE after 70 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_72 completed: 191 chars, 70 chunks, TTFT=507.8ms
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] INFO:     127.0.0.1:44750 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] Prefill batch. #new-seq: 2, #new-token: 219, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_106
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_106
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_34 received DONE after 74 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_34 completed: 286 chars, 74 chunks, TTFT=446.3ms
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] INFO:     127.0.0.1:41776 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_38 received DONE after 73 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_38 completed: 279 chars, 73 chunks, TTFT=516.9ms
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_107
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_107
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] INFO:     127.0.0.1:44632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_108
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_108
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_81 received DONE after 75 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_81 completed: 296 chars, 75 chunks, TTFT=620.8ms
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] INFO:     127.0.0.1:41976 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_109
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_109
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_67 received DONE after 78 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_67 completed: 301 chars, 78 chunks, TTFT=625.5ms
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] INFO:     127.0.0.1:44864 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_33 received DONE after 79 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_33 completed: 306 chars, 79 chunks, TTFT=446.2ms
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_110
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_110
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] INFO:     127.0.0.1:41766 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_111
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_111
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_87 received DONE after 86 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_87 completed: 331 chars, 86 chunks, TTFT=611.0ms
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] INFO:     127.0.0.1:44792 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_112
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_112
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_16 received DONE after 87 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_16 completed: 87 chars, 87 chunks, TTFT=453.8ms
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_0 received DONE after 88 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_0 completed: 90 chars, 88 chunks, TTFT=217.2ms
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_95 received DONE after 87 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_95 completed: 348 chars, 87 chunks, TTFT=428.2ms
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] INFO:     127.0.0.1:44880 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] INFO:     127.0.0.1:41824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_115
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_115
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_113
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_113
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] INFO:     127.0.0.1:41486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_114
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_114
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_97 received DONE after 88 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_97 completed: 92 chars, 88 chunks, TTFT=616.7ms
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] INFO:     127.0.0.1:42048 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_116
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_116
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] Prefill batch. #new-seq: 2, #new-token: 306, #cached-token: 12, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_10 received DONE after 92 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_10 completed: 257 chars, 92 chunks, TTFT=276.8ms
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_96 received DONE after 93 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_96 completed: 365 chars, 93 chunks, TTFT=609.7ms
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_78 received DONE after 93 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_78 completed: 94 chars, 93 chunks, TTFT=505.9ms
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] INFO:     127.0.0.1:41746 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] INFO:     127.0.0.1:44676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_32 received DONE after 93 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_32 completed: 372 chars, 93 chunks, TTFT=446.7ms
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] INFO:     127.0.0.1:44812 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_119
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_119
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_117
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_117
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_118
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_118
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] INFO:     127.0.0.1:44890 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:44] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 6, token usage: 0.07, #running-req: 43, #queue-req: 0,
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_71 received DONE after 94 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_71 completed: 186 chars, 94 chunks, TTFT=622.6ms
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_94 received DONE after 94 chunks
[2025-07-25 02:12:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_94 completed: 365 chars, 94 chunks, TTFT=617.0ms
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] Decode batch. #running-req: 50, #token: 9947, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2811.34, #queue-req: 0,
[2025-07-25 02:12:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:44] Prefill batch. #new-seq: 3, #new-token: 425, #cached-token: 17, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_46 received DONE after 94 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_46 completed: 94 chars, 94 chunks, TTFT=442.1ms
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_120
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_120
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44532 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41804 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_89 received DONE after 95 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_89 completed: 96 chars, 95 chunks, TTFT=611.4ms
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_66 received DONE after 96 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_66 completed: 188 chars, 96 chunks, TTFT=202.9ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:42026 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_122
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_122
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_121
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_121
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_123
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_123
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_124
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_124
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_125
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_125
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] Prefill batch. #new-seq: 3, #new-token: 367, #cached-token: 18, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] Prefill batch. #new-seq: 2, #new-token: 194, #cached-token: 10, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_8 received DONE after 97 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_8 completed: 298 chars, 97 chunks, TTFT=314.2ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:56380 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_126
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_126
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 6, token usage: 0.09, #running-req: 53, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] Decode batch. #running-req: 47, #token: 9468, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2550.32, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_69 received DONE after 102 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_69 completed: 404 chars, 102 chunks, TTFT=509.0ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41684 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_42 received DONE after 105 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_42 completed: 291 chars, 105 chunks, TTFT=442.3ms
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_28 received DONE after 105 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_28 completed: 416 chars, 105 chunks, TTFT=447.4ms
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_21 received DONE after 103 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_21 completed: 203 chars, 103 chunks, TTFT=309.1ms
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_70 received DONE after 103 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_70 completed: 397 chars, 103 chunks, TTFT=616.8ms
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_127
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_127
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44762 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_128
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_128
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41800 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_129
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_129
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] Prefill batch. #new-seq: 2, #new-token: 298, #cached-token: 12, token usage: 0.08, #running-req: 45, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_131
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_131
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44528 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_130
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_130
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_39 received DONE after 105 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_39 completed: 416 chars, 105 chunks, TTFT=517.5ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44596 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_132
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_132
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] Prefill batch. #new-seq: 2, #new-token: 193, #cached-token: 10, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_36 received DONE after 109 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_36 completed: 108 chars, 109 chunks, TTFT=519.0ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41702 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_133
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_133
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_99 received DONE after 110 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_99 completed: 217 chars, 110 chunks, TTFT=607.7ms
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_55 received DONE after 110 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_55 completed: 426 chars, 110 chunks, TTFT=513.0ms
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_68 received DONE after 110 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_68 completed: 467 chars, 110 chunks, TTFT=509.4ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:42036 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44712 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_135
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_135
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_136
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_136
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_134
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_134
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] Prefill batch. #new-seq: 2, #new-token: 310, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_76 received DONE after 114 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_76 completed: 441 chars, 114 chunks, TTFT=615.0ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41868 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_137
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_137
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_57 received DONE after 115 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_57 completed: 115 chars, 115 chunks, TTFT=628.2ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44770 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_138
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_138
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_82 received DONE after 117 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_82 completed: 468 chars, 117 chunks, TTFT=431.4ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41784 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_139
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_139
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_63 received DONE after 118 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_63 completed: 233 chars, 118 chunks, TTFT=510.1ms
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_75 received DONE after 119 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_75 completed: 476 chars, 119 chunks, TTFT=621.2ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44734 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_140
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_140
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41948 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_141
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_141
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_64 received DONE after 119 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_64 completed: 118 chars, 119 chunks, TTFT=508.4ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44738 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_142
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_142
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_58 received DONE after 125 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_58 completed: 347 chars, 125 chunks, TTFT=625.8ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_85 received DONE after 125 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_85 completed: 246 chars, 125 chunks, TTFT=612.3ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_143
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_143
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 100, #cached-token: 6, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_25 received DONE after 126 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_25 completed: 491 chars, 126 chunks, TTFT=524.1ms
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_144
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_144
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41898 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_145
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_145
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_9 received DONE after 128 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_9 completed: 498 chars, 128 chunks, TTFT=313.7ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:42060 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_146
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_146
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] Prefill batch. #new-seq: 2, #new-token: 205, #cached-token: 12, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_93 received DONE after 131 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_93 completed: 132 chars, 131 chunks, TTFT=610.3ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44826 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_147
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_147
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_51 received DONE after 133 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_51 completed: 528 chars, 133 chunks, TTFT=513.8ms
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_1 received DONE after 133 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_1 completed: 525 chars, 133 chunks, TTFT=460.4ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41820 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_148
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_148
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44688 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_149
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_149
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_40 received DONE after 134 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_40 completed: 264 chars, 134 chunks, TTFT=626.1ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:42066 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_150
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_150
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 5, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] Decode batch. #running-req: 47, #token: 9710, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2315.77, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_17 received DONE after 138 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_17 completed: 548 chars, 138 chunks, TTFT=525.8ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44560 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_151
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_151
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 6, token usage: 0.08, #running-req: 45, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_100 received DONE after 72 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_100 completed: 194 chars, 72 chunks, TTFT=1524.8ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44764 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_31 received DONE after 140 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_31 completed: 279 chars, 140 chunks, TTFT=445.7ms
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_152
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_152
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41754 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_153
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_153
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_92 received DONE after 142 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_92 completed: 559 chars, 142 chunks, TTFT=617.6ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] Decode batch. #running-req: 52, #token: 10607, token usage: 0.09, cuda graph: True, gen throughput (token/s): 2461.89, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_154
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_154
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_86 received DONE after 143 chunks
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_86 completed: 562 chars, 143 chunks, TTFT=619.6ms
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:42004 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_155
[2025-07-25 02:12:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_155
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:45] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:45] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_59 received DONE after 144 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_59 completed: 148 chars, 144 chunks, TTFT=627.4ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41854 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_156
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_156
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 6, token usage: 0.09, #running-req: 53, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_45 received DONE after 144 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_45 completed: 562 chars, 144 chunks, TTFT=516.1ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44658 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_157
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_157
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_43 received DONE after 145 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_43 completed: 491 chars, 145 chunks, TTFT=516.2ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:42022 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_158
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_158
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_91 received DONE after 148 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_91 completed: 588 chars, 148 chunks, TTFT=611.2ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44828 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_5 received DONE after 148 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_5 completed: 148 chars, 148 chunks, TTFT=279.3ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_159
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_159
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41510 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_160
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_160
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_77 received DONE after 151 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_77 completed: 424 chars, 151 chunks, TTFT=620.9ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_161
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_161
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 5, token usage: 0.08, #running-req: 45, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_6 received DONE after 153 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_6 completed: 427 chars, 153 chunks, TTFT=278.7ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_20 received DONE after 154 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_20 completed: 612 chars, 154 chunks, TTFT=309.3ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_35 received DONE after 154 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_35 completed: 603 chars, 154 chunks, TTFT=519.7ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41494 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_14 received DONE after 155 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_14 completed: 616 chars, 155 chunks, TTFT=528.5ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41944 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_163
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_163
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_164
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_164
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_162
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_162
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:42076 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] Prefill batch. #new-seq: 3, #new-token: 383, #cached-token: 18, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_165
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_165
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_105 received DONE after 87 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_105 completed: 86 chars, 87 chunks, TTFT=1539.4ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44610 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 5, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_166
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_166
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_65 received DONE after 158 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_65 completed: 629 chars, 158 chunks, TTFT=625.9ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_167
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_167
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_109 received DONE after 85 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_109 completed: 231 chars, 85 chunks, TTFT=1669.5ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41976 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_168
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_168
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_37 received DONE after 158 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_37 completed: 442 chars, 158 chunks, TTFT=518.8ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44586 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_169
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_169
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_3 received DONE after 159 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_3 completed: 160 chars, 159 chunks, TTFT=316.5ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41936 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_170
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_170
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 149, #cached-token: 5, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_56 received DONE after 162 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_56 completed: 648 chars, 162 chunks, TTFT=259.3ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:56370 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_171
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_171
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_98 received DONE after 164 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_98 completed: 656 chars, 164 chunks, TTFT=616.0ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:42040 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_172
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_172
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_41 received DONE after 165 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_41 completed: 167 chars, 165 chunks, TTFT=443.3ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_80 received DONE after 165 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_80 completed: 650 chars, 165 chunks, TTFT=620.9ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_116 received DONE after 77 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_116 completed: 291 chars, 77 chunks, TTFT=1928.3ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44516 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:42048 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44572 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_53 received DONE after 166 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_53 completed: 654 chars, 166 chunks, TTFT=627.8ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_173
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_173
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_175
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_175
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_174
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_174
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] Prefill batch. #new-seq: 2, #new-token: 234, #cached-token: 12, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_176
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_176
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_62 received DONE after 163 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_62 completed: 639 chars, 163 chunks, TTFT=619.5ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] Prefill batch. #new-seq: 2, #new-token: 233, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44842 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_177
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_177
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_4 received DONE after 168 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_4 completed: 167 chars, 168 chunks, TTFT=315.2ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_27 received DONE after 172 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_27 completed: 176 chars, 172 chunks, TTFT=448.8ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41730 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_178
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_178
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:56360 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_179
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_179
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_7 received DONE after 173 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_7 completed: 515 chars, 173 chunks, TTFT=278.3ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_180
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_180
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44836 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_111 received DONE after 94 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_111 completed: 185 chars, 94 chunks, TTFT=1777.9ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_26 received DONE after 174 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_26 completed: 346 chars, 174 chunks, TTFT=450.0ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_181
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_181
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_182
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_182
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_29 received DONE after 171 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_29 completed: 478 chars, 171 chunks, TTFT=521.4ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_126 received DONE after 76 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_126 completed: 286 chars, 76 chunks, TTFT=2099.7ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41766 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:56380 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_184
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_184
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_183
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_183
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 5, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_60 received DONE after 176 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_60 completed: 180 chars, 176 chunks, TTFT=625.6ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_119 received DONE after 82 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_119 completed: 83 chars, 82 chunks, TTFT=2053.1ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_50 received DONE after 176 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_50 completed: 695 chars, 176 chunks, TTFT=630.0ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41746 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44566 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_185
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_185
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41956 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_186
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_186
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_187
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_187
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] Prefill batch. #new-seq: 2, #new-token: 260, #cached-token: 12, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] Prefill batch. #new-seq: 3, #new-token: 451, #cached-token: 18, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] Decode batch. #running-req: 52, #token: 9893, token usage: 0.08, cuda graph: True, gen throughput (token/s): 1993.04, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_18 received DONE after 181 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_18 completed: 724 chars, 181 chunks, TTFT=452.0ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44742 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_48 received DONE after 176 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_48 completed: 697 chars, 176 chunks, TTFT=515.5ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_188
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_188
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] Decode batch. #running-req: 47, #token: 9121, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2296.51, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41706 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_22 received DONE after 182 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_22 completed: 182 chars, 182 chunks, TTFT=451.9ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_189
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_189
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_2 received DONE after 177 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_2 completed: 696 chars, 177 chunks, TTFT=532.3ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_190
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_190
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41816 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_44 received DONE after 178 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_44 completed: 177 chars, 178 chunks, TTFT=515.1ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_83 received DONE after 178 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_83 completed: 708 chars, 178 chunks, TTFT=613.2ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_52 received DONE after 184 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_52 completed: 736 chars, 184 chunks, TTFT=439.1ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_191
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_191
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41728 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44794 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_193
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_193
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_192
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_192
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44654 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_194
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_194
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] Prefill batch. #new-seq: 3, #new-token: 357, #cached-token: 15, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] Prefill batch. #new-seq: 2, #new-token: 318, #cached-token: 12, token usage: 0.06, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_132 received DONE after 75 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_132 completed: 296 chars, 75 chunks, TTFT=2272.8ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41884 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_195
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_195
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_24 received DONE after 185 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_24 completed: 187 chars, 185 chunks, TTFT=449.9ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_84 received DONE after 185 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_84 completed: 369 chars, 185 chunks, TTFT=620.3ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_12 received DONE after 185 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_12 completed: 730 chars, 185 chunks, TTFT=455.5ms
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_90 received DONE after 185 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_90 completed: 740 chars, 185 chunks, TTFT=618.9ms
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44596 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.metrics_collector] [INFO] Completed 100 requests, success rate: 100.0%
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_196
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_196
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:42020 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44580 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] INFO:     127.0.0.1:41990 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_198
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_198
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_197
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_197
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_199
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_199
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:46] Prefill batch. #new-seq: 3, #new-token: 443, #cached-token: 18, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] Prefill batch. #new-seq: 2, #new-token: 329, #cached-token: 12, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:46] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_112 received DONE after 94 chunks
[2025-07-25 02:12:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_112 completed: 360 chars, 94 chunks, TTFT=1900.9ms
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44792 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_135 received DONE after 75 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_135 completed: 296 chars, 75 chunks, TTFT=2400.0ms
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_200
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_200
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_23 received DONE after 188 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_23 completed: 374 chars, 188 chunks, TTFT=450.2ms
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41716 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44504 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_15 received DONE after 183 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_15 completed: 362 chars, 183 chunks, TTFT=311.4ms
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_201
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_201
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_202
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_202
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 5, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:42036 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_106 received DONE after 116 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_106 completed: 117 chars, 116 chunks, TTFT=1555.1ms
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_203
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_203
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_74 received DONE after 190 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_74 completed: 751 chars, 190 chunks, TTFT=622.8ms
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44750 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_204
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_204
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41926 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_205
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_205
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] Prefill batch. #new-seq: 2, #new-token: 221, #cached-token: 12, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] Prefill batch. #new-seq: 2, #new-token: 240, #cached-token: 10, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_79 received DONE after 187 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_79 completed: 371 chars, 187 chunks, TTFT=614.3ms
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44790 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_206
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_206
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_11 received DONE after 191 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_11 completed: 760 chars, 191 chunks, TTFT=313.0ms
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41694 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_61 received DONE after 191 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_61 completed: 192 chars, 191 chunks, TTFT=511.2ms
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_207
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_207
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_88 received DONE after 192 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_88 completed: 683 chars, 192 chunks, TTFT=612.0ms
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44850 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_208
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_208
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 146, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 62, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_54 received DONE after 193 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_54 completed: 192 chars, 193 chunks, TTFT=513.0ms
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_209
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_209
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41726 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_118 received DONE after 99 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_118 completed: 392 chars, 99 chunks, TTFT=2068.8ms
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_210
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_210
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44812 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_211
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_211
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 5, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] Prefill batch. #new-seq: 2, #new-token: 232, #cached-token: 12, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_129 received DONE after 98 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_129 completed: 99 chars, 98 chunks, TTFT=2274.3ms
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_133 received DONE after 93 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_133 completed: 368 chars, 93 chunks, TTFT=2400.1ms
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_212
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_212
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_213
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_213
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 145, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_113 received DONE after 134 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_113 completed: 520 chars, 134 chunks, TTFT=1919.0ms
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] Decode batch. #running-req: 48, #token: 9218, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2568.81, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:56388 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_214
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_214
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] Decode batch. #running-req: 52, #token: 9939, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2689.63, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_127 received DONE after 117 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_127 completed: 464 chars, 117 chunks, TTFT=2274.7ms
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41684 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_215
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_215
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_168 received DONE after 66 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_168 completed: 260 chars, 66 chunks, TTFT=3407.8ms
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_128 received DONE after 113 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_128 completed: 480 chars, 113 chunks, TTFT=2272.8ms
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41976 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_216
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_216
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44762 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_217
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_217
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 103, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_159 received DONE after 69 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_159 completed: 272 chars, 69 chunks, TTFT=3183.8ms
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_156 received DONE after 85 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_156 completed: 333 chars, 85 chunks, TTFT=3055.2ms
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44828 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_218
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_218
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_219
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_219
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_141 received DONE after 110 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_141 completed: 436 chars, 110 chunks, TTFT=2550.9ms
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41948 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_220
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_220
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 145, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_114 received DONE after 141 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_114 completed: 142 chars, 141 chunks, TTFT=1928.5ms
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44900 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_125 received DONE after 136 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_125 completed: 531 chars, 136 chunks, TTFT=2061.8ms
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_221
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_221
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 5, token usage: 0.09, #running-req: 53, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_222
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_222
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_144 received DONE after 99 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_144 completed: 98 chars, 99 chunks, TTFT=2717.4ms
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_115 received DONE after 139 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_115 completed: 440 chars, 139 chunks, TTFT=1900.5ms
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44880 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_224
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_224
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 6, token usage: 0.08, #running-req: 45, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_223
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_223
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 95, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_131 received DONE after 128 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_131 completed: 252 chars, 128 chunks, TTFT=2274.3ms
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41800 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_108 received DONE after 154 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_108 completed: 612 chars, 154 chunks, TTFT=1669.5ms
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_225
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_225
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_226
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_226
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_107 received DONE after 162 chunks
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_107 completed: 630 chars, 162 chunks, TTFT=1669.6ms
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:47] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41776 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_227
[2025-07-25 02:12:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_227
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:47] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_161 received DONE after 81 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_161 completed: 82 chars, 81 chunks, TTFT=3288.3ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41854 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 175, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_164 received DONE after 86 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_164 completed: 238 chars, 86 chunks, TTFT=3298.6ms
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_228
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_228
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_229
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_229
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_137 received DONE after 128 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_137 completed: 127 chars, 128 chunks, TTFT=2471.5ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_230
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_230
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 5, token usage: 0.09, #running-req: 53, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_187 received DONE after 74 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_187 completed: 75 chars, 74 chunks, TTFT=3752.2ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41956 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_231
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_231
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_177 received DONE after 79 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_177 completed: 154 chars, 79 chunks, TTFT=3559.8ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 6, token usage: 0.08, #running-req: 45, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41868 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_232
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_232
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_138 received DONE after 127 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_138 completed: 126 chars, 127 chunks, TTFT=2499.2ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44770 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_233
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_233
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_124 received DONE after 149 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_124 completed: 592 chars, 149 chunks, TTFT=2093.1ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41944 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_234
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_234
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] Prefill batch. #new-seq: 2, #new-token: 221, #cached-token: 12, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_103 received DONE after 184 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_103 completed: 185 chars, 184 chunks, TTFT=1539.6ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_235
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_235
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_102 received DONE after 178 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_102 completed: 708 chars, 178 chunks, TTFT=1555.5ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41908 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_236
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_236
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_184 received DONE after 78 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_184 completed: 77 chars, 78 chunks, TTFT=3741.9ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:56380 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_237
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_237
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_194 received DONE after 71 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_194 completed: 138 chars, 71 chunks, TTFT=3907.0ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41702 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_110 received DONE after 169 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_110 completed: 168 chars, 169 chunks, TTFT=1770.4ms
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_238
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_238
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44864 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_239
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_239
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_201 received DONE after 68 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_201 completed: 188 chars, 68 chunks, TTFT=4069.2ms
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_101 received DONE after 189 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_101 completed: 190 chars, 189 chunks, TTFT=1536.3ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:42034 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44654 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_241
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_241
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_240
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_240
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 5, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_139 received DONE after 141 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_139 completed: 548 chars, 141 chunks, TTFT=2547.9ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44504 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_202 received DONE after 68 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_202 completed: 133 chars, 68 chunks, TTFT=4064.8ms
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_190 received DONE after 74 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_190 completed: 312 chars, 74 chunks, TTFT=3903.1ms
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_242
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_242
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41784 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41716 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_244
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_244
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_243
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_243
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] Prefill batch. #new-seq: 2, #new-token: 172, #cached-token: 12, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] Decode batch. #running-req: 47, #token: 9150, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2107.07, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_123 received DONE after 169 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_123 completed: 334 chars, 169 chunks, TTFT=2062.0ms
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_162 received DONE after 108 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_162 completed: 425 chars, 108 chunks, TTFT=3298.8ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41494 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] Decode batch. #running-req: 51, #token: 10807, token usage: 0.09, cuda graph: True, gen throughput (token/s): 2330.85, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_246
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_246
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_143 received DONE after 137 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_143 completed: 136 chars, 137 chunks, TTFT=2717.8ms
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_245
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_245
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_247
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_247
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_199 received DONE after 82 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_199 completed: 310 chars, 82 chunks, TTFT=3950.8ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:56382 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_248
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_248
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_169 received DONE after 102 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_169 completed: 105 chars, 102 chunks, TTFT=3408.4ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41990 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_104 received DONE after 192 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_104 completed: 764 chars, 192 chunks, TTFT=1555.1ms
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_249
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_249
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44860 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_250
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_250
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 99, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_173 received DONE after 98 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_173 completed: 97 chars, 98 chunks, TTFT=3560.3ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44516 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_130 received DONE after 158 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_130 completed: 312 chars, 158 chunks, TTFT=2273.0ms
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_251
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_251
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:42026 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_252
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_252
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 171, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_134 received DONE after 152 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_134 completed: 591 chars, 152 chunks, TTFT=2415.7ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_253
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_253
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_121 received DONE after 187 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_121 completed: 731 chars, 187 chunks, TTFT=2062.1ms
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_122 received DONE after 175 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_122 completed: 176 chars, 175 chunks, TTFT=2093.5ms
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_142 received DONE after 152 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_142 completed: 155 chars, 152 chunks, TTFT=2578.4ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41804 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44532 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_255
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_255
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_254
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_254
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44738 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_256
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_256
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] Prefill batch. #new-seq: 2, #new-token: 264, #cached-token: 12, token usage: 0.09, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_117 received DONE after 177 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_117 completed: 350 chars, 177 chunks, TTFT=2068.9ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41482 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_257
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_257
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_181 received DONE after 109 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_181 completed: 214 chars, 109 chunks, TTFT=3735.9ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_258
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_258
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 150, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_120 received DONE after 179 chunks
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_120 completed: 712 chars, 179 chunks, TTFT=2068.3ms
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_259
[2025-07-25 02:12:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_259
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:48] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:48] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_150 received DONE after 156 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_150 completed: 620 chars, 156 chunks, TTFT=2866.2ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:42066 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_260
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_260
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 140, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_147 received DONE after 149 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_147 completed: 592 chars, 149 chunks, TTFT=2822.4ms
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_188 received DONE after 104 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_188 completed: 107 chars, 104 chunks, TTFT=3899.4ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41966 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_212 received DONE after 86 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44742 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_212 completed: 337 chars, 86 chunks, TTFT=4373.5ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 5, token usage: 0.09, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_262
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_262
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_261
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_261
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_263
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_263
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] Prefill batch. #new-seq: 2, #new-token: 206, #cached-token: 12, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_154 received DONE after 144 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_154 completed: 572 chars, 144 chunks, TTFT=3011.2ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_264
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_264
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_153 received DONE after 152 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_153 completed: 155 chars, 152 chunks, TTFT=3018.0ms
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_146 received DONE after 167 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_146 completed: 168 chars, 167 chunks, TTFT=2732.7ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:42060 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44712 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_192 received DONE after 109 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_192 completed: 432 chars, 109 chunks, TTFT=3906.3ms
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_136 received DONE after 174 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_136 completed: 175 chars, 174 chunks, TTFT=2415.4ms
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_265
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_265
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_266
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_266
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44794 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41754 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_268
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_268
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_203 received DONE after 106 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_203 completed: 407 chars, 106 chunks, TTFT=4072.9ms
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_267
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_267
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:42036 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_269
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_269
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 2, #new-token: 257, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_167 received DONE after 130 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_167 completed: 257 chars, 130 chunks, TTFT=3407.8ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] Prefill batch. #new-seq: 2, #new-token: 250, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_270
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_270
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 5, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_175 received DONE after 134 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_175 completed: 532 chars, 134 chunks, TTFT=3532.2ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:42048 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_271
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_271
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_140 received DONE after 171 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_140 completed: 680 chars, 171 chunks, TTFT=2576.8ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_216 received DONE after 76 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_216 completed: 77 chars, 76 chunks, TTFT=4689.5ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41976 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_273
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_273
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44734 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_272
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_272
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_208 received DONE after 100 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_208 completed: 277 chars, 100 chunks, TTFT=4268.0ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44850 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_274
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_274
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] Decode batch. #running-req: 51, #token: 10162, token usage: 0.09, cuda graph: True, gen throughput (token/s): 2290.31, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_152 received DONE after 154 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_152 completed: 304 chars, 154 chunks, TTFT=3003.7ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41790 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_155 received DONE after 161 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_155 completed: 160 chars, 161 chunks, TTFT=3041.0ms
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_275
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_275
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44764 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_276
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_276
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_145 received DONE after 177 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_145 completed: 495 chars, 177 chunks, TTFT=2720.9ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41898 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_277
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_277
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Decode batch. #running-req: 49, #token: 10182, token usage: 0.09, cuda graph: True, gen throughput (token/s): 2191.09, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_170 received DONE after 144 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_170 completed: 449 chars, 144 chunks, TTFT=3457.5ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44826 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_278
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_278
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 6, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_148 received DONE after 174 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_148 completed: 748 chars, 174 chunks, TTFT=2860.9ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41820 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_279
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_279
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_172 received DONE after 146 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_172 completed: 147 chars, 146 chunks, TTFT=3528.1ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44890 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_280
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_280
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 5, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_179 received DONE after 133 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_179 completed: 264 chars, 133 chunks, TTFT=3686.2ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:42040 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_281
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_281
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_221 received DONE after 83 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_221 completed: 87 chars, 83 chunks, TTFT=4792.1ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44900 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_282
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_282
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 6, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_149 received DONE after 175 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_149 completed: 177 chars, 175 chunks, TTFT=2835.1ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41936 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_215 received DONE after 93 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_215 completed: 368 chars, 93 chunks, TTFT=4663.1ms
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_283
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_283
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41684 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_284
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_284
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] Prefill batch. #new-seq: 2, #new-token: 208, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_160 received DONE after 171 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_160 completed: 170 chars, 171 chunks, TTFT=3205.4ms
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_210 received DONE after 120 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_210 completed: 476 chars, 120 chunks, TTFT=4263.5ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44688 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_174 received DONE after 145 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_174 completed: 577 chars, 145 chunks, TTFT=3560.1ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44572 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_285
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_285
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 6, token usage: 0.09, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_286
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_286
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41726 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_287
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_287
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_204 received DONE after 127 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_204 completed: 505 chars, 127 chunks, TTFT=4067.7ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44750 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_288
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_288
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_207 received DONE after 122 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_207 completed: 472 chars, 122 chunks, TTFT=4261.4ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41694 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_289
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_289
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_191 received DONE after 140 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_191 completed: 542 chars, 140 chunks, TTFT=3930.4ms
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_158 received DONE after 177 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_158 completed: 350 chars, 177 chunks, TTFT=3136.1ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:56360 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_290
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_290
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44528 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_291
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_291
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_165 received DONE after 170 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_165 completed: 664 chars, 170 chunks, TTFT=3298.3ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:42076 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_292
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_292
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_193 received DONE after 144 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_193 completed: 569 chars, 144 chunks, TTFT=3930.0ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44586 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_293
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_293
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_151 received DONE after 171 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_151 completed: 341 chars, 171 chunks, TTFT=2983.3ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_294
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_294
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44560 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_233 received DONE after 68 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_233 completed: 70 chars, 68 chunks, TTFT=5233.1ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41728 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_295
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_295
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_176 received DONE after 165 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_176 completed: 653 chars, 165 chunks, TTFT=3538.8ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_163 received DONE after 159 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_163 completed: 161 chars, 159 chunks, TTFT=3312.7ms
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_296
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_296
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_297
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_297
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 89, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_182 received DONE after 145 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_182 completed: 580 chars, 145 chunks, TTFT=3735.5ms
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:42022 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_247 received DONE after 69 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_247 completed: 227 chars, 69 chunks, TTFT=5535.8ms
[2025-07-25 02:12:49] [sglang_test_framework.core.metrics_collector] [INFO] Completed 200 requests, success rate: 100.0%
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_298
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_298
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44812 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_211 received DONE after 122 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_211 completed: 124 chars, 122 chunks, TTFT=4271.6ms
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_299
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_299
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] INFO:     127.0.0.1:44626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:49] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_178 received DONE after 162 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_178 completed: 631 chars, 162 chunks, TTFT=3659.5ms
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_227 received DONE after 100 chunks
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_227 completed: 396 chars, 100 chunks, TTFT=4930.7ms
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_300
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_300
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_301
[2025-07-25 02:12:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_301
[2025-07-25 02:12:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:49] INFO:     127.0.0.1:41730 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44770 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_219 received DONE after 99 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_219 completed: 383 chars, 99 chunks, TTFT=4703.3ms
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_302
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_302
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41776 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_303
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_303
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] Prefill batch. #new-seq: 2, #new-token: 272, #cached-token: 12, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] Prefill batch. #new-seq: 2, #new-token: 200, #cached-token: 10, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_189 received DONE after 156 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_189 completed: 155 chars, 156 chunks, TTFT=3902.3ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44828 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_186 received DONE after 152 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_186 completed: 595 chars, 152 chunks, TTFT=3741.5ms
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_304
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_304
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41706 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_305
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_305
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_157 received DONE after 177 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_157 completed: 696 chars, 177 chunks, TTFT=3108.7ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44658 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_306
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_306
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_232 received DONE after 92 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_232 completed: 95 chars, 92 chunks, TTFT=5209.6ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44566 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_307
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_307
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] Prefill batch. #new-seq: 2, #new-token: 229, #cached-token: 12, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] Decode batch. #running-req: 47, #token: 9223, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2286.14, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_231 received DONE after 94 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_231 completed: 372 chars, 94 chunks, TTFT=5205.8ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41956 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_308
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_308
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_166 received DONE after 171 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_166 completed: 171 chars, 171 chunks, TTFT=3315.8ms
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_246 received DONE after 82 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_246 completed: 85 chars, 82 chunks, TTFT=5533.1ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44610 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_309
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_309
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44842 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_310
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_310
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] Prefill batch. #new-seq: 2, #new-token: 214, #cached-token: 11, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_252 received DONE after 80 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_252 completed: 304 chars, 80 chunks, TTFT=5657.5ms
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_222 received DONE after 120 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_222 completed: 236 chars, 120 chunks, TTFT=4792.1ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:42026 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_311
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_311
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_312
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_312
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] Prefill batch. #new-seq: 2, #new-token: 135, #cached-token: 12, token usage: 0.08, #running-req: 44, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_205 received DONE after 164 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_205 completed: 652 chars, 164 chunks, TTFT=4072.5ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44906 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] Decode batch. #running-req: 54, #token: 10508, token usage: 0.09, cuda graph: True, gen throughput (token/s): 2112.71, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_313
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_313
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 6, token usage: 0.09, #running-req: 54, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_239 received DONE after 88 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_239 completed: 175 chars, 88 chunks, TTFT=5364.2ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41926 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_314
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_314
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 168, #cached-token: 6, token usage: 0.08, #running-req: 45, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_198 received DONE after 160 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_198 completed: 628 chars, 160 chunks, TTFT=3952.3ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44580 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_206 received DONE after 151 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_206 completed: 300 chars, 151 chunks, TTFT=4163.3ms
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_315
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_315
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41766 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_183 received DONE after 184 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_183 completed: 732 chars, 184 chunks, TTFT=3752.8ms
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_316
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_316
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41494 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_317
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_317
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 150, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] Prefill batch. #new-seq: 2, #new-token: 196, #cached-token: 12, token usage: 0.07, #running-req: 43, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_195 received DONE after 177 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_195 completed: 178 chars, 177 chunks, TTFT=3951.5ms
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_185 received DONE after 185 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_185 completed: 186 chars, 185 chunks, TTFT=3752.7ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44790 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41746 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_319
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_319
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_318
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_318
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 6, token usage: 0.09, #running-req: 53, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_226 received DONE after 115 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_226 completed: 448 chars, 115 chunks, TTFT=4913.3ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_320
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_320
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 5, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_200 received DONE after 161 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_200 completed: 644 chars, 161 chunks, TTFT=4063.8ms
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_258 received DONE after 72 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_258 completed: 285 chars, 72 chunks, TTFT=5893.1ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41884 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_253 received DONE after 80 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_253 completed: 80 chars, 80 chunks, TTFT=5754.0ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 153, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 5, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_322
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_322
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_321
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_321
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41868 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_323
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_323
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_224 received DONE after 118 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_224 completed: 118 chars, 118 chunks, TTFT=4910.8ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44880 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_324
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_324
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_265 received DONE after 74 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_265 completed: 279 chars, 74 chunks, TTFT=6164.3ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:42060 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_325
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_325
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:42086 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44910 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_171 received DONE after 190 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_171 completed: 818 chars, 190 chunks, TTFT=3468.3ms
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_273 received DONE after 70 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_273 completed: 264 chars, 70 chunks, TTFT=6284.0ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_264 received DONE after 65 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_264 completed: 260 chars, 65 chunks, TTFT=6150.4ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_326
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_326
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:56370 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_328
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_328
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41976 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_327
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_327
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_197 received DONE after 189 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_197 completed: 739 chars, 189 chunks, TTFT=3951.2ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:42020 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_218 received DONE after 148 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_218 completed: 592 chars, 148 chunks, TTFT=4691.9ms
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_329
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_329
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_330
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_330
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] Prefill batch. #new-seq: 2, #new-token: 200, #cached-token: 12, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_229 received DONE after 116 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_229 completed: 460 chars, 116 chunks, TTFT=5083.2ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_331
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_331
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 5, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_235 received DONE after 111 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_235 completed: 432 chars, 111 chunks, TTFT=5239.7ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_332
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_332
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_180 received DONE after 187 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_180 completed: 189 chars, 187 chunks, TTFT=3713.8ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] INFO:     127.0.0.1:44836 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_333
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_333
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_225 received DONE after 146 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_225 completed: 584 chars, 146 chunks, TTFT=4922.3ms
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41800 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_334
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_334
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_275 received DONE after 77 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_275 completed: 308 chars, 77 chunks, TTFT=6379.4ms
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_335
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_335
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] INFO:     127.0.0.1:41790 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] Decode batch. #running-req: 48, #token: 9084, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2280.39, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:50] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_256 received DONE after 90 chunks
[2025-07-25 02:12:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_256 completed: 346 chars, 90 chunks, TTFT=5890.2ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44738 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_336
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_336
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 171, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_283 received DONE after 65 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_283 completed: 282 chars, 65 chunks, TTFT=6683.2ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41936 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_337
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_337
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_213 received DONE after 166 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_213 completed: 331 chars, 166 chunks, TTFT=4381.8ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_338
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_338
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 122, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_196 received DONE after 189 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_196 completed: 744 chars, 189 chunks, TTFT=3952.7ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41816 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_339
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_339
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_214 received DONE after 153 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_214 completed: 612 chars, 153 chunks, TTFT=4624.9ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:42066 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_260 received DONE after 98 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_260 completed: 100 chars, 98 chunks, TTFT=6065.9ms
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_340
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_340
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:56388 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_341
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_341
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_217 received DONE after 151 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_217 completed: 592 chars, 151 chunks, TTFT=4701.3ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41510 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_342
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_342
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_237 received DONE after 125 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_237 completed: 568 chars, 125 chunks, TTFT=5335.1ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:56380 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] Decode batch. #running-req: 48, #token: 9403, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2329.88, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_343
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_343
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_262 received DONE after 104 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_262 completed: 206 chars, 104 chunks, TTFT=6065.9ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41966 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_344
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_344
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_269 received DONE after 101 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_269 completed: 101 chars, 101 chunks, TTFT=6167.5ms
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_288 received DONE after 69 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_288 completed: 70 chars, 69 chunks, TTFT=6762.7ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44826 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_234 received DONE after 147 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_234 completed: 292 chars, 147 chunks, TTFT=5220.3ms
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_289 received DONE after 74 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_289 completed: 292 chars, 74 chunks, TTFT=6770.5ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41694 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_278 received DONE after 82 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_278 completed: 315 chars, 82 chunks, TTFT=6437.7ms
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_345
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_345
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_346
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_346
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41944 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] Prefill batch. #new-seq: 2, #new-token: 283, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 140, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44750 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_349
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_349
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44762 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_347
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_347
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_348
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_348
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] Prefill batch. #new-seq: 2, #new-token: 176, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_255 received DONE after 119 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_255 completed: 476 chars, 119 chunks, TTFT=5879.7ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44596 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_350
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_350
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_286 received DONE after 76 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_286 completed: 77 chars, 76 chunks, TTFT=6744.0ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 126, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41804 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_351
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_351
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_300 received DONE after 69 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_300 completed: 188 chars, 69 chunks, TTFT=7032.2ms
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_209 received DONE after 192 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_209 completed: 382 chars, 192 chunks, TTFT=4272.0ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_352
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_352
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:42036 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_353
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_353
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 145, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_297 received DONE after 77 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_297 completed: 79 chars, 77 chunks, TTFT=6921.1ms
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_251 received DONE after 126 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_251 completed: 504 chars, 126 chunks, TTFT=5663.5ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44516 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_302 received DONE after 72 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_302 completed: 284 chars, 72 chunks, TTFT=7031.8ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_276 received DONE after 95 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_276 completed: 380 chars, 95 chunks, TTFT=6377.4ms
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_354
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_354
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_355
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_355
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44764 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] Prefill batch. #new-seq: 2, #new-token: 135, #cached-token: 12, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44770 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_356
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_356
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_357
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_357
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_291 received DONE after 82 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_291 completed: 356 chars, 82 chunks, TTFT=6791.6ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:42004 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_358
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_358
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_257 received DONE after 127 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_257 completed: 496 chars, 127 chunks, TTFT=5902.6ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44528 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_359
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_359
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_249 received DONE after 143 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_249 completed: 572 chars, 143 chunks, TTFT=5646.5ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41990 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_360
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_360
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_263 received DONE after 122 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_263 completed: 488 chars, 122 chunks, TTFT=6065.8ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_361
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_361
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_220 received DONE after 186 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_220 completed: 744 chars, 186 chunks, TTFT=4790.1ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41948 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_362
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_362
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_296 received DONE after 86 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_296 completed: 328 chars, 86 chunks, TTFT=6910.7ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_363
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_363
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_223 received DONE after 185 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_223 completed: 185 chars, 185 chunks, TTFT=4899.3ms
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_241 received DONE after 163 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_241 completed: 640 chars, 163 chunks, TTFT=5360.8ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44712 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_266 received DONE after 114 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:42034 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_266 completed: 456 chars, 114 chunks, TTFT=6174.3ms
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_365
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_365
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_364
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_364
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_267 received DONE after 125 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_267 completed: 488 chars, 125 chunks, TTFT=6167.6ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_295 received DONE after 90 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_295 completed: 94 chars, 90 chunks, TTFT=6919.0ms
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_366
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_366
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44572 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_259 received DONE after 138 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_259 completed: 274 chars, 138 chunks, TTFT=5913.9ms
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_368
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_368
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_367
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_367
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_369
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_369
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_245 received DONE after 144 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_245 completed: 563 chars, 144 chunks, TTFT=5542.5ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] Decode batch. #running-req: 46, #token: 8599, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2282.56, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] Prefill batch. #new-seq: 2, #new-token: 254, #cached-token: 12, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41728 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_370
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_370
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] Prefill batch. #new-seq: 2, #new-token: 263, #cached-token: 12, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_244 received DONE after 161 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_244 completed: 734 chars, 161 chunks, TTFT=5460.3ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_371
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_371
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 5, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_284 received DONE after 106 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_284 completed: 421 chars, 106 chunks, TTFT=6683.2ms
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_310 received DONE after 75 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_310 completed: 296 chars, 75 chunks, TTFT=7268.4ms
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41684 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] INFO:     127.0.0.1:44842 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_372
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_372
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_373
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_373
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:51] Prefill batch. #new-seq: 1, #new-token: 149, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_287 received DONE after 109 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_287 completed: 111 chars, 109 chunks, TTFT=6685.1ms
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_236 received DONE after 175 chunks
[2025-07-25 02:12:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_236 completed: 175 chars, 175 chunks, TTFT=5286.6ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:51] INFO:     127.0.0.1:41908 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_374
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41726 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_374
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_375
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_375
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_228 received DONE after 190 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_228 completed: 760 chars, 190 chunks, TTFT=5050.2ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_319 received DONE after 72 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_319 completed: 142 chars, 72 chunks, TTFT=7507.8ms
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_376
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_376
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41746 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_377
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_377
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_243 received DONE after 172 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_243 completed: 172 chars, 172 chunks, TTFT=5460.5ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41784 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_378
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_378
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] Decode batch. #running-req: 53, #token: 9841, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2141.84, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_242 received DONE after 163 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_242 completed: 640 chars, 163 chunks, TTFT=5450.4ms
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_230 received DONE after 178 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_230 completed: 699 chars, 178 chunks, TTFT=5094.3ms
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_318 received DONE after 75 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_318 completed: 146 chars, 75 chunks, TTFT=7513.5ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44790 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41854 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_379
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_379
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_381
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_381
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 5, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_380
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_380
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_279 received DONE after 128 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_279 completed: 499 chars, 128 chunks, TTFT=6481.6ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44850 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_274 received DONE after 126 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_274 completed: 128 chars, 126 chunks, TTFT=6326.2ms
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_382
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_382
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41820 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_383
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_383
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_238 received DONE after 188 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_238 completed: 749 chars, 188 chunks, TTFT=5356.4ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44504 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_240 received DONE after 175 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_240 completed: 688 chars, 175 chunks, TTFT=5364.2ms
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_384
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_384
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41702 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_385
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_385
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_290 received DONE after 116 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_290 completed: 491 chars, 116 chunks, TTFT=6787.9ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_254 received DONE after 152 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_254 completed: 303 chars, 152 chunks, TTFT=5890.4ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44532 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_386
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_386
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:56360 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_387
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_387
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] Prefill batch. #new-seq: 2, #new-token: 181, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_268 received DONE after 141 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_268 completed: 141 chars, 141 chunks, TTFT=6173.9ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41716 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_388
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_388
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_250 received DONE after 166 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_250 completed: 168 chars, 166 chunks, TTFT=5660.1ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44860 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_321 received DONE after 84 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_321 completed: 333 chars, 84 chunks, TTFT=7644.2ms
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_389
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_389
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41884 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_308 received DONE after 107 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_308 completed: 415 chars, 107 chunks, TTFT=7228.6ms
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_390
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_390
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44794 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_391
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_391
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 5, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_339 received DONE after 69 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_339 completed: 296 chars, 69 chunks, TTFT=8151.3ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44654 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_392
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_392
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_323 received DONE after 92 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_323 completed: 94 chars, 92 chunks, TTFT=7675.1ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41868 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_393
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_393
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] Decode batch. #running-req: 46, #token: 9266, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2278.90, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_248 received DONE after 182 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_248 completed: 728 chars, 182 chunks, TTFT=5547.9ms
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_270 received DONE after 153 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_270 completed: 600 chars, 153 chunks, TTFT=6179.4ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:42076 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_292 received DONE after 137 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_292 completed: 548 chars, 137 chunks, TTFT=6837.8ms
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_395
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_395
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_394
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_394
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:56382 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_285 received DONE after 131 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_285 completed: 587 chars, 131 chunks, TTFT=6705.4ms
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_326 received DONE after 88 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_326 completed: 89 chars, 88 chunks, TTFT=7785.0ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_396
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_396
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41816 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_338 received DONE after 74 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_338 completed: 77 chars, 74 chunks, TTFT=8112.2ms
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_398
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_398
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_397
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_397
[2025-07-25 02:12:52] [sglang_test_framework.core.metrics_collector] [INFO] Completed 300 requests, success rate: 100.0%
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41956 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_399
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_399
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] Prefill batch. #new-seq: 2, #new-token: 328, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] Prefill batch. #new-seq: 2, #new-token: 274, #cached-token: 12, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_320 received DONE after 97 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_320 completed: 384 chars, 97 chunks, TTFT=7614.1ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_349 received DONE after 70 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_349 completed: 69 chars, 70 chunks, TTFT=8340.0ms
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_400
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_400
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_401
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_401
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] Prefill batch. #new-seq: 2, #new-token: 251, #cached-token: 12, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_281 received DONE after 154 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_281 completed: 616 chars, 154 chunks, TTFT=6564.4ms
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_303 received DONE after 133 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_303 completed: 529 chars, 133 chunks, TTFT=7026.2ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41776 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_402
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_402
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:42040 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 5, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_403
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_403
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_282 received DONE after 137 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_282 completed: 136 chars, 137 chunks, TTFT=6640.8ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44900 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_404
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_404
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 168, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_280 received DONE after 144 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_280 completed: 559 chars, 144 chunks, TTFT=6536.8ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44890 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_405
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_405
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_332 received DONE after 94 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_332 completed: 259 chars, 94 chunks, TTFT=7911.5ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:41870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_406
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_406
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_271 received DONE after 174 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_271 completed: 683 chars, 174 chunks, TTFT=6278.9ms
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_325 received DONE after 107 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_325 completed: 416 chars, 107 chunks, TTFT=7675.2ms
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:42060 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] INFO:     127.0.0.1:44688 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_261 received DONE after 166 chunks
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_261 completed: 650 chars, 166 chunks, TTFT=6064.3ms
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_407
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_407
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_408
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_408
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] INFO:     127.0.0.1:42048 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_409
[2025-07-25 02:12:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_409
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:52] Prefill batch. #new-seq: 2, #new-token: 136, #cached-token: 12, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:52] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_314 received DONE after 122 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_314 completed: 476 chars, 122 chunks, TTFT=7425.3ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:42022 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_298 received DONE after 145 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_298 completed: 149 chars, 145 chunks, TTFT=7018.7ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] Decode batch. #running-req: 52, #token: 9839, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2297.43, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_336 received DONE after 91 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_336 completed: 348 chars, 91 chunks, TTFT=8037.7ms
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_410
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_410
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44738 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_411
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_411
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_412
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_412
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41926 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 5, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_272 received DONE after 164 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_272 completed: 644 chars, 164 chunks, TTFT=6322.6ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44734 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_413
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_413
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 5, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_312 received DONE after 134 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_312 completed: 536 chars, 134 chunks, TTFT=7318.8ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_414
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_414
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_340 received DONE after 98 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_340 completed: 99 chars, 98 chunks, TTFT=8170.7ms
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_415
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_415
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44742 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_293 received DONE after 153 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_293 completed: 152 chars, 153 chunks, TTFT=6882.4ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:42066 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_416
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_416
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 99, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_316 received DONE after 131 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_316 completed: 524 chars, 131 chunks, TTFT=7506.0ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44586 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_417
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_417
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 103, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_277 received DONE after 190 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_277 completed: 760 chars, 190 chunks, TTFT=6386.5ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41898 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_418
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_418
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_299 received DONE after 155 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_299 completed: 665 chars, 155 chunks, TTFT=7028.0ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44812 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_419
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_419
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] Decode batch. #running-req: 47, #token: 9263, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2360.03, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_329 received DONE after 129 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_329 completed: 130 chars, 129 chunks, TTFT=7799.0ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:42020 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_420
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_420
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 162, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_294 received DONE after 167 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_294 completed: 664 chars, 167 chunks, TTFT=6907.3ms
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_306 received DONE after 156 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_306 completed: 157 chars, 156 chunks, TTFT=7164.0ms
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_304 received DONE after 156 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_304 completed: 608 chars, 156 chunks, TTFT=7161.1ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44828 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41766 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_421
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_421
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41944 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_422
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_422
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_423
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_423
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] Prefill batch. #new-seq: 2, #new-token: 197, #cached-token: 12, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_365 received DONE after 82 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_365 completed: 81 chars, 82 chunks, TTFT=8853.5ms
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_346 received DONE after 109 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_346 completed: 432 chars, 109 chunks, TTFT=8338.5ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44712 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_424
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_424
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44658 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_425
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_425
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] Prefill batch. #new-seq: 2, #new-token: 201, #cached-token: 10, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_358 received DONE after 100 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_358 completed: 396 chars, 100 chunks, TTFT=8597.9ms
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_330 received DONE after 136 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_330 completed: 135 chars, 136 chunks, TTFT=7798.8ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44560 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_427
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_427
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_426
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_426
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 175, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 118, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_361 received DONE after 92 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_361 completed: 364 chars, 92 chunks, TTFT=8715.8ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:42004 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_368 received DONE after 88 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_368 completed: 172 chars, 88 chunks, TTFT=8874.9ms
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_371 received DONE after 88 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_371 completed: 348 chars, 88 chunks, TTFT=8878.2ms
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_428
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_428
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_430
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_430
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41694 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_315 received DONE after 147 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_315 completed: 581 chars, 147 chunks, TTFT=7513.7ms
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_429
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_429
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41754 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_431
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_431
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] Prefill batch. #new-seq: 2, #new-token: 236, #cached-token: 11, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_369 received DONE after 95 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_369 completed: 399 chars, 95 chunks, TTFT=8861.4ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44580 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_432
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_432
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 140, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_305 received DONE after 175 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_305 completed: 688 chars, 175 chunks, TTFT=7153.2ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41706 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_433
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_433
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_307 received DONE after 168 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_307 completed: 668 chars, 168 chunks, TTFT=7171.4ms
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_434
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_434
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44566 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_347 received DONE after 112 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_347 completed: 311 chars, 112 chunks, TTFT=8368.9ms
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_317 received DONE after 158 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_317 completed: 632 chars, 158 chunks, TTFT=7505.8ms
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_301 received DONE after 184 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_301 completed: 186 chars, 184 chunks, TTFT=7026.5ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41730 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_435
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_435
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44750 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_436
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_436
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44572 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_437
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_437
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] Prefill batch. #new-seq: 2, #new-token: 236, #cached-token: 12, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_341 received DONE after 124 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_341 completed: 125 chars, 124 chunks, TTFT=8181.7ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] Decode batch. #running-req: 52, #token: 10282, token usage: 0.09, cuda graph: True, gen throughput (token/s): 2454.70, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41494 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_438
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_438
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_309 received DONE after 169 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_309 completed: 170 chars, 169 chunks, TTFT=7268.6ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44610 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_439
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_439
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_374 received DONE after 97 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_374 completed: 429 chars, 97 chunks, TTFT=9025.2ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41908 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_440
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_440
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_345 received DONE after 119 chunks
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_345 completed: 468 chars, 119 chunks, TTFT=8368.0ms
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44826 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_441
[2025-07-25 02:12:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_441
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:53] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:53] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_335 received DONE after 148 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_335 completed: 588 chars, 148 chunks, TTFT=7976.1ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_328 received DONE after 149 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_328 completed: 152 chars, 149 chunks, TTFT=7812.8ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41790 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] Prefill batch. #new-seq: 2, #new-token: 218, #cached-token: 12, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_311 received DONE after 179 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_311 completed: 500 chars, 179 chunks, TTFT=7318.9ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_443
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_443
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_442
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_442
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:56370 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_380 received DONE after 86 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_380 completed: 340 chars, 86 chunks, TTFT=9255.6ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_444
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_444
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:42026 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_445
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_445
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_391 received DONE after 74 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_391 completed: 145 chars, 74 chunks, TTFT=9532.5ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44794 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_446
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_446
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_313 received DONE after 170 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_313 completed: 676 chars, 170 chunks, TTFT=7401.2ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_352 received DONE after 121 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_352 completed: 480 chars, 121 chunks, TTFT=8485.6ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:56360 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_387 received DONE after 82 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_387 completed: 161 chars, 82 chunks, TTFT=9417.8ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_448
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_448
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_447
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_447
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41482 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_383 received DONE after 98 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_383 completed: 388 chars, 98 chunks, TTFT=9265.3ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_331 received DONE after 157 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_331 completed: 612 chars, 157 chunks, TTFT=7817.4ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_357 received DONE after 119 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_357 completed: 469 chars, 119 chunks, TTFT=8625.0ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_449
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_449
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41820 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_450
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_450
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_451
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_451
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:57504 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_452
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_452
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] Prefill batch. #new-seq: 3, #new-token: 322, #cached-token: 16, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_337 received DONE after 152 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_337 completed: 601 chars, 152 chunks, TTFT=8073.4ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44770 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_453
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_453
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_327 received DONE after 166 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_327 completed: 660 chars, 166 chunks, TTFT=7797.8ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_402 received DONE after 70 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_402 completed: 73 chars, 70 chunks, TTFT=9846.9ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41776 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_455
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_455
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_454
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_454
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] Decode batch. #running-req: 51, #token: 9878, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2212.77, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_351 received DONE after 139 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_351 completed: 538 chars, 139 chunks, TTFT=8484.1ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41804 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_378 received DONE after 111 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_378 completed: 440 chars, 111 chunks, TTFT=9157.4ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_456
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_456
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41784 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_457
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_457
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] Prefill batch. #new-seq: 2, #new-token: 184, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_354 received DONE after 127 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_354 completed: 355 chars, 127 chunks, TTFT=8605.2ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_458
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_458
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44516 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_390 received DONE after 95 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_390 completed: 363 chars, 95 chunks, TTFT=9541.4ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44906 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_459
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_459
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_381 received DONE after 115 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_381 completed: 456 chars, 115 chunks, TTFT=9209.5ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41854 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_460
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_460
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_392 received DONE after 87 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_392 completed: 86 chars, 87 chunks, TTFT=9635.5ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_322 received DONE after 177 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_322 completed: 701 chars, 177 chunks, TTFT=7645.4ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41884 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_462
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_462
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_461
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_461
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 145, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_385 received DONE after 107 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_385 completed: 411 chars, 107 chunks, TTFT=9406.4ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44654 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_463
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_463
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_344 received DONE after 160 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_344 completed: 161 chars, 160 chunks, TTFT=8327.6ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_400 received DONE after 86 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_400 completed: 340 chars, 86 chunks, TTFT=9768.8ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_401 received DONE after 86 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_401 completed: 328 chars, 86 chunks, TTFT=9779.9ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41966 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41702 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_464
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_464
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_466
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_466
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_465
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_465
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] Prefill batch. #new-seq: 2, #new-token: 282, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_413 received DONE after 72 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_413 completed: 73 chars, 72 chunks, TTFT=10108.4ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44734 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_467
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_467
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_362 received DONE after 145 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_362 completed: 148 chars, 145 chunks, TTFT=8753.1ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_397 received DONE after 97 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_397 completed: 98 chars, 97 chunks, TTFT=9755.1ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_416 received DONE after 70 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_416 completed: 69 chars, 70 chunks, TTFT=10303.4ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:42066 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_470
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_470
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_468
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_468
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41816 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_469
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_469
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] Prefill batch. #new-seq: 2, #new-token: 274, #cached-token: 12, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_353 received DONE after 158 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_353 completed: 313 chars, 158 chunks, TTFT=8486.6ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_471
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_471
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_359 received DONE after 141 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_359 completed: 144 chars, 141 chunks, TTFT=8632.7ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:42036 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_472
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_472
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 5, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_342 received DONE after 176 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_342 completed: 700 chars, 176 chunks, TTFT=8173.6ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_377 received DONE after 131 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_377 completed: 559 chars, 131 chunks, TTFT=9157.4ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41746 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_473
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_473
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44528 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_474
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_474
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_373 received DONE after 128 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_373 completed: 393 chars, 128 chunks, TTFT=8996.8ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_343 received DONE after 158 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_343 completed: 159 chars, 158 chunks, TTFT=8261.2ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:56380 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41510 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_475
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_475
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_476
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_476
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 188, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_411 received DONE after 79 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_411 completed: 300 chars, 79 chunks, TTFT=10108.5ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_376 received DONE after 122 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_376 completed: 484 chars, 122 chunks, TTFT=9138.5ms
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_324 received DONE after 190 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_324 completed: 756 chars, 190 chunks, TTFT=7650.4ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44880 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_478
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_478
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41948 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_477
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41976 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_477
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_479
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_479
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] Prefill batch. #new-seq: 2, #new-token: 260, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] Decode batch. #running-req: 49, #token: 9079, token usage: 0.08, cuda graph: True, gen throughput (token/s): 1986.23, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_334 received DONE after 190 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_334 completed: 529 chars, 190 chunks, TTFT=7976.1ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] INFO:     127.0.0.1:41800 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_480
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_480
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:54] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_410 received DONE after 91 chunks
[2025-07-25 02:12:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_410 completed: 92 chars, 91 chunks, TTFT=10103.8ms
[2025-07-25 02:12:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:54] INFO:     127.0.0.1:44676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_481
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_481
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 150, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_422 received DONE after 70 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_422 completed: 137 chars, 70 chunks, TTFT=10542.8ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41766 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_482
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_482
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_426 received DONE after 66 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_426 completed: 67 chars, 66 chunks, TTFT=10633.7ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44738 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_483
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_483
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_363 received DONE after 146 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_363 completed: 149 chars, 146 chunks, TTFT=8822.4ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_484
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_484
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_366 received DONE after 157 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_366 completed: 612 chars, 157 chunks, TTFT=8862.0ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_485
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_485
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_364 received DONE after 159 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_364 completed: 620 chars, 159 chunks, TTFT=8837.8ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:42034 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_486
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_486
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_412 received DONE after 100 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_412 completed: 383 chars, 100 chunks, TTFT=10103.8ms
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_394 received DONE after 108 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_394 completed: 212 chars, 108 chunks, TTFT=9743.6ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41926 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44586 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_487
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_487
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_417 received DONE after 81 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_417 completed: 80 chars, 81 chunks, TTFT=10330.5ms
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_488
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_488
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_489
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_489
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] Decode batch. #running-req: 48, #token: 9094, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2333.13, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] Prefill batch. #new-seq: 2, #new-token: 272, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_333 received DONE after 193 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_333 completed: 383 chars, 193 chunks, TTFT=7931.5ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44836 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_490
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_490
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_389 received DONE after 123 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_389 completed: 488 chars, 123 chunks, TTFT=9528.9ms
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_355 received DONE after 177 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_355 completed: 704 chars, 177 chunks, TTFT=8586.7ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_491
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_491
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44860 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_492
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_492
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_435 received DONE after 69 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_435 completed: 259 chars, 69 chunks, TTFT=10828.5ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41730 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_493
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_493
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_423 received DONE after 84 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_423 completed: 332 chars, 84 chunks, TTFT=10542.7ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_494
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_494
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_379 received DONE after 141 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_379 completed: 140 chars, 141 chunks, TTFT=9227.2ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41944 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_495
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_495
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_393 received DONE after 132 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_393 completed: 512 chars, 132 chunks, TTFT=9654.7ms
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_396 received DONE after 120 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_396 completed: 464 chars, 120 chunks, TTFT=9766.1ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44790 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41868 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_496
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_496
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_497
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_497
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_350 received DONE after 176 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_350 completed: 177 chars, 176 chunks, TTFT=8485.7ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:42022 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_498
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_498
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_360 received DONE after 182 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_360 completed: 185 chars, 182 chunks, TTFT=8689.6ms
[2025-07-25 02:12:55] [sglang_test_framework.core.metrics_collector] [INFO] Completed 400 requests, success rate: 100.0%
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44596 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_499
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_499
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_356 received DONE after 180 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_356 completed: 500 chars, 180 chunks, TTFT=8604.9ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41990 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_372 received DONE after 174 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_372 completed: 791 chars, 174 chunks, TTFT=9001.4ms
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_500
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_500
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44764 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_501
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_501
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 5, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_405 received DONE after 126 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_405 completed: 486 chars, 126 chunks, TTFT=9889.5ms
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_348 received DONE after 191 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_348 completed: 190 chars, 191 chunks, TTFT=8368.8ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 150, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41684 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44762 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_503
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_503
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_502
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_502
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_375 received DONE after 176 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_375 completed: 177 chars, 176 chunks, TTFT=9031.8ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44890 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_504
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_504
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] Prefill batch. #new-seq: 2, #new-token: 252, #cached-token: 10, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_384 received DONE after 149 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_384 completed: 580 chars, 149 chunks, TTFT=9412.0ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_434 received DONE after 83 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_434 completed: 226 chars, 83 chunks, TTFT=10828.5ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44566 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41726 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_505
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_505
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_506
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_506
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] Decode batch. #running-req: 47, #token: 9319, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2293.40, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_441 received DONE after 77 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_441 completed: 304 chars, 77 chunks, TTFT=10977.1ms
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_420 received DONE after 105 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_420 completed: 416 chars, 105 chunks, TTFT=10502.1ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41936 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_507
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_507
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:42020 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_508
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_508
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] Prefill batch. #new-seq: 2, #new-token: 349, #cached-token: 12, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_454 received DONE after 69 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_454 completed: 272 chars, 69 chunks, TTFT=11304.0ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44826 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_509
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_509
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_370 received DONE after 189 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_370 completed: 528 chars, 189 chunks, TTFT=8864.3ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44504 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 140, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_510
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_510
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_367 received DONE after 181 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_367 completed: 552 chars, 181 chunks, TTFT=8874.8ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41728 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_511
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_511
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 5, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_438 received DONE after 91 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_438 completed: 348 chars, 91 chunks, TTFT=10958.2ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41494 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_398 received DONE after 144 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_398 completed: 560 chars, 144 chunks, TTFT=9765.4ms
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_512
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_512
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_513
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_513
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:55] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_445 received DONE after 88 chunks
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_445 completed: 348 chars, 88 chunks, TTFT=11083.5ms
[2025-07-25 02:12:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:55] INFO:     127.0.0.1:44824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_514
[2025-07-25 02:12:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_514
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_414 received DONE after 133 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_414 completed: 525 chars, 133 chunks, TTFT=10203.7ms
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_418 received DONE after 123 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_418 completed: 485 chars, 123 chunks, TTFT=10382.5ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:56382 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:41898 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_399 received DONE after 155 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_399 completed: 604 chars, 155 chunks, TTFT=9755.0ms
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_516
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_516
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_515
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_515
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:41956 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_517
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_517
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_386 received DONE after 164 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_386 completed: 163 chars, 164 chunks, TTFT=9417.9ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44532 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_518
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_518
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] Decode batch. #running-req: 48, #token: 9203, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2363.89, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_408 received DONE after 140 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_408 completed: 543 chars, 140 chunks, TTFT=9989.5ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:41922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_519
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_519
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_403 received DONE after 159 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_403 completed: 619 chars, 159 chunks, TTFT=9849.6ms
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_436 received DONE after 104 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_436 completed: 412 chars, 104 chunks, TTFT=10838.1ms
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_404 received DONE after 150 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_404 completed: 296 chars, 150 chunks, TTFT=9881.4ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:42040 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_520
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44900 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_520
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_521
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_521
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:42026 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_522
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_522
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_465 received DONE after 71 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_465 completed: 138 chars, 71 chunks, TTFT=11664.4ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_523
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_523
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_462 received DONE after 79 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_462 completed: 300 chars, 79 chunks, TTFT=11525.7ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:41884 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_524
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_524
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 168, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_395 received DONE after 171 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_395 completed: 680 chars, 171 chunks, TTFT=9743.8ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44750 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_525
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_525
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_382 received DONE after 189 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_382 completed: 749 chars, 189 chunks, TTFT=9255.5ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44850 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_526
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_526
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_388 received DONE after 189 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_388 completed: 740 chars, 189 chunks, TTFT=9470.6ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:41716 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_527
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_527
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_407 received DONE after 168 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_407 completed: 716 chars, 168 chunks, TTFT=9964.3ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44688 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_528
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_528
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_483 received DONE after 66 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_483 completed: 260 chars, 66 chunks, TTFT=12079.5ms
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_421 received DONE after 130 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_421 completed: 504 chars, 130 chunks, TTFT=10555.1ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:42060 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44828 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_458 received DONE after 93 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_458 completed: 368 chars, 93 chunks, TTFT=11428.3ms
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_430 received DONE after 123 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_430 completed: 488 chars, 123 chunks, TTFT=10720.6ms
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_529
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_529
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_530
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_530
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_431 received DONE after 131 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_431 completed: 508 chars, 131 chunks, TTFT=10724.0ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:42076 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_532
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_532
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_531
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_531
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:41754 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_533
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_533
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] Prefill batch. #new-seq: 2, #new-token: 356, #cached-token: 10, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] Prefill batch. #new-seq: 2, #new-token: 321, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_406 received DONE after 173 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_406 completed: 176 chars, 173 chunks, TTFT=9960.3ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44516 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_534
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_534
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] Decode batch. #running-req: 49, #token: 10323, token usage: 0.09, cuda graph: True, gen throughput (token/s): 2151.90, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_409 received DONE after 176 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_409 completed: 349 chars, 176 chunks, TTFT=9972.5ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:42048 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_535
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_535
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_443 received DONE after 122 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_443 completed: 240 chars, 122 chunks, TTFT=11083.6ms
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_432 received DONE after 128 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_432 completed: 508 chars, 128 chunks, TTFT=10761.0ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:41722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44580 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_537
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_537
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_536
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_536
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 6, token usage: 0.09, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_481 received DONE after 80 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_481 completed: 79 chars, 80 chunks, TTFT=12014.7ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_538
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_538
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 6, token usage: 0.09, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_428 received DONE after 147 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_428 completed: 290 chars, 147 chunks, TTFT=10721.2ms
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_493 received DONE after 74 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_493 completed: 144 chars, 74 chunks, TTFT=12317.3ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:41730 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] Decode batch. #running-req: 49, #token: 9934, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2571.61, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:42004 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_540
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_540
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_539
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_539
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:56] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_460 received DONE after 115 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_460 completed: 226 chars, 115 chunks, TTFT=11521.1ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44738 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_433 received DONE after 150 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_433 completed: 418 chars, 150 chunks, TTFT=10826.5ms
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_541
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_541
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 6, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44842 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_542
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_542
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_474 received DONE after 107 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_474 completed: 421 chars, 107 chunks, TTFT=11782.2ms
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_450 received DONE after 129 chunks
[2025-07-25 02:12:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_450 completed: 500 chars, 129 chunks, TTFT=11233.3ms
[2025-07-25 02:12:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:56] INFO:     127.0.0.1:44528 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_544
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_544
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41706 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_543
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_543
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 6, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] Prefill batch. #new-seq: 2, #new-token: 230, #cached-token: 12, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_502 received DONE after 68 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_502 completed: 67 chars, 68 chunks, TTFT=12655.4ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41854 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_545
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_545
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_467 received DONE after 117 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_467 completed: 464 chars, 117 chunks, TTFT=11664.3ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44734 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_546
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_546
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_490 received DONE after 95 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_490 completed: 376 chars, 95 chunks, TTFT=12248.7ms
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_453 received DONE after 138 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_453 completed: 536 chars, 138 chunks, TTFT=11247.5ms
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_437 received DONE after 155 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_437 completed: 616 chars, 155 chunks, TTFT=10839.9ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44572 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_547
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_547
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44770 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_548
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_548
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_473 received DONE after 117 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_473 completed: 452 chars, 117 chunks, TTFT=11775.9ms
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_451 received DONE after 144 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_451 completed: 145 chars, 144 chunks, TTFT=11217.8ms
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_549
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_549
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41820 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_550
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_550
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41746 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_551
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_551
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] Prefill batch. #new-seq: 2, #new-token: 288, #cached-token: 12, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_442 received DONE after 151 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_442 completed: 152 chars, 151 chunks, TTFT=11083.8ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44836 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_552
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_552
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] Prefill batch. #new-seq: 2, #new-token: 300, #cached-token: 10, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_492 received DONE after 94 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_492 completed: 93 chars, 94 chunks, TTFT=12306.3ms
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_415 received DONE after 185 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_415 completed: 186 chars, 185 chunks, TTFT=10242.0ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44742 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41790 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_553
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_553
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_554
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_554
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 133, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_439 received DONE after 151 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_439 completed: 685 chars, 151 chunks, TTFT=10975.7ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44610 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_555
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_555
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_484 received DONE after 107 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_484 completed: 420 chars, 107 chunks, TTFT=12108.6ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_556
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_556
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 113, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_513 received DONE after 67 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_513 completed: 251 chars, 67 chunks, TTFT=12959.1ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_515 received DONE after 66 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_515 completed: 260 chars, 66 chunks, TTFT=13038.0ms
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_557
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_557
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_558
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_558
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 6, token usage: 0.09, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41898 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 6, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_479 received DONE after 121 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_479 completed: 477 chars, 121 chunks, TTFT=11883.5ms
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_449 received DONE after 152 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_449 completed: 688 chars, 152 chunks, TTFT=11218.2ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44860 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41482 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_559
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_559
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_560
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_560
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 6, token usage: 0.09, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_429 received DONE after 176 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_429 completed: 348 chars, 176 chunks, TTFT=10724.3ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44762 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_561
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_561
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] Decode batch. #running-req: 49, #token: 10599, token usage: 0.09, cuda graph: True, gen throughput (token/s): 2343.22, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 89, #cached-token: 5, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_446 received DONE after 154 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_446 completed: 612 chars, 154 chunks, TTFT=11094.7ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_485 received DONE after 112 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_485 completed: 444 chars, 112 chunks, TTFT=12115.1ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41694 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_562
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_562
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_563
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_563
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_419 received DONE after 185 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_419 completed: 736 chars, 185 chunks, TTFT=10420.9ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44812 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_564
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_564
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_486 received DONE after 116 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_486 completed: 519 chars, 116 chunks, TTFT=12182.6ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:42034 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_565
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_565
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 6, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_457 received DONE after 152 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_457 completed: 153 chars, 152 chunks, TTFT=11405.5ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44794 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_456 received DONE after 153 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_456 completed: 426 chars, 153 chunks, TTFT=11405.6ms
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_566
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_566
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 6, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41804 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_567
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_567
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_491 received DONE after 113 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_491 completed: 445 chars, 113 chunks, TTFT=12314.4ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_568
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_568
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_488 received DONE after 115 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_488 completed: 442 chars, 115 chunks, TTFT=12191.4ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_569
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_569
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] Decode batch. #running-req: 49, #token: 10025, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2328.85, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_520 received DONE after 73 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_520 completed: 285 chars, 73 chunks, TTFT=13211.1ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:42040 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_570
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_570
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_489 received DONE after 122 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_489 completed: 471 chars, 122 chunks, TTFT=12191.6ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44586 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_571
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_571
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 162, #cached-token: 5, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 6, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_470 received DONE after 138 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_470 completed: 495 chars, 138 chunks, TTFT=11753.3ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_572
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_572
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_459 received DONE after 149 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_459 completed: 592 chars, 149 chunks, TTFT=11480.2ms
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_425 received DONE after 189 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_425 completed: 752 chars, 189 chunks, TTFT=10562.5ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 6, token usage: 0.09, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_498 received DONE after 114 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_498 completed: 439 chars, 114 chunks, TTFT=12456.3ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44906 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:42022 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_427 received DONE after 187 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_427 completed: 572 chars, 187 chunks, TTFT=10629.7ms
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_573
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_573
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_575
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_575
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44560 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41784 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_424 received DONE after 191 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_424 completed: 760 chars, 191 chunks, TTFT=10562.3ms
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_461 received DONE after 148 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_461 completed: 585 chars, 148 chunks, TTFT=11553.4ms
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_576
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_576
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_574
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_574
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41976 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_577
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_577
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_578
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_578
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] Prefill batch. #new-seq: 3, #new-token: 387, #cached-token: 18, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] Prefill batch. #new-seq: 2, #new-token: 352, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_447 received DONE after 172 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_447 completed: 672 chars, 172 chunks, TTFT=11213.5ms
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_463 received DONE after 149 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_463 completed: 152 chars, 149 chunks, TTFT=11556.4ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44654 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_579
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_579
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_580
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_580
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_482 received DONE after 135 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_482 completed: 536 chars, 135 chunks, TTFT=12059.8ms
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41684 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_523 received DONE after 78 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_523 completed: 295 chars, 78 chunks, TTFT=13223.7ms
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_452 received DONE after 176 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_452 completed: 700 chars, 176 chunks, TTFT=11218.0ms
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_503 received DONE after 109 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_503 completed: 432 chars, 109 chunks, TTFT=12650.4ms
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_581
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_581
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] INFO:     127.0.0.1:41908 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:57] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:57] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:57] INFO:     127.0.0.1:44824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_440 received DONE after 189 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_440 completed: 739 chars, 189 chunks, TTFT=10959.0ms
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_514 received DONE after 90 chunks
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_514 completed: 397 chars, 90 chunks, TTFT=13017.3ms
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_583
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_583
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_582
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_582
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_584
[2025-07-25 02:12:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_584
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:57504 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44712 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Prefill batch. #new-seq: 3, #new-token: 337, #cached-token: 18, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_585
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_585
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_586
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_586
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_444 received DONE after 176 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_444 completed: 688 chars, 176 chunks, TTFT=11091.9ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41766 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_587
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_587
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] Prefill batch. #new-seq: 3, #new-token: 273, #cached-token: 18, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_497 received DONE after 124 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_497 completed: 343 chars, 124 chunks, TTFT=12454.4ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:56370 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_588
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_588
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_518 received DONE after 96 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_518 completed: 380 chars, 96 chunks, TTFT=13045.3ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41868 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_589
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_589
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_475 received DONE after 150 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_475 completed: 584 chars, 150 chunks, TTFT=11882.1ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:56380 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_590
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_590
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 5, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_504 received DONE after 114 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_504 completed: 439 chars, 114 chunks, TTFT=12655.1ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41776 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_591
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_591
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_505 received DONE after 116 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_505 completed: 229 chars, 116 chunks, TTFT=12746.7ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44890 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_592
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_592
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_471 received DONE after 160 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_471 completed: 636 chars, 160 chunks, TTFT=11782.1ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_593
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_593
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_469 received DONE after 165 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_469 completed: 656 chars, 165 chunks, TTFT=11747.8ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41816 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_594
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_594
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_477 received DONE after 163 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_477 completed: 162 chars, 163 chunks, TTFT=11883.9ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44532 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_595
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_595
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 122, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_448 received DONE after 186 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_448 completed: 740 chars, 186 chunks, TTFT=11209.3ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41948 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_596
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_596
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_455 received DONE after 184 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_455 completed: 729 chars, 184 chunks, TTFT=11310.7ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_597
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_597
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_535 received DONE after 81 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_535 completed: 308 chars, 81 chunks, TTFT=13661.6ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:56360 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_598
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_598
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Decode batch. #running-req: 47, #token: 8843, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2101.57, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Prefill batch. #new-seq: 2, #new-token: 169, #cached-token: 12, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_500 received DONE after 131 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_500 completed: 520 chars, 131 chunks, TTFT=12647.7ms
[2025-07-25 02:12:58] [sglang_test_framework.core.metrics_collector] [INFO] Completed 500 requests, success rate: 100.0%
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41990 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_599
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_599
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_501 received DONE after 126 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_501 completed: 127 chars, 126 chunks, TTFT=12651.7ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_476 received DONE after 168 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_476 completed: 765 chars, 168 chunks, TTFT=11872.9ms
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_487 received DONE after 154 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_487 completed: 153 chars, 154 chunks, TTFT=12191.9ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41926 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_494 received DONE after 142 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_494 completed: 564 chars, 142 chunks, TTFT=12359.7ms
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_601
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_601
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_602
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_602
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44764 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_600
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_600
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_603
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_603
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41510 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Prefill batch. #new-seq: 2, #new-token: 182, #cached-token: 10, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] Prefill batch. #new-seq: 2, #new-token: 156, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_478 received DONE after 167 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_478 completed: 652 chars, 167 chunks, TTFT=11889.9ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44880 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_604
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_604
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_522 received DONE after 110 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_522 completed: 436 chars, 110 chunks, TTFT=13235.6ms
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_468 received DONE after 176 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_468 completed: 175 chars, 176 chunks, TTFT=11748.1ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44658 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:42066 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_472 received DONE after 177 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_472 completed: 807 chars, 177 chunks, TTFT=11775.6ms
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_507 received DONE after 133 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_507 completed: 528 chars, 133 chunks, TTFT=12755.8ms
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_606
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_606
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_605
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_605
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 88, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_608
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_608
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_607
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_607
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:42036 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] Prefill batch. #new-seq: 2, #new-token: 228, #cached-token: 12, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_525 received DONE after 98 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_525 completed: 99 chars, 98 chunks, TTFT=13393.1ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41800 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_480 received DONE after 170 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_480 completed: 528 chars, 170 chunks, TTFT=11984.2ms
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_609
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_609
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44750 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_610
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_610
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Prefill batch. #new-seq: 2, #new-token: 192, #cached-token: 12, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] Decode batch. #running-req: 47, #token: 8852, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2272.42, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 149, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_495 received DONE after 151 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_495 completed: 600 chars, 151 chunks, TTFT=12428.2ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:56388 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_611
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_611
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 6, token usage: 0.07, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_496 received DONE after 144 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_496 completed: 568 chars, 144 chunks, TTFT=12444.3ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41944 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_612
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_612
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 5, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_527 received DONE after 104 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_527 completed: 103 chars, 104 chunks, TTFT=13426.7ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44790 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_533 received DONE after 100 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_533 completed: 393 chars, 100 chunks, TTFT=13540.1ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 6, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_613
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_613
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41754 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_614
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_614
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_536 received DONE after 88 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_536 completed: 334 chars, 88 chunks, TTFT=13675.9ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44580 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_615
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_615
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 5, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 179, #cached-token: 6, token usage: 0.07, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_526 received DONE after 101 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_526 completed: 102 chars, 101 chunks, TTFT=13396.0ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41716 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_616
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_616
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_538 received DONE after 88 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_538 completed: 91 chars, 88 chunks, TTFT=13758.0ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_466 received DONE after 190 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_466 completed: 189 chars, 190 chunks, TTFT=11649.0ms
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_617
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_617
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 6, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41702 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_618
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_618
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_508 received DONE after 143 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_508 completed: 555 chars, 143 chunks, TTFT=12755.8ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44850 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_619
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_619
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.07, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_464 received DONE after 193 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_464 completed: 768 chars, 193 chunks, TTFT=11649.3ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41966 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_620
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_620
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 86, #cached-token: 5, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_506 received DONE after 139 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_506 completed: 539 chars, 139 chunks, TTFT=12739.5ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:42020 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_621
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_621
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_541 received DONE after 79 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_541 completed: 80 chars, 79 chunks, TTFT=13991.4ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 89, #cached-token: 5, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_530 received DONE after 105 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_530 completed: 404 chars, 105 chunks, TTFT=13511.3ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44828 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_622
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_622
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41936 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_623
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_623
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_548 received DONE after 71 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_548 completed: 72 chars, 71 chunks, TTFT=14188.2ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] INFO:     127.0.0.1:44572 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_624
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_624
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:58] Prefill batch. #new-seq: 1, #new-token: 140, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_524 received DONE after 127 chunks
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_524 completed: 504 chars, 127 chunks, TTFT=13243.6ms
[2025-07-25 02:12:58] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:58] INFO:     127.0.0.1:41884 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_625
[2025-07-25 02:12:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_625
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_534 received DONE after 118 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_534 completed: 456 chars, 118 chunks, TTFT=13574.2ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44516 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_543 received DONE after 98 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_543 completed: 376 chars, 98 chunks, TTFT=14001.3ms
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_626
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_626
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41706 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_627
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_627
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_511 received DONE after 157 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_511 completed: 310 chars, 157 chunks, TTFT=12875.2ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44738 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_628
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_628
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_576 received DONE after 68 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_576 completed: 133 chars, 68 chunks, TTFT=14830.0ms
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_516 received DONE after 148 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_516 completed: 588 chars, 148 chunks, TTFT=13037.6ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] Decode batch. #running-req: 51, #token: 9128, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2238.89, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44566 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_629
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_629
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_567 received DONE after 77 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_567 completed: 78 chars, 77 chunks, TTFT=14613.0ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41784 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_630
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_630
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:56382 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_631
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_631
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 153, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_554 received DONE after 94 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_554 completed: 372 chars, 94 chunks, TTFT=14298.5ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41790 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_632
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_632
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_529 received DONE after 134 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_529 completed: 518 chars, 134 chunks, TTFT=13540.4ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:51796 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_633
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_633
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_509 received DONE after 163 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_509 completed: 636 chars, 163 chunks, TTFT=12799.8ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] Decode batch. #running-req: 47, #token: 8981, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2371.40, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:42060 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_634
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_634
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_575 received DONE after 77 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_575 completed: 291 chars, 77 chunks, TTFT=14830.3ms
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_555 received DONE after 92 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_555 completed: 95 chars, 92 chunks, TTFT=14295.5ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:42022 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_635
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_635
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44610 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_636
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_636
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_499 received DONE after 176 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_499 completed: 700 chars, 176 chunks, TTFT=12553.9ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41804 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_637
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_637
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] Prefill batch. #new-seq: 2, #new-token: 210, #cached-token: 12, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_531 received DONE after 143 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_531 completed: 556 chars, 143 chunks, TTFT=13540.3ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44596 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_510 received DONE after 169 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_510 completed: 170 chars, 169 chunks, TTFT=12841.3ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_638
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_638
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_639
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_639
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:42076 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_561 received DONE after 95 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_561 completed: 376 chars, 95 chunks, TTFT=14466.8ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44762 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_640
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_640
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_563 received DONE after 100 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_563 completed: 424 chars, 100 chunks, TTFT=14521.7ms
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_539 received DONE after 132 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_539 completed: 260 chars, 132 chunks, TTFT=13854.4ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44504 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41730 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_641
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_641
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_642
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_642
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 89, #cached-token: 5, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_585 received DONE after 82 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_585 completed: 161 chars, 82 chunks, TTFT=14999.3ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44586 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_571 received DONE after 87 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_571 completed: 344 chars, 87 chunks, TTFT=14733.1ms
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_643
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_643
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:57504 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_644
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_644
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 103, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_560 received DONE after 110 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_560 completed: 424 chars, 110 chunks, TTFT=14404.3ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41482 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_645
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_645
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 175, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_545 received DONE after 127 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_545 completed: 251 chars, 127 chunks, TTFT=14072.2ms
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_517 received DONE after 180 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_517 completed: 703 chars, 180 chunks, TTFT=13037.8ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44826 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:51808 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_646
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_646
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_647
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_647
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] Prefill batch. #new-seq: 2, #new-token: 285, #cached-token: 12, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_537 received DONE after 152 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_537 completed: 153 chars, 152 chunks, TTFT=13661.6ms
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_512 received DONE after 187 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_512 completed: 732 chars, 187 chunks, TTFT=12937.1ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41494 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_648
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_648
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 162, #cached-token: 6, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:51822 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_649
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_649
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 6, token usage: 0.08, #running-req: 54, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_574 received DONE after 93 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_574 completed: 355 chars, 93 chunks, TTFT=14855.0ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_650
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_650
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_580 received DONE after 95 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_580 completed: 98 chars, 95 chunks, TTFT=14854.6ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41956 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_651
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_651
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_532 received DONE after 157 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_532 completed: 612 chars, 157 chunks, TTFT=13511.1ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_652
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_652
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_593 received DONE after 78 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_593 completed: 308 chars, 78 chunks, TTFT=15247.4ms
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_519 received DONE after 184 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_519 completed: 732 chars, 184 chunks, TTFT=13138.8ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 5, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_654
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_654
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_653
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_653
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_597 received DONE after 75 chunks
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_597 completed: 146 chars, 75 chunks, TTFT=15352.2ms
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:12:59] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:12:59] INFO:     127.0.0.1:44722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_655
[2025-07-25 02:12:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_655
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] Prefill batch. #new-seq: 2, #new-token: 195, #cached-token: 10, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_598 received DONE after 76 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_598 completed: 148 chars, 76 chunks, TTFT=15359.3ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41854 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_656
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_656
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_592 received DONE after 81 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_592 completed: 320 chars, 81 chunks, TTFT=15245.1ms
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_557 received DONE after 118 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_557 completed: 327 chars, 118 chunks, TTFT=14398.0ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41694 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_658
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_658
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_657
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_657
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_542 received DONE after 138 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_542 completed: 548 chars, 138 chunks, TTFT=13993.2ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44842 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_659
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_659
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_547 received DONE after 135 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_547 completed: 524 chars, 135 chunks, TTFT=14191.9ms
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_660
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_660
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] Decode batch. #running-req: 51, #token: 9245, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2301.36, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_604 received DONE after 74 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_604 completed: 144 chars, 74 chunks, TTFT=15527.3ms
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_606 received DONE after 74 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_606 completed: 73 chars, 74 chunks, TTFT=15552.9ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41728 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44658 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_662
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_662
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_661
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_661
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_565 received DONE after 119 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_565 completed: 469 chars, 119 chunks, TTFT=14609.4ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:42034 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_528 received DONE after 168 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_528 completed: 668 chars, 168 chunks, TTFT=13502.9ms
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_540 received DONE after 156 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_540 completed: 608 chars, 156 chunks, TTFT=13856.7ms
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_663
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_663
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44688 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_664
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_664
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44880 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_665
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_665
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] Prefill batch. #new-seq: 2, #new-token: 155, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] Decode batch. #running-req: 49, #token: 8941, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2119.68, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_521 received DONE after 185 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_521 completed: 186 chars, 185 chunks, TTFT=13220.1ms
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_551 received DONE after 142 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_551 completed: 551 chars, 142 chunks, TTFT=14200.4ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41746 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_666
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_666
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44900 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_667
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_667
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_569 received DONE after 123 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_569 completed: 242 chars, 123 chunks, TTFT=14710.3ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_668
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_668
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_621 received DONE after 73 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_621 completed: 74 chars, 73 chunks, TTFT=15886.4ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44890 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_556 received DONE after 143 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_556 completed: 568 chars, 143 chunks, TTFT=14302.7ms
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_669
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_669
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_670
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_670
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_581 received DONE after 115 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_581 completed: 444 chars, 115 chunks, TTFT=14996.8ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:56360 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_671
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_671
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 5, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_600 received DONE after 89 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_600 completed: 176 chars, 89 chunks, TTFT=15451.9ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41684 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_672
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_672
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_602 received DONE after 94 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_602 completed: 185 chars, 94 chunks, TTFT=15440.3ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41926 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_673
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_673
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_587 received DONE after 117 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_587 completed: 230 chars, 117 chunks, TTFT=15003.8ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44770 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_549 received DONE after 145 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_549 completed: 567 chars, 145 chunks, TTFT=14188.0ms
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_674
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_674
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41766 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_675
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_675
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_596 received DONE after 100 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_596 completed: 384 chars, 100 chunks, TTFT=15349.1ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44764 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_676
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_676
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_608 received DONE after 94 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_608 completed: 96 chars, 94 chunks, TTFT=15558.1ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_677
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_677
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:51832 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:57516 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_579 received DONE after 135 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_579 completed: 134 chars, 135 chunks, TTFT=14877.9ms
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_570 received DONE after 140 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_570 completed: 143 chars, 140 chunks, TTFT=14713.6ms
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_583 received DONE after 129 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_583 completed: 128 chars, 129 chunks, TTFT=14999.4ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44654 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41908 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_679
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_679
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:42040 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_678
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_678
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_680
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_680
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_588 received DONE after 119 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_588 completed: 236 chars, 119 chunks, TTFT=15108.0ms
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_624 received DONE after 86 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_624 completed: 344 chars, 86 chunks, TTFT=15912.9ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] Prefill batch. #new-seq: 2, #new-token: 352, #cached-token: 11, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44572 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:56370 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_603 received DONE after 110 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_603 completed: 436 chars, 110 chunks, TTFT=15442.7ms
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_681
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_681
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_682
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_682
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41510 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_683
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_683
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] Prefill batch. #new-seq: 2, #new-token: 177, #cached-token: 12, token usage: 0.09, #running-req: 54, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 5, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_601 received DONE after 105 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_601 completed: 107 chars, 105 chunks, TTFT=15451.8ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_684
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_684
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 6, token usage: 0.09, #running-req: 53, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_578 received DONE after 143 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_578 completed: 565 chars, 143 chunks, TTFT=14829.9ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41976 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_685
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_685
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_628 received DONE after 76 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_628 completed: 210 chars, 76 chunks, TTFT=16165.7ms
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_568 received DONE after 144 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_568 completed: 562 chars, 144 chunks, TTFT=14664.5ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_687
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_687
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_686
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_686
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_614 received DONE after 108 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_614 completed: 415 chars, 108 chunks, TTFT=15658.1ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41754 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_688
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_688
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_566 received DONE after 149 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_566 completed: 596 chars, 149 chunks, TTFT=14620.7ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44794 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_689
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_689
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_613 received DONE after 106 chunks
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_613 completed: 452 chars, 106 chunks, TTFT=15667.4ms
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] INFO:     127.0.0.1:44790 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_690
[2025-07-25 02:13:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_690
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:00] Prefill batch. #new-seq: 1, #new-token: 103, #cached-token: 6, token usage: 0.08, #running-req: 54, #queue-req: 0,
[2025-07-25 02:13:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:00] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_546 received DONE after 167 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_546 completed: 332 chars, 167 chunks, TTFT=14160.6ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41948 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] Decode batch. #running-req: 52, #token: 9877, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2334.27, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_691
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_691
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_552 received DONE after 169 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_552 completed: 173 chars, 169 chunks, TTFT=14191.1ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44836 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_692
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_692
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 126, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_577 received DONE after 146 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_577 completed: 571 chars, 146 chunks, TTFT=14854.7ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:42020 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_693
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_693
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_558 received DONE after 173 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_558 completed: 675 chars, 173 chunks, TTFT=14401.4ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_694
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_694
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_582 received DONE after 140 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_582 completed: 142 chars, 140 chunks, TTFT=14990.8ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41898 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_695
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_695
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Decode batch. #running-req: 49, #token: 9391, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2170.96, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_626 received DONE after 90 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_626 completed: 360 chars, 90 chunks, TTFT=16163.2ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44516 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_696
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_696
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_562 received DONE after 164 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_562 completed: 326 chars, 164 chunks, TTFT=14538.6ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_572 received DONE after 159 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_572 completed: 162 chars, 159 chunks, TTFT=14815.4ms
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_697
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_697
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_698
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_698
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_544 received DONE after 187 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_544 completed: 187 chars, 187 chunks, TTFT=13992.9ms
[2025-07-25 02:13:01] [sglang_test_framework.core.metrics_collector] [INFO] Completed 600 requests, success rate: 100.0%
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:42004 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_699
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_699
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_550 received DONE after 187 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_550 completed: 188 chars, 187 chunks, TTFT=14200.6ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44528 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_700
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_700
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] Prefill batch. #new-seq: 2, #new-token: 265, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_637 received DONE after 85 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_637 completed: 84 chars, 85 chunks, TTFT=16439.2ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41804 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_701
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_701
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_553 received DONE after 177 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_553 completed: 704 chars, 177 chunks, TTFT=14293.1ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44742 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_564 received DONE after 169 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_564 completed: 336 chars, 169 chunks, TTFT=14539.1ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_702
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_702
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41820 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_703
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_703
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_644 received DONE after 76 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_644 completed: 300 chars, 76 chunks, TTFT=16654.2ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:57504 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_704
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_704
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_605 received DONE after 131 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_605 completed: 132 chars, 131 chunks, TTFT=15570.2ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44812 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_705
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_705
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 188, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_586 received DONE after 153 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_586 completed: 695 chars, 153 chunks, TTFT=14990.3ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:42066 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_559 received DONE after 179 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_559 completed: 179 chars, 179 chunks, TTFT=14398.4ms
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_706
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_706
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_595 received DONE after 138 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_595 completed: 142 chars, 138 chunks, TTFT=15352.1ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44532 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_708
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_708
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:42026 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_707
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_707
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 6, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_609 received DONE after 134 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_609 completed: 532 chars, 134 chunks, TTFT=15570.2ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44860 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_589 received DONE after 157 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_589 completed: 310 chars, 157 chunks, TTFT=15124.8ms
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_709
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_709
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41944 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_612 received DONE after 133 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_612 completed: 528 chars, 133 chunks, TTFT=15658.1ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_590 received DONE after 153 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_590 completed: 305 chars, 153 chunks, TTFT=15107.9ms
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_710
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_710
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:56380 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_650 received DONE after 70 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_650 completed: 276 chars, 70 chunks, TTFT=16918.8ms
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_620 received DONE after 125 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_620 completed: 246 chars, 125 chunks, TTFT=15868.1ms
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_635 received DONE after 95 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_635 completed: 376 chars, 95 chunks, TTFT=16427.8ms
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_711
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_711
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44712 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_712
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_712
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:42022 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_714
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_714
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_713
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_713
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_715
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_715
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] Prefill batch. #new-seq: 3, #new-token: 434, #cached-token: 15, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_646 received DONE after 80 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_646 completed: 317 chars, 80 chunks, TTFT=16785.1ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 2, #new-token: 227, #cached-token: 12, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41966 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_716
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_716
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_654 received DONE after 75 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_654 completed: 300 chars, 75 chunks, TTFT=16969.8ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_631 received DONE after 108 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_631 completed: 420 chars, 108 chunks, TTFT=16286.8ms
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_573 received DONE after 174 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_573 completed: 176 chars, 174 chunks, TTFT=14822.9ms
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_717
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_717
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41868 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41800 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_719
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_719
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_718
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_718
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_618 received DONE after 136 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_618 completed: 540 chars, 136 chunks, TTFT=15789.2ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44906 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_720
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_720
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 6, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_594 received DONE after 158 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_594 completed: 614 chars, 158 chunks, TTFT=15300.4ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41816 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_721
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_721
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 5, token usage: 0.07, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_611 received DONE after 147 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_611 completed: 588 chars, 147 chunks, TTFT=15623.1ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41702 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_622 received DONE after 136 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_622 completed: 136 chars, 136 chunks, TTFT=15910.4ms
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_722
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_722
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44828 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_723
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_723
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] Decode batch. #running-req: 48, #token: 8990, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2349.05, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_615 received DONE after 150 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_615 completed: 587 chars, 150 chunks, TTFT=15670.7ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:42048 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_724
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_724
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_636 received DONE after 115 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_636 completed: 460 chars, 115 chunks, TTFT=16431.7ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] INFO:     127.0.0.1:44610 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_725
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_725
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_629 received DONE after 122 chunks
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_629 completed: 488 chars, 122 chunks, TTFT=16283.9ms
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] INFO:     127.0.0.1:41726 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_726
[2025-07-25 02:13:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_726
[2025-07-25 02:13:01] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:01] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_617 received DONE after 149 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_617 completed: 149 chars, 149 chunks, TTFT=15796.2ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:57520 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_727
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_727
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_676 received DONE after 75 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_676 completed: 296 chars, 75 chunks, TTFT=17499.9ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44764 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_652 received DONE after 98 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_652 completed: 389 chars, 98 chunks, TTFT=16966.6ms
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_728
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_728
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 87, #cached-token: 6, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_729
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_729
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] Decode batch. #running-req: 54, #token: 9965, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2146.98, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_627 received DONE after 134 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_627 completed: 519 chars, 134 chunks, TTFT=16156.7ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41706 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_730
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_730
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 5, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_584 received DONE after 190 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_584 completed: 757 chars, 190 chunks, TTFT=14990.5ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_731
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_731
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_668 received DONE after 80 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_668 completed: 156 chars, 80 chunks, TTFT=17377.6ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_732
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_732
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 146, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_619 received DONE after 158 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_619 completed: 618 chars, 158 chunks, TTFT=15804.7ms
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_607 received DONE after 167 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_607 completed: 170 chars, 167 chunks, TTFT=15570.3ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:42036 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44850 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_734
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_734
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_733
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_733
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_625 received DONE after 153 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_625 completed: 608 chars, 153 chunks, TTFT=15988.0ms
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_591 received DONE after 192 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_591 completed: 761 chars, 192 chunks, TTFT=15135.2ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41776 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_651 received DONE after 104 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_651 completed: 107 chars, 104 chunks, TTFT=16937.9ms
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_736
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_736
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_735
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_735
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44566 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_657 received DONE after 103 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_657 completed: 204 chars, 103 chunks, TTFT=17082.2ms
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_737
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_737
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_599 received DONE after 179 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_599 completed: 712 chars, 179 chunks, TTFT=15437.3ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41990 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_738
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_738
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41956 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_739
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_739
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] Prefill batch. #new-seq: 2, #new-token: 226, #cached-token: 12, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_666 received DONE after 92 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_666 completed: 91 chars, 92 chunks, TTFT=17306.0ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_740
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_740
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_610 received DONE after 177 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_610 completed: 495 chars, 177 chunks, TTFT=15563.8ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_653 received DONE after 111 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_653 completed: 428 chars, 111 chunks, TTFT=16949.7ms
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_741
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_741
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 100, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44750 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_742
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_742
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_640 received DONE after 133 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_640 completed: 569 chars, 133 chunks, TTFT=16606.5ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41746 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_743
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_743
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_684 received DONE after 82 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_684 completed: 312 chars, 82 chunks, TTFT=17821.3ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_744
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_744
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_696 received DONE after 68 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_696 completed: 67 chars, 68 chunks, TTFT=18201.6ms
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_642 received DONE after 132 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_642 completed: 131 chars, 132 chunks, TTFT=16651.6ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41730 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_745
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_745
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44516 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_746
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_746
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_632 received DONE after 150 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_632 completed: 151 chars, 150 chunks, TTFT=16324.4ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44762 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_747
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_747
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] Prefill batch. #new-seq: 2, #new-token: 241, #cached-token: 12, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_658 received DONE after 116 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_658 completed: 447 chars, 116 chunks, TTFT=17061.3ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41694 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_748
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_748
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] Decode batch. #running-req: 48, #token: 9347, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2297.81, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_678 received DONE after 87 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_678 completed: 332 chars, 87 chunks, TTFT=17734.5ms
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_659 received DONE after 121 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_659 completed: 121 chars, 121 chunks, TTFT=17085.4ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44842 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41766 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 6, token usage: 0.08, #running-req: 45, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_749
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_749
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_675 received DONE after 104 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_675 completed: 399 chars, 104 chunks, TTFT=17489.0ms
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_750
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_750
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_690 received DONE after 87 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_690 completed: 170 chars, 87 chunks, TTFT=17930.0ms
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_643 received DONE after 144 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_643 completed: 144 chars, 144 chunks, TTFT=16654.4ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41898 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_695 received DONE after 74 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_695 completed: 292 chars, 74 chunks, TTFT=18097.3ms
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_751
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_751
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44586 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_752
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_752
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44790 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41908 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_753
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_753
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_754
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_754
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] Prefill batch. #new-seq: 2, #new-token: 247, #cached-token: 10, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] Prefill batch. #new-seq: 2, #new-token: 260, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_616 received DONE after 192 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_616 completed: 533 chars, 192 chunks, TTFT=15716.9ms
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_630 received DONE after 162 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_630 completed: 644 chars, 162 chunks, TTFT=16273.4ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44580 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41784 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_755
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_755
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_756
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_756
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 140, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_670 received DONE after 114 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_670 completed: 452 chars, 114 chunks, TTFT=17385.8ms
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_623 received DONE after 188 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_623 completed: 189 chars, 188 chunks, TTFT=15891.1ms
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_633 received DONE after 166 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_633 completed: 168 chars, 166 chunks, TTFT=16351.5ms
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_697 received DONE after 82 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_697 completed: 321 chars, 82 chunks, TTFT=18211.2ms
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_757
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_757
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:44496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] INFO:     127.0.0.1:41936 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_758
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_758
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] INFO:     127.0.0.1:51796 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_759
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_759
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_760
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_760
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] Prefill batch. #new-seq: 2, #new-token: 291, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:02] Prefill batch. #new-seq: 2, #new-token: 257, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:02] Decode batch. #running-req: 51, #token: 9549, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2411.64, #queue-req: 0,
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_661 received DONE after 130 chunks
[2025-07-25 02:13:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_661 completed: 520 chars, 130 chunks, TTFT=17186.6ms
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_693 received DONE after 84 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_693 completed: 83 chars, 84 chunks, TTFT=18085.1ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44658 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:42020 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_761
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_761
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_762
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_762
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_656 received DONE after 136 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_656 completed: 540 chars, 136 chunks, TTFT=17008.1ms
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_663 received DONE after 129 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_663 completed: 512 chars, 129 chunks, TTFT=17191.6ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:42034 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:56380 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_705 received DONE after 79 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_705 completed: 299 chars, 79 chunks, TTFT=18399.3ms
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_764
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_764
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_763
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_763
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_711 received DONE after 73 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_711 completed: 288 chars, 73 chunks, TTFT=18544.4ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41854 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44812 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_766
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_766
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_765
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_765
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] Prefill batch. #new-seq: 2, #new-token: 201, #cached-token: 10, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] Prefill batch. #new-seq: 2, #new-token: 315, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_714 received DONE after 72 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_714 completed: 73 chars, 72 chunks, TTFT=18559.3ms
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_716 received DONE after 72 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_716 completed: 284 chars, 72 chunks, TTFT=18561.4ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:56388 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:42022 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_677 received DONE after 117 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_677 completed: 118 chars, 117 chunks, TTFT=17631.3ms
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_768
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_768
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_767
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_767
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:42040 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_649 received DONE after 155 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_649 completed: 159 chars, 155 chunks, TTFT=16822.5ms
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_680 received DONE after 109 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_680 completed: 420 chars, 109 chunks, TTFT=17734.2ms
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_769
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_769
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:51822 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_770
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_770
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_771
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_771
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] Prefill batch. #new-seq: 2, #new-token: 246, #cached-token: 10, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_660 received DONE after 142 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_660 completed: 280 chars, 142 chunks, TTFT=17132.4ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_772
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_772
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_641 received DONE after 172 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_641 completed: 688 chars, 172 chunks, TTFT=16654.4ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41966 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_773
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_773
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_710 received DONE after 84 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_710 completed: 332 chars, 84 chunks, TTFT=18535.4ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44504 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_774
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_774
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_720 received DONE after 83 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_720 completed: 316 chars, 83 chunks, TTFT=18700.0ms
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_645 received DONE after 162 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_645 completed: 632 chars, 162 chunks, TTFT=16765.3ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41944 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_775
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_775
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41482 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_776
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_776
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] Prefill batch. #new-seq: 2, #new-token: 170, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_707 received DONE after 93 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_707 completed: 354 chars, 93 chunks, TTFT=18410.5ms
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_647 received DONE after 170 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_647 completed: 668 chars, 170 chunks, TTFT=16784.9ms
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_694 received DONE after 112 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_694 completed: 221 chars, 112 chunks, TTFT=18090.0ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:42026 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_777
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_777
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_778
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_778
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:51808 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 153, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_779
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_779
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_725 received DONE after 73 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_725 completed: 275 chars, 73 chunks, TTFT=18929.9ms
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_723 received DONE after 78 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_723 completed: 295 chars, 78 chunks, TTFT=18841.5ms
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_721 received DONE after 81 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_721 completed: 320 chars, 81 chunks, TTFT=18729.9ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44828 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41816 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_781
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_781
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_780
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_780
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41716 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_782
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_782
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] Prefill batch. #new-seq: 2, #new-token: 245, #cached-token: 10, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] Prefill batch. #new-seq: 2, #new-token: 274, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_692 received DONE after 116 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_692 completed: 117 chars, 116 chunks, TTFT=18053.0ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44836 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_783
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_783
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_634 received DONE after 184 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_634 completed: 365 chars, 184 chunks, TTFT=16424.6ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:42060 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_648 received DONE after 165 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_648 completed: 644 chars, 165 chunks, TTFT=16822.7ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_784
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_784
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44610 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_785
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_785
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_702 received DONE after 105 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_702 completed: 106 chars, 105 chunks, TTFT=18319.1ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41494 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_786
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_786
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] Decode batch. #running-req: 48, #token: 9522, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2183.81, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_639 received DONE after 184 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_639 completed: 732 chars, 184 chunks, TTFT=16556.2ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:42076 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_638 received DONE after 191 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_638 completed: 191 chars, 191 chunks, TTFT=16537.9ms
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_787
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_787
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44596 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_788
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_788
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_687 received DONE after 127 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_687 completed: 128 chars, 127 chunks, TTFT=17886.0ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_789
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_789
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_719 received DONE after 96 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_719 completed: 368 chars, 96 chunks, TTFT=18726.1ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44742 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] Decode batch. #running-req: 51, #token: 9560, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2393.76, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_790
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_790
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_682 received DONE after 147 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_682 completed: 291 chars, 147 chunks, TTFT=17727.0ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:56370 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_791
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_791
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_665 received DONE after 173 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_665 completed: 344 chars, 173 chunks, TTFT=17195.7ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41800 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_701 received DONE after 120 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_701 completed: 329 chars, 120 chunks, TTFT=18251.9ms
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_792
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_792
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44880 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_793
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_793
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_691 received DONE after 129 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_691 completed: 130 chars, 129 chunks, TTFT=18030.7ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41948 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_794
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_794
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_743 received DONE after 66 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_743 completed: 260 chars, 66 chunks, TTFT=19488.7ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41746 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_795
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_795
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] Prefill batch. #new-seq: 2, #new-token: 238, #cached-token: 10, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_655 received DONE after 184 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_655 completed: 736 chars, 184 chunks, TTFT=16969.5ms
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_796
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_796
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_704 received DONE after 121 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_704 completed: 335 chars, 121 chunks, TTFT=18343.2ms
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_734 received DONE after 82 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_734 completed: 160 chars, 82 chunks, TTFT=19227.3ms
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_679 received DONE after 154 chunks
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_679 completed: 599 chars, 154 chunks, TTFT=17718.2ms
[2025-07-25 02:13:03] [sglang_test_framework.core.metrics_collector] [INFO] Completed 700 requests, success rate: 100.0%
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:03] INFO:     127.0.0.1:44654 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:42036 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_798
[2025-07-25 02:13:03] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:03] INFO:     127.0.0.1:57504 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_798
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_797
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_797
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_799
[2025-07-25 02:13:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_799
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_688 received DONE after 143 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_688 completed: 556 chars, 143 chunks, TTFT=17892.1ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] Prefill batch. #new-seq: 2, #new-token: 312, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 150, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44906 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_800
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_800
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_674 received DONE after 166 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_674 completed: 167 chars, 166 chunks, TTFT=17500.0ms
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_669 received DONE after 170 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_669 completed: 169 chars, 170 chunks, TTFT=17390.6ms
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_746 received DONE after 67 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_746 completed: 264 chars, 67 chunks, TTFT=19581.8ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44516 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41754 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_802
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_802
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_801
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_801
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41804 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_803
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_803
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] Prefill batch. #new-seq: 2, #new-token: 289, #cached-token: 10, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] Prefill batch. #new-seq: 2, #new-token: 220, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_722 received DONE after 104 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_722 completed: 288 chars, 104 chunks, TTFT=18836.7ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44890 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_804
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_804
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 5, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_673 received DONE after 168 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_673 completed: 668 chars, 168 chunks, TTFT=17486.1ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41926 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_805
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_805
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_713 received DONE after 124 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_713 completed: 245 chars, 124 chunks, TTFT=18544.2ms
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_703 received DONE after 130 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_703 completed: 516 chars, 130 chunks, TTFT=18335.5ms
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_662 received DONE after 183 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_662 completed: 725 chars, 183 chunks, TTFT=17188.0ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44712 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41728 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_806
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_806
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_807
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_807
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44770 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_808
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_808
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_699 received DONE after 135 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_699 completed: 136 chars, 135 chunks, TTFT=18236.2ms
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_752 received DONE after 67 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_752 completed: 264 chars, 67 chunks, TTFT=19724.2ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:42004 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_809
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_809
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44586 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_810
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_810
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] Prefill batch. #new-seq: 2, #new-token: 307, #cached-token: 11, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_671 received DONE after 177 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_671 completed: 691 chars, 177 chunks, TTFT=17434.9ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41820 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_672 received DONE after 176 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_672 completed: 700 chars, 176 chunks, TTFT=17462.6ms
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_811
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_811
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44566 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_737 received DONE after 90 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_737 completed: 344 chars, 90 chunks, TTFT=19328.6ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41684 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_812
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_812
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_813
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_813
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_667 received DONE after 184 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_667 completed: 364 chars, 184 chunks, TTFT=17314.9ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44900 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_814
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_814
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_664 received DONE after 191 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_664 completed: 380 chars, 191 chunks, TTFT=17193.8ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41702 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_815
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_815
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] Prefill batch. #new-seq: 2, #new-token: 307, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_730 received DONE after 104 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_730 completed: 204 chars, 104 chunks, TTFT=19104.9ms
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_816
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_816
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44688 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_689 received DONE after 163 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_689 completed: 322 chars, 163 chunks, TTFT=17925.5ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41706 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_683 received DONE after 170 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_683 completed: 664 chars, 170 chunks, TTFT=17737.3ms
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_817
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_817
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44794 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] Decode batch. #running-req: 48, #token: 9398, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2204.25, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_818
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_818
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_708 received DONE after 144 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_708 completed: 143 chars, 144 chunks, TTFT=18399.8ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44532 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_819
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_819
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_706 received DONE after 147 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_706 completed: 584 chars, 147 chunks, TTFT=18408.0ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:42066 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_820
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_820
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_749 received DONE after 83 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_749 completed: 316 chars, 83 chunks, TTFT=19721.1ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44842 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_821
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_821
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] Decode batch. #running-req: 51, #token: 10085, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2479.79, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_762 received DONE after 78 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_762 completed: 79 chars, 78 chunks, TTFT=19996.7ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:56360 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_822
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_822
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_685 received DONE after 175 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_685 completed: 696 chars, 175 chunks, TTFT=17859.9ms
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_738 received DONE after 112 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_738 completed: 444 chars, 112 chunks, TTFT=19312.1ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_758 received DONE after 79 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_758 completed: 299 chars, 79 chunks, TTFT=19870.0ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41990 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:56382 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_823
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_823
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_824
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_824
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41976 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_825
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_825
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] Prefill batch. #new-seq: 2, #new-token: 291, #cached-token: 12, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_726 received DONE after 130 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_726 completed: 256 chars, 130 chunks, TTFT=18955.9ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_751 received DONE after 93 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_751 completed: 368 chars, 93 chunks, TTFT=19735.5ms
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_826
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_826
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41898 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_827
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_827
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] Prefill batch. #new-seq: 2, #new-token: 235, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_709 received DONE after 148 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_709 completed: 588 chars, 148 chunks, TTFT=18527.7ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44860 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_828
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_828
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_764 received DONE after 84 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_764 completed: 332 chars, 84 chunks, TTFT=20000.3ms
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_747 received DONE after 98 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_747 completed: 385 chars, 98 chunks, TTFT=19588.3ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:42034 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44762 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_829
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_829
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_830
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_830
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_739 received DONE after 118 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_739 completed: 468 chars, 118 chunks, TTFT=19311.9ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41956 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_831
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_831
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_780 received DONE after 70 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_780 completed: 263 chars, 70 chunks, TTFT=20414.2ms
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_733 received DONE after 120 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_733 completed: 119 chars, 120 chunks, TTFT=19203.6ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44826 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_681 received DONE after 190 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_681 completed: 189 chars, 190 chunks, TTFT=17727.2ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41816 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_832
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_832
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_833
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_833
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_686 received DONE after 183 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_686 completed: 728 chars, 183 chunks, TTFT=17900.7ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44572 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_753 received DONE after 96 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_753 completed: 189 chars, 96 chunks, TTFT=19725.7ms
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_834
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_834
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41726 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_835
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_835
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44790 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_836
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_836
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] Prefill batch. #new-seq: 2, #new-token: 303, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:04] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_732 received DONE after 132 chunks
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_732 completed: 524 chars, 132 chunks, TTFT=19167.9ms
[2025-07-25 02:13:04] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:04] INFO:     127.0.0.1:41840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_837
[2025-07-25 02:13:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_837
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_736 received DONE after 123 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_736 completed: 488 chars, 123 chunks, TTFT=19309.9ms
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_717 received DONE after 154 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_717 completed: 599 chars, 154 chunks, TTFT=18700.1ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:42020 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_838
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_838
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_839
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_839
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_712 received DONE after 165 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_712 completed: 656 chars, 165 chunks, TTFT=18559.7ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_840
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_840
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_744 received DONE after 118 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_744 completed: 119 chars, 118 chunks, TTFT=19581.8ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_724 received DONE after 154 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_724 completed: 609 chars, 154 chunks, TTFT=18900.4ms
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_841
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_841
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:42048 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_842
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_842
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_729 received DONE after 144 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_729 completed: 284 chars, 144 chunks, TTFT=19105.3ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41510 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_731 received DONE after 145 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_731 completed: 576 chars, 145 chunks, TTFT=19107.6ms
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_700 received DONE after 189 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_700 completed: 752 chars, 189 chunks, TTFT=18210.9ms
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_843
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_843
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44528 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_844
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_844
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_845
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_845
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] Prefill batch. #new-seq: 2, #new-token: 194, #cached-token: 12, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_765 received DONE after 107 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_765 completed: 106 chars, 107 chunks, TTFT=20003.2ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41854 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_846
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_846
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_698 received DONE after 188 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_698 completed: 373 chars, 188 chunks, TTFT=18212.3ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_847
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_847
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_745 received DONE after 127 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_745 completed: 504 chars, 127 chunks, TTFT=19600.5ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41730 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_848
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_848
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] Decode batch. #running-req: 49, #token: 9365, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2209.24, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_794 received DONE after 70 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_794 completed: 276 chars, 70 chunks, TTFT=20853.3ms
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_788 received DONE after 74 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_788 completed: 292 chars, 74 chunks, TTFT=20653.0ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41948 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_849
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_849
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44596 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_850
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_850
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_799 received DONE after 67 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_799 completed: 252 chars, 67 chunks, TTFT=20981.3ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_851
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_851
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] Decode batch. #running-req: 50, #token: 9505, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2282.76, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_778 received DONE after 98 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_778 completed: 388 chars, 98 chunks, TTFT=20403.3ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41746 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_795 received DONE after 76 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_795 completed: 286 chars, 76 chunks, TTFT=20853.3ms
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_852
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_852
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:42026 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_853
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_853
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] Prefill batch. #new-seq: 2, #new-token: 266, #cached-token: 10, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_760 received DONE after 123 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_760 completed: 242 chars, 123 chunks, TTFT=19869.9ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:51796 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_769 received DONE after 115 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_769 completed: 443 chars, 115 chunks, TTFT=20127.5ms
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_757 received DONE after 127 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_757 completed: 504 chars, 127 chunks, TTFT=19871.0ms
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_797 received DONE after 74 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_797 completed: 292 chars, 74 chunks, TTFT=20981.7ms
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_854
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_854
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:42036 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_856
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_856
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 87, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44850 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_750 received DONE after 134 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_750 completed: 133 chars, 134 chunks, TTFT=19728.0ms
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_855
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_855
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_857
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_857
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41766 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_858
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_858
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_768 received DONE after 113 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_768 completed: 223 chars, 113 chunks, TTFT=20132.0ms
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_798 received DONE after 74 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_798 completed: 292 chars, 74 chunks, TTFT=20971.8ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41944 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_775 received DONE after 105 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:56388 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_775 completed: 416 chars, 105 chunks, TTFT=20378.7ms
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_860
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_860
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_859
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_859
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44654 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_861
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_861
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] Prefill batch. #new-seq: 4, #new-token: 398, #cached-token: 23, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_715 received DONE after 192 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_715 completed: 752 chars, 192 chunks, TTFT=18543.7ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] Prefill batch. #new-seq: 2, #new-token: 293, #cached-token: 12, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_862
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_862
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 5, token usage: 0.08, #running-req: 54, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_813 received DONE after 68 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_813 completed: 255 chars, 68 chunks, TTFT=21282.3ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41684 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_863
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_863
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_759 received DONE after 135 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_759 completed: 524 chars, 135 chunks, TTFT=19870.6ms
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_790 received DONE after 84 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_790 completed: 165 chars, 84 chunks, TTFT=20789.6ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 118, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41936 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44742 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_865
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_865
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_864
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_864
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_718 received DONE after 191 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_718 completed: 378 chars, 191 chunks, TTFT=18700.6ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44734 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_866
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_866
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 133, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_728 received DONE after 169 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_728 completed: 170 chars, 169 chunks, TTFT=19080.0ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41868 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_867
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_867
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_763 received DONE after 127 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_763 completed: 504 chars, 127 chunks, TTFT=20005.3ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:56380 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_767 received DONE after 126 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_767 completed: 500 chars, 126 chunks, TTFT=20124.5ms
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_868
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_868
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:42022 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 171, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_869
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_869
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_741 received DONE after 159 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_741 completed: 158 chars, 159 chunks, TTFT=19440.5ms
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_809 received DONE after 78 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_809 completed: 152 chars, 78 chunks, TTFT=21163.0ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44764 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_870
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_870
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:42004 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_871
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_871
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 5, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_770 received DONE after 124 chunks
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_770 completed: 492 chars, 124 chunks, TTFT=20135.0ms
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:05] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:51822 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_872
[2025-07-25 02:13:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_872
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:13:05] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:05] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_814 received DONE after 76 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_814 completed: 300 chars, 76 chunks, TTFT=21307.5ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 113, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_873
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_873
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_782 received DONE after 124 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_782 completed: 492 chars, 124 chunks, TTFT=20415.9ms
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_742 received DONE after 163 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_742 completed: 635 chars, 163 chunks, TTFT=19458.5ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44900 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_874
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_874
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41716 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_875
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_875
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_740 received DONE after 171 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_740 completed: 680 chars, 171 chunks, TTFT=19338.3ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_876
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_876
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_727 received DONE after 193 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_727 completed: 755 chars, 193 chunks, TTFT=18985.9ms
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_748 received DONE after 162 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_748 completed: 631 chars, 162 chunks, TTFT=19605.0ms
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_807 received DONE after 89 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_807 completed: 339 chars, 89 chunks, TTFT=21160.6ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41728 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_877
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_877
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44750 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41694 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_878
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_878
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_879
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_879
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] Prefill batch. #new-seq: 2, #new-token: 235, #cached-token: 12, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] Prefill batch. #new-seq: 2, #new-token: 218, #cached-token: 12, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_808 received DONE after 87 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_808 completed: 90 chars, 87 chunks, TTFT=21171.0ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44770 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_880
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_880
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_735 received DONE after 178 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_735 completed: 708 chars, 178 chunks, TTFT=19306.3ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41776 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_881
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_881
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 5, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_777 received DONE after 121 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_777 completed: 468 chars, 121 chunks, TTFT=20417.8ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_826 received DONE after 70 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_826 completed: 276 chars, 70 chunks, TTFT=21639.3ms
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_882
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_882
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] Prefill batch. #new-seq: 2, #new-token: 138, #cached-token: 12, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_883
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_883
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_803 received DONE after 103 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_803 completed: 404 chars, 103 chunks, TTFT=20986.8ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41804 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_884
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_884
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] Decode batch. #running-req: 51, #token: 9903, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2260.36, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] Decode batch. #running-req: 47, #token: 8948, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2205.60, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_821 received DONE after 81 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_821 completed: 222 chars, 81 chunks, TTFT=21574.7ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44842 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_885
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_885
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_789 received DONE after 131 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_789 completed: 520 chars, 131 chunks, TTFT=20660.6ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:53220 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_886
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_886
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_804 received DONE after 110 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_804 completed: 436 chars, 110 chunks, TTFT=21008.1ms
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_802 received DONE after 110 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_802 completed: 432 chars, 110 chunks, TTFT=20999.6ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 145, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_887
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:57520 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_887
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_888
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_888
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] Prefill batch. #new-seq: 2, #new-token: 166, #cached-token: 12, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_820 received DONE after 91 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_820 completed: 347 chars, 91 chunks, TTFT=21527.4ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44516 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_889
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_889
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_812 received DONE after 99 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_812 completed: 194 chars, 99 chunks, TTFT=21279.1ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:42066 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_890
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_890
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_766 received DONE after 159 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_766 completed: 620 chars, 159 chunks, TTFT=20005.0ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44812 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_891
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_891
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 171, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_816 received DONE after 103 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_816 completed: 106 chars, 103 chunks, TTFT=21309.5ms
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_755 received DONE after 168 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_755 completed: 655 chars, 168 chunks, TTFT=19863.7ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_786 received DONE after 146 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_786 completed: 576 chars, 146 chunks, TTFT=20550.9ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44580 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_892
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_892
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_893
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_893
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44688 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_894
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_894
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_784 received DONE after 149 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_784 completed: 592 chars, 149 chunks, TTFT=20496.7ms
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_776 received DONE after 153 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_776 completed: 608 chars, 153 chunks, TTFT=20378.7ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] Prefill batch. #new-seq: 2, #new-token: 259, #cached-token: 12, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41482 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_895
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_895
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:42060 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_896
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_896
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_792 received DONE after 131 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_792 completed: 134 chars, 131 chunks, TTFT=20849.8ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44566 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_897
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_897
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] Prefill batch. #new-seq: 2, #new-token: 186, #cached-token: 12, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_787 received DONE after 144 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_787 completed: 572 chars, 144 chunks, TTFT=20655.2ms
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_836 received DONE after 81 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_836 completed: 257 chars, 81 chunks, TTFT=21874.7ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:42076 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.metrics_collector] [INFO] Completed 800 requests, success rate: 100.0%
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41800 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_898
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_898
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_899
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_899
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_783 received DONE after 147 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_783 completed: 584 chars, 147 chunks, TTFT=20461.9ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44836 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_900
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_900
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 89, #cached-token: 5, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_754 received DONE after 190 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_754 completed: 377 chars, 190 chunks, TTFT=19735.0ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41908 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_901
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_901
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_771 received DONE after 165 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_771 completed: 656 chars, 165 chunks, TTFT=20135.0ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41494 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_902
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_902
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_761 received DONE after 173 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_761 completed: 172 chars, 173 chunks, TTFT=19997.8ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44658 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_903
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_903
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_756 received DONE after 188 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_756 completed: 748 chars, 188 chunks, TTFT=19863.5ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41784 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_904
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_904
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_819 received DONE after 114 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_819 completed: 113 chars, 114 chunks, TTFT=21453.9ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] INFO:     127.0.0.1:44532 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:06] Prefill batch. #new-seq: 1, #new-token: 175, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_905
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_905
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_846 received DONE after 81 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_846 completed: 222 chars, 81 chunks, TTFT=22229.1ms
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_829 received DONE after 102 chunks
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_829 completed: 103 chars, 102 chunks, TTFT=21759.7ms
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:42034 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_907
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_907
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] INFO:     127.0.0.1:41854 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:06] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:06] Prefill batch. #new-seq: 2, #new-token: 271, #cached-token: 12, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_906
[2025-07-25 02:13:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_906
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_774 received DONE after 166 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_774 completed: 648 chars, 166 chunks, TTFT=20344.0ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] Decode batch. #running-req: 50, #token: 9777, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2664.29, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44504 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_839 received DONE after 94 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_839 completed: 93 chars, 94 chunks, TTFT=22018.4ms
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_908
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_908
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_909
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_909
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_772 received DONE after 178 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_772 completed: 712 chars, 178 chunks, TTFT=20256.0ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_910
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_910
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] Decode batch. #running-req: 49, #token: 9279, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2398.21, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_793 received DONE after 152 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_793 completed: 604 chars, 152 chunks, TTFT=20821.5ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44880 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_911
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_911
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 95, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_847 received DONE after 90 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_847 completed: 344 chars, 90 chunks, TTFT=22266.4ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:42040 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_912
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_912
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_837 received DONE after 107 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_837 completed: 107 chars, 107 chunks, TTFT=21964.6ms
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_773 received DONE after 186 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_773 completed: 190 chars, 186 chunks, TTFT=20308.3ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_913
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_913
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_914
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_914
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] Prefill batch. #new-seq: 2, #new-token: 246, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_779 received DONE after 173 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_779 completed: 676 chars, 173 chunks, TTFT=20462.4ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41966 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_866 received DONE after 71 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_866 completed: 139 chars, 71 chunks, TTFT=22728.2ms
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_915
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_915
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44734 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_916
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_916
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 99, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_801 received DONE after 158 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_801 completed: 314 chars, 158 chunks, TTFT=20986.5ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41754 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_917
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_917
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_791 received DONE after 159 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_791 completed: 629 chars, 159 chunks, TTFT=20816.7ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:56370 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_845 received DONE after 96 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_845 completed: 97 chars, 96 chunks, TTFT=22266.4ms
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_918
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_918
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_919
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_919
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_840 received DONE after 112 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_840 completed: 478 chars, 112 chunks, TTFT=22032.2ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_781 received DONE after 180 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_781 completed: 181 chars, 180 chunks, TTFT=20462.2ms
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_920
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_920
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_921
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_921
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_796 received DONE after 157 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_796 completed: 624 chars, 157 chunks, TTFT=20949.6ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:57504 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_922
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_922
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_810 received DONE after 150 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_810 completed: 584 chars, 150 chunks, TTFT=21170.9ms
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_806 received DONE after 150 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_806 completed: 583 chars, 150 chunks, TTFT=21158.5ms
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_785 received DONE after 180 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_785 completed: 716 chars, 180 chunks, TTFT=20516.9ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_924
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_924
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44712 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44610 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_923
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_923
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_925
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_925
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] Prefill batch. #new-seq: 2, #new-token: 228, #cached-token: 12, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_862 received DONE after 88 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_862 completed: 89 chars, 88 chunks, TTFT=22597.0ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_926
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_926
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_825 received DONE after 132 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_825 completed: 515 chars, 132 chunks, TTFT=21645.5ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41976 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_927
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_927
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_867 received DONE after 85 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_867 completed: 340 chars, 85 chunks, TTFT=22764.0ms
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_805 received DONE after 163 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_805 completed: 652 chars, 163 chunks, TTFT=21090.6ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41926 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_850 received DONE after 102 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44586 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_850 completed: 282 chars, 102 chunks, TTFT=22362.1ms
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_818 received DONE after 145 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_818 completed: 403 chars, 145 chunks, TTFT=21447.2ms
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_868 received DONE after 82 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_868 completed: 324 chars, 82 chunks, TTFT=22828.7ms
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_929
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_929
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:56380 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_928
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_928
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41868 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_930
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_930
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_931
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_931
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] Prefill batch. #new-seq: 2, #new-token: 221, #cached-token: 12, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44794 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_932
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_932
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 5, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_855 received DONE after 97 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_855 completed: 190 chars, 97 chunks, TTFT=22594.3ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:42576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_933
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_933
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_811 received DONE after 162 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_811 completed: 635 chars, 162 chunks, TTFT=21274.0ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_822 received DONE after 144 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_822 completed: 563 chars, 144 chunks, TTFT=21639.4ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41820 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_842 received DONE after 120 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_842 completed: 239 chars, 120 chunks, TTFT=22153.4ms
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_934
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_934
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_935
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_935
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:56360 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_936
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_936
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] Prefill batch. #new-seq: 2, #new-token: 146, #cached-token: 12, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_841 received DONE after 120 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_841 completed: 473 chars, 120 chunks, TTFT=22153.4ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:42048 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_937
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_937
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_871 received DONE after 91 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_871 completed: 93 chars, 91 chunks, TTFT=22840.0ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_938
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_938
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_824 received DONE after 147 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_824 completed: 150 chars, 147 chunks, TTFT=21639.4ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:56382 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_939
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_939
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_831 received DONE after 141 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_831 completed: 143 chars, 141 chunks, TTFT=21761.9ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41956 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_940
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_940
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_886 received DONE after 66 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_886 completed: 248 chars, 66 chunks, TTFT=23385.0ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:53220 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_941
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_941
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 133, #cached-token: 5, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_832 received DONE after 140 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_832 completed: 276 chars, 140 chunks, TTFT=21872.1ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] INFO:     127.0.0.1:42004 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_942
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_942
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:07] Prefill batch. #new-seq: 1, #new-token: 145, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] Decode batch. #running-req: 47, #token: 8453, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2085.08, #queue-req: 0,
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_817 received DONE after 162 chunks
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_817 completed: 322 chars, 162 chunks, TTFT=21437.8ms
[2025-07-25 02:13:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:07] INFO:     127.0.0.1:44826 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_943
[2025-07-25 02:13:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_943
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] Decode batch. #running-req: 52, #token: 10055, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2241.76, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_884 received DONE after 84 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_884 completed: 324 chars, 84 chunks, TTFT=23219.7ms
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41804 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_944
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_944
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 88, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_800 received DONE after 187 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_800 completed: 732 chars, 187 chunks, TTFT=21000.0ms
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_835 received DONE after 148 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_835 completed: 150 chars, 148 chunks, TTFT=21874.0ms
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41726 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_946
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_946
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44906 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_945
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_945
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_890 received DONE after 77 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_890 completed: 295 chars, 77 chunks, TTFT=23443.7ms
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:42066 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_947
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_947
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_823 received DONE after 163 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_823 completed: 324 chars, 163 chunks, TTFT=21645.8ms
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_901 received DONE after 65 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_901 completed: 180 chars, 65 chunks, TTFT=23749.6ms
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44596 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_948
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_948
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_878 received DONE after 103 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_878 completed: 287 chars, 103 chunks, TTFT=23064.8ms
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_949
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_949
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41908 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_857 received DONE after 124 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_857 completed: 125 chars, 124 chunks, TTFT=22594.1ms
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_950
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_950
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44850 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_951
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_951
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] Prefill batch. #new-seq: 2, #new-token: 285, #cached-token: 11, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_828 received DONE after 167 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_828 completed: 652 chars, 167 chunks, TTFT=21738.1ms
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_903 received DONE after 70 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_903 completed: 272 chars, 70 chunks, TTFT=23790.2ms
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_843 received DONE after 142 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_843 completed: 556 chars, 142 chunks, TTFT=22226.4ms
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_815 received DONE after 188 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_815 completed: 190 chars, 188 chunks, TTFT=21282.6ms
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44658 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41702 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44860 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41510 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_952
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_952
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_955
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_955
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_953
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_953
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_954
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_954
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] Prefill batch. #new-seq: 2, #new-token: 293, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_833 received DONE after 160 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_833 completed: 318 chars, 160 chunks, TTFT=21871.7ms
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41816 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_956
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_956
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_897 received DONE after 89 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_897 completed: 339 chars, 89 chunks, TTFT=23560.5ms
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_957
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_957
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44566 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_893 received DONE after 91 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_893 completed: 94 chars, 91 chunks, TTFT=23551.5ms
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_834 received DONE after 169 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_834 completed: 172 chars, 169 chunks, TTFT=21874.9ms
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44572 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41990 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_958
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_958
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_959
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_959
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_849 received DONE after 147 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_849 completed: 588 chars, 147 chunks, TTFT=22331.4ms
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44580 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_960
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_960
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 6, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_887 received DONE after 96 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_887 completed: 96 chars, 96 chunks, TTFT=23399.9ms
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44750 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_961
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_961
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_863 received DONE after 134 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_863 completed: 136 chars, 134 chunks, TTFT=22713.5ms
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41684 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_962
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_962
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_872 received DONE after 130 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_872 completed: 504 chars, 130 chunks, TTFT=22866.8ms
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_963
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_963
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 5, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] Decode batch. #running-req: 49, #token: 9319, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2455.38, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_827 received DONE after 188 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_827 completed: 374 chars, 188 chunks, TTFT=21648.1ms
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:51822 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_964
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_964
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_861 received DONE after 149 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_861 completed: 150 chars, 149 chunks, TTFT=22593.6ms
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_830 received DONE after 190 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_830 completed: 191 chars, 190 chunks, TTFT=21740.9ms
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44762 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_966
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_966
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41898 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_921 received DONE after 65 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_921 completed: 66 chars, 65 chunks, TTFT=24329.5ms
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_877 received DONE after 129 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_877 completed: 516 chars, 129 chunks, TTFT=23038.1ms
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_965
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_965
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41728 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44654 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_967
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_967
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_968
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_968
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] Prefill batch. #new-seq: 2, #new-token: 206, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] Prefill batch. #new-seq: 2, #new-token: 287, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] Decode batch. #running-req: 50, #token: 10058, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2427.34, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_875 received DONE after 133 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_875 completed: 264 chars, 133 chunks, TTFT=23028.3ms
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_909 received DONE after 84 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_909 completed: 85 chars, 84 chunks, TTFT=24014.2ms
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41716 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 122, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_905 received DONE after 91 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_905 completed: 360 chars, 91 chunks, TTFT=23896.4ms
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_969
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_969
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_970
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_970
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_971
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_971
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_879 received DONE after 136 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_879 completed: 136 chars, 136 chunks, TTFT=23039.8ms
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] INFO:     127.0.0.1:44532 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_972
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_972
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:08] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:08] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_838 received DONE after 183 chunks
[2025-07-25 02:13:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_838 completed: 732 chars, 183 chunks, TTFT=22020.8ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:08] INFO:     127.0.0.1:42020 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_973
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_973
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] Prefill batch. #new-seq: 1, #new-token: 89, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_859 received DONE after 158 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_859 completed: 675 chars, 158 chunks, TTFT=22593.7ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:41694 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_891 received DONE after 116 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_891 completed: 448 chars, 116 chunks, TTFT=23524.6ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_885 received DONE after 124 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_885 completed: 245 chars, 124 chunks, TTFT=23336.1ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_974
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_974
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:42036 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44842 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] Prefill batch. #new-seq: 1, #new-token: 95, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_856 received DONE after 161 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_856 completed: 449 chars, 161 chunks, TTFT=22567.9ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_976
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_976
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_975
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_975
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_898 received DONE after 109 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_898 completed: 304 chars, 109 chunks, TTFT=23653.4ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44812 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_876 received DONE after 141 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_876 completed: 547 chars, 141 chunks, TTFT=23065.1ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_977
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_977
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_978
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_978
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:42076 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_979
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_979
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] Prefill batch. #new-seq: 2, #new-token: 275, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] Prefill batch. #new-seq: 2, #new-token: 193, #cached-token: 12, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_860 received DONE after 163 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_860 completed: 652 chars, 163 chunks, TTFT=22570.1ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:56388 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_980
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_980
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 5, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_848 received DONE after 178 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_848 completed: 712 chars, 178 chunks, TTFT=22331.4ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:41730 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_851 received DONE after 169 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_851 completed: 659 chars, 169 chunks, TTFT=22435.8ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_981
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_981
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_925 received DONE after 77 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_925 completed: 208 chars, 77 chunks, TTFT=24449.7ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_853 received DONE after 172 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_853 completed: 676 chars, 172 chunks, TTFT=22452.6ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_929 received DONE after 73 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_929 completed: 72 chars, 73 chunks, TTFT=24570.8ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_982
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_982
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44610 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:42022 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44828 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_869 received DONE after 157 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_869 completed: 616 chars, 157 chunks, TTFT=22837.3ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_983
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_983
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_984
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_984
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_985
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_985
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:41926 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_986
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_986
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] Prefill batch. #new-seq: 2, #new-token: 303, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_852 received DONE after 174 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_852 completed: 176 chars, 174 chunks, TTFT=22452.8ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:51808 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_987
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_987
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] Prefill batch. #new-seq: 2, #new-token: 196, #cached-token: 12, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_858 received DONE after 172 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_858 completed: 688 chars, 172 chunks, TTFT=22570.5ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44790 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_988
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_988
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_910 received DONE after 104 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_910 completed: 105 chars, 104 chunks, TTFT=24022.3ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:41870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_989
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_989
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_940 received DONE after 72 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_940 completed: 71 chars, 72 chunks, TTFT=24830.6ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_907 received DONE after 112 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_907 completed: 115 chars, 112 chunks, TTFT=23931.4ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:42034 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_844 received DONE after 186 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_844 completed: 368 chars, 186 chunks, TTFT=22266.5ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_991
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_991
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44890 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_990
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_990
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 5, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44528 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_992
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_992
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] Prefill batch. #new-seq: 2, #new-token: 259, #cached-token: 12, token usage: 0.07, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_882 received DONE after 146 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_882 completed: 408 chars, 146 chunks, TTFT=23181.9ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:41956 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_880 received DONE after 153 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_880 completed: 152 chars, 153 chunks, TTFT=23067.8ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_993
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_993
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44770 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_994
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_994
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_908 received DONE after 107 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_908 completed: 424 chars, 107 chunks, TTFT=24011.6ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_939 received DONE after 75 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_939 completed: 292 chars, 75 chunks, TTFT=24760.0ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:41766 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:56382 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] Prefill batch. #new-seq: 1, #new-token: 179, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_996
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_996
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_995
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_995
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_894 received DONE after 136 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_894 completed: 528 chars, 136 chunks, TTFT=23551.5ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_874 received DONE after 159 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_874 completed: 632 chars, 159 chunks, TTFT=23039.5ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44900 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_997
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_997
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44688 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_998
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_998
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] Prefill batch. #new-seq: 2, #new-token: 262, #cached-token: 12, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_870 received DONE after 170 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_870 completed: 173 chars, 170 chunks, TTFT=22857.8ms
[2025-07-25 02:13:09] [sglang_test_framework.core.metrics_collector] [INFO] Completed 900 requests, success rate: 100.0%
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:41746 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_999
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_999
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] Prefill batch. #new-seq: 1, #new-token: 118, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_854 received DONE after 183 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_854 completed: 728 chars, 183 chunks, TTFT=22558.0ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_865 received DONE after 184 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_865 completed: 732 chars, 184 chunks, TTFT=22716.0ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_873 received DONE after 172 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_873 completed: 688 chars, 172 chunks, TTFT=23004.7ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_896 received DONE after 143 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_896 completed: 143 chars, 143 chunks, TTFT=23558.1ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_900 received DONE after 136 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_900 completed: 135 chars, 136 chunks, TTFT=23706.6ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] Decode batch. #running-req: 50, #token: 8241, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2051.63, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] Decode batch. #running-req: 46, #token: 9473, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2234.55, #queue-req: 0,
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_883 received DONE after 162 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_883 completed: 644 chars, 162 chunks, TTFT=23181.9ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_913 received DONE after 112 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_913 completed: 220 chars, 112 chunks, TTFT=24202.1ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_950 received DONE after 76 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_950 completed: 77 chars, 76 chunks, TTFT=25169.6ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_888 received DONE after 157 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_888 completed: 313 chars, 157 chunks, TTFT=23399.7ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_881 received DONE after 176 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_881 completed: 701 chars, 176 chunks, TTFT=23120.5ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_919 received DONE after 118 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_919 completed: 232 chars, 118 chunks, TTFT=24321.1ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_918 received DONE after 115 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_918 completed: 442 chars, 115 chunks, TTFT=24332.9ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_864 received DONE after 191 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_864 completed: 760 chars, 191 chunks, TTFT=22724.8ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_914 received DONE after 122 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_914 completed: 125 chars, 122 chunks, TTFT=24202.0ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_923 received DONE after 111 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_923 completed: 428 chars, 111 chunks, TTFT=24449.9ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_947 received DONE after 84 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_947 completed: 332 chars, 84 chunks, TTFT=25165.0ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_936 received DONE after 100 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_936 completed: 396 chars, 100 chunks, TTFT=24726.4ms
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_895 received DONE after 158 chunks
[2025-07-25 02:13:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_895 completed: 632 chars, 158 chunks, TTFT=23558.1ms
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:09] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:09] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:09] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_892 received DONE after 166 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_892 completed: 664 chars, 166 chunks, TTFT=23558.2ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_899 received DONE after 164 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_899 completed: 603 chars, 164 chunks, TTFT=23653.4ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_927 received DONE after 127 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_927 completed: 504 chars, 127 chunks, TTFT=24480.8ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_941 received DONE after 108 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_941 completed: 109 chars, 108 chunks, TTFT=24849.5ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:10] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_902 received DONE after 161 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_902 completed: 644 chars, 161 chunks, TTFT=23752.3ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_960 received DONE after 80 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_960 completed: 246 chars, 80 chunks, TTFT=25452.0ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_904 received DONE after 159 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_904 completed: 161 chars, 159 chunks, TTFT=23839.7ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:10] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_951 received DONE after 93 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_951 completed: 365 chars, 93 chunks, TTFT=25191.8ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_969 received DONE after 68 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_969 completed: 69 chars, 68 chunks, TTFT=25843.4ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_917 received DONE after 141 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_917 completed: 547 chars, 141 chunks, TTFT=24293.9ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:10] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_970 received DONE after 68 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_970 completed: 256 chars, 68 chunks, TTFT=25894.2ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:10] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_922 received DONE after 144 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_922 completed: 560 chars, 144 chunks, TTFT=24382.9ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_931 received DONE after 137 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_931 completed: 531 chars, 137 chunks, TTFT=24572.6ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_926 received DONE after 140 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_926 completed: 139 chars, 140 chunks, TTFT=24451.6ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:10] Decode batch. #running-req: 38, #token: 7578, token usage: 0.06, cuda graph: True, gen throughput (token/s): 3219.47, #queue-req: 0,
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:10] Decode batch. #running-req: 31, #token: 7059, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2922.65, #queue-req: 0,
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_938 received DONE after 129 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_938 completed: 254 chars, 129 chunks, TTFT=24754.1ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:10] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_948 received DONE after 107 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_948 completed: 410 chars, 107 chunks, TTFT=25184.4ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_932 received DONE after 137 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_932 completed: 532 chars, 137 chunks, TTFT=24582.3ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_889 received DONE after 192 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_889 completed: 764 chars, 192 chunks, TTFT=23420.0ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_946 received DONE after 121 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_946 completed: 238 chars, 121 chunks, TTFT=25031.1ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_915 received DONE after 157 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_915 completed: 160 chars, 157 chunks, TTFT=24201.7ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_930 received DONE after 139 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_930 completed: 275 chars, 139 chunks, TTFT=24578.5ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:10] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_920 received DONE after 154 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_920 completed: 612 chars, 154 chunks, TTFT=24336.3ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_933 received DONE after 142 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_933 completed: 564 chars, 142 chunks, TTFT=24700.5ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_966 received DONE after 89 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_966 completed: 340 chars, 89 chunks, TTFT=25740.7ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:10] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_928 received DONE after 147 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_928 completed: 146 chars, 147 chunks, TTFT=24578.8ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_985 received DONE after 75 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_985 completed: 76 chars, 75 chunks, TTFT=26201.7ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:10] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_984 received DONE after 82 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_984 completed: 324 chars, 82 chunks, TTFT=26162.2ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_949 received DONE after 121 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_949 completed: 122 chars, 121 chunks, TTFT=25192.0ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_945 received DONE after 131 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_945 completed: 360 chars, 131 chunks, TTFT=25045.4ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_906 received DONE after 188 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_906 completed: 734 chars, 188 chunks, TTFT=23931.4ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_980 received DONE after 89 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_980 completed: 92 chars, 89 chunks, TTFT=26058.6ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:10] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_924 received DONE after 167 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_924 completed: 168 chars, 167 chunks, TTFT=24417.6ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:10] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_911 received DONE after 177 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_911 completed: 704 chars, 177 chunks, TTFT=24140.0ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_963 received DONE after 114 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_963 completed: 117 chars, 114 chunks, TTFT=25605.9ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_998 received DONE after 72 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_998 completed: 271 chars, 72 chunks, TTFT=26540.1ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_934 received DONE after 152 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_934 completed: 300 chars, 152 chunks, TTFT=24726.9ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_957 received DONE after 119 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_957 completed: 326 chars, 119 chunks, TTFT=25423.2ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_961 received DONE after 117 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_961 completed: 464 chars, 117 chunks, TTFT=25510.6ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_993 received DONE after 82 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_993 completed: 321 chars, 82 chunks, TTFT=26363.4ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_916 received DONE after 178 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_916 completed: 179 chars, 178 chunks, TTFT=24202.7ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_972 received DONE after 100 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_972 completed: 383 chars, 100 chunks, TTFT=25902.9ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_997 received DONE after 74 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_997 completed: 144 chars, 74 chunks, TTFT=26540.3ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_976 received DONE after 98 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_976 completed: 388 chars, 98 chunks, TTFT=26024.8ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_991 received DONE after 85 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_991 completed: 258 chars, 85 chunks, TTFT=26357.8ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_967 received DONE after 111 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_967 completed: 110 chars, 111 chunks, TTFT=25751.3ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_968 received DONE after 108 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_968 completed: 107 chars, 108 chunks, TTFT=25740.3ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:10] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_974 received DONE after 103 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_974 completed: 359 chars, 103 chunks, TTFT=26017.7ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:10] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:10] INFO:     127.0.0.1:53236 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:10] INFO:     127.0.0.1:42592 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_935 received DONE after 168 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_935 completed: 169 chars, 168 chunks, TTFT=24725.3ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_943 received DONE after 156 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_943 completed: 620 chars, 156 chunks, TTFT=24952.4ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_912 received DONE after 193 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_912 completed: 194 chars, 193 chunks, TTFT=24160.0ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_937 received DONE after 171 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_937 completed: 668 chars, 171 chunks, TTFT=24726.9ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:10] Decode batch. #running-req: 15, #token: 3100, token usage: 0.03, cuda graph: True, gen throughput (token/s): 2091.89, #queue-req: 0,
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_942 received DONE after 165 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_942 completed: 644 chars, 165 chunks, TTFT=24882.3ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_952 received DONE after 142 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_952 completed: 280 chars, 142 chunks, TTFT=25286.7ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:10] Decode batch. #running-req: 15, #token: 3873, token usage: 0.03, cuda graph: True, gen throughput (token/s): 2027.94, #queue-req: 0,
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:10] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_956 received DONE after 147 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_956 completed: 148 chars, 147 chunks, TTFT=25305.7ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:10] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_944 received DONE after 166 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_944 completed: 165 chars, 166 chunks, TTFT=25026.9ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_958 received DONE after 146 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_958 completed: 580 chars, 146 chunks, TTFT=25444.1ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:10] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_977 received DONE after 120 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_977 completed: 330 chars, 120 chunks, TTFT=26055.9ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:10] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_953 received DONE after 159 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_953 completed: 620 chars, 159 chunks, TTFT=25303.8ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_999 received DONE after 101 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_999 completed: 102 chars, 101 chunks, TTFT=26550.5ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_973 received DONE after 131 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_973 completed: 130 chars, 131 chunks, TTFT=25961.1ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_965 received DONE after 140 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_965 completed: 276 chars, 140 chunks, TTFT=25751.4ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_964 received DONE after 138 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_964 completed: 137 chars, 138 chunks, TTFT=25734.1ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_988 received DONE after 121 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_988 completed: 120 chars, 121 chunks, TTFT=26290.9ms
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_982 received DONE after 124 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_982 completed: 245 chars, 124 chunks, TTFT=26174.6ms
[2025-07-25 02:13:10] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:10] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_983 received DONE after 127 chunks
[2025-07-25 02:13:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_983 completed: 355 chars, 127 chunks, TTFT=26202.0ms
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:11] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_987 received DONE after 129 chunks
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_987 completed: 132 chars, 129 chunks, TTFT=26202.9ms
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_959 received DONE after 166 chunks
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_959 completed: 647 chars, 166 chunks, TTFT=25433.6ms
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:11] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:11] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:11] Decode batch. #running-req: 7, #token: 1786, token usage: 0.01, cuda graph: True, gen throughput (token/s): 985.76, #queue-req: 0,
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:11] Decode batch. #running-req: 8, #token: 2154, token usage: 0.02, cuda graph: True, gen throughput (token/s): 960.52, #queue-req: 0,
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_955 received DONE after 184 chunks
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_955 completed: 364 chars, 184 chunks, TTFT=25293.2ms
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_962 received DONE after 172 chunks
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_962 completed: 171 chars, 172 chunks, TTFT=25604.6ms
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:11] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:11] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_992 received DONE after 143 chunks
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_992 completed: 144 chars, 143 chunks, TTFT=26373.2ms
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_954 received DONE after 193 chunks
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_954 completed: 194 chars, 193 chunks, TTFT=25303.7ms
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_986 received DONE after 158 chunks
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_986 completed: 615 chars, 158 chunks, TTFT=26161.9ms
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_971 received DONE after 171 chunks
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_971 completed: 668 chars, 171 chunks, TTFT=25851.1ms
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:11] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:11] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_995 received DONE after 149 chunks
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_995 completed: 295 chars, 149 chunks, TTFT=26477.6ms
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_979 received DONE after 173 chunks
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_979 completed: 682 chars, 173 chunks, TTFT=26024.1ms
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_989 received DONE after 158 chunks
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_989 completed: 615 chars, 158 chunks, TTFT=26330.2ms
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_981 received DONE after 168 chunks
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_981 completed: 655 chars, 168 chunks, TTFT=26155.1ms
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_994 received DONE after 161 chunks
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_994 completed: 640 chars, 161 chunks, TTFT=26376.6ms
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:11] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_990 received DONE after 163 chunks
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_990 completed: 648 chars, 163 chunks, TTFT=26373.3ms
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:11] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_978 received DONE after 177 chunks
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_978 completed: 701 chars, 177 chunks, TTFT=26055.6ms
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_975 received DONE after 185 chunks
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:11] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_975 completed: 184 chars, 185 chunks, TTFT=26029.0ms
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:11] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:11] Decode batch. #running-req: 1, #token: 356, token usage: 0.00, cuda graph: True, gen throughput (token/s): 332.75, #queue-req: 0,
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:11] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:11] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_996 received DONE after 187 chunks
[2025-07-25 02:13:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_996 completed: 732 chars, 187 chunks, TTFT=26471.7ms
[2025-07-25 02:13:11] [sglang_test_framework.core.metrics_collector] [INFO] Completed 1000 requests, success rate: 100.0%
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:11] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:11] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:11] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:11] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:11] INFO:     127.0.0.1:41676 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:11] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:11] INFO:     127.0.0.1:44490 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:13:12] [sglang_test_framework.core.request_generator] [DEBUG] RequestSender session closed
[2025-07-25 02:13:12] [sglang_test_framework.core.metrics_collector] [INFO] Stopped metrics collection
[2025-07-25 02:13:12] [sglang_test_framework.core.metrics_collector] [INFO] Stopped metrics collection
[2025-07-25 02:13:12] [sglang_test_framework.core.metrics_collector] [INFO] Stopped metrics collection
[2025-07-25 02:13:12] [sglang_test_framework.core.metrics_collector] [INFO] Exported metrics to metrics_20250725_021312.csv
[2025-07-25 02:13:12] [sglang_test_framework.core.metrics_collector] [INFO] Exported metrics to metrics_20250725_021312.json
[2025-07-25 02:13:12] [sglang_test_framework.tests.routing_test] [ERROR] Test failed: "None of [Index(['req_id', 'input_length', 'decode_length', 'arrival_time',\n       'to_server_time', 'finish_time', 'server_latency', 'total_latency',\n       'ttft', 'queue_time', 'success', 'error'],\n      dtype='object')] are in the [columns]"
[2025-07-25 02:13:12] [sglang_test_framework.core.metrics_collector] [WARNING] Metrics collection not started
[2025-07-25 02:13:12] [sglang_test_framework.core.metrics_collector] [WARNING] Metrics collection not started
[2025-07-25 02:13:12] [sglang_test_framework.core.metrics_collector] [WARNING] Metrics collection not started
[2025-07-25 02:13:12] [sglang_test_framework.core.server_manager] [INFO] Stopping router
[2025-07-25 02:13:12] [sglang_test_framework.core.server_manager] [INFO] Stopping server worker_1
[2025-07-25 02:13:12] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:12] SIGTERM received. signum=None frame=None. Draining requests and shutting down...
[2025-07-25 02:13:16] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:16] Gracefully exiting... remaining number of requests 0
[2025-07-25 02:13:16] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:13:16] Dumping requests before crash. self.crash_dump_folder=None
[2025-07-25 02:13:16] [sglang_test_framework.core.server_manager] [INFO] Stopping server worker_0
[2025-07-25 02:13:16] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:16] SIGTERM received. signum=None frame=None. Draining requests and shutting down...
[2025-07-25 02:13:20] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:20] Gracefully exiting... remaining number of requests 0
[2025-07-25 02:13:20] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:13:20] Dumping requests before crash. self.crash_dump_folder=None
[2025-07-25 02:13:20] [__main__] [ERROR] Test failed with error: "None of [Index(['req_id', 'input_length', 'decode_length', 'arrival_time',\n       'to_server_time', 'finish_time', 'server_latency', 'total_latency',\n       'ttft', 'queue_time', 'success', 'error'],\n      dtype='object')] are in the [columns]"
Traceback (most recent call last):
  File "/home/lg/sglang/sglang_test_framework/test_route.py", line 281, in <module>
    asyncio.run(run_custom_test())
  File "/home/lg/.conda/envs/sglang_test/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/home/lg/.conda/envs/sglang_test/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/lg/sglang/sglang_test_framework/test_route.py", line 277, in run_custom_test
    results = await routing_test._run_async()
  File "/home/lg/sglang/sglang_test_framework/tests/routing_test.py", line 229, in _run_async
    server_csv = collector.export_metrics("csv",
  File "/home/lg/sglang/sglang_test_framework/core/metrics_collector.py", line 473, in export_metrics
    self._export_csv(path)
  File "/home/lg/sglang/sglang_test_framework/core/metrics_collector.py", line 556, in _export_csv
    df = df[columns]
  File "/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/pandas/core/frame.py", line 4113, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6212, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6261, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['req_id', 'input_length', 'decode_length', 'arrival_time',\n       'to_server_time', 'finish_time', 'server_latency', 'total_latency',\n       'ttft', 'queue_time', 'success', 'error'],\n      dtype='object')] are in the [columns]"
