[2025-07-25 00:03:34] [sglang_test_framework] [INFO] SGLang Testing Framework v1.0.0 initialized with log level: DEBUG
[2025-07-25 00:03:37] [__main__] [INFO] ==================================================
[2025-07-25 00:03:37] [__main__] [INFO] SGLang Testing Framework - Node Test
[2025-07-25 00:03:37] [__main__] [INFO] ==================================================
[2025-07-25 00:03:37] [asyncio] [DEBUG] Using selector: EpollSelector
[2025-07-25 00:03:37] [__main__] [INFO] Starting SGLang node test...
[2025-07-25 00:03:37] [__main__] [INFO] Setting up test configuration...
[2025-07-25 00:03:37] [__main__] [INFO] Test configuration: 1000 prompts at 50.0 req/s
[2025-07-25 00:03:37] [__main__] [INFO] Initializing test components...
[2025-07-25 00:03:37] [__main__] [INFO] Launching SGLang server...
[2025-07-25 00:03:37] [sglang_test_framework.core.server_manager] [INFO] Starting server node_1 with command: python -m sglang.launch_server --model-path /data/pretrained_models/Llama-2-7b-hf --port 30000 --host 0.0.0.0 --mem-fraction-static 0.9 --max-running-requests 256 --chunked-prefill-size 8192 --max-prefill-tokens 16384 --schedule-conservativeness 1.0 --tp-size 1 --tokenizer-mode auto --dtype auto --load-format auto --log-level info --enable-metrics
[2025-07-25 00:03:37] [sglang_test_framework.core.server_manager] [INFO] Server logs will be displayed for node_1
[2025-07-25 00:03:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:03:44] server_args=ServerArgs(model_path='/data/pretrained_models/Llama-2-7b-hf', tokenizer_path='/data/pretrained_models/Llama-2-7b-hf', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=False, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='0.0.0.0', port=30000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.9, max_running_requests=256, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=1, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=502428866, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=0, crash_dump_folder=None, show_time_cost=False, enable_metrics=True, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, api_key=None, served_model_name='/data/pretrained_models/Llama-2-7b-hf', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, dp_size=1, load_balance_method='round_robin', dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, ep_size=1, enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_moe=False, enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through_selective', hicache_io_backend='', hicache_storage_backend=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, cuda_graph_max_bs=None, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_nccl_nvls=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, enable_triton_kernel_moe=False, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, pdlb_url=None, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3)
[2025-07-25 00:03:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:03:50] Attention backend not explicitly specified. Use flashinfer backend by default.
[2025-07-25 00:03:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:03:50] Init torch distributed begin.
[2025-07-25 00:03:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:03:50] Init torch distributed ends. mem usage=0.00 GB
[2025-07-25 00:03:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:03:51] Load weight begin. avail mem=78.64 GB
[2025-07-25 00:03:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[2025-07-25 00:03:52] [sglang_test_framework.core.server_manager] [INFO] [node_1] Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.83it/s]
[2025-07-25 00:03:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.14s/it]
[2025-07-25 00:03:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.05s/it]
[2025-07-25 00:03:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:03:53] Load weight end. type=LlamaForCausalLM, dtype=torch.float16, avail mem=66.07 GB, mem usage=12.57 GB.
[2025-07-25 00:03:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:03:53] KV Cache is allocated. #tokens: 119182, K size: 29.10 GB, V size: 29.10 GB
[2025-07-25 00:03:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:03:53] Memory pool end. avail mem=7.80 GB
[2025-07-25 00:03:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:03:54] Capture cuda graph begin. This can take up to several minutes. avail mem=7.30 GB
[2025-07-25 00:03:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:03:54] Capture cuda graph bs [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160]
[2025-07-25 00:03:54] [sglang_test_framework.core.server_manager] [INFO] [node_1]   0%|          | 0/23 [00:00<?, ?it/s]
[2025-07-25 00:03:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=160 avail_mem=7.30 GB):   0%|          | 0/23 [00:00<?, ?it/s]
[2025-07-25 00:03:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=160 avail_mem=7.30 GB):   4%|▍         | 1/23 [00:00<00:16,  1.33it/s]
[2025-07-25 00:03:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=152 avail_mem=7.21 GB):   4%|▍         | 1/23 [00:00<00:16,  1.33it/s]
[2025-07-25 00:03:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=152 avail_mem=7.21 GB):   9%|▊         | 2/23 [00:01<00:09,  2.19it/s]
[2025-07-25 00:03:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=144 avail_mem=7.19 GB):   9%|▊         | 2/23 [00:01<00:09,  2.19it/s]
[2025-07-25 00:03:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=144 avail_mem=7.19 GB):  13%|█▎        | 3/23 [00:01<00:07,  2.72it/s]
[2025-07-25 00:03:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=136 avail_mem=7.16 GB):  13%|█▎        | 3/23 [00:01<00:07,  2.72it/s]
[2025-07-25 00:03:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=136 avail_mem=7.16 GB):  17%|█▋        | 4/23 [00:01<00:06,  3.12it/s]
[2025-07-25 00:03:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=128 avail_mem=7.12 GB):  17%|█▋        | 4/23 [00:01<00:06,  3.12it/s]
[2025-07-25 00:03:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=128 avail_mem=7.12 GB):  22%|██▏       | 5/23 [00:01<00:05,  3.42it/s]
[2025-07-25 00:03:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=120 avail_mem=7.09 GB):  22%|██▏       | 5/23 [00:01<00:05,  3.42it/s]
[2025-07-25 00:03:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=120 avail_mem=7.09 GB):  26%|██▌       | 6/23 [00:02<00:04,  3.56it/s]
[2025-07-25 00:03:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=112 avail_mem=7.05 GB):  26%|██▌       | 6/23 [00:02<00:04,  3.56it/s]
[2025-07-25 00:03:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=112 avail_mem=7.05 GB):  30%|███       | 7/23 [00:02<00:04,  3.70it/s]
[2025-07-25 00:03:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=104 avail_mem=7.03 GB):  30%|███       | 7/23 [00:02<00:04,  3.70it/s]
[2025-07-25 00:03:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=104 avail_mem=7.03 GB):  35%|███▍      | 8/23 [00:02<00:03,  3.82it/s]
[2025-07-25 00:03:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=96 avail_mem=7.00 GB):  35%|███▍      | 8/23 [00:02<00:03,  3.82it/s]
[2025-07-25 00:03:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=96 avail_mem=7.00 GB):  39%|███▉      | 9/23 [00:02<00:03,  3.91it/s]
[2025-07-25 00:03:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=88 avail_mem=6.98 GB):  39%|███▉      | 9/23 [00:02<00:03,  3.91it/s]
[2025-07-25 00:03:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=88 avail_mem=6.98 GB):  43%|████▎     | 10/23 [00:02<00:03,  3.95it/s]
[2025-07-25 00:03:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=80 avail_mem=6.94 GB):  43%|████▎     | 10/23 [00:02<00:03,  3.95it/s]
[2025-07-25 00:03:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=80 avail_mem=6.94 GB):  48%|████▊     | 11/23 [00:03<00:03,  3.99it/s]
[2025-07-25 00:03:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=72 avail_mem=6.91 GB):  48%|████▊     | 11/23 [00:03<00:03,  3.99it/s]
[2025-07-25 00:03:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=72 avail_mem=6.91 GB):  52%|█████▏    | 12/23 [00:03<00:02,  4.03it/s]
[2025-07-25 00:03:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=64 avail_mem=6.88 GB):  52%|█████▏    | 12/23 [00:03<00:02,  4.03it/s]
[2025-07-25 00:03:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=64 avail_mem=6.88 GB):  57%|█████▋    | 13/23 [00:03<00:02,  4.02it/s]
[2025-07-25 00:03:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=56 avail_mem=6.86 GB):  57%|█████▋    | 13/23 [00:03<00:02,  4.02it/s]
[2025-07-25 00:03:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=56 avail_mem=6.86 GB):  61%|██████    | 14/23 [00:03<00:02,  4.06it/s]
[2025-07-25 00:03:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=48 avail_mem=6.84 GB):  61%|██████    | 14/23 [00:03<00:02,  4.06it/s]
[2025-07-25 00:03:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=48 avail_mem=6.84 GB):  65%|██████▌   | 15/23 [00:04<00:01,  4.10it/s]
[2025-07-25 00:03:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=40 avail_mem=6.83 GB):  65%|██████▌   | 15/23 [00:04<00:01,  4.10it/s]
[2025-07-25 00:03:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=40 avail_mem=6.83 GB):  70%|██████▉   | 16/23 [00:04<00:01,  4.11it/s]
[2025-07-25 00:03:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=32 avail_mem=6.78 GB):  70%|██████▉   | 16/23 [00:04<00:01,  4.11it/s]
[2025-07-25 00:03:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=32 avail_mem=6.78 GB):  74%|███████▍  | 17/23 [00:04<00:01,  4.13it/s]
[2025-07-25 00:03:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=24 avail_mem=6.78 GB):  74%|███████▍  | 17/23 [00:04<00:01,  4.13it/s]
[2025-07-25 00:03:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=24 avail_mem=6.78 GB):  78%|███████▊  | 18/23 [00:04<00:01,  4.14it/s]
[2025-07-25 00:03:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=16 avail_mem=6.76 GB):  78%|███████▊  | 18/23 [00:04<00:01,  4.14it/s]
[2025-07-25 00:03:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=16 avail_mem=6.76 GB):  83%|████████▎ | 19/23 [00:05<00:00,  4.15it/s]
[2025-07-25 00:03:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=8 avail_mem=6.75 GB):  83%|████████▎ | 19/23 [00:05<00:00,  4.15it/s]
[2025-07-25 00:03:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=8 avail_mem=6.75 GB):  87%|████████▋ | 20/23 [00:05<00:00,  4.15it/s]
[2025-07-25 00:03:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=4 avail_mem=6.73 GB):  87%|████████▋ | 20/23 [00:05<00:00,  4.15it/s]
[2025-07-25 00:03:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=4 avail_mem=6.73 GB):  91%|█████████▏| 21/23 [00:05<00:00,  4.16it/s]
[2025-07-25 00:03:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=2 avail_mem=6.72 GB):  91%|█████████▏| 21/23 [00:05<00:00,  4.16it/s]
[2025-07-25 00:03:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=2 avail_mem=6.72 GB):  96%|█████████▌| 22/23 [00:05<00:00,  4.17it/s]
[2025-07-25 00:04:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=1 avail_mem=6.70 GB):  96%|█████████▌| 22/23 [00:05<00:00,  4.17it/s]
[2025-07-25 00:04:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=1 avail_mem=6.70 GB): 100%|██████████| 23/23 [00:06<00:00,  4.17it/s]
[2025-07-25 00:04:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] Capturing batches (bs=1 avail_mem=6.70 GB): 100%|██████████| 23/23 [00:06<00:00,  3.75it/s]
[2025-07-25 00:04:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:00] Capture cuda graph end. Time elapsed: 6.17 s. mem usage=0.61 GB. avail mem=6.69 GB.
[2025-07-25 00:04:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:00] max_total_num_tokens=119182, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=256, context_len=4096, available_gpu_mem=6.69 GB
[2025-07-25 00:04:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:00] INFO:     Started server process [1399818]
[2025-07-25 00:04:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:00] INFO:     Waiting for application startup.
[2025-07-25 00:04:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:00] INFO:     Application startup complete.
[2025-07-25 00:04:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:00] INFO:     Uvicorn running on http://0.0.0.0:30000 (Press CTRL+C to quit)
[2025-07-25 00:04:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:01] INFO:     127.0.0.1:45508 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-07-25 00:04:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:01] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0,
[2025-07-25 00:04:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:01] INFO:     127.0.0.1:45524 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 00:04:01] [sglang_test_framework.core.server_manager] [INFO] Server node_1 started successfully in 24.0s
[2025-07-25 00:04:01] [__main__] [INFO] Server started successfully on port 30000
[2025-07-25 00:04:01] [__main__] [INFO] Generating 1000 test requests...
[2025-07-25 00:04:01] [sglang_test_framework.core.request_generator] [INFO] Generating 1000 requests from dataset 'random'...
[2025-07-25 00:04:01] [sglang_test_framework.core.request_generator] [INFO] Generating random requests with input_len=1024, output_len=128, range_ratio=0.5
[2025-07-25 00:04:01] [sglang_test_framework.core.request_generator] [INFO] Generated 1000/1000 random requests
[2025-07-25 00:04:01] [sglang_test_framework.core.request_generator] [INFO] Successfully generated 1000 random requests
[2025-07-25 00:04:01] [__main__] [INFO] Generated 1000 requests
[2025-07-25 00:04:01] [sglang_test_framework.core.request_generator] [INFO] Generating Poisson arrivals with rate=50.0 req/s
[2025-07-25 00:04:01] [sglang_test_framework.core.request_generator] [INFO] Total test duration: 20.0 seconds
[2025-07-25 00:04:01] [__main__] [INFO] Starting metrics collection...
[2025-07-25 00:04:01] [sglang_test_framework.core.metrics_collector] [INFO] Started metrics collection
[2025-07-25 00:04:01] [sglang_test_framework.core.metrics_collector] [INFO] Enabled incremental saving to /home/lg/sglang/results/new_test/node_test_example/results every 50 requests
[2025-07-25 00:04:01] [sglang_test_framework.core.request_generator] [DEBUG] RequestSender session created with connection pool limit=100
[2025-07-25 00:04:01] [__main__] [DEBUG] Request 1: relative_arrival=0.000, absolute_arrival=2069483.167, current_time=2069483.167, wait_time=-0.000
[2025-07-25 00:04:01] [__main__] [INFO] Sending request 1/1000 (ID: req_0)
[2025-07-25 00:04:01] [__main__] [DEBUG] Request 2: relative_arrival=0.006, absolute_arrival=2069483.173, current_time=2069483.167, wait_time=0.006
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_0 to http://localhost:30000/generate at 1753373042.0335565
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_0 with payload: {'text': 'Random prompt 0 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 2/1000 (ID: req_1)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 3: relative_arrival=0.012, absolute_arrival=2069483.178, current_time=2069483.277, wait_time=-0.099
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 3/1000 (ID: req_2)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 4: relative_arrival=0.059, absolute_arrival=2069483.226, current_time=2069483.277, wait_time=-0.052
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 4/1000 (ID: req_3)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 5: relative_arrival=0.065, absolute_arrival=2069483.231, current_time=2069483.277, wait_time=-0.046
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 5/1000 (ID: req_4)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 6: relative_arrival=0.071, absolute_arrival=2069483.238, current_time=2069483.277, wait_time=-0.040
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 6/1000 (ID: req_5)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 7: relative_arrival=0.100, absolute_arrival=2069483.266, current_time=2069483.277, wait_time=-0.011
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 7/1000 (ID: req_6)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 8: relative_arrival=0.112, absolute_arrival=2069483.278, current_time=2069483.277, wait_time=0.001
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_1 to http://localhost:30000/generate at 1753373042.0356808
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_1 with payload: {'text': 'Random prompt 1 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_2 to http://localhost:30000/generate at 1753373042.0359333
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_2 with payload: {'text': 'Random prompt 2 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_3 to http://localhost:30000/generate at 1753373042.0361125
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_3 with payload: {'text': 'Random prompt 3 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_4 to http://localhost:30000/generate at 1753373042.0363653
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_4 with payload: {'text': 'Random prompt 4 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_5 to http://localhost:30000/generate at 1753373042.0365279
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_5 with payload: {'text': 'Random prompt 5 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_6 to http://localhost:30000/generate at 1753373042.0366745
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_6 with payload: {'text': 'Random prompt 6 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 8/1000 (ID: req_7)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 9: relative_arrival=0.142, absolute_arrival=2069483.308, current_time=2069483.279, wait_time=0.029
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_7 to http://localhost:30000/generate at 1753373042.0376873
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_7 with payload: {'text': 'Random prompt 7 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 173, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_3
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_3
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 9/1000 (ID: req_8)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 10: relative_arrival=0.143, absolute_arrival=2069483.309, current_time=2069483.309, wait_time=0.001
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_8 to http://localhost:30000/generate at 1753373042.067184
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_8 with payload: {'text': 'Random prompt 8 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 96, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 10/1000 (ID: req_9)
[2025-07-25 00:04:02] [__main__] [INFO] Progress: 10/1000 requests sent in 0.1s
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 11: relative_arrival=0.156, absolute_arrival=2069483.323, current_time=2069483.310, wait_time=0.013
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_9 to http://localhost:30000/generate at 1753373042.0680077
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_9 with payload: {'text': 'Random prompt 9 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_0
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_0
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_7
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_7
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_6
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_6
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_5
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_5
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_4
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_4
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_2
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_2
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_1
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_1
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_8
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_8
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_9
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_9
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 11/1000 (ID: req_10)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 12: relative_arrival=0.157, absolute_arrival=2069483.324, current_time=2069483.324, wait_time=-0.000
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 12/1000 (ID: req_11)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 13: relative_arrival=0.158, absolute_arrival=2069483.325, current_time=2069483.324, wait_time=0.001
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_10 to http://localhost:30000/generate at 1753373042.0820994
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_10 with payload: {'text': 'Random prompt 10 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_11 to http://localhost:30000/generate at 1753373042.0823946
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_11 with payload: {'text': 'Random prompt 11 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 13/1000 (ID: req_12)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 14: relative_arrival=0.206, absolute_arrival=2069483.372, current_time=2069483.325, wait_time=0.047
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_12 to http://localhost:30000/generate at 1753373042.0832007
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_12 with payload: {'text': 'Random prompt 12 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_10
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_10
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_11
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_11
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_12
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_12
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] Prefill batch. #new-seq: 13, #new-token: 3466, #cached-token: 13, token usage: 0.00, #running-req: 1, #queue-req: 0,
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 14/1000 (ID: req_13)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 15: relative_arrival=0.209, absolute_arrival=2069483.375, current_time=2069483.373, wait_time=0.002
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_13 to http://localhost:30000/generate at 1753373042.1311202
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_13 with payload: {'text': 'Random prompt 13 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 15/1000 (ID: req_14)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 16: relative_arrival=0.224, absolute_arrival=2069483.390, current_time=2069483.376, wait_time=0.015
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_14 to http://localhost:30000/generate at 1753373042.134004
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_14 with payload: {'text': 'Random prompt 14 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 154, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_13
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_13
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_14
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_14
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 16/1000 (ID: req_15)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 17: relative_arrival=0.234, absolute_arrival=2069483.401, current_time=2069483.391, wait_time=0.010
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_15 to http://localhost:30000/generate at 1753373042.1496296
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_15 with payload: {'text': 'Random prompt 15 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 182, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_15
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_15
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 17/1000 (ID: req_16)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 18: relative_arrival=0.243, absolute_arrival=2069483.410, current_time=2069483.401, wait_time=0.008
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_16 to http://localhost:30000/generate at 1753373042.1593978
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_16 with payload: {'text': 'Random prompt 16 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_16
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_16
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] Prefill batch. #new-seq: 3, #new-token: 535, #cached-token: 3, token usage: 0.03, #running-req: 14, #queue-req: 0,
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 18/1000 (ID: req_17)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 19: relative_arrival=0.289, absolute_arrival=2069483.456, current_time=2069483.411, wait_time=0.045
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_17 to http://localhost:30000/generate at 1753373042.168789
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_17 with payload: {'text': 'Random prompt 17 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 137, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_17
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_17
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 19/1000 (ID: req_18)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 20: relative_arrival=0.289, absolute_arrival=2069483.456, current_time=2069483.456, wait_time=0.000
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_18 to http://localhost:30000/generate at 1753373042.2141862
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_18 with payload: {'text': 'Random prompt 18 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 181, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 20/1000 (ID: req_19)
[2025-07-25 00:04:02] [__main__] [INFO] Progress: 20/1000 requests sent in 0.3s
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 21: relative_arrival=0.311, absolute_arrival=2069483.478, current_time=2069483.456, wait_time=0.021
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_19 to http://localhost:30000/generate at 1753373042.2147348
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_19 with payload: {'text': 'Random prompt 19 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_18
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_18
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_19
[2025-07-25 00:04:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_19
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 21/1000 (ID: req_20)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 22: relative_arrival=0.377, absolute_arrival=2069483.544, current_time=2069483.478, wait_time=0.066
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 22/1000 (ID: req_21)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 23: relative_arrival=0.394, absolute_arrival=2069483.560, current_time=2069483.545, wait_time=0.016
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 23/1000 (ID: req_22)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 24: relative_arrival=0.449, absolute_arrival=2069483.616, current_time=2069483.561, wait_time=0.055
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 24/1000 (ID: req_23)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 25: relative_arrival=0.450, absolute_arrival=2069483.617, current_time=2069483.616, wait_time=0.001
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 25/1000 (ID: req_24)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 26: relative_arrival=0.461, absolute_arrival=2069483.628, current_time=2069483.617, wait_time=0.010
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 26/1000 (ID: req_25)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 27: relative_arrival=0.467, absolute_arrival=2069483.634, current_time=2069483.628, wait_time=0.005
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 27/1000 (ID: req_26)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 28: relative_arrival=0.493, absolute_arrival=2069483.660, current_time=2069483.635, wait_time=0.025
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] Prefill batch. #new-seq: 4, #new-token: 898, #cached-token: 20, token usage: 0.03, #running-req: 17, #queue-req: 0,
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 28/1000 (ID: req_27)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 29: relative_arrival=0.573, absolute_arrival=2069483.739, current_time=2069483.660, wait_time=0.079
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 29/1000 (ID: req_28)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 30: relative_arrival=0.579, absolute_arrival=2069483.745, current_time=2069483.740, wait_time=0.005
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 30/1000 (ID: req_29)
[2025-07-25 00:04:02] [__main__] [INFO] Progress: 30/1000 requests sent in 0.6s
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 31: relative_arrival=0.600, absolute_arrival=2069483.767, current_time=2069483.746, wait_time=0.020
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 31/1000 (ID: req_30)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 32: relative_arrival=0.604, absolute_arrival=2069483.771, current_time=2069483.768, wait_time=0.003
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 32/1000 (ID: req_31)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 33: relative_arrival=0.621, absolute_arrival=2069483.788, current_time=2069483.772, wait_time=0.016
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 33/1000 (ID: req_32)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 34: relative_arrival=0.634, absolute_arrival=2069483.800, current_time=2069483.788, wait_time=0.012
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 34/1000 (ID: req_33)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 35: relative_arrival=0.705, absolute_arrival=2069483.872, current_time=2069483.800, wait_time=0.071
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 35/1000 (ID: req_34)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 36: relative_arrival=0.724, absolute_arrival=2069483.890, current_time=2069483.872, wait_time=0.018
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 36/1000 (ID: req_35)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 37: relative_arrival=0.732, absolute_arrival=2069483.899, current_time=2069483.891, wait_time=0.008
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] INFO:     127.0.0.1:45522 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 37/1000 (ID: req_36)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 38: relative_arrival=0.735, absolute_arrival=2069483.901, current_time=2069483.899, wait_time=0.002
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 38/1000 (ID: req_37)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 39: relative_arrival=0.738, absolute_arrival=2069483.905, current_time=2069483.902, wait_time=0.003
[2025-07-25 00:04:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:02] The server is fired up and ready to roll!
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 39/1000 (ID: req_38)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 40: relative_arrival=0.743, absolute_arrival=2069483.910, current_time=2069483.905, wait_time=0.004
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 40/1000 (ID: req_39)
[2025-07-25 00:04:02] [__main__] [INFO] Progress: 40/1000 requests sent in 0.7s
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 41: relative_arrival=0.749, absolute_arrival=2069483.916, current_time=2069483.910, wait_time=0.006
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 41/1000 (ID: req_40)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 42: relative_arrival=0.787, absolute_arrival=2069483.954, current_time=2069483.916, wait_time=0.038
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 42/1000 (ID: req_41)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 43: relative_arrival=0.804, absolute_arrival=2069483.970, current_time=2069483.955, wait_time=0.015
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 43/1000 (ID: req_42)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 44: relative_arrival=0.818, absolute_arrival=2069483.985, current_time=2069483.971, wait_time=0.014
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 44/1000 (ID: req_43)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 45: relative_arrival=0.821, absolute_arrival=2069483.987, current_time=2069483.986, wait_time=0.002
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 45/1000 (ID: req_44)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 46: relative_arrival=0.860, absolute_arrival=2069484.027, current_time=2069483.988, wait_time=0.039
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 46/1000 (ID: req_45)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 47: relative_arrival=0.886, absolute_arrival=2069484.052, current_time=2069484.027, wait_time=0.025
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 47/1000 (ID: req_46)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 48: relative_arrival=0.887, absolute_arrival=2069484.054, current_time=2069484.053, wait_time=0.000
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 48/1000 (ID: req_47)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 49: relative_arrival=0.912, absolute_arrival=2069484.078, current_time=2069484.055, wait_time=0.023
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 49/1000 (ID: req_48)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 50: relative_arrival=0.927, absolute_arrival=2069484.094, current_time=2069484.079, wait_time=0.015
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 50/1000 (ID: req_49)
[2025-07-25 00:04:02] [__main__] [INFO] Progress: 50/1000 requests sent in 0.9s
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 51: relative_arrival=0.929, absolute_arrival=2069484.096, current_time=2069484.095, wait_time=0.001
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 51/1000 (ID: req_50)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 52: relative_arrival=0.941, absolute_arrival=2069484.108, current_time=2069484.097, wait_time=0.011
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 52/1000 (ID: req_51)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 53: relative_arrival=0.955, absolute_arrival=2069484.121, current_time=2069484.109, wait_time=0.012
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 53/1000 (ID: req_52)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 54: relative_arrival=0.958, absolute_arrival=2069484.125, current_time=2069484.122, wait_time=0.003
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 54/1000 (ID: req_53)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 55: relative_arrival=1.017, absolute_arrival=2069484.183, current_time=2069484.126, wait_time=0.057
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 55/1000 (ID: req_54)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 56: relative_arrival=1.055, absolute_arrival=2069484.221, current_time=2069484.184, wait_time=0.037
[2025-07-25 00:04:02] [__main__] [INFO] Sending request 56/1000 (ID: req_55)
[2025-07-25 00:04:02] [__main__] [DEBUG] Request 57: relative_arrival=1.077, absolute_arrival=2069484.243, current_time=2069484.223, wait_time=0.020
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 57/1000 (ID: req_56)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 58: relative_arrival=1.089, absolute_arrival=2069484.256, current_time=2069484.244, wait_time=0.011
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 58/1000 (ID: req_57)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 59: relative_arrival=1.100, absolute_arrival=2069484.266, current_time=2069484.257, wait_time=0.009
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 59/1000 (ID: req_58)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 60: relative_arrival=1.121, absolute_arrival=2069484.287, current_time=2069484.267, wait_time=0.020
[2025-07-25 00:04:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:03] Decode batch. #running-req: 20, #token: 5649, token usage: 0.05, cuda graph: True, gen throughput (token/s): 288.39, #queue-req: 0,
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 60/1000 (ID: req_59)
[2025-07-25 00:04:03] [__main__] [INFO] Progress: 60/1000 requests sent in 1.1s
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 61: relative_arrival=1.137, absolute_arrival=2069484.303, current_time=2069484.288, wait_time=0.015
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 61/1000 (ID: req_60)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 62: relative_arrival=1.138, absolute_arrival=2069484.304, current_time=2069484.304, wait_time=0.000
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 62/1000 (ID: req_61)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 63: relative_arrival=1.152, absolute_arrival=2069484.319, current_time=2069484.307, wait_time=0.012
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 63/1000 (ID: req_62)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 64: relative_arrival=1.185, absolute_arrival=2069484.352, current_time=2069484.319, wait_time=0.032
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 64/1000 (ID: req_63)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 65: relative_arrival=1.197, absolute_arrival=2069484.364, current_time=2069484.352, wait_time=0.012
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 65/1000 (ID: req_64)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 66: relative_arrival=1.198, absolute_arrival=2069484.365, current_time=2069484.365, wait_time=0.000
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 66/1000 (ID: req_65)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 67: relative_arrival=1.229, absolute_arrival=2069484.396, current_time=2069484.365, wait_time=0.031
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 67/1000 (ID: req_66)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 68: relative_arrival=1.234, absolute_arrival=2069484.400, current_time=2069484.397, wait_time=0.003
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 68/1000 (ID: req_67)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 69: relative_arrival=1.240, absolute_arrival=2069484.406, current_time=2069484.401, wait_time=0.005
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 69/1000 (ID: req_68)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 70: relative_arrival=1.243, absolute_arrival=2069484.410, current_time=2069484.407, wait_time=0.003
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 70/1000 (ID: req_69)
[2025-07-25 00:04:03] [__main__] [INFO] Progress: 70/1000 requests sent in 1.2s
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 71: relative_arrival=1.251, absolute_arrival=2069484.418, current_time=2069484.412, wait_time=0.006
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 71/1000 (ID: req_70)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 72: relative_arrival=1.280, absolute_arrival=2069484.446, current_time=2069484.419, wait_time=0.028
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 72/1000 (ID: req_71)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 73: relative_arrival=1.294, absolute_arrival=2069484.461, current_time=2069484.447, wait_time=0.014
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 73/1000 (ID: req_72)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 74: relative_arrival=1.299, absolute_arrival=2069484.465, current_time=2069484.462, wait_time=0.003
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 74/1000 (ID: req_73)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 75: relative_arrival=1.341, absolute_arrival=2069484.507, current_time=2069484.466, wait_time=0.041
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 75/1000 (ID: req_74)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 76: relative_arrival=1.383, absolute_arrival=2069484.550, current_time=2069484.508, wait_time=0.042
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 76/1000 (ID: req_75)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 77: relative_arrival=1.424, absolute_arrival=2069484.591, current_time=2069484.551, wait_time=0.039
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 77/1000 (ID: req_76)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 78: relative_arrival=1.430, absolute_arrival=2069484.596, current_time=2069484.592, wait_time=0.004
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 78/1000 (ID: req_77)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 79: relative_arrival=1.442, absolute_arrival=2069484.608, current_time=2069484.597, wait_time=0.011
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 79/1000 (ID: req_78)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 80: relative_arrival=1.526, absolute_arrival=2069484.692, current_time=2069484.610, wait_time=0.082
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_19 received DONE after 69 chunks
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_19 completed: 263 chars, 69 chunks, TTFT=369.6ms
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_20 to http://localhost:30000/generate at 1753373043.37127
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_20 with payload: {'text': 'Random prompt 20 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:03] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_20
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_20
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_13 received DONE after 70 chunks
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_13 completed: 276 chars, 70 chunks, TTFT=333.0ms
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_21 to http://localhost:30000/generate at 1753373043.3863451
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_21 with payload: {'text': 'Random prompt 21 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 102, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:03] Prefill batch. #new-seq: 1, #new-token: 282, #cached-token: 5, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:03] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_21
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_21
[2025-07-25 00:04:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:03] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 80/1000 (ID: req_79)
[2025-07-25 00:04:03] [__main__] [INFO] Progress: 80/1000 requests sent in 1.5s
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 81: relative_arrival=1.555, absolute_arrival=2069484.722, current_time=2069484.694, wait_time=0.028
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 81/1000 (ID: req_80)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 82: relative_arrival=1.556, absolute_arrival=2069484.722, current_time=2069484.723, wait_time=-0.000
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 82/1000 (ID: req_81)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 83: relative_arrival=1.557, absolute_arrival=2069484.724, current_time=2069484.723, wait_time=0.001
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 83/1000 (ID: req_82)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 84: relative_arrival=1.569, absolute_arrival=2069484.736, current_time=2069484.725, wait_time=0.011
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 84/1000 (ID: req_83)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 85: relative_arrival=1.617, absolute_arrival=2069484.784, current_time=2069484.737, wait_time=0.047
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 85/1000 (ID: req_84)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 86: relative_arrival=1.633, absolute_arrival=2069484.799, current_time=2069484.786, wait_time=0.014
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 86/1000 (ID: req_85)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 87: relative_arrival=1.647, absolute_arrival=2069484.813, current_time=2069484.801, wait_time=0.013
[2025-07-25 00:04:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:03] Decode batch. #running-req: 20, #token: 6373, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1512.43, #queue-req: 0,
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 87/1000 (ID: req_86)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 88: relative_arrival=1.649, absolute_arrival=2069484.815, current_time=2069484.814, wait_time=0.001
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 88/1000 (ID: req_87)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 89: relative_arrival=1.670, absolute_arrival=2069484.837, current_time=2069484.817, wait_time=0.020
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 89/1000 (ID: req_88)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 90: relative_arrival=1.705, absolute_arrival=2069484.871, current_time=2069484.838, wait_time=0.034
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 90/1000 (ID: req_89)
[2025-07-25 00:04:03] [__main__] [INFO] Progress: 90/1000 requests sent in 1.7s
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 91: relative_arrival=1.714, absolute_arrival=2069484.881, current_time=2069484.872, wait_time=0.009
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 91/1000 (ID: req_90)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 92: relative_arrival=1.744, absolute_arrival=2069484.911, current_time=2069484.881, wait_time=0.029
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_16 received DONE after 88 chunks
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_16 completed: 339 chars, 88 chunks, TTFT=425.0ms
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_22 to http://localhost:30000/generate at 1753373043.6519363
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_22 with payload: {'text': 'Random prompt 22 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 182, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:03] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_22
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_22
[2025-07-25 00:04:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:03] Prefill batch. #new-seq: 1, #new-token: 200, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_0 received DONE after 89 chunks
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_0 completed: 345 chars, 89 chunks, TTFT=383.1ms
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_23 to http://localhost:30000/generate at 1753373043.663581
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_23 with payload: {'text': 'Random prompt 23 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:03] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_23
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_23
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 92/1000 (ID: req_91)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 93: relative_arrival=1.811, absolute_arrival=2069484.978, current_time=2069484.912, wait_time=0.066
[2025-07-25 00:04:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:03] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 93/1000 (ID: req_92)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 94: relative_arrival=1.816, absolute_arrival=2069484.982, current_time=2069484.979, wait_time=0.003
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 94/1000 (ID: req_93)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 95: relative_arrival=1.830, absolute_arrival=2069484.997, current_time=2069484.983, wait_time=0.014
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 95/1000 (ID: req_94)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 96: relative_arrival=1.837, absolute_arrival=2069485.004, current_time=2069484.998, wait_time=0.006
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 96/1000 (ID: req_95)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 97: relative_arrival=1.869, absolute_arrival=2069485.035, current_time=2069485.005, wait_time=0.031
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_10 received DONE after 93 chunks
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_10 completed: 368 chars, 93 chunks, TTFT=334.8ms
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_24 to http://localhost:30000/generate at 1753373043.765699
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_24 with payload: {'text': 'Random prompt 24 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:03] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_24
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_24
[2025-07-25 00:04:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:03] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 97/1000 (ID: req_96)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 98: relative_arrival=1.886, absolute_arrival=2069485.052, current_time=2069485.036, wait_time=0.017
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 98/1000 (ID: req_97)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 99: relative_arrival=1.906, absolute_arrival=2069485.073, current_time=2069485.053, wait_time=0.019
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 99/1000 (ID: req_98)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 100: relative_arrival=1.938, absolute_arrival=2069485.105, current_time=2069485.074, wait_time=0.030
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_8 received DONE after 97 chunks
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_8 completed: 370 chars, 97 chunks, TTFT=349.7ms
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_25 to http://localhost:30000/generate at 1753373043.8366551
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_25 with payload: {'text': 'Random prompt 25 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:03] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_25
[2025-07-25 00:04:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_25
[2025-07-25 00:04:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:03] Prefill batch. #new-seq: 1, #new-token: 326, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 100/1000 (ID: req_99)
[2025-07-25 00:04:03] [__main__] [INFO] Progress: 100/1000 requests sent in 1.9s
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 101: relative_arrival=1.948, absolute_arrival=2069485.115, current_time=2069485.106, wait_time=0.009
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 101/1000 (ID: req_100)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 102: relative_arrival=1.997, absolute_arrival=2069485.164, current_time=2069485.116, wait_time=0.048
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 102/1000 (ID: req_101)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 103: relative_arrival=2.013, absolute_arrival=2069485.179, current_time=2069485.165, wait_time=0.015
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 103/1000 (ID: req_102)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 104: relative_arrival=2.016, absolute_arrival=2069485.183, current_time=2069485.180, wait_time=0.002
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 104/1000 (ID: req_103)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 105: relative_arrival=2.040, absolute_arrival=2069485.206, current_time=2069485.184, wait_time=0.023
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 105/1000 (ID: req_104)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 106: relative_arrival=2.071, absolute_arrival=2069485.238, current_time=2069485.207, wait_time=0.031
[2025-07-25 00:04:03] [__main__] [INFO] Sending request 106/1000 (ID: req_105)
[2025-07-25 00:04:03] [__main__] [DEBUG] Request 107: relative_arrival=2.079, absolute_arrival=2069485.246, current_time=2069485.240, wait_time=0.006
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 107/1000 (ID: req_106)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 108: relative_arrival=2.118, absolute_arrival=2069485.285, current_time=2069485.247, wait_time=0.037
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 108/1000 (ID: req_107)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 109: relative_arrival=2.165, absolute_arrival=2069485.332, current_time=2069485.285, wait_time=0.047
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 109/1000 (ID: req_108)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 110: relative_arrival=2.172, absolute_arrival=2069485.338, current_time=2069485.332, wait_time=0.006
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 110/1000 (ID: req_109)
[2025-07-25 00:04:04] [__main__] [INFO] Progress: 110/1000 requests sent in 2.2s
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 111: relative_arrival=2.254, absolute_arrival=2069485.420, current_time=2069485.339, wait_time=0.081
[2025-07-25 00:04:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:04] Decode batch. #running-req: 20, #token: 6959, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1354.56, #queue-req: 0,
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 111/1000 (ID: req_110)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 112: relative_arrival=2.257, absolute_arrival=2069485.423, current_time=2069485.421, wait_time=0.002
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 112/1000 (ID: req_111)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 113: relative_arrival=2.261, absolute_arrival=2069485.428, current_time=2069485.424, wait_time=0.004
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 113/1000 (ID: req_112)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 114: relative_arrival=2.266, absolute_arrival=2069485.432, current_time=2069485.429, wait_time=0.003
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 114/1000 (ID: req_113)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 115: relative_arrival=2.310, absolute_arrival=2069485.477, current_time=2069485.433, wait_time=0.044
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 115/1000 (ID: req_114)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 116: relative_arrival=2.332, absolute_arrival=2069485.498, current_time=2069485.478, wait_time=0.020
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_9 received DONE after 128 chunks
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_9 completed: 508 chars, 128 chunks, TTFT=349.2ms
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_26 to http://localhost:30000/generate at 1753373044.2410796
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_26 with payload: {'text': 'Random prompt 26 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 174, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:04] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_26
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_26
[2025-07-25 00:04:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:04] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 5, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 116/1000 (ID: req_115)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 117: relative_arrival=2.335, absolute_arrival=2069485.501, current_time=2069485.499, wait_time=0.002
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 117/1000 (ID: req_116)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 118: relative_arrival=2.347, absolute_arrival=2069485.513, current_time=2069485.503, wait_time=0.010
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 118/1000 (ID: req_117)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 119: relative_arrival=2.366, absolute_arrival=2069485.532, current_time=2069485.514, wait_time=0.018
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 119/1000 (ID: req_118)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 120: relative_arrival=2.367, absolute_arrival=2069485.534, current_time=2069485.533, wait_time=0.001
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 120/1000 (ID: req_119)
[2025-07-25 00:04:04] [__main__] [INFO] Progress: 120/1000 requests sent in 2.4s
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 121: relative_arrival=2.410, absolute_arrival=2069485.577, current_time=2069485.535, wait_time=0.042
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_1 received DONE after 134 chunks
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_1 completed: 133 chars, 134 chunks, TTFT=381.5ms
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_27 to http://localhost:30000/generate at 1753373044.3370755
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_27 with payload: {'text': 'Random prompt 27 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 121/1000 (ID: req_120)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 122: relative_arrival=2.443, absolute_arrival=2069485.609, current_time=2069485.580, wait_time=0.029
[2025-07-25 00:04:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:04] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_27
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_27
[2025-07-25 00:04:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:04] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 122/1000 (ID: req_121)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 123: relative_arrival=2.457, absolute_arrival=2069485.623, current_time=2069485.611, wait_time=0.013
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 123/1000 (ID: req_122)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 124: relative_arrival=2.525, absolute_arrival=2069485.692, current_time=2069485.625, wait_time=0.067
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_17 received DONE after 138 chunks
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_17 completed: 548 chars, 138 chunks, TTFT=415.6ms
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_28 to http://localhost:30000/generate at 1753373044.413488
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_28 with payload: {'text': 'Random prompt 28 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 105, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:04] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_28
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_28
[2025-07-25 00:04:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:04] Prefill batch. #new-seq: 1, #new-token: 277, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 124/1000 (ID: req_123)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 125: relative_arrival=2.536, absolute_arrival=2069485.703, current_time=2069485.694, wait_time=0.009
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 125/1000 (ID: req_124)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 126: relative_arrival=2.619, absolute_arrival=2069485.785, current_time=2069485.704, wait_time=0.081
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 126/1000 (ID: req_125)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 127: relative_arrival=2.641, absolute_arrival=2069485.807, current_time=2069485.787, wait_time=0.021
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 127/1000 (ID: req_126)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 128: relative_arrival=2.661, absolute_arrival=2069485.828, current_time=2069485.808, wait_time=0.019
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_5 received DONE after 149 chunks
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_5 completed: 586 chars, 149 chunks, TTFT=380.5ms
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_29 to http://localhost:30000/generate at 1753373044.5763621
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_29 with payload: {'text': 'Random prompt 29 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:04] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_29
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_29
[2025-07-25 00:04:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:04] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 5, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 128/1000 (ID: req_127)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 129: relative_arrival=2.665, absolute_arrival=2069485.831, current_time=2069485.828, wait_time=0.003
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 129/1000 (ID: req_128)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 130: relative_arrival=2.707, absolute_arrival=2069485.874, current_time=2069485.832, wait_time=0.042
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 130/1000 (ID: req_129)
[2025-07-25 00:04:04] [__main__] [INFO] Progress: 130/1000 requests sent in 2.7s
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 131: relative_arrival=2.719, absolute_arrival=2069485.885, current_time=2069485.875, wait_time=0.010
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 131/1000 (ID: req_130)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 132: relative_arrival=2.722, absolute_arrival=2069485.889, current_time=2069485.886, wait_time=0.003
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 132/1000 (ID: req_131)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 133: relative_arrival=2.722, absolute_arrival=2069485.889, current_time=2069485.890, wait_time=-0.002
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 133/1000 (ID: req_132)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 134: relative_arrival=2.739, absolute_arrival=2069485.905, current_time=2069485.891, wait_time=0.015
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_6 received DONE after 154 chunks
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_6 completed: 605 chars, 154 chunks, TTFT=380.3ms
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_30 to http://localhost:30000/generate at 1753373044.662224
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_30 with payload: {'text': 'Random prompt 30 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 134/1000 (ID: req_133)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 135: relative_arrival=2.754, absolute_arrival=2069485.920, current_time=2069485.906, wait_time=0.014
[2025-07-25 00:04:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:04] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_30
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_30
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_14 received DONE after 155 chunks
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_14 completed: 606 chars, 155 chunks, TTFT=330.0ms
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_31 to http://localhost:30000/generate at 1753373044.6749325
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_31 with payload: {'text': 'Random prompt 31 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:04] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 135/1000 (ID: req_134)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 136: relative_arrival=2.779, absolute_arrival=2069485.946, current_time=2069485.921, wait_time=0.025
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_31
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_31
[2025-07-25 00:04:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:04] Prefill batch. #new-seq: 1, #new-token: 281, #cached-token: 5, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 136/1000 (ID: req_135)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 137: relative_arrival=2.823, absolute_arrival=2069485.990, current_time=2069485.948, wait_time=0.042
[2025-07-25 00:04:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:04] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 137/1000 (ID: req_136)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 138: relative_arrival=2.825, absolute_arrival=2069485.992, current_time=2069485.990, wait_time=0.001
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 138/1000 (ID: req_137)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 139: relative_arrival=2.851, absolute_arrival=2069486.018, current_time=2069485.992, wait_time=0.025
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_3 received DONE after 159 chunks
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_3 completed: 632 chars, 159 chunks, TTFT=380.9ms
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_32 to http://localhost:30000/generate at 1753373044.7727425
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_32 with payload: {'text': 'Random prompt 32 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:04] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 139/1000 (ID: req_138)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 140: relative_arrival=2.855, absolute_arrival=2069486.022, current_time=2069486.018, wait_time=0.004
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_32
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_32
[2025-07-25 00:04:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:04] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 140/1000 (ID: req_139)
[2025-07-25 00:04:04] [__main__] [INFO] Progress: 140/1000 requests sent in 2.9s
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 141: relative_arrival=2.895, absolute_arrival=2069486.061, current_time=2069486.023, wait_time=0.038
[2025-07-25 00:04:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:04] Decode batch. #running-req: 19, #token: 6471, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1190.09, #queue-req: 0,
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 141/1000 (ID: req_140)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 142: relative_arrival=2.929, absolute_arrival=2069486.095, current_time=2069486.062, wait_time=0.033
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 142/1000 (ID: req_141)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 143: relative_arrival=2.944, absolute_arrival=2069486.111, current_time=2069486.096, wait_time=0.015
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 143/1000 (ID: req_142)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 144: relative_arrival=2.969, absolute_arrival=2069486.136, current_time=2069486.113, wait_time=0.023
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 144/1000 (ID: req_143)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 145: relative_arrival=2.977, absolute_arrival=2069486.143, current_time=2069486.137, wait_time=0.006
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 145/1000 (ID: req_144)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 146: relative_arrival=2.989, absolute_arrival=2069486.156, current_time=2069486.144, wait_time=0.012
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_4 received DONE after 168 chunks
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_4 completed: 662 chars, 168 chunks, TTFT=380.7ms
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_33 to http://localhost:30000/generate at 1753373044.90768
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_33 with payload: {'text': 'Random prompt 33 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 79, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:04] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 146/1000 (ID: req_145)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 147: relative_arrival=3.024, absolute_arrival=2069486.190, current_time=2069486.156, wait_time=0.034
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_33
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_33
[2025-07-25 00:04:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:04] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 147/1000 (ID: req_146)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 148: relative_arrival=3.036, absolute_arrival=2069486.203, current_time=2069486.191, wait_time=0.012
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 148/1000 (ID: req_147)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 149: relative_arrival=3.045, absolute_arrival=2069486.211, current_time=2069486.203, wait_time=0.008
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 149/1000 (ID: req_148)
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 150: relative_arrival=3.059, absolute_arrival=2069486.225, current_time=2069486.213, wait_time=0.012
[2025-07-25 00:04:04] [__main__] [INFO] Sending request 150/1000 (ID: req_149)
[2025-07-25 00:04:04] [__main__] [INFO] Progress: 150/1000 requests sent in 3.1s
[2025-07-25 00:04:04] [__main__] [DEBUG] Request 151: relative_arrival=3.094, absolute_arrival=2069486.260, current_time=2069486.227, wait_time=0.034
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_21 received DONE after 103 chunks
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_21 completed: 398 chars, 103 chunks, TTFT=67.1ms
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_34 to http://localhost:30000/generate at 1753373044.997632
[2025-07-25 00:04:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_34 with payload: {'text': 'Random prompt 34 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_34
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_34
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_7 received DONE after 174 chunks
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_7 completed: 175 chars, 174 chunks, TTFT=379.2ms
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_35 to http://localhost:30000/generate at 1753373045.011703
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_35 with payload: {'text': 'Random prompt 35 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_35
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_35
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 151/1000 (ID: req_150)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 152: relative_arrival=3.102, absolute_arrival=2069486.269, current_time=2069486.261, wait_time=0.008
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 152/1000 (ID: req_151)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 153: relative_arrival=3.106, absolute_arrival=2069486.272, current_time=2069486.269, wait_time=0.003
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 153/1000 (ID: req_152)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 154: relative_arrival=3.131, absolute_arrival=2069486.297, current_time=2069486.273, wait_time=0.024
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 154/1000 (ID: req_153)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 155: relative_arrival=3.166, absolute_arrival=2069486.332, current_time=2069486.299, wait_time=0.033
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 155/1000 (ID: req_154)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 156: relative_arrival=3.168, absolute_arrival=2069486.334, current_time=2069486.333, wait_time=0.001
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 156/1000 (ID: req_155)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 157: relative_arrival=3.173, absolute_arrival=2069486.340, current_time=2069486.337, wait_time=0.003
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 157/1000 (ID: req_156)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 158: relative_arrival=3.176, absolute_arrival=2069486.343, current_time=2069486.341, wait_time=0.002
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 158/1000 (ID: req_157)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 159: relative_arrival=3.185, absolute_arrival=2069486.351, current_time=2069486.343, wait_time=0.008
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_2 received DONE after 177 chunks
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_2 completed: 658 chars, 177 chunks, TTFT=381.2ms
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_36 to http://localhost:30000/generate at 1753373045.108379
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_36 with payload: {'text': 'Random prompt 36 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 159/1000 (ID: req_158)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 160: relative_arrival=3.197, absolute_arrival=2069486.363, current_time=2069486.352, wait_time=0.011
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_36
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_36
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 160/1000 (ID: req_159)
[2025-07-25 00:04:05] [__main__] [INFO] Progress: 160/1000 requests sent in 3.2s
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 161: relative_arrival=3.225, absolute_arrival=2069486.391, current_time=2069486.365, wait_time=0.026
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] Prefill batch. #new-seq: 1, #new-token: 203, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 161/1000 (ID: req_160)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 162: relative_arrival=3.246, absolute_arrival=2069486.412, current_time=2069486.393, wait_time=0.019
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 162/1000 (ID: req_161)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 163: relative_arrival=3.265, absolute_arrival=2069486.431, current_time=2069486.413, wait_time=0.018
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 163/1000 (ID: req_162)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 164: relative_arrival=3.274, absolute_arrival=2069486.440, current_time=2069486.432, wait_time=0.008
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_18 received DONE after 182 chunks
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_18 completed: 670 chars, 182 chunks, TTFT=370.0ms
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_37 to http://localhost:30000/generate at 1753373045.192832
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_37 with payload: {'text': 'Random prompt 37 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_37
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_37
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] Prefill batch. #new-seq: 1, #new-token: 150, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 164/1000 (ID: req_163)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 165: relative_arrival=3.310, absolute_arrival=2069486.477, current_time=2069486.441, wait_time=0.036
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_15 received DONE after 183 chunks
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_15 completed: 718 chars, 183 chunks, TTFT=314.5ms
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_38 to http://localhost:30000/generate at 1753373045.2054136
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_38 with payload: {'text': 'Random prompt 38 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_38
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_38
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] Prefill batch. #new-seq: 1, #new-token: 300, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 165/1000 (ID: req_164)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 166: relative_arrival=3.323, absolute_arrival=2069486.490, current_time=2069486.479, wait_time=0.011
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 166/1000 (ID: req_165)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 167: relative_arrival=3.401, absolute_arrival=2069486.567, current_time=2069486.490, wait_time=0.077
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_12 received DONE after 186 chunks
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_12 completed: 688 chars, 186 chunks, TTFT=333.8ms
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_39 to http://localhost:30000/generate at 1753373045.2953613
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_39 with payload: {'text': 'Random prompt 39 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 104, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_39
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_39
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] Prefill batch. #new-seq: 1, #new-token: 238, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 167/1000 (ID: req_166)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 168: relative_arrival=3.421, absolute_arrival=2069486.587, current_time=2069486.568, wait_time=0.020
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 168/1000 (ID: req_167)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 169: relative_arrival=3.423, absolute_arrival=2069486.590, current_time=2069486.588, wait_time=0.002
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 169/1000 (ID: req_168)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 170: relative_arrival=3.446, absolute_arrival=2069486.612, current_time=2069486.590, wait_time=0.022
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 170/1000 (ID: req_169)
[2025-07-25 00:04:05] [__main__] [INFO] Progress: 170/1000 requests sent in 3.4s
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 171: relative_arrival=3.454, absolute_arrival=2069486.620, current_time=2069486.614, wait_time=0.007
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_11 received DONE after 191 chunks
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_11 completed: 760 chars, 191 chunks, TTFT=334.6ms
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_40 to http://localhost:30000/generate at 1753373045.379221
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_40 with payload: {'text': 'Random prompt 40 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 171/1000 (ID: req_170)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 172: relative_arrival=3.477, absolute_arrival=2069486.644, current_time=2069486.623, wait_time=0.021
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_40
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_40
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 172/1000 (ID: req_171)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 173: relative_arrival=3.478, absolute_arrival=2069486.645, current_time=2069486.644, wait_time=0.001
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 173/1000 (ID: req_172)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 174: relative_arrival=3.482, absolute_arrival=2069486.649, current_time=2069486.646, wait_time=0.003
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 174/1000 (ID: req_173)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 175: relative_arrival=3.521, absolute_arrival=2069486.688, current_time=2069486.650, wait_time=0.037
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 175/1000 (ID: req_174)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 176: relative_arrival=3.526, absolute_arrival=2069486.693, current_time=2069486.688, wait_time=0.004
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 176/1000 (ID: req_175)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 177: relative_arrival=3.562, absolute_arrival=2069486.729, current_time=2069486.693, wait_time=0.036
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 177/1000 (ID: req_176)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 178: relative_arrival=3.569, absolute_arrival=2069486.736, current_time=2069486.730, wait_time=0.006
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 178/1000 (ID: req_177)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 179: relative_arrival=3.590, absolute_arrival=2069486.756, current_time=2069486.736, wait_time=0.020
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] Decode batch. #running-req: 20, #token: 5941, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1126.35, #queue-req: 0,
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 179/1000 (ID: req_178)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 180: relative_arrival=3.613, absolute_arrival=2069486.780, current_time=2069486.757, wait_time=0.023
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 180/1000 (ID: req_179)
[2025-07-25 00:04:05] [__main__] [INFO] Progress: 180/1000 requests sent in 3.6s
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 181: relative_arrival=3.628, absolute_arrival=2069486.794, current_time=2069486.781, wait_time=0.013
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 181/1000 (ID: req_180)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 182: relative_arrival=3.635, absolute_arrival=2069486.801, current_time=2069486.795, wait_time=0.007
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 182/1000 (ID: req_181)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 183: relative_arrival=3.640, absolute_arrival=2069486.806, current_time=2069486.802, wait_time=0.004
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 183/1000 (ID: req_182)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 184: relative_arrival=3.640, absolute_arrival=2069486.807, current_time=2069486.807, wait_time=0.000
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 184/1000 (ID: req_183)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 185: relative_arrival=3.648, absolute_arrival=2069486.814, current_time=2069486.808, wait_time=0.006
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 185/1000 (ID: req_184)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 186: relative_arrival=3.669, absolute_arrival=2069486.835, current_time=2069486.815, wait_time=0.021
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 186/1000 (ID: req_185)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 187: relative_arrival=3.725, absolute_arrival=2069486.891, current_time=2069486.836, wait_time=0.055
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 187/1000 (ID: req_186)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 188: relative_arrival=3.766, absolute_arrival=2069486.932, current_time=2069486.892, wait_time=0.040
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 188/1000 (ID: req_187)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 189: relative_arrival=3.795, absolute_arrival=2069486.961, current_time=2069486.933, wait_time=0.028
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 189/1000 (ID: req_188)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 190: relative_arrival=3.826, absolute_arrival=2069486.992, current_time=2069486.962, wait_time=0.030
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 190/1000 (ID: req_189)
[2025-07-25 00:04:05] [__main__] [INFO] Progress: 190/1000 requests sent in 3.8s
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 191: relative_arrival=3.848, absolute_arrival=2069487.014, current_time=2069486.994, wait_time=0.021
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 191/1000 (ID: req_190)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 192: relative_arrival=3.854, absolute_arrival=2069487.020, current_time=2069487.015, wait_time=0.005
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 192/1000 (ID: req_191)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 193: relative_arrival=3.901, absolute_arrival=2069487.068, current_time=2069487.020, wait_time=0.047
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_25 received DONE after 126 chunks
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_25 completed: 377 chars, 126 chunks, TTFT=58.8ms
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_20 received DONE after 154 chunks
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_20 completed: 551 chars, 154 chunks, TTFT=79.0ms
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_41 to http://localhost:30000/generate at 1753373045.796155
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_41 with payload: {'text': 'Random prompt 41 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_42 to http://localhost:30000/generate at 1753373045.7969558
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_42 with payload: {'text': 'Random prompt 42 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 105, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_41
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_41
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_42
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_42
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_30 received DONE after 70 chunks
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_30 completed: 206 chars, 70 chunks, TTFT=78.0ms
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_43 to http://localhost:30000/generate at 1753373045.8120878
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_43 with payload: {'text': 'Random prompt 43 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] Prefill batch. #new-seq: 2, #new-token: 386, #cached-token: 10, token usage: 0.04, #running-req: 17, #queue-req: 0,
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_43
[2025-07-25 00:04:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_43
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 193/1000 (ID: req_192)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 194: relative_arrival=3.923, absolute_arrival=2069487.090, current_time=2069487.069, wait_time=0.021
[2025-07-25 00:04:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:05] Prefill batch. #new-seq: 1, #new-token: 358, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 194/1000 (ID: req_193)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 195: relative_arrival=3.940, absolute_arrival=2069487.106, current_time=2069487.091, wait_time=0.015
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 195/1000 (ID: req_194)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 196: relative_arrival=3.942, absolute_arrival=2069487.109, current_time=2069487.108, wait_time=0.001
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 196/1000 (ID: req_195)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 197: relative_arrival=3.954, absolute_arrival=2069487.120, current_time=2069487.109, wait_time=0.011
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 197/1000 (ID: req_196)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 198: relative_arrival=3.966, absolute_arrival=2069487.133, current_time=2069487.122, wait_time=0.011
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 198/1000 (ID: req_197)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 199: relative_arrival=4.006, absolute_arrival=2069487.173, current_time=2069487.133, wait_time=0.039
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 199/1000 (ID: req_198)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 200: relative_arrival=4.022, absolute_arrival=2069487.189, current_time=2069487.174, wait_time=0.014
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 200/1000 (ID: req_199)
[2025-07-25 00:04:05] [__main__] [INFO] Progress: 200/1000 requests sent in 4.0s
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 201: relative_arrival=4.032, absolute_arrival=2069487.198, current_time=2069487.189, wait_time=0.009
[2025-07-25 00:04:05] [__main__] [INFO] Sending request 201/1000 (ID: req_200)
[2025-07-25 00:04:05] [__main__] [DEBUG] Request 202: relative_arrival=4.107, absolute_arrival=2069487.273, current_time=2069487.199, wait_time=0.075
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 202/1000 (ID: req_201)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 203: relative_arrival=4.109, absolute_arrival=2069487.276, current_time=2069487.274, wait_time=0.002
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 203/1000 (ID: req_202)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 204: relative_arrival=4.120, absolute_arrival=2069487.287, current_time=2069487.277, wait_time=0.010
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 204/1000 (ID: req_203)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 205: relative_arrival=4.121, absolute_arrival=2069487.288, current_time=2069487.288, wait_time=-0.000
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 205/1000 (ID: req_204)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 206: relative_arrival=4.148, absolute_arrival=2069487.315, current_time=2069487.288, wait_time=0.026
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] Decode batch. #running-req: 20, #token: 6244, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1462.47, #queue-req: 0,
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 206/1000 (ID: req_205)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 207: relative_arrival=4.198, absolute_arrival=2069487.365, current_time=2069487.317, wait_time=0.048
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_28 received DONE after 106 chunks
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_28 completed: 420 chars, 106 chunks, TTFT=59.3ms
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_44 to http://localhost:30000/generate at 1753373046.1128078
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_44 with payload: {'text': 'Random prompt 44 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_44
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_44
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] Prefill batch. #new-seq: 1, #new-token: 191, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 207/1000 (ID: req_206)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 208: relative_arrival=4.205, absolute_arrival=2069487.371, current_time=2069487.366, wait_time=0.005
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 208/1000 (ID: req_207)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 209: relative_arrival=4.244, absolute_arrival=2069487.410, current_time=2069487.372, wait_time=0.038
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_34 received DONE after 75 chunks
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_34 completed: 296 chars, 75 chunks, TTFT=68.3ms
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 209/1000 (ID: req_208)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 210: relative_arrival=4.251, absolute_arrival=2069487.417, current_time=2069487.411, wait_time=0.006
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_45 to http://localhost:30000/generate at 1753373046.169928
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_45 with payload: {'text': 'Random prompt 45 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_45
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_45
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 210/1000 (ID: req_209)
[2025-07-25 00:04:06] [__main__] [INFO] Progress: 210/1000 requests sent in 4.3s
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 211: relative_arrival=4.299, absolute_arrival=2069487.466, current_time=2069487.418, wait_time=0.048
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] Prefill batch. #new-seq: 1, #new-token: 295, #cached-token: 5, token usage: 0.04, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_33 received DONE after 80 chunks
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_33 completed: 304 chars, 80 chunks, TTFT=59.8ms
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_46 to http://localhost:30000/generate at 1753373046.1829453
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_46 with payload: {'text': 'Random prompt 46 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_46
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_46
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] Prefill batch. #new-seq: 1, #new-token: 205, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 211/1000 (ID: req_210)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 212: relative_arrival=4.327, absolute_arrival=2069487.494, current_time=2069487.467, wait_time=0.027
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 212/1000 (ID: req_211)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 213: relative_arrival=4.360, absolute_arrival=2069487.526, current_time=2069487.494, wait_time=0.032
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_32 received DONE after 94 chunks
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_32 completed: 95 chars, 94 chunks, TTFT=47.6ms
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_47 to http://localhost:30000/generate at 1753373046.2861085
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_47 with payload: {'text': 'Random prompt 47 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 213/1000 (ID: req_212)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 214: relative_arrival=4.360, absolute_arrival=2069487.527, current_time=2069487.529, wait_time=-0.002
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 214/1000 (ID: req_213)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 215: relative_arrival=4.426, absolute_arrival=2069487.592, current_time=2069487.529, wait_time=0.063
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_47
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_47
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 5, token usage: 0.04, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_38 received DONE after 73 chunks
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_38 completed: 288 chars, 73 chunks, TTFT=59.3ms
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_48 to http://localhost:30000/generate at 1753373046.3093035
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_48 with payload: {'text': 'Random prompt 48 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_48
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_48
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] Prefill batch. #new-seq: 1, #new-token: 265, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 215/1000 (ID: req_214)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 216: relative_arrival=4.452, absolute_arrival=2069487.618, current_time=2069487.593, wait_time=0.025
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 216/1000 (ID: req_215)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 217: relative_arrival=4.459, absolute_arrival=2069487.626, current_time=2069487.619, wait_time=0.007
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 217/1000 (ID: req_216)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 218: relative_arrival=4.495, absolute_arrival=2069487.661, current_time=2069487.626, wait_time=0.035
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 218/1000 (ID: req_217)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 219: relative_arrival=4.501, absolute_arrival=2069487.668, current_time=2069487.662, wait_time=0.006
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 219/1000 (ID: req_218)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 220: relative_arrival=4.542, absolute_arrival=2069487.709, current_time=2069487.668, wait_time=0.041
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 220/1000 (ID: req_219)
[2025-07-25 00:04:06] [__main__] [INFO] Progress: 220/1000 requests sent in 4.5s
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 221: relative_arrival=4.545, absolute_arrival=2069487.711, current_time=2069487.710, wait_time=0.002
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 221/1000 (ID: req_220)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 222: relative_arrival=4.569, absolute_arrival=2069487.736, current_time=2069487.712, wait_time=0.023
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 222/1000 (ID: req_221)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 223: relative_arrival=4.585, absolute_arrival=2069487.751, current_time=2069487.737, wait_time=0.014
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 223/1000 (ID: req_222)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 224: relative_arrival=4.587, absolute_arrival=2069487.753, current_time=2069487.752, wait_time=0.001
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 224/1000 (ID: req_223)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 225: relative_arrival=4.592, absolute_arrival=2069487.759, current_time=2069487.754, wait_time=0.004
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 225/1000 (ID: req_224)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 226: relative_arrival=4.592, absolute_arrival=2069487.759, current_time=2069487.760, wait_time=-0.001
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 226/1000 (ID: req_225)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 227: relative_arrival=4.605, absolute_arrival=2069487.772, current_time=2069487.760, wait_time=0.012
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 227/1000 (ID: req_226)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 228: relative_arrival=4.612, absolute_arrival=2069487.779, current_time=2069487.773, wait_time=0.006
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 228/1000 (ID: req_227)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 229: relative_arrival=4.631, absolute_arrival=2069487.797, current_time=2069487.779, wait_time=0.018
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_22 received DONE after 183 chunks
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_22 completed: 717 chars, 183 chunks, TTFT=67.5ms
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_49 to http://localhost:30000/generate at 1753373046.556672
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_49 with payload: {'text': 'Random prompt 49 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 229/1000 (ID: req_228)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 230: relative_arrival=4.638, absolute_arrival=2069487.804, current_time=2069487.800, wait_time=0.004
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_49
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_49
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 230/1000 (ID: req_229)
[2025-07-25 00:04:06] [__main__] [INFO] Progress: 230/1000 requests sent in 4.6s
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 231: relative_arrival=4.645, absolute_arrival=2069487.811, current_time=2069487.805, wait_time=0.006
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 231/1000 (ID: req_230)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 232: relative_arrival=4.672, absolute_arrival=2069487.838, current_time=2069487.812, wait_time=0.027
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 232/1000 (ID: req_231)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 233: relative_arrival=4.673, absolute_arrival=2069487.839, current_time=2069487.839, wait_time=0.000
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 233/1000 (ID: req_232)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 234: relative_arrival=4.720, absolute_arrival=2069487.886, current_time=2069487.841, wait_time=0.045
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 234/1000 (ID: req_233)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 235: relative_arrival=4.758, absolute_arrival=2069487.924, current_time=2069487.887, wait_time=0.037
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_23 received DONE after 189 chunks
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_23 completed: 555 chars, 189 chunks, TTFT=59.5ms
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_50 to http://localhost:30000/generate at 1753373046.6532586
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_50 with payload: {'text': 'Random prompt 50 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_50
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_50
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] Prefill batch. #new-seq: 1, #new-token: 373, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 235/1000 (ID: req_234)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 236: relative_arrival=4.780, absolute_arrival=2069487.946, current_time=2069487.926, wait_time=0.021
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 236/1000 (ID: req_235)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 237: relative_arrival=4.798, absolute_arrival=2069487.964, current_time=2069487.947, wait_time=0.017
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_24 received DONE after 186 chunks
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_24 completed: 682 chars, 186 chunks, TTFT=55.1ms
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_51 to http://localhost:30000/generate at 1753373046.7101169
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_51 with payload: {'text': 'Random prompt 51 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 132, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_51
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_51
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 237/1000 (ID: req_236)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 238: relative_arrival=4.842, absolute_arrival=2069488.009, current_time=2069487.965, wait_time=0.044
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] Decode batch. #running-req: 19, #token: 5698, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1189.61, #queue-req: 0,
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] Prefill batch. #new-seq: 1, #new-token: 324, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 238/1000 (ID: req_237)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 239: relative_arrival=4.846, absolute_arrival=2069488.013, current_time=2069488.009, wait_time=0.004
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 239/1000 (ID: req_238)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 240: relative_arrival=4.848, absolute_arrival=2069488.015, current_time=2069488.014, wait_time=0.001
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 240/1000 (ID: req_239)
[2025-07-25 00:04:06] [__main__] [INFO] Progress: 240/1000 requests sent in 4.8s
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 241: relative_arrival=4.854, absolute_arrival=2069488.020, current_time=2069488.016, wait_time=0.004
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 241/1000 (ID: req_240)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 242: relative_arrival=4.885, absolute_arrival=2069488.052, current_time=2069488.021, wait_time=0.030
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 242/1000 (ID: req_241)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 243: relative_arrival=4.886, absolute_arrival=2069488.052, current_time=2069488.053, wait_time=-0.000
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 243/1000 (ID: req_242)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 244: relative_arrival=4.903, absolute_arrival=2069488.070, current_time=2069488.053, wait_time=0.017
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 244/1000 (ID: req_243)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 245: relative_arrival=5.011, absolute_arrival=2069488.178, current_time=2069488.070, wait_time=0.107
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_36 received DONE after 109 chunks
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_36 completed: 423 chars, 109 chunks, TTFT=56.5ms
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_52 to http://localhost:30000/generate at 1753373046.8337076
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_52 with payload: {'text': 'Random prompt 52 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_52
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_52
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] Prefill batch. #new-seq: 1, #new-token: 366, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_39 received DONE after 105 chunks
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_39 completed: 406 chars, 105 chunks, TTFT=57.1ms
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_53 to http://localhost:30000/generate at 1753373046.9239728
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_53 with payload: {'text': 'Random prompt 53 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_53
[2025-07-25 00:04:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_53
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 245/1000 (ID: req_244)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 246: relative_arrival=5.050, absolute_arrival=2069488.216, current_time=2069488.179, wait_time=0.038
[2025-07-25 00:04:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:06] Prefill batch. #new-seq: 1, #new-token: 354, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 246/1000 (ID: req_245)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 247: relative_arrival=5.065, absolute_arrival=2069488.231, current_time=2069488.218, wait_time=0.014
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 247/1000 (ID: req_246)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 248: relative_arrival=5.066, absolute_arrival=2069488.233, current_time=2069488.232, wait_time=0.000
[2025-07-25 00:04:06] [__main__] [INFO] Sending request 248/1000 (ID: req_247)
[2025-07-25 00:04:06] [__main__] [DEBUG] Request 249: relative_arrival=5.102, absolute_arrival=2069488.268, current_time=2069488.234, wait_time=0.034
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_31 received DONE after 141 chunks
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_31 completed: 549 chars, 141 chunks, TTFT=68.3ms
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_54 to http://localhost:30000/generate at 1753373047.0026112
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_54 with payload: {'text': 'Random prompt 54 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_54
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_54
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 249/1000 (ID: req_248)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 250: relative_arrival=5.120, absolute_arrival=2069488.286, current_time=2069488.269, wait_time=0.018
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 250/1000 (ID: req_249)
[2025-07-25 00:04:07] [__main__] [INFO] Progress: 250/1000 requests sent in 5.1s
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 251: relative_arrival=5.122, absolute_arrival=2069488.289, current_time=2069488.288, wait_time=0.001
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 251/1000 (ID: req_250)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 252: relative_arrival=5.124, absolute_arrival=2069488.291, current_time=2069488.289, wait_time=0.002
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 252/1000 (ID: req_251)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 253: relative_arrival=5.172, absolute_arrival=2069488.339, current_time=2069488.292, wait_time=0.047
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 253/1000 (ID: req_252)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 254: relative_arrival=5.195, absolute_arrival=2069488.361, current_time=2069488.340, wait_time=0.021
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_26 received DONE after 175 chunks
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_26 completed: 686 chars, 175 chunks, TTFT=44.0ms
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_55 to http://localhost:30000/generate at 1753373047.1164005
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_55 with payload: {'text': 'Random prompt 55 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 254/1000 (ID: req_253)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 255: relative_arrival=5.230, absolute_arrival=2069488.396, current_time=2069488.362, wait_time=0.035
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_55
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_55
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] Prefill batch. #new-seq: 1, #new-token: 361, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 255/1000 (ID: req_254)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 256: relative_arrival=5.272, absolute_arrival=2069488.439, current_time=2069488.397, wait_time=0.042
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 256/1000 (ID: req_255)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 257: relative_arrival=5.289, absolute_arrival=2069488.456, current_time=2069488.439, wait_time=0.016
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_27 received DONE after 173 chunks
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_27 completed: 700 chars, 173 chunks, TTFT=58.2ms
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_56 to http://localhost:30000/generate at 1753373047.2056355
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_56 with payload: {'text': 'Random prompt 56 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_56
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_56
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 257/1000 (ID: req_256)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 258: relative_arrival=5.304, absolute_arrival=2069488.470, current_time=2069488.456, wait_time=0.014
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 258/1000 (ID: req_257)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 259: relative_arrival=5.315, absolute_arrival=2069488.481, current_time=2069488.471, wait_time=0.010
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 259/1000 (ID: req_258)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 260: relative_arrival=5.323, absolute_arrival=2069488.489, current_time=2069488.482, wait_time=0.007
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 260/1000 (ID: req_259)
[2025-07-25 00:04:07] [__main__] [INFO] Progress: 260/1000 requests sent in 5.3s
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 261: relative_arrival=5.334, absolute_arrival=2069488.500, current_time=2069488.490, wait_time=0.011
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 261/1000 (ID: req_260)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 262: relative_arrival=5.364, absolute_arrival=2069488.530, current_time=2069488.503, wait_time=0.027
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 262/1000 (ID: req_261)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 263: relative_arrival=5.382, absolute_arrival=2069488.549, current_time=2069488.532, wait_time=0.017
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 263/1000 (ID: req_262)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 264: relative_arrival=5.427, absolute_arrival=2069488.593, current_time=2069488.549, wait_time=0.044
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 264/1000 (ID: req_263)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 265: relative_arrival=5.438, absolute_arrival=2069488.605, current_time=2069488.594, wait_time=0.011
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 265/1000 (ID: req_264)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 266: relative_arrival=5.457, absolute_arrival=2069488.624, current_time=2069488.606, wait_time=0.018
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_29 received DONE after 171 chunks
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_29 completed: 170 chars, 171 chunks, TTFT=46.2ms
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_57 to http://localhost:30000/generate at 1753373047.3743095
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_57 with payload: {'text': 'Random prompt 57 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] Decode batch. #running-req: 20, #token: 6270, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1206.50, #queue-req: 0,
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_57
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_57
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] Prefill batch. #new-seq: 1, #new-token: 175, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 266/1000 (ID: req_265)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 267: relative_arrival=5.477, absolute_arrival=2069488.644, current_time=2069488.624, wait_time=0.019
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 267/1000 (ID: req_266)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 268: relative_arrival=5.495, absolute_arrival=2069488.661, current_time=2069488.644, wait_time=0.017
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_47 received DONE after 68 chunks
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_47 completed: 268 chars, 68 chunks, TTFT=77.8ms
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_58 to http://localhost:30000/generate at 1753373047.419625
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_58 with payload: {'text': 'Random prompt 58 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 268/1000 (ID: req_267)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 269: relative_arrival=5.519, absolute_arrival=2069488.686, current_time=2069488.663, wait_time=0.023
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_58
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_58
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 269/1000 (ID: req_268)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 270: relative_arrival=5.525, absolute_arrival=2069488.691, current_time=2069488.687, wait_time=0.004
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 270/1000 (ID: req_269)
[2025-07-25 00:04:07] [__main__] [INFO] Progress: 270/1000 requests sent in 5.5s
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 271: relative_arrival=5.539, absolute_arrival=2069488.706, current_time=2069488.692, wait_time=0.014
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 271/1000 (ID: req_270)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 272: relative_arrival=5.541, absolute_arrival=2069488.708, current_time=2069488.708, wait_time=-0.000
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 272/1000 (ID: req_271)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 273: relative_arrival=5.551, absolute_arrival=2069488.717, current_time=2069488.708, wait_time=0.009
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 273/1000 (ID: req_272)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 274: relative_arrival=5.564, absolute_arrival=2069488.731, current_time=2069488.719, wait_time=0.012
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_40 received DONE after 134 chunks
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_40 completed: 532 chars, 134 chunks, TTFT=45.8ms
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_59 to http://localhost:30000/generate at 1753373047.4803205
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_59 with payload: {'text': 'Random prompt 59 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_59
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_59
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 274/1000 (ID: req_273)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 275: relative_arrival=5.585, absolute_arrival=2069488.752, current_time=2069488.732, wait_time=0.020
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] Prefill batch. #new-seq: 1, #new-token: 208, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_35 received DONE after 154 chunks
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_35 completed: 589 chars, 154 chunks, TTFT=65.5ms
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_60 to http://localhost:30000/generate at 1753373047.5050998
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_60 with payload: {'text': 'Random prompt 60 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_60
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_60
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 275/1000 (ID: req_274)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 276: relative_arrival=5.646, absolute_arrival=2069488.812, current_time=2069488.752, wait_time=0.060
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 276/1000 (ID: req_275)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 277: relative_arrival=5.664, absolute_arrival=2069488.830, current_time=2069488.814, wait_time=0.016
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 277/1000 (ID: req_276)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 278: relative_arrival=5.691, absolute_arrival=2069488.858, current_time=2069488.831, wait_time=0.027
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_42 received DONE after 106 chunks
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_42 completed: 107 chars, 106 chunks, TTFT=86.1ms
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_61 to http://localhost:30000/generate at 1753373047.6030939
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_61 with payload: {'text': 'Random prompt 61 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_61
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_61
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 278/1000 (ID: req_277)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 279: relative_arrival=5.705, absolute_arrival=2069488.872, current_time=2069488.859, wait_time=0.013
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] Prefill batch. #new-seq: 1, #new-token: 195, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 279/1000 (ID: req_278)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 280: relative_arrival=5.725, absolute_arrival=2069488.892, current_time=2069488.873, wait_time=0.019
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 280/1000 (ID: req_279)
[2025-07-25 00:04:07] [__main__] [INFO] Progress: 280/1000 requests sent in 5.7s
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 281: relative_arrival=5.727, absolute_arrival=2069488.893, current_time=2069488.892, wait_time=0.001
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 281/1000 (ID: req_280)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 282: relative_arrival=5.733, absolute_arrival=2069488.899, current_time=2069488.894, wait_time=0.005
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 282/1000 (ID: req_281)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 283: relative_arrival=5.742, absolute_arrival=2069488.908, current_time=2069488.901, wait_time=0.007
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 283/1000 (ID: req_282)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 284: relative_arrival=5.754, absolute_arrival=2069488.921, current_time=2069488.909, wait_time=0.012
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 284/1000 (ID: req_283)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 285: relative_arrival=5.755, absolute_arrival=2069488.922, current_time=2069488.922, wait_time=0.000
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 285/1000 (ID: req_284)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 286: relative_arrival=5.758, absolute_arrival=2069488.925, current_time=2069488.923, wait_time=0.002
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 286/1000 (ID: req_285)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 287: relative_arrival=5.765, absolute_arrival=2069488.931, current_time=2069488.927, wait_time=0.005
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 287/1000 (ID: req_286)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 288: relative_arrival=5.836, absolute_arrival=2069489.003, current_time=2069488.932, wait_time=0.071
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_49 received DONE after 68 chunks
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_49 completed: 268 chars, 68 chunks, TTFT=46.0ms
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_62 to http://localhost:30000/generate at 1753373047.721062
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_62 with payload: {'text': 'Random prompt 62 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_62
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_62
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_37 received DONE after 158 chunks
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_37 completed: 619 chars, 158 chunks, TTFT=64.8ms
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_63 to http://localhost:30000/generate at 1753373047.7342713
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_63 with payload: {'text': 'Random prompt 63 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] Prefill batch. #new-seq: 1, #new-token: 337, #cached-token: 5, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_63
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_63
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 288/1000 (ID: req_287)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 289: relative_arrival=5.844, absolute_arrival=2069489.011, current_time=2069489.004, wait_time=0.007
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 289/1000 (ID: req_288)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 290: relative_arrival=5.857, absolute_arrival=2069489.024, current_time=2069489.011, wait_time=0.013
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] Prefill batch. #new-seq: 1, #new-token: 216, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 290/1000 (ID: req_289)
[2025-07-25 00:04:07] [__main__] [INFO] Progress: 290/1000 requests sent in 5.9s
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 291: relative_arrival=5.862, absolute_arrival=2069489.028, current_time=2069489.024, wait_time=0.004
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 291/1000 (ID: req_290)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 292: relative_arrival=5.881, absolute_arrival=2069489.047, current_time=2069489.029, wait_time=0.018
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 292/1000 (ID: req_291)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 293: relative_arrival=5.887, absolute_arrival=2069489.054, current_time=2069489.048, wait_time=0.005
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 293/1000 (ID: req_292)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 294: relative_arrival=5.892, absolute_arrival=2069489.058, current_time=2069489.055, wait_time=0.004
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 294/1000 (ID: req_293)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 295: relative_arrival=5.906, absolute_arrival=2069489.073, current_time=2069489.059, wait_time=0.014
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_46 received DONE after 95 chunks
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_46 completed: 366 chars, 95 chunks, TTFT=61.0ms
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_64 to http://localhost:30000/generate at 1753373047.823238
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_64 with payload: {'text': 'Random prompt 64 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 118, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_64
[2025-07-25 00:04:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_64
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 295/1000 (ID: req_294)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 296: relative_arrival=5.906, absolute_arrival=2069489.073, current_time=2069489.073, wait_time=-0.001
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 296/1000 (ID: req_295)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 297: relative_arrival=5.907, absolute_arrival=2069489.073, current_time=2069489.074, wait_time=-0.001
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 297/1000 (ID: req_296)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 298: relative_arrival=5.911, absolute_arrival=2069489.078, current_time=2069489.074, wait_time=0.004
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 298/1000 (ID: req_297)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 299: relative_arrival=5.912, absolute_arrival=2069489.079, current_time=2069489.079, wait_time=-0.000
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 299/1000 (ID: req_298)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 300: relative_arrival=5.915, absolute_arrival=2069489.081, current_time=2069489.079, wait_time=0.002
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 300/1000 (ID: req_299)
[2025-07-25 00:04:07] [__main__] [INFO] Progress: 300/1000 requests sent in 5.9s
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 301: relative_arrival=5.923, absolute_arrival=2069489.089, current_time=2069489.082, wait_time=0.008
[2025-07-25 00:04:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:07] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 301/1000 (ID: req_300)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 302: relative_arrival=5.955, absolute_arrival=2069489.122, current_time=2069489.090, wait_time=0.031
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 302/1000 (ID: req_301)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 303: relative_arrival=5.972, absolute_arrival=2069489.139, current_time=2069489.123, wait_time=0.016
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 303/1000 (ID: req_302)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 304: relative_arrival=5.987, absolute_arrival=2069489.153, current_time=2069489.140, wait_time=0.013
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 304/1000 (ID: req_303)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 305: relative_arrival=5.994, absolute_arrival=2069489.160, current_time=2069489.154, wait_time=0.006
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 305/1000 (ID: req_304)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 306: relative_arrival=6.047, absolute_arrival=2069489.214, current_time=2069489.161, wait_time=0.053
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 306/1000 (ID: req_305)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 307: relative_arrival=6.057, absolute_arrival=2069489.224, current_time=2069489.214, wait_time=0.009
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 307/1000 (ID: req_306)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 308: relative_arrival=6.059, absolute_arrival=2069489.226, current_time=2069489.225, wait_time=0.001
[2025-07-25 00:04:07] [__main__] [INFO] Sending request 308/1000 (ID: req_307)
[2025-07-25 00:04:07] [__main__] [DEBUG] Request 309: relative_arrival=6.078, absolute_arrival=2069489.245, current_time=2069489.227, wait_time=0.018
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 309/1000 (ID: req_308)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 310: relative_arrival=6.081, absolute_arrival=2069489.247, current_time=2069489.246, wait_time=0.002
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 310/1000 (ID: req_309)
[2025-07-25 00:04:08] [__main__] [INFO] Progress: 310/1000 requests sent in 6.1s
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 311: relative_arrival=6.089, absolute_arrival=2069489.256, current_time=2069489.248, wait_time=0.008
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 311/1000 (ID: req_310)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 312: relative_arrival=6.103, absolute_arrival=2069489.270, current_time=2069489.257, wait_time=0.013
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 312/1000 (ID: req_311)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 313: relative_arrival=6.145, absolute_arrival=2069489.311, current_time=2069489.271, wait_time=0.041
[2025-07-25 00:04:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:08] Decode batch. #running-req: 20, #token: 6567, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1165.19, #queue-req: 0,
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 313/1000 (ID: req_312)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 314: relative_arrival=6.158, absolute_arrival=2069489.325, current_time=2069489.312, wait_time=0.013
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 314/1000 (ID: req_313)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 315: relative_arrival=6.183, absolute_arrival=2069489.349, current_time=2069489.326, wait_time=0.023
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 315/1000 (ID: req_314)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 316: relative_arrival=6.281, absolute_arrival=2069489.448, current_time=2069489.352, wait_time=0.096
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_43 received DONE after 145 chunks
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_43 completed: 146 chars, 145 chunks, TTFT=79.3ms
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_65 to http://localhost:30000/generate at 1753373048.1710176
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_65 with payload: {'text': 'Random prompt 65 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:08] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_65
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_65
[2025-07-25 00:04:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:08] Prefill batch. #new-seq: 1, #new-token: 264, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 316/1000 (ID: req_315)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 317: relative_arrival=6.284, absolute_arrival=2069489.451, current_time=2069489.449, wait_time=0.002
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 317/1000 (ID: req_316)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 318: relative_arrival=6.291, absolute_arrival=2069489.457, current_time=2069489.451, wait_time=0.006
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 318/1000 (ID: req_317)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 319: relative_arrival=6.301, absolute_arrival=2069489.467, current_time=2069489.458, wait_time=0.009
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 319/1000 (ID: req_318)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 320: relative_arrival=6.312, absolute_arrival=2069489.478, current_time=2069489.468, wait_time=0.010
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 320/1000 (ID: req_319)
[2025-07-25 00:04:08] [__main__] [INFO] Progress: 320/1000 requests sent in 6.3s
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 321: relative_arrival=6.322, absolute_arrival=2069489.489, current_time=2069489.479, wait_time=0.010
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 321/1000 (ID: req_320)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 322: relative_arrival=6.370, absolute_arrival=2069489.536, current_time=2069489.490, wait_time=0.047
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 322/1000 (ID: req_321)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 323: relative_arrival=6.395, absolute_arrival=2069489.561, current_time=2069489.538, wait_time=0.024
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 323/1000 (ID: req_322)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 324: relative_arrival=6.414, absolute_arrival=2069489.580, current_time=2069489.562, wait_time=0.018
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 324/1000 (ID: req_323)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 325: relative_arrival=6.421, absolute_arrival=2069489.588, current_time=2069489.581, wait_time=0.006
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 325/1000 (ID: req_324)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 326: relative_arrival=6.456, absolute_arrival=2069489.622, current_time=2069489.588, wait_time=0.034
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 326/1000 (ID: req_325)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 327: relative_arrival=6.518, absolute_arrival=2069489.684, current_time=2069489.623, wait_time=0.061
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 327/1000 (ID: req_326)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 328: relative_arrival=6.552, absolute_arrival=2069489.719, current_time=2069489.685, wait_time=0.034
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_41 received DONE after 166 chunks
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_41 completed: 650 chars, 166 chunks, TTFT=87.0ms
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_66 to http://localhost:30000/generate at 1753373048.452643
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_66 with payload: {'text': 'Random prompt 66 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 95, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:08] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_66
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_66
[2025-07-25 00:04:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:08] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_45 received DONE after 144 chunks
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_45 completed: 547 chars, 144 chunks, TTFT=70.1ms
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_67 to http://localhost:30000/generate at 1753373048.4665713
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_67 with payload: {'text': 'Random prompt 67 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:08] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_67
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_67
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 328/1000 (ID: req_327)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 329: relative_arrival=6.552, absolute_arrival=2069489.719, current_time=2069489.720, wait_time=-0.001
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 329/1000 (ID: req_328)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 330: relative_arrival=6.573, absolute_arrival=2069489.739, current_time=2069489.720, wait_time=0.019
[2025-07-25 00:04:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:08] Prefill batch. #new-seq: 1, #new-token: 330, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 330/1000 (ID: req_329)
[2025-07-25 00:04:08] [__main__] [INFO] Progress: 330/1000 requests sent in 6.6s
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 331: relative_arrival=6.574, absolute_arrival=2069489.740, current_time=2069489.740, wait_time=-0.000
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 331/1000 (ID: req_330)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 332: relative_arrival=6.580, absolute_arrival=2069489.746, current_time=2069489.740, wait_time=0.006
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 332/1000 (ID: req_331)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 333: relative_arrival=6.581, absolute_arrival=2069489.747, current_time=2069489.747, wait_time=0.000
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 333/1000 (ID: req_332)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 334: relative_arrival=6.599, absolute_arrival=2069489.766, current_time=2069489.748, wait_time=0.018
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 334/1000 (ID: req_333)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 335: relative_arrival=6.622, absolute_arrival=2069489.789, current_time=2069489.766, wait_time=0.023
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 335/1000 (ID: req_334)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 336: relative_arrival=6.625, absolute_arrival=2069489.791, current_time=2069489.790, wait_time=0.002
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 336/1000 (ID: req_335)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 337: relative_arrival=6.635, absolute_arrival=2069489.801, current_time=2069489.792, wait_time=0.009
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 337/1000 (ID: req_336)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 338: relative_arrival=6.647, absolute_arrival=2069489.813, current_time=2069489.802, wait_time=0.011
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 338/1000 (ID: req_337)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 339: relative_arrival=6.656, absolute_arrival=2069489.823, current_time=2069489.814, wait_time=0.008
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 339/1000 (ID: req_338)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 340: relative_arrival=6.659, absolute_arrival=2069489.825, current_time=2069489.823, wait_time=0.002
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 340/1000 (ID: req_339)
[2025-07-25 00:04:08] [__main__] [INFO] Progress: 340/1000 requests sent in 6.7s
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 341: relative_arrival=6.669, absolute_arrival=2069489.836, current_time=2069489.826, wait_time=0.010
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 341/1000 (ID: req_340)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 342: relative_arrival=6.697, absolute_arrival=2069489.864, current_time=2069489.837, wait_time=0.027
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 342/1000 (ID: req_341)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 343: relative_arrival=6.699, absolute_arrival=2069489.865, current_time=2069489.865, wait_time=0.000
[2025-07-25 00:04:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:08] Decode batch. #running-req: 20, #token: 6762, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1402.45, #queue-req: 0,
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 343/1000 (ID: req_342)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 344: relative_arrival=6.700, absolute_arrival=2069489.867, current_time=2069489.866, wait_time=0.000
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 344/1000 (ID: req_343)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 345: relative_arrival=6.709, absolute_arrival=2069489.876, current_time=2069489.868, wait_time=0.008
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 345/1000 (ID: req_344)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 346: relative_arrival=6.766, absolute_arrival=2069489.933, current_time=2069489.876, wait_time=0.056
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 346/1000 (ID: req_345)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 347: relative_arrival=6.788, absolute_arrival=2069489.955, current_time=2069489.933, wait_time=0.021
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 347/1000 (ID: req_346)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 348: relative_arrival=6.811, absolute_arrival=2069489.977, current_time=2069489.955, wait_time=0.022
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 348/1000 (ID: req_347)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 349: relative_arrival=6.820, absolute_arrival=2069489.986, current_time=2069489.978, wait_time=0.008
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 349/1000 (ID: req_348)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 350: relative_arrival=6.838, absolute_arrival=2069490.004, current_time=2069489.987, wait_time=0.017
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 350/1000 (ID: req_349)
[2025-07-25 00:04:08] [__main__] [INFO] Progress: 350/1000 requests sent in 6.8s
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 351: relative_arrival=6.838, absolute_arrival=2069490.005, current_time=2069490.005, wait_time=-0.001
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 351/1000 (ID: req_350)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 352: relative_arrival=6.858, absolute_arrival=2069490.025, current_time=2069490.005, wait_time=0.019
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_51 received DONE after 133 chunks
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_51 completed: 511 chars, 133 chunks, TTFT=57.1ms
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_68 to http://localhost:30000/generate at 1753373048.7766783
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_68 with payload: {'text': 'Random prompt 68 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:08] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_68
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_68
[2025-07-25 00:04:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:08] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 352/1000 (ID: req_351)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 353: relative_arrival=6.907, absolute_arrival=2069490.074, current_time=2069490.026, wait_time=0.048
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_55 received DONE after 110 chunks
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_55 completed: 311 chars, 110 chunks, TTFT=59.2ms
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_69 to http://localhost:30000/generate at 1753373048.7905421
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_69 with payload: {'text': 'Random prompt 69 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 101, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:08] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_69
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_69
[2025-07-25 00:04:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:08] Prefill batch. #new-seq: 1, #new-token: 378, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 353/1000 (ID: req_352)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 354: relative_arrival=6.926, absolute_arrival=2069490.093, current_time=2069490.075, wait_time=0.018
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 354/1000 (ID: req_353)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 355: relative_arrival=6.967, absolute_arrival=2069490.134, current_time=2069490.094, wait_time=0.040
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 355/1000 (ID: req_354)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 356: relative_arrival=6.993, absolute_arrival=2069490.160, current_time=2069490.136, wait_time=0.024
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 356/1000 (ID: req_355)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 357: relative_arrival=6.996, absolute_arrival=2069490.162, current_time=2069490.161, wait_time=0.001
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 357/1000 (ID: req_356)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 358: relative_arrival=7.042, absolute_arrival=2069490.209, current_time=2069490.163, wait_time=0.045
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_44 received DONE after 178 chunks
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_44 completed: 708 chars, 178 chunks, TTFT=44.7ms
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_70 to http://localhost:30000/generate at 1753373048.9570754
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_70 with payload: {'text': 'Random prompt 70 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 102, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:08] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_70
[2025-07-25 00:04:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_70
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 358/1000 (ID: req_357)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 359: relative_arrival=7.044, absolute_arrival=2069490.210, current_time=2069490.210, wait_time=0.000
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 359/1000 (ID: req_358)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 360: relative_arrival=7.059, absolute_arrival=2069490.225, current_time=2069490.211, wait_time=0.014
[2025-07-25 00:04:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:08] Prefill batch. #new-seq: 1, #new-token: 323, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 360/1000 (ID: req_359)
[2025-07-25 00:04:08] [__main__] [INFO] Progress: 360/1000 requests sent in 7.1s
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 361: relative_arrival=7.062, absolute_arrival=2069490.229, current_time=2069490.226, wait_time=0.002
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 361/1000 (ID: req_360)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 362: relative_arrival=7.062, absolute_arrival=2069490.229, current_time=2069490.229, wait_time=-0.001
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 362/1000 (ID: req_361)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 363: relative_arrival=7.073, absolute_arrival=2069490.240, current_time=2069490.229, wait_time=0.010
[2025-07-25 00:04:08] [__main__] [INFO] Sending request 363/1000 (ID: req_362)
[2025-07-25 00:04:08] [__main__] [DEBUG] Request 364: relative_arrival=7.080, absolute_arrival=2069490.247, current_time=2069490.241, wait_time=0.006
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 364/1000 (ID: req_363)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 365: relative_arrival=7.094, absolute_arrival=2069490.260, current_time=2069490.248, wait_time=0.012
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 365/1000 (ID: req_364)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 366: relative_arrival=7.111, absolute_arrival=2069490.277, current_time=2069490.261, wait_time=0.016
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 366/1000 (ID: req_365)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 367: relative_arrival=7.112, absolute_arrival=2069490.278, current_time=2069490.278, wait_time=-0.000
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 367/1000 (ID: req_366)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 368: relative_arrival=7.114, absolute_arrival=2069490.281, current_time=2069490.279, wait_time=0.002
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 368/1000 (ID: req_367)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 369: relative_arrival=7.131, absolute_arrival=2069490.297, current_time=2069490.281, wait_time=0.016
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 369/1000 (ID: req_368)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 370: relative_arrival=7.139, absolute_arrival=2069490.306, current_time=2069490.299, wait_time=0.006
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 370/1000 (ID: req_369)
[2025-07-25 00:04:09] [__main__] [INFO] Progress: 370/1000 requests sent in 7.1s
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 371: relative_arrival=7.165, absolute_arrival=2069490.332, current_time=2069490.307, wait_time=0.025
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_48 received DONE after 176 chunks
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_48 completed: 700 chars, 176 chunks, TTFT=62.5ms
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_71 to http://localhost:30000/generate at 1753373049.0704415
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_71 with payload: {'text': 'Random prompt 71 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_71
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_71
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 371/1000 (ID: req_370)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 372: relative_arrival=7.186, absolute_arrival=2069490.353, current_time=2069490.334, wait_time=0.019
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 372/1000 (ID: req_371)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 373: relative_arrival=7.224, absolute_arrival=2069490.390, current_time=2069490.353, wait_time=0.037
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 373/1000 (ID: req_372)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 374: relative_arrival=7.247, absolute_arrival=2069490.414, current_time=2069490.391, wait_time=0.023
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_57 received DONE after 116 chunks
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_57 completed: 460 chars, 116 chunks, TTFT=46.1ms
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_72 to http://localhost:30000/generate at 1753373049.166456
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_72 with payload: {'text': 'Random prompt 72 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_72
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_72
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 374/1000 (ID: req_373)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 375: relative_arrival=7.258, absolute_arrival=2069490.425, current_time=2069490.414, wait_time=0.011
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 375/1000 (ID: req_374)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 376: relative_arrival=7.281, absolute_arrival=2069490.447, current_time=2069490.426, wait_time=0.022
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 376/1000 (ID: req_375)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 377: relative_arrival=7.287, absolute_arrival=2069490.454, current_time=2069490.448, wait_time=0.006
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 377/1000 (ID: req_376)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 378: relative_arrival=7.295, absolute_arrival=2069490.461, current_time=2069490.454, wait_time=0.007
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 378/1000 (ID: req_377)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 379: relative_arrival=7.326, absolute_arrival=2069490.492, current_time=2069490.462, wait_time=0.031
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] Decode batch. #running-req: 20, #token: 6681, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1283.48, #queue-req: 0,
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 379/1000 (ID: req_378)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 380: relative_arrival=7.338, absolute_arrival=2069490.504, current_time=2069490.493, wait_time=0.011
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 380/1000 (ID: req_379)
[2025-07-25 00:04:09] [__main__] [INFO] Progress: 380/1000 requests sent in 7.3s
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 381: relative_arrival=7.370, absolute_arrival=2069490.536, current_time=2069490.505, wait_time=0.031
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 381/1000 (ID: req_380)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 382: relative_arrival=7.404, absolute_arrival=2069490.571, current_time=2069490.537, wait_time=0.034
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 382/1000 (ID: req_381)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 383: relative_arrival=7.443, absolute_arrival=2069490.610, current_time=2069490.571, wait_time=0.038
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_58 received DONE after 126 chunks
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_58 completed: 497 chars, 126 chunks, TTFT=46.8ms
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_73 to http://localhost:30000/generate at 1753373049.3346014
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_73 with payload: {'text': 'Random prompt 73 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 66, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_73
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_73
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 5, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 383/1000 (ID: req_382)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 384: relative_arrival=7.493, absolute_arrival=2069490.659, current_time=2069490.611, wait_time=0.049
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 384/1000 (ID: req_383)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 385: relative_arrival=7.504, absolute_arrival=2069490.671, current_time=2069490.660, wait_time=0.011
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 385/1000 (ID: req_384)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 386: relative_arrival=7.512, absolute_arrival=2069490.678, current_time=2069490.671, wait_time=0.007
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 386/1000 (ID: req_385)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 387: relative_arrival=7.529, absolute_arrival=2069490.696, current_time=2069490.680, wait_time=0.016
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_50 received DONE after 177 chunks
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_50 completed: 704 chars, 177 chunks, TTFT=63.5ms
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_74 to http://localhost:30000/generate at 1753373049.4479845
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_74 with payload: {'text': 'Random prompt 74 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_74
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_74
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 387/1000 (ID: req_386)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 388: relative_arrival=7.539, absolute_arrival=2069490.705, current_time=2069490.696, wait_time=0.009
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] Prefill batch. #new-seq: 1, #new-token: 306, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 388/1000 (ID: req_387)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 389: relative_arrival=7.557, absolute_arrival=2069490.723, current_time=2069490.706, wait_time=0.018
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 389/1000 (ID: req_388)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 390: relative_arrival=7.581, absolute_arrival=2069490.748, current_time=2069490.725, wait_time=0.023
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 390/1000 (ID: req_389)
[2025-07-25 00:04:09] [__main__] [INFO] Progress: 390/1000 requests sent in 7.6s
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 391: relative_arrival=7.605, absolute_arrival=2069490.771, current_time=2069490.749, wait_time=0.022
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_63 received DONE after 118 chunks
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_63 completed: 468 chars, 118 chunks, TTFT=70.8ms
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_75 to http://localhost:30000/generate at 1753373049.5150638
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_75 with payload: {'text': 'Random prompt 75 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_75
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_75
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 391/1000 (ID: req_390)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 392: relative_arrival=7.614, absolute_arrival=2069490.781, current_time=2069490.773, wait_time=0.008
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] Prefill batch. #new-seq: 1, #new-token: 312, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_53 received DONE after 167 chunks
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_53 completed: 755 chars, 167 chunks, TTFT=60.1ms
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_76 to http://localhost:30000/generate at 1753373049.5376244
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_76 with payload: {'text': 'Random prompt 76 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 113, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 392/1000 (ID: req_391)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 393: relative_arrival=7.618, absolute_arrival=2069490.784, current_time=2069490.781, wait_time=0.003
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_76
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_76
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 393/1000 (ID: req_392)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 394: relative_arrival=7.629, absolute_arrival=2069490.795, current_time=2069490.785, wait_time=0.011
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 394/1000 (ID: req_393)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 395: relative_arrival=7.632, absolute_arrival=2069490.799, current_time=2069490.796, wait_time=0.003
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 395/1000 (ID: req_394)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 396: relative_arrival=7.676, absolute_arrival=2069490.843, current_time=2069490.799, wait_time=0.044
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] Prefill batch. #new-seq: 1, #new-token: 323, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 396/1000 (ID: req_395)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 397: relative_arrival=7.685, absolute_arrival=2069490.851, current_time=2069490.843, wait_time=0.008
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 397/1000 (ID: req_396)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 398: relative_arrival=7.688, absolute_arrival=2069490.855, current_time=2069490.852, wait_time=0.002
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 398/1000 (ID: req_397)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 399: relative_arrival=7.689, absolute_arrival=2069490.855, current_time=2069490.856, wait_time=-0.001
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 399/1000 (ID: req_398)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 400: relative_arrival=7.709, absolute_arrival=2069490.876, current_time=2069490.856, wait_time=0.020
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_64 received DONE after 119 chunks
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_64 completed: 463 chars, 119 chunks, TTFT=55.3ms
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_77 to http://localhost:30000/generate at 1753373049.6359289
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_77 with payload: {'text': 'Random prompt 77 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 400/1000 (ID: req_399)
[2025-07-25 00:04:09] [__main__] [INFO] Progress: 400/1000 requests sent in 7.7s
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 401: relative_arrival=7.730, absolute_arrival=2069490.896, current_time=2069490.880, wait_time=0.016
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_77
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_77
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 401/1000 (ID: req_400)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 402: relative_arrival=7.738, absolute_arrival=2069490.904, current_time=2069490.898, wait_time=0.006
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 402/1000 (ID: req_401)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 403: relative_arrival=7.739, absolute_arrival=2069490.906, current_time=2069490.906, wait_time=0.000
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 403/1000 (ID: req_402)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 404: relative_arrival=7.750, absolute_arrival=2069490.916, current_time=2069490.907, wait_time=0.009
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 404/1000 (ID: req_403)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 405: relative_arrival=7.757, absolute_arrival=2069490.924, current_time=2069490.918, wait_time=0.006
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 405/1000 (ID: req_404)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 406: relative_arrival=7.780, absolute_arrival=2069490.947, current_time=2069490.925, wait_time=0.022
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 406/1000 (ID: req_405)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 407: relative_arrival=7.799, absolute_arrival=2069490.965, current_time=2069490.948, wait_time=0.018
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 407/1000 (ID: req_406)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 408: relative_arrival=7.808, absolute_arrival=2069490.974, current_time=2069490.966, wait_time=0.008
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 408/1000 (ID: req_407)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 409: relative_arrival=7.813, absolute_arrival=2069490.979, current_time=2069490.975, wait_time=0.004
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 409/1000 (ID: req_408)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 410: relative_arrival=7.901, absolute_arrival=2069491.068, current_time=2069490.980, wait_time=0.087
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_67 received DONE after 79 chunks
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_67 completed: 312 chars, 79 chunks, TTFT=60.9ms
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_78 to http://localhost:30000/generate at 1753373049.7426307
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_78 with payload: {'text': 'Random prompt 78 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_78
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_78
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] Prefill batch. #new-seq: 1, #new-token: 217, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_59 received DONE after 145 chunks
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_59 completed: 576 chars, 145 chunks, TTFT=77.6ms
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_56 received DONE after 163 chunks
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_56 completed: 638 chars, 163 chunks, TTFT=45.0ms
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_79 to http://localhost:30000/generate at 1753373049.7557642
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_79 with payload: {'text': 'Random prompt 79 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_80 to http://localhost:30000/generate at 1753373049.7564824
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_80 with payload: {'text': 'Random prompt 80 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_79
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_79
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_80
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_80
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] Prefill batch. #new-seq: 2, #new-token: 501, #cached-token: 10, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 410/1000 (ID: req_409)
[2025-07-25 00:04:09] [__main__] [INFO] Progress: 410/1000 requests sent in 7.9s
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 411: relative_arrival=7.913, absolute_arrival=2069491.080, current_time=2069491.068, wait_time=0.011
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_52 received DONE after 185 chunks
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_52 completed: 184 chars, 185 chunks, TTFT=60.3ms
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 411/1000 (ID: req_410)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 412: relative_arrival=7.937, absolute_arrival=2069491.103, current_time=2069491.082, wait_time=0.021
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_81 to http://localhost:30000/generate at 1753373049.8406901
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_81 with payload: {'text': 'Random prompt 81 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_81
[2025-07-25 00:04:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_81
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] Prefill batch. #new-seq: 1, #new-token: 285, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 412/1000 (ID: req_411)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 413: relative_arrival=7.940, absolute_arrival=2069491.106, current_time=2069491.104, wait_time=0.002
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 413/1000 (ID: req_412)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 414: relative_arrival=7.953, absolute_arrival=2069491.119, current_time=2069491.107, wait_time=0.012
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 414/1000 (ID: req_413)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 415: relative_arrival=7.953, absolute_arrival=2069491.120, current_time=2069491.122, wait_time=-0.002
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 415/1000 (ID: req_414)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 416: relative_arrival=7.968, absolute_arrival=2069491.134, current_time=2069491.122, wait_time=0.012
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 416/1000 (ID: req_415)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 417: relative_arrival=8.034, absolute_arrival=2069491.201, current_time=2069491.135, wait_time=0.066
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 417/1000 (ID: req_416)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 418: relative_arrival=8.044, absolute_arrival=2069491.210, current_time=2069491.201, wait_time=0.009
[2025-07-25 00:04:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:09] Decode batch. #running-req: 20, #token: 6296, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1100.19, #queue-req: 0,
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 418/1000 (ID: req_417)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 419: relative_arrival=8.044, absolute_arrival=2069491.211, current_time=2069491.211, wait_time=-0.000
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 419/1000 (ID: req_418)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 420: relative_arrival=8.045, absolute_arrival=2069491.212, current_time=2069491.211, wait_time=0.000
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 420/1000 (ID: req_419)
[2025-07-25 00:04:09] [__main__] [INFO] Progress: 420/1000 requests sent in 8.0s
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 421: relative_arrival=8.055, absolute_arrival=2069491.221, current_time=2069491.213, wait_time=0.009
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 421/1000 (ID: req_420)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 422: relative_arrival=8.058, absolute_arrival=2069491.225, current_time=2069491.222, wait_time=0.003
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 422/1000 (ID: req_421)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 423: relative_arrival=8.059, absolute_arrival=2069491.225, current_time=2069491.225, wait_time=0.000
[2025-07-25 00:04:09] [__main__] [INFO] Sending request 423/1000 (ID: req_422)
[2025-07-25 00:04:09] [__main__] [DEBUG] Request 424: relative_arrival=8.087, absolute_arrival=2069491.254, current_time=2069491.226, wait_time=0.028
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 424/1000 (ID: req_423)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 425: relative_arrival=8.099, absolute_arrival=2069491.266, current_time=2069491.256, wait_time=0.010
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 425/1000 (ID: req_424)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 426: relative_arrival=8.106, absolute_arrival=2069491.273, current_time=2069491.268, wait_time=0.005
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 426/1000 (ID: req_425)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 427: relative_arrival=8.152, absolute_arrival=2069491.319, current_time=2069491.273, wait_time=0.045
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_66 received DONE after 96 chunks
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_66 completed: 370 chars, 96 chunks, TTFT=66.6ms
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_82 to http://localhost:30000/generate at 1753373050.0405414
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_82 with payload: {'text': 'Random prompt 82 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_82
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_82
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] Prefill batch. #new-seq: 1, #new-token: 210, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 427/1000 (ID: req_426)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 428: relative_arrival=8.155, absolute_arrival=2069491.321, current_time=2069491.321, wait_time=0.000
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 428/1000 (ID: req_427)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 429: relative_arrival=8.217, absolute_arrival=2069491.384, current_time=2069491.322, wait_time=0.061
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_54 received DONE after 193 chunks
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_54 completed: 761 chars, 193 chunks, TTFT=59.0ms
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_83 to http://localhost:30000/generate at 1753373050.1010203
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_83 with payload: {'text': 'Random prompt 83 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_83
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_83
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 429/1000 (ID: req_428)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 430: relative_arrival=8.225, absolute_arrival=2069491.391, current_time=2069491.386, wait_time=0.005
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 430/1000 (ID: req_429)
[2025-07-25 00:04:10] [__main__] [INFO] Progress: 430/1000 requests sent in 8.2s
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 431: relative_arrival=8.269, absolute_arrival=2069491.435, current_time=2069491.393, wait_time=0.043
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 431/1000 (ID: req_430)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 432: relative_arrival=8.287, absolute_arrival=2069491.454, current_time=2069491.436, wait_time=0.018
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 432/1000 (ID: req_431)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 433: relative_arrival=8.322, absolute_arrival=2069491.489, current_time=2069491.455, wait_time=0.034
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 433/1000 (ID: req_432)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 434: relative_arrival=8.405, absolute_arrival=2069491.571, current_time=2069491.490, wait_time=0.082
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_60 received DONE after 177 chunks
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_60 completed: 648 chars, 177 chunks, TTFT=56.9ms
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_62 received DONE after 163 chunks
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_62 completed: 648 chars, 163 chunks, TTFT=80.4ms
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_84 to http://localhost:30000/generate at 1753373050.279129
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_84 with payload: {'text': 'Random prompt 84 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_85 to http://localhost:30000/generate at 1753373050.2798824
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_85 with payload: {'text': 'Random prompt 85 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 124, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_84
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_84
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_85
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_85
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] Prefill batch. #new-seq: 2, #new-token: 413, #cached-token: 10, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 434/1000 (ID: req_433)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 435: relative_arrival=8.412, absolute_arrival=2069491.578, current_time=2069491.573, wait_time=0.006
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_72 received DONE after 70 chunks
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_72 completed: 71 chars, 70 chunks, TTFT=43.6ms
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_86 to http://localhost:30000/generate at 1753373050.3345459
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_86 with payload: {'text': 'Random prompt 86 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 435/1000 (ID: req_434)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 436: relative_arrival=8.477, absolute_arrival=2069491.643, current_time=2069491.579, wait_time=0.064
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_86
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_86
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] Prefill batch. #new-seq: 1, #new-token: 312, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 436/1000 (ID: req_435)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 437: relative_arrival=8.486, absolute_arrival=2069491.653, current_time=2069491.644, wait_time=0.009
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 437/1000 (ID: req_436)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 438: relative_arrival=8.496, absolute_arrival=2069491.663, current_time=2069491.655, wait_time=0.008
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 438/1000 (ID: req_437)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 439: relative_arrival=8.505, absolute_arrival=2069491.671, current_time=2069491.664, wait_time=0.007
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 439/1000 (ID: req_438)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 440: relative_arrival=8.520, absolute_arrival=2069491.687, current_time=2069491.672, wait_time=0.015
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 440/1000 (ID: req_439)
[2025-07-25 00:04:10] [__main__] [INFO] Progress: 440/1000 requests sent in 8.5s
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 441: relative_arrival=8.523, absolute_arrival=2069491.690, current_time=2069491.687, wait_time=0.003
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 441/1000 (ID: req_440)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 442: relative_arrival=8.540, absolute_arrival=2069491.706, current_time=2069491.691, wait_time=0.015
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 442/1000 (ID: req_441)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 443: relative_arrival=8.555, absolute_arrival=2069491.722, current_time=2069491.707, wait_time=0.015
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 443/1000 (ID: req_442)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 444: relative_arrival=8.584, absolute_arrival=2069491.750, current_time=2069491.723, wait_time=0.027
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_69 received DONE after 102 chunks
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_69 completed: 103 chars, 102 chunks, TTFT=61.7ms
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_87 to http://localhost:30000/generate at 1753373050.4905534
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_87 with payload: {'text': 'Random prompt 87 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_87
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_87
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_73 received DONE after 67 chunks
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_73 completed: 68 chars, 67 chunks, TTFT=58.8ms
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_88 to http://localhost:30000/generate at 1753373050.502534
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_88 with payload: {'text': 'Random prompt 88 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_88
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_88
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] Prefill batch. #new-seq: 1, #new-token: 288, #cached-token: 5, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 444/1000 (ID: req_443)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 445: relative_arrival=8.620, absolute_arrival=2069491.786, current_time=2069491.751, wait_time=0.035
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] Prefill batch. #new-seq: 1, #new-token: 352, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 445/1000 (ID: req_444)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 446: relative_arrival=8.631, absolute_arrival=2069491.798, current_time=2069491.787, wait_time=0.011
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 446/1000 (ID: req_445)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 447: relative_arrival=8.639, absolute_arrival=2069491.805, current_time=2069491.799, wait_time=0.006
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 447/1000 (ID: req_446)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 448: relative_arrival=8.645, absolute_arrival=2069491.811, current_time=2069491.806, wait_time=0.005
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 448/1000 (ID: req_447)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 449: relative_arrival=8.649, absolute_arrival=2069491.815, current_time=2069491.812, wait_time=0.003
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 449/1000 (ID: req_448)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 450: relative_arrival=8.650, absolute_arrival=2069491.817, current_time=2069491.817, wait_time=-0.000
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 450/1000 (ID: req_449)
[2025-07-25 00:04:10] [__main__] [INFO] Progress: 450/1000 requests sent in 8.7s
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 451: relative_arrival=8.659, absolute_arrival=2069491.825, current_time=2069491.817, wait_time=0.008
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 451/1000 (ID: req_450)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 452: relative_arrival=8.665, absolute_arrival=2069491.831, current_time=2069491.826, wait_time=0.005
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 452/1000 (ID: req_451)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 453: relative_arrival=8.733, absolute_arrival=2069491.899, current_time=2069491.833, wait_time=0.066
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] Decode batch. #running-req: 20, #token: 6101, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1212.43, #queue-req: 0,
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_61 received DONE after 191 chunks
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_61 completed: 751 chars, 191 chunks, TTFT=55.9ms
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_89 to http://localhost:30000/generate at 1753373050.6428037
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_89 with payload: {'text': 'Random prompt 89 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_68 received DONE after 110 chunks
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_68 completed: 427 chars, 110 chunks, TTFT=66.8ms
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_90 to http://localhost:30000/generate at 1753373050.643698
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_90 with payload: {'text': 'Random prompt 90 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_89
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_89
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 5, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_90
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_90
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 453/1000 (ID: req_452)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 454: relative_arrival=8.749, absolute_arrival=2069491.916, current_time=2069491.900, wait_time=0.015
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 454/1000 (ID: req_453)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 455: relative_arrival=8.758, absolute_arrival=2069491.924, current_time=2069491.917, wait_time=0.007
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 455/1000 (ID: req_454)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 456: relative_arrival=8.775, absolute_arrival=2069491.941, current_time=2069491.925, wait_time=0.016
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_71 received DONE after 95 chunks
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_71 completed: 308 chars, 95 chunks, TTFT=43.5ms
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_91 to http://localhost:30000/generate at 1753373050.6898036
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_91 with payload: {'text': 'Random prompt 91 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_91
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_91
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 456/1000 (ID: req_455)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 457: relative_arrival=8.778, absolute_arrival=2069491.944, current_time=2069491.942, wait_time=0.002
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 457/1000 (ID: req_456)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 458: relative_arrival=8.790, absolute_arrival=2069491.956, current_time=2069491.945, wait_time=0.011
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] Prefill batch. #new-seq: 1, #new-token: 308, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 458/1000 (ID: req_457)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 459: relative_arrival=8.809, absolute_arrival=2069491.976, current_time=2069491.957, wait_time=0.019
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 459/1000 (ID: req_458)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 460: relative_arrival=8.823, absolute_arrival=2069491.989, current_time=2069491.977, wait_time=0.013
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 460/1000 (ID: req_459)
[2025-07-25 00:04:10] [__main__] [INFO] Progress: 460/1000 requests sent in 8.8s
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 461: relative_arrival=8.833, absolute_arrival=2069492.000, current_time=2069491.990, wait_time=0.009
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 461/1000 (ID: req_460)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 462: relative_arrival=8.935, absolute_arrival=2069492.101, current_time=2069492.000, wait_time=0.101
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_70 received DONE after 103 chunks
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_70 completed: 104 chars, 103 chunks, TTFT=58.2ms
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_92 to http://localhost:30000/generate at 1753373050.7732375
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_92 with payload: {'text': 'Random prompt 92 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_92
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_92
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] Prefill batch. #new-seq: 1, #new-token: 320, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_65 received DONE after 159 chunks
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_65 completed: 630 chars, 159 chunks, TTFT=57.8ms
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_93 to http://localhost:30000/generate at 1753373050.8294117
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_93 with payload: {'text': 'Random prompt 93 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_93
[2025-07-25 00:04:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_93
[2025-07-25 00:04:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:10] Prefill batch. #new-seq: 1, #new-token: 269, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 462/1000 (ID: req_461)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 463: relative_arrival=8.977, absolute_arrival=2069492.144, current_time=2069492.102, wait_time=0.041
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 463/1000 (ID: req_462)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 464: relative_arrival=8.997, absolute_arrival=2069492.163, current_time=2069492.145, wait_time=0.018
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 464/1000 (ID: req_463)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 465: relative_arrival=9.014, absolute_arrival=2069492.180, current_time=2069492.164, wait_time=0.016
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 465/1000 (ID: req_464)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 466: relative_arrival=9.033, absolute_arrival=2069492.200, current_time=2069492.182, wait_time=0.018
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 466/1000 (ID: req_465)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 467: relative_arrival=9.038, absolute_arrival=2069492.204, current_time=2069492.202, wait_time=0.003
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 467/1000 (ID: req_466)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 468: relative_arrival=9.048, absolute_arrival=2069492.214, current_time=2069492.205, wait_time=0.009
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 468/1000 (ID: req_467)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 469: relative_arrival=9.048, absolute_arrival=2069492.215, current_time=2069492.215, wait_time=-0.000
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 469/1000 (ID: req_468)
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 470: relative_arrival=9.061, absolute_arrival=2069492.228, current_time=2069492.216, wait_time=0.012
[2025-07-25 00:04:10] [__main__] [INFO] Sending request 470/1000 (ID: req_469)
[2025-07-25 00:04:10] [__main__] [INFO] Progress: 470/1000 requests sent in 9.1s
[2025-07-25 00:04:10] [__main__] [DEBUG] Request 471: relative_arrival=9.077, absolute_arrival=2069492.244, current_time=2069492.229, wait_time=0.014
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 471/1000 (ID: req_470)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 472: relative_arrival=9.082, absolute_arrival=2069492.249, current_time=2069492.245, wait_time=0.004
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 472/1000 (ID: req_471)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 473: relative_arrival=9.149, absolute_arrival=2069492.315, current_time=2069492.250, wait_time=0.065
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 473/1000 (ID: req_472)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 474: relative_arrival=9.197, absolute_arrival=2069492.363, current_time=2069492.316, wait_time=0.047
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_81 received DONE after 76 chunks
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_81 completed: 291 chars, 76 chunks, TTFT=50.0ms
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_94 to http://localhost:30000/generate at 1753373051.0934527
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_94 with payload: {'text': 'Random prompt 94 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:11] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_94
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_94
[2025-07-25 00:04:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:11] Prefill batch. #new-seq: 1, #new-token: 322, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 474/1000 (ID: req_473)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 475: relative_arrival=9.222, absolute_arrival=2069492.389, current_time=2069492.365, wait_time=0.024
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 475/1000 (ID: req_474)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 476: relative_arrival=9.238, absolute_arrival=2069492.404, current_time=2069492.390, wait_time=0.014
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 476/1000 (ID: req_475)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 477: relative_arrival=9.278, absolute_arrival=2069492.445, current_time=2069492.405, wait_time=0.040
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 477/1000 (ID: req_476)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 478: relative_arrival=9.281, absolute_arrival=2069492.448, current_time=2069492.448, wait_time=-0.000
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 478/1000 (ID: req_477)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 479: relative_arrival=9.312, absolute_arrival=2069492.479, current_time=2069492.448, wait_time=0.031
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 479/1000 (ID: req_478)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 480: relative_arrival=9.315, absolute_arrival=2069492.482, current_time=2069492.480, wait_time=0.002
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 480/1000 (ID: req_479)
[2025-07-25 00:04:11] [__main__] [INFO] Progress: 480/1000 requests sent in 9.3s
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 481: relative_arrival=9.347, absolute_arrival=2069492.513, current_time=2069492.482, wait_time=0.031
[2025-07-25 00:04:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:11] Decode batch. #running-req: 20, #token: 6401, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1227.40, #queue-req: 0,
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 481/1000 (ID: req_480)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 482: relative_arrival=9.353, absolute_arrival=2069492.520, current_time=2069492.514, wait_time=0.006
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 482/1000 (ID: req_481)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 483: relative_arrival=9.395, absolute_arrival=2069492.562, current_time=2069492.521, wait_time=0.041
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_78 received DONE after 93 chunks
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_78 completed: 358 chars, 93 chunks, TTFT=64.1ms
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_95 to http://localhost:30000/generate at 1753373051.28949
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_95 with payload: {'text': 'Random prompt 95 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:11] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_95
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_95
[2025-07-25 00:04:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:11] Prefill batch. #new-seq: 1, #new-token: 252, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 483/1000 (ID: req_482)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 484: relative_arrival=9.453, absolute_arrival=2069492.619, current_time=2069492.563, wait_time=0.057
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 484/1000 (ID: req_483)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 485: relative_arrival=9.456, absolute_arrival=2069492.622, current_time=2069492.620, wait_time=0.003
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 485/1000 (ID: req_484)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 486: relative_arrival=9.468, absolute_arrival=2069492.635, current_time=2069492.623, wait_time=0.012
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 486/1000 (ID: req_485)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 487: relative_arrival=9.548, absolute_arrival=2069492.714, current_time=2069492.637, wait_time=0.077
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_76 received DONE after 114 chunks
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_76 completed: 325 chars, 114 chunks, TTFT=66.5ms
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_96 to http://localhost:30000/generate at 1753373051.4338923
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_96 with payload: {'text': 'Random prompt 96 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:11] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_96
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_96
[2025-07-25 00:04:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:11] Prefill batch. #new-seq: 1, #new-token: 259, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 487/1000 (ID: req_486)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 488: relative_arrival=9.561, absolute_arrival=2069492.727, current_time=2069492.716, wait_time=0.011
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 488/1000 (ID: req_487)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 489: relative_arrival=9.601, absolute_arrival=2069492.767, current_time=2069492.729, wait_time=0.039
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 489/1000 (ID: req_488)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 490: relative_arrival=9.618, absolute_arrival=2069492.785, current_time=2069492.769, wait_time=0.016
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_75 received DONE after 120 chunks
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_75 completed: 343 chars, 120 chunks, TTFT=80.0ms
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_97 to http://localhost:30000/generate at 1753373051.5337987
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_97 with payload: {'text': 'Random prompt 97 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:11] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_97
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_97
[2025-07-25 00:04:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:11] Prefill batch. #new-seq: 1, #new-token: 235, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 490/1000 (ID: req_489)
[2025-07-25 00:04:11] [__main__] [INFO] Progress: 490/1000 requests sent in 9.6s
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 491: relative_arrival=9.628, absolute_arrival=2069492.794, current_time=2069492.787, wait_time=0.007
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 491/1000 (ID: req_490)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 492: relative_arrival=9.635, absolute_arrival=2069492.801, current_time=2069492.795, wait_time=0.006
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 492/1000 (ID: req_491)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 493: relative_arrival=9.639, absolute_arrival=2069492.806, current_time=2069492.802, wait_time=0.004
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 493/1000 (ID: req_492)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 494: relative_arrival=9.668, absolute_arrival=2069492.834, current_time=2069492.806, wait_time=0.028
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 494/1000 (ID: req_493)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 495: relative_arrival=9.678, absolute_arrival=2069492.844, current_time=2069492.835, wait_time=0.009
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 495/1000 (ID: req_494)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 496: relative_arrival=9.692, absolute_arrival=2069492.858, current_time=2069492.846, wait_time=0.013
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 496/1000 (ID: req_495)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 497: relative_arrival=9.705, absolute_arrival=2069492.872, current_time=2069492.859, wait_time=0.013
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 497/1000 (ID: req_496)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 498: relative_arrival=9.723, absolute_arrival=2069492.889, current_time=2069492.872, wait_time=0.017
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 498/1000 (ID: req_497)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 499: relative_arrival=9.763, absolute_arrival=2069492.929, current_time=2069492.891, wait_time=0.039
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 499/1000 (ID: req_498)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 500: relative_arrival=9.842, absolute_arrival=2069493.008, current_time=2069492.931, wait_time=0.077
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 500/1000 (ID: req_499)
[2025-07-25 00:04:11] [__main__] [INFO] Progress: 500/1000 requests sent in 9.8s
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 501: relative_arrival=9.852, absolute_arrival=2069493.019, current_time=2069493.010, wait_time=0.009
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 501/1000 (ID: req_500)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 502: relative_arrival=9.887, absolute_arrival=2069493.054, current_time=2069493.020, wait_time=0.034
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 502/1000 (ID: req_501)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 503: relative_arrival=9.916, absolute_arrival=2069493.083, current_time=2069493.055, wait_time=0.028
[2025-07-25 00:04:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:11] Decode batch. #running-req: 20, #token: 6767, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1428.96, #queue-req: 0,
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_87 received DONE after 86 chunks
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_87 completed: 340 chars, 86 chunks, TTFT=77.5ms
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_98 to http://localhost:30000/generate at 1753373051.8352244
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_98 with payload: {'text': 'Random prompt 98 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:11] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_98
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_98
[2025-07-25 00:04:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:11] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 503/1000 (ID: req_502)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 504: relative_arrival=9.933, absolute_arrival=2069493.100, current_time=2069493.084, wait_time=0.016
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 504/1000 (ID: req_503)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 505: relative_arrival=9.996, absolute_arrival=2069493.162, current_time=2069493.102, wait_time=0.060
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_82 received DONE after 118 chunks
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_82 completed: 458 chars, 118 chunks, TTFT=44.3ms
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_99 to http://localhost:30000/generate at 1753373051.8966784
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_99 with payload: {'text': 'Random prompt 99 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:11] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_99
[2025-07-25 00:04:11] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_99
[2025-07-25 00:04:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:11] Prefill batch. #new-seq: 1, #new-token: 153, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 505/1000 (ID: req_504)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 506: relative_arrival=10.000, absolute_arrival=2069493.167, current_time=2069493.164, wait_time=0.003
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 506/1000 (ID: req_505)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 507: relative_arrival=10.003, absolute_arrival=2069493.169, current_time=2069493.168, wait_time=0.002
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 507/1000 (ID: req_506)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 508: relative_arrival=10.041, absolute_arrival=2069493.208, current_time=2069493.170, wait_time=0.038
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 508/1000 (ID: req_507)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 509: relative_arrival=10.053, absolute_arrival=2069493.219, current_time=2069493.209, wait_time=0.010
[2025-07-25 00:04:11] [__main__] [INFO] Sending request 509/1000 (ID: req_508)
[2025-07-25 00:04:11] [__main__] [DEBUG] Request 510: relative_arrival=10.090, absolute_arrival=2069493.257, current_time=2069493.221, wait_time=0.036
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 510/1000 (ID: req_509)
[2025-07-25 00:04:12] [__main__] [INFO] Progress: 510/1000 requests sent in 10.1s
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 511: relative_arrival=10.135, absolute_arrival=2069493.302, current_time=2069493.258, wait_time=0.043
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_77 received DONE after 152 chunks
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_77 completed: 595 chars, 152 chunks, TTFT=54.6ms
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_100 to http://localhost:30000/generate at 1753373052.0521739
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_100 with payload: {'text': 'Random prompt 100 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_100
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_100
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] Prefill batch. #new-seq: 1, #new-token: 133, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 511/1000 (ID: req_510)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 512: relative_arrival=10.136, absolute_arrival=2069493.303, current_time=2069493.303, wait_time=0.000
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 512/1000 (ID: req_511)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 513: relative_arrival=10.179, absolute_arrival=2069493.346, current_time=2069493.303, wait_time=0.042
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_89 received DONE after 95 chunks
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_89 completed: 368 chars, 95 chunks, TTFT=67.1ms
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_101 to http://localhost:30000/generate at 1753373052.0974092
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_101 with payload: {'text': 'Random prompt 101 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_101
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_101
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 513/1000 (ID: req_512)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 514: relative_arrival=10.191, absolute_arrival=2069493.358, current_time=2069493.346, wait_time=0.011
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] Prefill batch. #new-seq: 1, #new-token: 288, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 514/1000 (ID: req_513)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 515: relative_arrival=10.205, absolute_arrival=2069493.372, current_time=2069493.359, wait_time=0.013
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 515/1000 (ID: req_514)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 516: relative_arrival=10.225, absolute_arrival=2069493.392, current_time=2069493.373, wait_time=0.018
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 516/1000 (ID: req_515)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 517: relative_arrival=10.277, absolute_arrival=2069493.444, current_time=2069493.392, wait_time=0.052
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 517/1000 (ID: req_516)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 518: relative_arrival=10.278, absolute_arrival=2069493.444, current_time=2069493.445, wait_time=-0.000
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 518/1000 (ID: req_517)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 519: relative_arrival=10.291, absolute_arrival=2069493.457, current_time=2069493.445, wait_time=0.012
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 519/1000 (ID: req_518)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 520: relative_arrival=10.314, absolute_arrival=2069493.480, current_time=2069493.458, wait_time=0.023
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 520/1000 (ID: req_519)
[2025-07-25 00:04:12] [__main__] [INFO] Progress: 520/1000 requests sent in 10.3s
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 521: relative_arrival=10.340, absolute_arrival=2069493.506, current_time=2069493.481, wait_time=0.025
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_85 received DONE after 125 chunks
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_85 completed: 496 chars, 125 chunks, TTFT=66.6ms
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_102 to http://localhost:30000/generate at 1753373052.262864
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_102 with payload: {'text': 'Random prompt 102 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 521/1000 (ID: req_520)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 522: relative_arrival=10.363, absolute_arrival=2069493.530, current_time=2069493.507, wait_time=0.022
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_102
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_102
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] Prefill batch. #new-seq: 1, #new-token: 206, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 522/1000 (ID: req_521)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 523: relative_arrival=10.366, absolute_arrival=2069493.533, current_time=2069493.530, wait_time=0.002
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 523/1000 (ID: req_522)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 524: relative_arrival=10.373, absolute_arrival=2069493.540, current_time=2069493.534, wait_time=0.006
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 524/1000 (ID: req_523)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 525: relative_arrival=10.382, absolute_arrival=2069493.549, current_time=2069493.540, wait_time=0.008
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 525/1000 (ID: req_524)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 526: relative_arrival=10.415, absolute_arrival=2069493.581, current_time=2069493.550, wait_time=0.032
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 526/1000 (ID: req_525)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 527: relative_arrival=10.421, absolute_arrival=2069493.588, current_time=2069493.582, wait_time=0.006
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 527/1000 (ID: req_526)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 528: relative_arrival=10.426, absolute_arrival=2069493.593, current_time=2069493.588, wait_time=0.004
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 528/1000 (ID: req_527)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 529: relative_arrival=10.489, absolute_arrival=2069493.656, current_time=2069493.594, wait_time=0.062
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_80 received DONE after 166 chunks
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_80 completed: 729 chars, 166 chunks, TTFT=67.7ms
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_103 to http://localhost:30000/generate at 1753373052.3729973
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_103 with payload: {'text': 'Random prompt 103 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_103
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_103
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 529/1000 (ID: req_528)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 530: relative_arrival=10.489, absolute_arrival=2069493.656, current_time=2069493.656, wait_time=-0.001
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 530/1000 (ID: req_529)
[2025-07-25 00:04:12] [__main__] [INFO] Progress: 530/1000 requests sent in 10.5s
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 531: relative_arrival=10.612, absolute_arrival=2069493.778, current_time=2069493.657, wait_time=0.122
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] Decode batch. #running-req: 20, #token: 6551, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1249.47, #queue-req: 0,
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_94 received DONE after 95 chunks
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_94 completed: 376 chars, 95 chunks, TTFT=58.0ms
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_104 to http://localhost:30000/generate at 1753373052.5060475
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_104 with payload: {'text': 'Random prompt 104 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_104
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_104
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_74 received DONE after 191 chunks
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_74 completed: 547 chars, 191 chunks, TTFT=48.7ms
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_105 to http://localhost:30000/generate at 1753373052.5166407
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_105 with payload: {'text': 'Random prompt 105 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_105
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_105
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] Prefill batch. #new-seq: 2, #new-token: 546, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 531/1000 (ID: req_530)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 532: relative_arrival=10.634, absolute_arrival=2069493.801, current_time=2069493.780, wait_time=0.021
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 532/1000 (ID: req_531)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 533: relative_arrival=10.670, absolute_arrival=2069493.836, current_time=2069493.803, wait_time=0.033
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 533/1000 (ID: req_532)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 534: relative_arrival=10.677, absolute_arrival=2069493.843, current_time=2069493.837, wait_time=0.006
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_86 received DONE after 144 chunks
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_86 completed: 408 chars, 144 chunks, TTFT=53.2ms
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_106 to http://localhost:30000/generate at 1753373052.5977976
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_106 with payload: {'text': 'Random prompt 106 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 534/1000 (ID: req_533)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 535: relative_arrival=10.677, absolute_arrival=2069493.844, current_time=2069493.844, wait_time=-0.000
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 535/1000 (ID: req_534)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 536: relative_arrival=10.704, absolute_arrival=2069493.870, current_time=2069493.844, wait_time=0.026
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_106
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_106
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] Prefill batch. #new-seq: 1, #new-token: 230, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 536/1000 (ID: req_535)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 537: relative_arrival=10.740, absolute_arrival=2069493.906, current_time=2069493.872, wait_time=0.035
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_95 received DONE after 88 chunks
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_95 completed: 352 chars, 88 chunks, TTFT=56.2ms
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_107 to http://localhost:30000/generate at 1753373052.6615117
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_107 with payload: {'text': 'Random prompt 107 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 537/1000 (ID: req_536)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 538: relative_arrival=10.767, absolute_arrival=2069493.933, current_time=2069493.908, wait_time=0.026
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_107
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_107
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] Prefill batch. #new-seq: 1, #new-token: 319, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 538/1000 (ID: req_537)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 539: relative_arrival=10.770, absolute_arrival=2069493.936, current_time=2069493.934, wait_time=0.002
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 539/1000 (ID: req_538)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 540: relative_arrival=10.798, absolute_arrival=2069493.964, current_time=2069493.937, wait_time=0.027
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 540/1000 (ID: req_539)
[2025-07-25 00:04:12] [__main__] [INFO] Progress: 540/1000 requests sent in 10.8s
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 541: relative_arrival=10.827, absolute_arrival=2069493.994, current_time=2069493.965, wait_time=0.028
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_79 received DONE after 187 chunks
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_79 completed: 733 chars, 187 chunks, TTFT=68.5ms
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_108 to http://localhost:30000/generate at 1753373052.7479043
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_108 with payload: {'text': 'Random prompt 108 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 541/1000 (ID: req_540)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 542: relative_arrival=10.849, absolute_arrival=2069494.015, current_time=2069493.995, wait_time=0.020
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_108
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_108
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 542/1000 (ID: req_541)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 543: relative_arrival=10.878, absolute_arrival=2069494.044, current_time=2069494.016, wait_time=0.028
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 543/1000 (ID: req_542)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 544: relative_arrival=10.915, absolute_arrival=2069494.082, current_time=2069494.045, wait_time=0.037
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_93 received DONE after 131 chunks
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_93 completed: 470 chars, 131 chunks, TTFT=55.6ms
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_109 to http://localhost:30000/generate at 1753373052.8196394
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_109 with payload: {'text': 'Random prompt 109 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 84, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_109
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_109
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] Prefill batch. #new-seq: 1, #new-token: 145, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 544/1000 (ID: req_543)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 545: relative_arrival=10.934, absolute_arrival=2069494.101, current_time=2069494.082, wait_time=0.019
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 545/1000 (ID: req_544)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 546: relative_arrival=10.936, absolute_arrival=2069494.102, current_time=2069494.102, wait_time=0.001
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 546/1000 (ID: req_545)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 547: relative_arrival=10.949, absolute_arrival=2069494.116, current_time=2069494.104, wait_time=0.012
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 547/1000 (ID: req_546)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 548: relative_arrival=10.951, absolute_arrival=2069494.117, current_time=2069494.118, wait_time=-0.001
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 548/1000 (ID: req_547)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 549: relative_arrival=10.961, absolute_arrival=2069494.128, current_time=2069494.118, wait_time=0.010
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 549/1000 (ID: req_548)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 550: relative_arrival=10.972, absolute_arrival=2069494.138, current_time=2069494.130, wait_time=0.008
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 550/1000 (ID: req_549)
[2025-07-25 00:04:12] [__main__] [INFO] Progress: 550/1000 requests sent in 11.0s
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 551: relative_arrival=10.973, absolute_arrival=2069494.140, current_time=2069494.140, wait_time=-0.001
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 551/1000 (ID: req_550)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 552: relative_arrival=10.982, absolute_arrival=2069494.148, current_time=2069494.141, wait_time=0.008
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_96 received DONE after 93 chunks
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_96 completed: 308 chars, 93 chunks, TTFT=45.5ms
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_110 to http://localhost:30000/generate at 1753373052.901545
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_110 with payload: {'text': 'Random prompt 110 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_110
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_110
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 552/1000 (ID: req_551)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 553: relative_arrival=10.984, absolute_arrival=2069494.151, current_time=2069494.150, wait_time=0.001
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 553/1000 (ID: req_552)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 554: relative_arrival=11.017, absolute_arrival=2069494.184, current_time=2069494.152, wait_time=0.032
[2025-07-25 00:04:12] [__main__] [INFO] Sending request 554/1000 (ID: req_553)
[2025-07-25 00:04:12] [__main__] [DEBUG] Request 555: relative_arrival=11.076, absolute_arrival=2069494.243, current_time=2069494.185, wait_time=0.058
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_97 received DONE after 89 chunks
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_97 completed: 320 chars, 89 chunks, TTFT=45.5ms
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_83 received DONE after 178 chunks
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_83 completed: 708 chars, 178 chunks, TTFT=43.0ms
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_111 to http://localhost:30000/generate at 1753373052.9465332
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_111 with payload: {'text': 'Random prompt 111 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_112 to http://localhost:30000/generate at 1753373052.9472783
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_112 with payload: {'text': 'Random prompt 112 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_111
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_111
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 6, token usage: 0.04, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_112
[2025-07-25 00:04:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_112
[2025-07-25 00:04:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:12] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 555/1000 (ID: req_554)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 556: relative_arrival=11.078, absolute_arrival=2069494.244, current_time=2069494.243, wait_time=0.001
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 556/1000 (ID: req_555)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 557: relative_arrival=11.140, absolute_arrival=2069494.306, current_time=2069494.245, wait_time=0.061
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_91 received DONE after 148 chunks
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_91 completed: 566 chars, 148 chunks, TTFT=53.5ms
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_113 to http://localhost:30000/generate at 1753373053.0395958
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_113 with payload: {'text': 'Random prompt 113 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_92 received DONE after 143 chunks
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_92 completed: 407 chars, 143 chunks, TTFT=61.6ms
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_114 to http://localhost:30000/generate at 1753373053.041493
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_114 with payload: {'text': 'Random prompt 114 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:13] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_113
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_113
[2025-07-25 00:04:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:13] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_114
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_114
[2025-07-25 00:04:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:13] Prefill batch. #new-seq: 2, #new-token: 619, #cached-token: 12, token usage: 0.04, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 557/1000 (ID: req_556)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 558: relative_arrival=11.155, absolute_arrival=2069494.321, current_time=2069494.308, wait_time=0.013
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 558/1000 (ID: req_557)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 559: relative_arrival=11.162, absolute_arrival=2069494.328, current_time=2069494.322, wait_time=0.006
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 559/1000 (ID: req_558)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 560: relative_arrival=11.163, absolute_arrival=2069494.330, current_time=2069494.329, wait_time=0.000
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 560/1000 (ID: req_559)
[2025-07-25 00:04:13] [__main__] [INFO] Progress: 560/1000 requests sent in 11.2s
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 561: relative_arrival=11.177, absolute_arrival=2069494.344, current_time=2069494.331, wait_time=0.013
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 561/1000 (ID: req_560)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 562: relative_arrival=11.209, absolute_arrival=2069494.375, current_time=2069494.345, wait_time=0.031
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 562/1000 (ID: req_561)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 563: relative_arrival=11.233, absolute_arrival=2069494.400, current_time=2069494.376, wait_time=0.023
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 563/1000 (ID: req_562)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 564: relative_arrival=11.234, absolute_arrival=2069494.401, current_time=2069494.400, wait_time=0.000
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 564/1000 (ID: req_563)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 565: relative_arrival=11.236, absolute_arrival=2069494.402, current_time=2069494.402, wait_time=0.001
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 565/1000 (ID: req_564)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 566: relative_arrival=11.246, absolute_arrival=2069494.413, current_time=2069494.403, wait_time=0.009
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 566/1000 (ID: req_565)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 567: relative_arrival=11.253, absolute_arrival=2069494.420, current_time=2069494.414, wait_time=0.006
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 567/1000 (ID: req_566)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 568: relative_arrival=11.258, absolute_arrival=2069494.425, current_time=2069494.420, wait_time=0.005
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 568/1000 (ID: req_567)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 569: relative_arrival=11.265, absolute_arrival=2069494.432, current_time=2069494.426, wait_time=0.006
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 569/1000 (ID: req_568)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 570: relative_arrival=11.298, absolute_arrival=2069494.464, current_time=2069494.432, wait_time=0.032
[2025-07-25 00:04:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:13] Decode batch. #running-req: 20, #token: 5752, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1047.46, #queue-req: 0,
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 570/1000 (ID: req_569)
[2025-07-25 00:04:13] [__main__] [INFO] Progress: 570/1000 requests sent in 11.3s
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 571: relative_arrival=11.351, absolute_arrival=2069494.517, current_time=2069494.466, wait_time=0.051
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 571/1000 (ID: req_570)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 572: relative_arrival=11.361, absolute_arrival=2069494.528, current_time=2069494.518, wait_time=0.009
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_100 received DONE after 72 chunks
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_100 completed: 281 chars, 72 chunks, TTFT=46.7ms
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_115 to http://localhost:30000/generate at 1753373053.2866504
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_115 with payload: {'text': 'Random prompt 115 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 138, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 572/1000 (ID: req_571)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 573: relative_arrival=11.408, absolute_arrival=2069494.575, current_time=2069494.530, wait_time=0.045
[2025-07-25 00:04:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:13] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_115
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_115
[2025-07-25 00:04:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:13] Prefill batch. #new-seq: 1, #new-token: 348, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_84 received DONE after 186 chunks
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_84 completed: 731 chars, 186 chunks, TTFT=67.2ms
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_116 to http://localhost:30000/generate at 1753373053.331512
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_116 with payload: {'text': 'Random prompt 116 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 76, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 573/1000 (ID: req_572)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 574: relative_arrival=11.416, absolute_arrival=2069494.583, current_time=2069494.576, wait_time=0.007
[2025-07-25 00:04:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:13] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_116
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_116
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 574/1000 (ID: req_573)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 575: relative_arrival=11.429, absolute_arrival=2069494.596, current_time=2069494.583, wait_time=0.012
[2025-07-25 00:04:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:13] Prefill batch. #new-seq: 1, #new-token: 331, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 575/1000 (ID: req_574)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 576: relative_arrival=11.434, absolute_arrival=2069494.601, current_time=2069494.596, wait_time=0.004
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 576/1000 (ID: req_575)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 577: relative_arrival=11.455, absolute_arrival=2069494.621, current_time=2069494.602, wait_time=0.019
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 577/1000 (ID: req_576)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 578: relative_arrival=11.532, absolute_arrival=2069494.698, current_time=2069494.622, wait_time=0.076
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 578/1000 (ID: req_577)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 579: relative_arrival=11.550, absolute_arrival=2069494.717, current_time=2069494.700, wait_time=0.017
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 579/1000 (ID: req_578)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 580: relative_arrival=11.559, absolute_arrival=2069494.726, current_time=2069494.719, wait_time=0.007
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 580/1000 (ID: req_579)
[2025-07-25 00:04:13] [__main__] [INFO] Progress: 580/1000 requests sent in 11.6s
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 581: relative_arrival=11.580, absolute_arrival=2069494.747, current_time=2069494.727, wait_time=0.020
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 581/1000 (ID: req_580)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 582: relative_arrival=11.583, absolute_arrival=2069494.749, current_time=2069494.747, wait_time=0.002
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 582/1000 (ID: req_581)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 583: relative_arrival=11.627, absolute_arrival=2069494.793, current_time=2069494.750, wait_time=0.044
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 583/1000 (ID: req_582)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 584: relative_arrival=11.641, absolute_arrival=2069494.807, current_time=2069494.794, wait_time=0.013
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 584/1000 (ID: req_583)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 585: relative_arrival=11.653, absolute_arrival=2069494.819, current_time=2069494.808, wait_time=0.011
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 585/1000 (ID: req_584)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 586: relative_arrival=11.670, absolute_arrival=2069494.837, current_time=2069494.820, wait_time=0.016
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_88 received DONE after 192 chunks
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_88 completed: 764 chars, 192 chunks, TTFT=75.5ms
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_117 to http://localhost:30000/generate at 1753373053.5871375
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_117 with payload: {'text': 'Random prompt 117 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:13] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_117
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_117
[2025-07-25 00:04:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:13] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 586/1000 (ID: req_585)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 587: relative_arrival=11.690, absolute_arrival=2069494.856, current_time=2069494.837, wait_time=0.019
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_90 received DONE after 186 chunks
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_90 completed: 730 chars, 186 chunks, TTFT=91.7ms
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_118 to http://localhost:30000/generate at 1753373053.598204
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_118 with payload: {'text': 'Random prompt 118 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 98, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:13] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_118
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_118
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 587/1000 (ID: req_586)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 588: relative_arrival=11.691, absolute_arrival=2069494.858, current_time=2069494.857, wait_time=0.001
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 588/1000 (ID: req_587)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 589: relative_arrival=11.714, absolute_arrival=2069494.881, current_time=2069494.858, wait_time=0.022
[2025-07-25 00:04:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:13] Prefill batch. #new-seq: 1, #new-token: 354, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 589/1000 (ID: req_588)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 590: relative_arrival=11.720, absolute_arrival=2069494.886, current_time=2069494.882, wait_time=0.004
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 590/1000 (ID: req_589)
[2025-07-25 00:04:13] [__main__] [INFO] Progress: 590/1000 requests sent in 11.7s
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 591: relative_arrival=11.745, absolute_arrival=2069494.911, current_time=2069494.888, wait_time=0.024
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 591/1000 (ID: req_590)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 592: relative_arrival=11.779, absolute_arrival=2069494.946, current_time=2069494.912, wait_time=0.034
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 592/1000 (ID: req_591)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 593: relative_arrival=11.812, absolute_arrival=2069494.978, current_time=2069494.946, wait_time=0.032
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_99 received DONE after 110 chunks
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_99 completed: 426 chars, 110 chunks, TTFT=43.3ms
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_119 to http://localhost:30000/generate at 1753373053.7254827
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_119 with payload: {'text': 'Random prompt 119 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:13] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_119
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_119
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 593/1000 (ID: req_592)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 594: relative_arrival=11.828, absolute_arrival=2069494.995, current_time=2069494.980, wait_time=0.015
[2025-07-25 00:04:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:13] Prefill batch. #new-seq: 1, #new-token: 263, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 594/1000 (ID: req_593)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 595: relative_arrival=11.843, absolute_arrival=2069495.009, current_time=2069494.995, wait_time=0.014
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 595/1000 (ID: req_594)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 596: relative_arrival=11.846, absolute_arrival=2069495.012, current_time=2069495.010, wait_time=0.002
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 596/1000 (ID: req_595)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 597: relative_arrival=11.876, absolute_arrival=2069495.042, current_time=2069495.013, wait_time=0.029
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 597/1000 (ID: req_596)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 598: relative_arrival=11.882, absolute_arrival=2069495.048, current_time=2069495.043, wait_time=0.005
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 598/1000 (ID: req_597)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 599: relative_arrival=11.896, absolute_arrival=2069495.062, current_time=2069495.049, wait_time=0.013
[2025-07-25 00:04:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:13] Decode batch. #running-req: 20, #token: 6275, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1277.70, #queue-req: 0,
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 599/1000 (ID: req_598)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 600: relative_arrival=11.902, absolute_arrival=2069495.069, current_time=2069495.065, wait_time=0.004
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 600/1000 (ID: req_599)
[2025-07-25 00:04:13] [__main__] [INFO] Progress: 600/1000 requests sent in 11.9s
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 601: relative_arrival=11.905, absolute_arrival=2069495.072, current_time=2069495.070, wait_time=0.002
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 601/1000 (ID: req_600)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 602: relative_arrival=11.925, absolute_arrival=2069495.092, current_time=2069495.072, wait_time=0.019
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 602/1000 (ID: req_601)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 603: relative_arrival=11.926, absolute_arrival=2069495.093, current_time=2069495.092, wait_time=0.001
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 603/1000 (ID: req_602)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 604: relative_arrival=11.954, absolute_arrival=2069495.120, current_time=2069495.093, wait_time=0.027
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 604/1000 (ID: req_603)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 605: relative_arrival=11.962, absolute_arrival=2069495.128, current_time=2069495.122, wait_time=0.006
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 605/1000 (ID: req_604)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 606: relative_arrival=11.962, absolute_arrival=2069495.128, current_time=2069495.129, wait_time=-0.001
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 606/1000 (ID: req_605)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 607: relative_arrival=11.976, absolute_arrival=2069495.142, current_time=2069495.129, wait_time=0.013
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 607/1000 (ID: req_606)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 608: relative_arrival=11.977, absolute_arrival=2069495.143, current_time=2069495.143, wait_time=0.000
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 608/1000 (ID: req_607)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 609: relative_arrival=11.983, absolute_arrival=2069495.150, current_time=2069495.144, wait_time=0.005
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 609/1000 (ID: req_608)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 610: relative_arrival=12.008, absolute_arrival=2069495.174, current_time=2069495.151, wait_time=0.024
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 610/1000 (ID: req_609)
[2025-07-25 00:04:13] [__main__] [INFO] Progress: 610/1000 requests sent in 12.0s
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 611: relative_arrival=12.009, absolute_arrival=2069495.176, current_time=2069495.175, wait_time=0.000
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 611/1000 (ID: req_610)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 612: relative_arrival=12.046, absolute_arrival=2069495.212, current_time=2069495.177, wait_time=0.035
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_105 received DONE after 87 chunks
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_105 completed: 331 chars, 87 chunks, TTFT=63.2ms
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_120 to http://localhost:30000/generate at 1753373053.9668005
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_120 with payload: {'text': 'Random prompt 120 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 178, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:13] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 612/1000 (ID: req_611)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 613: relative_arrival=12.046, absolute_arrival=2069495.212, current_time=2069495.213, wait_time=-0.001
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 613/1000 (ID: req_612)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 614: relative_arrival=12.051, absolute_arrival=2069495.218, current_time=2069495.213, wait_time=0.005
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_120
[2025-07-25 00:04:13] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_120
[2025-07-25 00:04:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:13] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:13] [__main__] [INFO] Sending request 614/1000 (ID: req_613)
[2025-07-25 00:04:13] [__main__] [DEBUG] Request 615: relative_arrival=12.078, absolute_arrival=2069495.245, current_time=2069495.219, wait_time=0.026
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 615/1000 (ID: req_614)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 616: relative_arrival=12.086, absolute_arrival=2069495.253, current_time=2069495.246, wait_time=0.006
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 616/1000 (ID: req_615)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 617: relative_arrival=12.088, absolute_arrival=2069495.255, current_time=2069495.255, wait_time=0.000
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 617/1000 (ID: req_616)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 618: relative_arrival=12.097, absolute_arrival=2069495.264, current_time=2069495.256, wait_time=0.008
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 618/1000 (ID: req_617)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 619: relative_arrival=12.103, absolute_arrival=2069495.270, current_time=2069495.265, wait_time=0.005
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 619/1000 (ID: req_618)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 620: relative_arrival=12.140, absolute_arrival=2069495.307, current_time=2069495.271, wait_time=0.036
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 620/1000 (ID: req_619)
[2025-07-25 00:04:14] [__main__] [INFO] Progress: 620/1000 requests sent in 12.1s
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 621: relative_arrival=12.148, absolute_arrival=2069495.314, current_time=2069495.308, wait_time=0.007
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 621/1000 (ID: req_620)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 622: relative_arrival=12.179, absolute_arrival=2069495.346, current_time=2069495.316, wait_time=0.030
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 622/1000 (ID: req_621)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 623: relative_arrival=12.224, absolute_arrival=2069495.390, current_time=2069495.346, wait_time=0.044
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 623/1000 (ID: req_622)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 624: relative_arrival=12.235, absolute_arrival=2069495.401, current_time=2069495.390, wait_time=0.011
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_109 received DONE after 85 chunks
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_109 completed: 322 chars, 85 chunks, TTFT=42.3ms
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_121 to http://localhost:30000/generate at 1753373054.1558695
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_121 with payload: {'text': 'Random prompt 121 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:14] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_121
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_121
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 624/1000 (ID: req_623)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 625: relative_arrival=12.283, absolute_arrival=2069495.450, current_time=2069495.403, wait_time=0.047
[2025-07-25 00:04:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:14] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 625/1000 (ID: req_624)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 626: relative_arrival=12.293, absolute_arrival=2069495.459, current_time=2069495.450, wait_time=0.009
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 626/1000 (ID: req_625)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 627: relative_arrival=12.359, absolute_arrival=2069495.526, current_time=2069495.460, wait_time=0.065
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 627/1000 (ID: req_626)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 628: relative_arrival=12.361, absolute_arrival=2069495.527, current_time=2069495.526, wait_time=0.001
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 628/1000 (ID: req_627)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 629: relative_arrival=12.384, absolute_arrival=2069495.551, current_time=2069495.528, wait_time=0.023
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 629/1000 (ID: req_628)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 630: relative_arrival=12.398, absolute_arrival=2069495.564, current_time=2069495.552, wait_time=0.012
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 630/1000 (ID: req_629)
[2025-07-25 00:04:14] [__main__] [INFO] Progress: 630/1000 requests sent in 12.4s
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 631: relative_arrival=12.408, absolute_arrival=2069495.574, current_time=2069495.565, wait_time=0.009
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 631/1000 (ID: req_630)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 632: relative_arrival=12.428, absolute_arrival=2069495.594, current_time=2069495.575, wait_time=0.019
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 632/1000 (ID: req_631)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 633: relative_arrival=12.452, absolute_arrival=2069495.618, current_time=2069495.596, wait_time=0.023
[2025-07-25 00:04:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:14] Decode batch. #running-req: 20, #token: 7257, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1463.21, #queue-req: 0,
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 633/1000 (ID: req_632)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 634: relative_arrival=12.452, absolute_arrival=2069495.619, current_time=2069495.620, wait_time=-0.002
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 634/1000 (ID: req_633)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 635: relative_arrival=12.456, absolute_arrival=2069495.622, current_time=2069495.621, wait_time=0.002
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_111 received DONE after 94 chunks
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_111 completed: 372 chars, 94 chunks, TTFT=65.4ms
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_112 received DONE after 94 chunks
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_112 completed: 273 chars, 94 chunks, TTFT=74.5ms
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 635/1000 (ID: req_634)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 636: relative_arrival=12.481, absolute_arrival=2069495.647, current_time=2069495.625, wait_time=0.022
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_122 to http://localhost:30000/generate at 1753373054.3838017
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_122 with payload: {'text': 'Random prompt 122 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 174, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_123 to http://localhost:30000/generate at 1753373054.3845534
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_123 with payload: {'text': 'Random prompt 123 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:14] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_122
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_122
[2025-07-25 00:04:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:14] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_123
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_123
[2025-07-25 00:04:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:14] Prefill batch. #new-seq: 2, #new-token: 360, #cached-token: 12, token usage: 0.06, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 636/1000 (ID: req_635)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 637: relative_arrival=12.503, absolute_arrival=2069495.669, current_time=2069495.649, wait_time=0.020
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 637/1000 (ID: req_636)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 638: relative_arrival=12.570, absolute_arrival=2069495.737, current_time=2069495.670, wait_time=0.067
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_106 received DONE after 116 chunks
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_106 completed: 448 chars, 116 chunks, TTFT=48.9ms
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_124 to http://localhost:30000/generate at 1753373054.4474292
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_124 with payload: {'text': 'Random prompt 124 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:14] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_124
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_124
[2025-07-25 00:04:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:14] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_116 received DONE after 77 chunks
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_116 completed: 228 chars, 77 chunks, TTFT=57.6ms
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_98 received DONE after 165 chunks
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_98 completed: 653 chars, 165 chunks, TTFT=45.6ms
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_125 to http://localhost:30000/generate at 1753373054.4933543
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_125 with payload: {'text': 'Random prompt 125 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 135, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_126 to http://localhost:30000/generate at 1753373054.4940608
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_126 with payload: {'text': 'Random prompt 126 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:14] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 638/1000 (ID: req_637)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 639: relative_arrival=12.599, absolute_arrival=2069495.765, current_time=2069495.738, wait_time=0.027
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_125
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_125
[2025-07-25 00:04:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:14] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_126
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_126
[2025-07-25 00:04:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:14] Prefill batch. #new-seq: 2, #new-token: 569, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 639/1000 (ID: req_638)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 640: relative_arrival=12.659, absolute_arrival=2069495.826, current_time=2069495.766, wait_time=0.060
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 640/1000 (ID: req_639)
[2025-07-25 00:04:14] [__main__] [INFO] Progress: 640/1000 requests sent in 12.7s
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 641: relative_arrival=12.683, absolute_arrival=2069495.850, current_time=2069495.826, wait_time=0.023
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 641/1000 (ID: req_640)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 642: relative_arrival=12.690, absolute_arrival=2069495.857, current_time=2069495.851, wait_time=0.006
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 642/1000 (ID: req_641)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 643: relative_arrival=12.693, absolute_arrival=2069495.859, current_time=2069495.858, wait_time=0.001
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 643/1000 (ID: req_642)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 644: relative_arrival=12.723, absolute_arrival=2069495.890, current_time=2069495.860, wait_time=0.030
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 644/1000 (ID: req_643)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 645: relative_arrival=12.744, absolute_arrival=2069495.910, current_time=2069495.891, wait_time=0.019
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 645/1000 (ID: req_644)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 646: relative_arrival=12.745, absolute_arrival=2069495.911, current_time=2069495.911, wait_time=0.000
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 646/1000 (ID: req_645)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 647: relative_arrival=12.754, absolute_arrival=2069495.920, current_time=2069495.912, wait_time=0.008
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 647/1000 (ID: req_646)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 648: relative_arrival=12.817, absolute_arrival=2069495.983, current_time=2069495.921, wait_time=0.062
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 648/1000 (ID: req_647)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 649: relative_arrival=12.830, absolute_arrival=2069495.997, current_time=2069495.984, wait_time=0.013
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 649/1000 (ID: req_648)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 650: relative_arrival=12.842, absolute_arrival=2069496.008, current_time=2069495.998, wait_time=0.010
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 650/1000 (ID: req_649)
[2025-07-25 00:04:14] [__main__] [INFO] Progress: 650/1000 requests sent in 12.8s
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 651: relative_arrival=12.854, absolute_arrival=2069496.021, current_time=2069496.011, wait_time=0.010
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 651/1000 (ID: req_650)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 652: relative_arrival=12.859, absolute_arrival=2069496.025, current_time=2069496.023, wait_time=0.002
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 652/1000 (ID: req_651)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 653: relative_arrival=12.868, absolute_arrival=2069496.034, current_time=2069496.026, wait_time=0.009
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 653/1000 (ID: req_652)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 654: relative_arrival=12.877, absolute_arrival=2069496.044, current_time=2069496.036, wait_time=0.008
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 654/1000 (ID: req_653)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 655: relative_arrival=12.878, absolute_arrival=2069496.045, current_time=2069496.045, wait_time=-0.000
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 655/1000 (ID: req_654)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 656: relative_arrival=12.907, absolute_arrival=2069496.074, current_time=2069496.045, wait_time=0.029
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 656/1000 (ID: req_655)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 657: relative_arrival=12.918, absolute_arrival=2069496.085, current_time=2069496.075, wait_time=0.010
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 657/1000 (ID: req_656)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 658: relative_arrival=12.953, absolute_arrival=2069496.119, current_time=2069496.086, wait_time=0.033
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 658/1000 (ID: req_657)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 659: relative_arrival=12.991, absolute_arrival=2069496.157, current_time=2069496.120, wait_time=0.037
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 659/1000 (ID: req_658)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 660: relative_arrival=12.995, absolute_arrival=2069496.162, current_time=2069496.159, wait_time=0.003
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_119 received DONE after 82 chunks
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_119 completed: 312 chars, 82 chunks, TTFT=58.0ms
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_127 to http://localhost:30000/generate at 1753373054.920095
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_127 with payload: {'text': 'Random prompt 127 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 660/1000 (ID: req_659)
[2025-07-25 00:04:14] [__main__] [INFO] Progress: 660/1000 requests sent in 13.0s
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 661: relative_arrival=13.017, absolute_arrival=2069496.183, current_time=2069496.164, wait_time=0.019
[2025-07-25 00:04:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:14] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_127
[2025-07-25 00:04:14] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_127
[2025-07-25 00:04:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:14] Prefill batch. #new-seq: 1, #new-token: 345, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 661/1000 (ID: req_660)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 662: relative_arrival=13.030, absolute_arrival=2069496.196, current_time=2069496.186, wait_time=0.011
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 662/1000 (ID: req_661)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 663: relative_arrival=13.072, absolute_arrival=2069496.239, current_time=2069496.197, wait_time=0.042
[2025-07-25 00:04:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:14] Decode batch. #running-req: 19, #token: 7379, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1302.24, #queue-req: 0,
[2025-07-25 00:04:14] [__main__] [INFO] Sending request 663/1000 (ID: req_662)
[2025-07-25 00:04:14] [__main__] [DEBUG] Request 664: relative_arrival=13.077, absolute_arrival=2069496.243, current_time=2069496.240, wait_time=0.004
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 664/1000 (ID: req_663)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 665: relative_arrival=13.100, absolute_arrival=2069496.266, current_time=2069496.244, wait_time=0.022
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 665/1000 (ID: req_664)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 666: relative_arrival=13.118, absolute_arrival=2069496.285, current_time=2069496.267, wait_time=0.018
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 666/1000 (ID: req_665)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 667: relative_arrival=13.125, absolute_arrival=2069496.292, current_time=2069496.287, wait_time=0.005
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_113 received DONE after 134 chunks
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_113 completed: 520 chars, 134 chunks, TTFT=75.2ms
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_128 to http://localhost:30000/generate at 1753373055.0484471
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_128 with payload: {'text': 'Random prompt 128 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 112, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 667/1000 (ID: req_666)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 668: relative_arrival=13.128, absolute_arrival=2069496.295, current_time=2069496.293, wait_time=0.002
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_128
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_128
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 668/1000 (ID: req_667)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 669: relative_arrival=13.149, absolute_arrival=2069496.316, current_time=2069496.296, wait_time=0.020
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_101 received DONE after 189 chunks
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_101 completed: 740 chars, 189 chunks, TTFT=49.5ms
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_102 received DONE after 178 chunks
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_102 completed: 695 chars, 178 chunks, TTFT=42.6ms
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_118 received DONE after 99 chunks
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_118 completed: 292 chars, 99 chunks, TTFT=60.4ms
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_129 to http://localhost:30000/generate at 1753373055.0632238
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_129 with payload: {'text': 'Random prompt 129 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_130 to http://localhost:30000/generate at 1753373055.0639563
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_130 with payload: {'text': 'Random prompt 130 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_131 to http://localhost:30000/generate at 1753373055.0645888
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_131 with payload: {'text': 'Random prompt 131 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_129
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_129
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_131
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_131
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_130
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_130
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 669/1000 (ID: req_668)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 670: relative_arrival=13.176, absolute_arrival=2069496.343, current_time=2069496.317, wait_time=0.026
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] Prefill batch. #new-seq: 3, #new-token: 670, #cached-token: 18, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 670/1000 (ID: req_669)
[2025-07-25 00:04:15] [__main__] [INFO] Progress: 670/1000 requests sent in 13.2s
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 671: relative_arrival=13.184, absolute_arrival=2069496.350, current_time=2069496.345, wait_time=0.005
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 671/1000 (ID: req_670)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 672: relative_arrival=13.204, absolute_arrival=2069496.371, current_time=2069496.351, wait_time=0.020
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 672/1000 (ID: req_671)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 673: relative_arrival=13.215, absolute_arrival=2069496.381, current_time=2069496.372, wait_time=0.009
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 673/1000 (ID: req_672)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 674: relative_arrival=13.239, absolute_arrival=2069496.406, current_time=2069496.383, wait_time=0.023
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 674/1000 (ID: req_673)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 675: relative_arrival=13.244, absolute_arrival=2069496.410, current_time=2069496.407, wait_time=0.004
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 675/1000 (ID: req_674)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 676: relative_arrival=13.288, absolute_arrival=2069496.455, current_time=2069496.411, wait_time=0.043
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_108 received DONE after 154 chunks
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_108 completed: 599 chars, 154 chunks, TTFT=43.9ms
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_132 to http://localhost:30000/generate at 1753373055.186751
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_132 with payload: {'text': 'Random prompt 132 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_132
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_132
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 676/1000 (ID: req_675)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 677: relative_arrival=13.295, absolute_arrival=2069496.461, current_time=2069496.456, wait_time=0.006
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 677/1000 (ID: req_676)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 678: relative_arrival=13.304, absolute_arrival=2069496.471, current_time=2069496.462, wait_time=0.008
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 678/1000 (ID: req_677)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 679: relative_arrival=13.305, absolute_arrival=2069496.472, current_time=2069496.472, wait_time=-0.000
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 679/1000 (ID: req_678)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 680: relative_arrival=13.308, absolute_arrival=2069496.474, current_time=2069496.472, wait_time=0.002
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_114 received DONE after 141 chunks
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_114 completed: 560 chars, 141 chunks, TTFT=73.4ms
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_133 to http://localhost:30000/generate at 1753373055.2324462
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_133 with payload: {'text': 'Random prompt 133 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 680/1000 (ID: req_679)
[2025-07-25 00:04:15] [__main__] [INFO] Progress: 680/1000 requests sent in 13.3s
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 681: relative_arrival=13.322, absolute_arrival=2069496.489, current_time=2069496.476, wait_time=0.013
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_133
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_133
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] Prefill batch. #new-seq: 1, #new-token: 212, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 681/1000 (ID: req_680)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 682: relative_arrival=13.328, absolute_arrival=2069496.495, current_time=2069496.490, wait_time=0.005
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 682/1000 (ID: req_681)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 683: relative_arrival=13.364, absolute_arrival=2069496.531, current_time=2069496.496, wait_time=0.035
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_107 received DONE after 162 chunks
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_107 completed: 480 chars, 162 chunks, TTFT=56.3ms
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_134 to http://localhost:30000/generate at 1753373055.2798083
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_134 with payload: {'text': 'Random prompt 134 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_134
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_134
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 683/1000 (ID: req_682)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 684: relative_arrival=13.365, absolute_arrival=2069496.531, current_time=2069496.532, wait_time=-0.000
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 684/1000 (ID: req_683)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 685: relative_arrival=13.374, absolute_arrival=2069496.541, current_time=2069496.532, wait_time=0.009
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] Prefill batch. #new-seq: 1, #new-token: 367, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 685/1000 (ID: req_684)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 686: relative_arrival=13.383, absolute_arrival=2069496.549, current_time=2069496.542, wait_time=0.007
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 686/1000 (ID: req_685)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 687: relative_arrival=13.383, absolute_arrival=2069496.549, current_time=2069496.550, wait_time=-0.001
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 687/1000 (ID: req_686)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 688: relative_arrival=13.386, absolute_arrival=2069496.552, current_time=2069496.550, wait_time=0.002
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 688/1000 (ID: req_687)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 689: relative_arrival=13.396, absolute_arrival=2069496.563, current_time=2069496.553, wait_time=0.010
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 689/1000 (ID: req_688)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 690: relative_arrival=13.410, absolute_arrival=2069496.576, current_time=2069496.564, wait_time=0.012
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 690/1000 (ID: req_689)
[2025-07-25 00:04:15] [__main__] [INFO] Progress: 690/1000 requests sent in 13.4s
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 691: relative_arrival=13.420, absolute_arrival=2069496.587, current_time=2069496.577, wait_time=0.010
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 691/1000 (ID: req_690)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 692: relative_arrival=13.435, absolute_arrival=2069496.602, current_time=2069496.587, wait_time=0.015
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 692/1000 (ID: req_691)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 693: relative_arrival=13.453, absolute_arrival=2069496.620, current_time=2069496.603, wait_time=0.017
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 693/1000 (ID: req_692)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 694: relative_arrival=13.454, absolute_arrival=2069496.620, current_time=2069496.620, wait_time=-0.000
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 694/1000 (ID: req_693)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 695: relative_arrival=13.466, absolute_arrival=2069496.633, current_time=2069496.621, wait_time=0.012
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_103 received DONE after 184 chunks
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_103 completed: 732 chars, 184 chunks, TTFT=55.2ms
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_135 to http://localhost:30000/generate at 1753373055.3901205
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_135 with payload: {'text': 'Random prompt 135 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 695/1000 (ID: req_694)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 696: relative_arrival=13.532, absolute_arrival=2069496.699, current_time=2069496.633, wait_time=0.066
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_135
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_135
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] Prefill batch. #new-seq: 1, #new-token: 208, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 696/1000 (ID: req_695)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 697: relative_arrival=13.547, absolute_arrival=2069496.713, current_time=2069496.699, wait_time=0.014
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 697/1000 (ID: req_696)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 698: relative_arrival=13.570, absolute_arrival=2069496.736, current_time=2069496.715, wait_time=0.021
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_115 received DONE after 139 chunks
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_115 completed: 408 chars, 139 chunks, TTFT=51.3ms
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_136 to http://localhost:30000/generate at 1753373055.4847686
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_136 with payload: {'text': 'Random prompt 136 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 173, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_136
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_136
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 698/1000 (ID: req_697)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 699: relative_arrival=13.577, absolute_arrival=2069496.744, current_time=2069496.738, wait_time=0.006
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 699/1000 (ID: req_698)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 700: relative_arrival=13.607, absolute_arrival=2069496.773, current_time=2069496.744, wait_time=0.029
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 700/1000 (ID: req_699)
[2025-07-25 00:04:15] [__main__] [INFO] Progress: 700/1000 requests sent in 13.6s
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 701: relative_arrival=13.636, absolute_arrival=2069496.803, current_time=2069496.774, wait_time=0.029
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 701/1000 (ID: req_700)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 702: relative_arrival=13.651, absolute_arrival=2069496.818, current_time=2069496.804, wait_time=0.014
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 702/1000 (ID: req_701)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 703: relative_arrival=13.726, absolute_arrival=2069496.892, current_time=2069496.818, wait_time=0.074
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_110 received DONE after 169 chunks
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_110 completed: 672 chars, 169 chunks, TTFT=46.4ms
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_137 to http://localhost:30000/generate at 1753373055.6090631
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_137 with payload: {'text': 'Random prompt 137 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_137
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_137
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] Prefill batch. #new-seq: 1, #new-token: 305, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 703/1000 (ID: req_702)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 704: relative_arrival=13.728, absolute_arrival=2069496.895, current_time=2069496.893, wait_time=0.002
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 704/1000 (ID: req_703)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 705: relative_arrival=13.729, absolute_arrival=2069496.895, current_time=2069496.896, wait_time=-0.000
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 705/1000 (ID: req_704)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 706: relative_arrival=13.758, absolute_arrival=2069496.925, current_time=2069496.896, wait_time=0.029
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_104 received DONE after 192 chunks
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_104 completed: 764 chars, 192 chunks, TTFT=74.0ms
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_138 to http://localhost:30000/generate at 1753373055.6657093
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_138 with payload: {'text': 'Random prompt 138 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_138
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_138
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] Prefill batch. #new-seq: 1, #new-token: 218, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 706/1000 (ID: req_705)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 707: relative_arrival=13.791, absolute_arrival=2069496.958, current_time=2069496.925, wait_time=0.032
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 707/1000 (ID: req_706)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 708: relative_arrival=13.794, absolute_arrival=2069496.960, current_time=2069496.958, wait_time=0.002
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 708/1000 (ID: req_707)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 709: relative_arrival=13.800, absolute_arrival=2069496.966, current_time=2069496.961, wait_time=0.006
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 709/1000 (ID: req_708)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 710: relative_arrival=13.800, absolute_arrival=2069496.967, current_time=2069496.967, wait_time=-0.001
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 710/1000 (ID: req_709)
[2025-07-25 00:04:15] [__main__] [INFO] Progress: 710/1000 requests sent in 13.8s
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 711: relative_arrival=13.807, absolute_arrival=2069496.974, current_time=2069496.968, wait_time=0.006
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] Decode batch. #running-req: 20, #token: 5851, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1040.56, #queue-req: 0,
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 711/1000 (ID: req_710)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 712: relative_arrival=13.837, absolute_arrival=2069497.003, current_time=2069496.976, wait_time=0.028
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_126 received DONE after 76 chunks
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_126 completed: 225 chars, 76 chunks, TTFT=67.0ms
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_139 to http://localhost:30000/generate at 1753373055.7586913
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_139 with payload: {'text': 'Random prompt 139 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 712/1000 (ID: req_711)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 713: relative_arrival=13.851, absolute_arrival=2069497.018, current_time=2069497.005, wait_time=0.013
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_139
[2025-07-25 00:04:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_139
[2025-07-25 00:04:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:15] Prefill batch. #new-seq: 1, #new-token: 374, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 713/1000 (ID: req_712)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 714: relative_arrival=13.860, absolute_arrival=2069497.026, current_time=2069497.019, wait_time=0.008
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 714/1000 (ID: req_713)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 715: relative_arrival=13.869, absolute_arrival=2069497.036, current_time=2069497.027, wait_time=0.009
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 715/1000 (ID: req_714)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 716: relative_arrival=13.869, absolute_arrival=2069497.036, current_time=2069497.037, wait_time=-0.002
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 716/1000 (ID: req_715)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 717: relative_arrival=13.876, absolute_arrival=2069497.043, current_time=2069497.038, wait_time=0.005
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 717/1000 (ID: req_716)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 718: relative_arrival=13.897, absolute_arrival=2069497.064, current_time=2069497.044, wait_time=0.020
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 718/1000 (ID: req_717)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 719: relative_arrival=13.970, absolute_arrival=2069497.137, current_time=2069497.064, wait_time=0.073
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 719/1000 (ID: req_718)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 720: relative_arrival=14.008, absolute_arrival=2069497.174, current_time=2069497.138, wait_time=0.037
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 720/1000 (ID: req_719)
[2025-07-25 00:04:15] [__main__] [INFO] Progress: 720/1000 requests sent in 14.0s
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 721: relative_arrival=14.008, absolute_arrival=2069497.175, current_time=2069497.175, wait_time=-0.000
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 721/1000 (ID: req_720)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 722: relative_arrival=14.054, absolute_arrival=2069497.221, current_time=2069497.176, wait_time=0.045
[2025-07-25 00:04:15] [__main__] [INFO] Sending request 722/1000 (ID: req_721)
[2025-07-25 00:04:15] [__main__] [DEBUG] Request 723: relative_arrival=14.085, absolute_arrival=2069497.251, current_time=2069497.222, wait_time=0.029
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 723/1000 (ID: req_722)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 724: relative_arrival=14.115, absolute_arrival=2069497.282, current_time=2069497.252, wait_time=0.030
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 724/1000 (ID: req_723)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 725: relative_arrival=14.127, absolute_arrival=2069497.294, current_time=2069497.283, wait_time=0.011
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 725/1000 (ID: req_724)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 726: relative_arrival=14.137, absolute_arrival=2069497.304, current_time=2069497.295, wait_time=0.009
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 726/1000 (ID: req_725)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 727: relative_arrival=14.145, absolute_arrival=2069497.311, current_time=2069497.305, wait_time=0.006
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 727/1000 (ID: req_726)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 728: relative_arrival=14.146, absolute_arrival=2069497.313, current_time=2069497.312, wait_time=0.001
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 728/1000 (ID: req_727)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 729: relative_arrival=14.151, absolute_arrival=2069497.318, current_time=2069497.313, wait_time=0.004
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 729/1000 (ID: req_728)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 730: relative_arrival=14.157, absolute_arrival=2069497.323, current_time=2069497.319, wait_time=0.005
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 730/1000 (ID: req_729)
[2025-07-25 00:04:16] [__main__] [INFO] Progress: 730/1000 requests sent in 14.2s
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 731: relative_arrival=14.170, absolute_arrival=2069497.337, current_time=2069497.324, wait_time=0.013
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 731/1000 (ID: req_730)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 732: relative_arrival=14.198, absolute_arrival=2069497.364, current_time=2069497.338, wait_time=0.026
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 732/1000 (ID: req_731)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 733: relative_arrival=14.210, absolute_arrival=2069497.377, current_time=2069497.366, wait_time=0.011
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 733/1000 (ID: req_732)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 734: relative_arrival=14.212, absolute_arrival=2069497.378, current_time=2069497.381, wait_time=-0.003
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 734/1000 (ID: req_733)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 735: relative_arrival=14.275, absolute_arrival=2069497.441, current_time=2069497.381, wait_time=0.060
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 735/1000 (ID: req_734)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 736: relative_arrival=14.332, absolute_arrival=2069497.499, current_time=2069497.442, wait_time=0.056
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] Decode batch. #running-req: 20, #token: 6613, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1565.47, #queue-req: 0,
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 736/1000 (ID: req_735)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 737: relative_arrival=14.363, absolute_arrival=2069497.529, current_time=2069497.500, wait_time=0.030
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 737/1000 (ID: req_736)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 738: relative_arrival=14.458, absolute_arrival=2069497.624, current_time=2069497.531, wait_time=0.093
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_117 received DONE after 177 chunks
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_117 completed: 691 chars, 177 chunks, TTFT=63.3ms
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_140 to http://localhost:30000/generate at 1753373056.2932305
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_140 with payload: {'text': 'Random prompt 140 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_140
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_140
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_132 received DONE after 75 chunks
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_132 completed: 283 chars, 75 chunks, TTFT=46.7ms
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_141 to http://localhost:30000/generate at 1753373056.3046556
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_141 with payload: {'text': 'Random prompt 141 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_141
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_141
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] Prefill batch. #new-seq: 2, #new-token: 562, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 738/1000 (ID: req_737)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 739: relative_arrival=14.474, absolute_arrival=2069497.640, current_time=2069497.625, wait_time=0.015
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 739/1000 (ID: req_738)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 740: relative_arrival=14.539, absolute_arrival=2069497.706, current_time=2069497.641, wait_time=0.065
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 740/1000 (ID: req_739)
[2025-07-25 00:04:16] [__main__] [INFO] Progress: 740/1000 requests sent in 14.5s
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 741: relative_arrival=14.541, absolute_arrival=2069497.708, current_time=2069497.707, wait_time=0.000
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 741/1000 (ID: req_740)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 742: relative_arrival=14.550, absolute_arrival=2069497.717, current_time=2069497.708, wait_time=0.008
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 742/1000 (ID: req_741)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 743: relative_arrival=14.555, absolute_arrival=2069497.722, current_time=2069497.717, wait_time=0.005
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 743/1000 (ID: req_742)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 744: relative_arrival=14.560, absolute_arrival=2069497.726, current_time=2069497.722, wait_time=0.004
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_135 received DONE after 75 chunks
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_135 completed: 283 chars, 75 chunks, TTFT=56.1ms
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_142 to http://localhost:30000/generate at 1753373056.4837627
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_142 with payload: {'text': 'Random prompt 142 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 744/1000 (ID: req_743)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 745: relative_arrival=14.563, absolute_arrival=2069497.729, current_time=2069497.727, wait_time=0.002
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 745/1000 (ID: req_744)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 746: relative_arrival=14.582, absolute_arrival=2069497.749, current_time=2069497.730, wait_time=0.018
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_142
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_142
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] Prefill batch. #new-seq: 1, #new-token: 252, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 746/1000 (ID: req_745)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 747: relative_arrival=14.612, absolute_arrival=2069497.779, current_time=2069497.751, wait_time=0.028
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 747/1000 (ID: req_746)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 748: relative_arrival=14.630, absolute_arrival=2069497.796, current_time=2069497.781, wait_time=0.015
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 748/1000 (ID: req_747)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 749: relative_arrival=14.633, absolute_arrival=2069497.799, current_time=2069497.798, wait_time=0.002
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 749/1000 (ID: req_748)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 750: relative_arrival=14.666, absolute_arrival=2069497.833, current_time=2069497.800, wait_time=0.033
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_125 received DONE after 136 chunks
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_125 completed: 540 chars, 136 chunks, TTFT=67.6ms
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_143 to http://localhost:30000/generate at 1753373056.5822601
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_143 with payload: {'text': 'Random prompt 143 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 136, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_143
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_143
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 750/1000 (ID: req_749)
[2025-07-25 00:04:16] [__main__] [INFO] Progress: 750/1000 requests sent in 14.7s
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 751: relative_arrival=14.686, absolute_arrival=2069497.853, current_time=2069497.834, wait_time=0.019
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_129 received DONE after 98 chunks
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_129 completed: 375 chars, 98 chunks, TTFT=84.6ms
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_144 to http://localhost:30000/generate at 1753373056.5944166
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_144 with payload: {'text': 'Random prompt 144 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 98, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_144
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_144
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] Prefill batch. #new-seq: 2, #new-token: 400, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 751/1000 (ID: req_750)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 752: relative_arrival=14.696, absolute_arrival=2069497.863, current_time=2069497.854, wait_time=0.009
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 752/1000 (ID: req_751)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 753: relative_arrival=14.719, absolute_arrival=2069497.885, current_time=2069497.864, wait_time=0.021
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_133 received DONE after 93 chunks
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_133 completed: 356 chars, 93 chunks, TTFT=49.3ms
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_145 to http://localhost:30000/generate at 1753373056.6428835
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_145 with payload: {'text': 'Random prompt 145 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 753/1000 (ID: req_752)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 754: relative_arrival=14.725, absolute_arrival=2069497.891, current_time=2069497.886, wait_time=0.005
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_145
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_145
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 754/1000 (ID: req_753)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 755: relative_arrival=14.733, absolute_arrival=2069497.900, current_time=2069497.892, wait_time=0.008
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 755/1000 (ID: req_754)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 756: relative_arrival=14.783, absolute_arrival=2069497.950, current_time=2069497.901, wait_time=0.049
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 756/1000 (ID: req_755)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 757: relative_arrival=14.790, absolute_arrival=2069497.956, current_time=2069497.951, wait_time=0.006
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 757/1000 (ID: req_756)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 758: relative_arrival=14.803, absolute_arrival=2069497.969, current_time=2069497.958, wait_time=0.011
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 758/1000 (ID: req_757)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 759: relative_arrival=14.847, absolute_arrival=2069498.013, current_time=2069497.970, wait_time=0.043
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_120 received DONE after 179 chunks
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_120 completed: 533 chars, 179 chunks, TTFT=49.8ms
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_146 to http://localhost:30000/generate at 1753373056.7524126
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_146 with payload: {'text': 'Random prompt 146 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_146
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_146
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] Prefill batch. #new-seq: 1, #new-token: 281, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 759/1000 (ID: req_758)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 760: relative_arrival=14.871, absolute_arrival=2069498.038, current_time=2069498.014, wait_time=0.024
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_124 received DONE after 149 chunks
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_124 completed: 592 chars, 149 chunks, TTFT=47.3ms
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_147 to http://localhost:30000/generate at 1753373056.7773578
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_147 with payload: {'text': 'Random prompt 147 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_147
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_147
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 760/1000 (ID: req_759)
[2025-07-25 00:04:16] [__main__] [INFO] Progress: 760/1000 requests sent in 14.9s
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 761: relative_arrival=14.873, absolute_arrival=2069498.039, current_time=2069498.039, wait_time=0.000
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 761/1000 (ID: req_760)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 762: relative_arrival=14.876, absolute_arrival=2069498.042, current_time=2069498.040, wait_time=0.002
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 762/1000 (ID: req_761)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 763: relative_arrival=14.876, absolute_arrival=2069498.043, current_time=2069498.044, wait_time=-0.001
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 763/1000 (ID: req_762)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 764: relative_arrival=14.896, absolute_arrival=2069498.063, current_time=2069498.044, wait_time=0.019
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] Prefill batch. #new-seq: 1, #new-token: 254, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 764/1000 (ID: req_763)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 765: relative_arrival=14.908, absolute_arrival=2069498.074, current_time=2069498.064, wait_time=0.010
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 765/1000 (ID: req_764)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 766: relative_arrival=14.911, absolute_arrival=2069498.077, current_time=2069498.075, wait_time=0.002
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 766/1000 (ID: req_765)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 767: relative_arrival=14.974, absolute_arrival=2069498.141, current_time=2069498.078, wait_time=0.063
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_127 received DONE after 117 chunks
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_127 completed: 464 chars, 117 chunks, TTFT=61.1ms
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_148 to http://localhost:30000/generate at 1753373056.8537345
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_148 with payload: {'text': 'Random prompt 148 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 173, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_148
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_148
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 767/1000 (ID: req_766)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 768: relative_arrival=14.989, absolute_arrival=2069498.156, current_time=2069498.141, wait_time=0.014
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_128 received DONE after 113 chunks
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_128 completed: 116 chars, 113 chunks, TTFT=69.6ms
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_149 to http://localhost:30000/generate at 1753373056.912577
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_149 with payload: {'text': 'Random prompt 149 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 768/1000 (ID: req_767)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 769: relative_arrival=14.995, absolute_arrival=2069498.161, current_time=2069498.157, wait_time=0.004
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_149
[2025-07-25 00:04:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_149
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] Prefill batch. #new-seq: 1, #new-token: 196, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 769/1000 (ID: req_768)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 770: relative_arrival=15.009, absolute_arrival=2069498.175, current_time=2069498.162, wait_time=0.013
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 770/1000 (ID: req_769)
[2025-07-25 00:04:16] [__main__] [INFO] Progress: 770/1000 requests sent in 15.0s
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 771: relative_arrival=15.031, absolute_arrival=2069498.198, current_time=2069498.177, wait_time=0.021
[2025-07-25 00:04:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:16] Decode batch. #running-req: 19, #token: 6172, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1101.94, #queue-req: 0,
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 771/1000 (ID: req_770)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 772: relative_arrival=15.033, absolute_arrival=2069498.200, current_time=2069498.199, wait_time=0.001
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 772/1000 (ID: req_771)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 773: relative_arrival=15.039, absolute_arrival=2069498.206, current_time=2069498.201, wait_time=0.005
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 773/1000 (ID: req_772)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 774: relative_arrival=15.072, absolute_arrival=2069498.239, current_time=2069498.206, wait_time=0.032
[2025-07-25 00:04:16] [__main__] [INFO] Sending request 774/1000 (ID: req_773)
[2025-07-25 00:04:16] [__main__] [DEBUG] Request 775: relative_arrival=15.085, absolute_arrival=2069498.251, current_time=2069498.241, wait_time=0.010
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 775/1000 (ID: req_774)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 776: relative_arrival=15.100, absolute_arrival=2069498.267, current_time=2069498.253, wait_time=0.014
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 776/1000 (ID: req_775)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 777: relative_arrival=15.112, absolute_arrival=2069498.278, current_time=2069498.268, wait_time=0.011
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 777/1000 (ID: req_776)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 778: relative_arrival=15.113, absolute_arrival=2069498.279, current_time=2069498.279, wait_time=0.001
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 778/1000 (ID: req_777)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 779: relative_arrival=15.116, absolute_arrival=2069498.283, current_time=2069498.280, wait_time=0.003
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 779/1000 (ID: req_778)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 780: relative_arrival=15.128, absolute_arrival=2069498.295, current_time=2069498.283, wait_time=0.011
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 780/1000 (ID: req_779)
[2025-07-25 00:04:17] [__main__] [INFO] Progress: 780/1000 requests sent in 15.1s
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 781: relative_arrival=15.133, absolute_arrival=2069498.299, current_time=2069498.295, wait_time=0.004
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 781/1000 (ID: req_780)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 782: relative_arrival=15.134, absolute_arrival=2069498.300, current_time=2069498.301, wait_time=-0.000
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 782/1000 (ID: req_781)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 783: relative_arrival=15.171, absolute_arrival=2069498.337, current_time=2069498.301, wait_time=0.037
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_123 received DONE after 169 chunks
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_123 completed: 672 chars, 169 chunks, TTFT=46.0ms
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_150 to http://localhost:30000/generate at 1753373057.0837328
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_150 with payload: {'text': 'Random prompt 150 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:17] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_150
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_150
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 783/1000 (ID: req_782)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 784: relative_arrival=15.250, absolute_arrival=2069498.417, current_time=2069498.339, wait_time=0.078
[2025-07-25 00:04:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:17] Prefill batch. #new-seq: 1, #new-token: 358, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_121 received DONE after 187 chunks
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_121 completed: 553 chars, 187 chunks, TTFT=49.1ms
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_151 to http://localhost:30000/generate at 1753373057.1077964
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_151 with payload: {'text': 'Random prompt 151 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 171, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:17] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_151
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_151
[2025-07-25 00:04:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:17] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_131 received DONE after 128 chunks
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_131 completed: 495 chars, 128 chunks, TTFT=83.3ms
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_152 to http://localhost:30000/generate at 1753373057.141033
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_152 with payload: {'text': 'Random prompt 152 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:17] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_152
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_152
[2025-07-25 00:04:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:17] Prefill batch. #new-seq: 1, #new-token: 162, #cached-token: 6, token usage: 0.05, #running-req: 21, #queue-req: 0,
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 784/1000 (ID: req_783)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 785: relative_arrival=15.282, absolute_arrival=2069498.448, current_time=2069498.418, wait_time=0.030
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 785/1000 (ID: req_784)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 786: relative_arrival=15.320, absolute_arrival=2069498.487, current_time=2069498.449, wait_time=0.037
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_122 received DONE after 175 chunks
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_122 completed: 684 chars, 175 chunks, TTFT=46.7ms
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_153 to http://localhost:30000/generate at 1753373057.2342265
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_153 with payload: {'text': 'Random prompt 153 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:17] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_153
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_153
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 786/1000 (ID: req_785)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 787: relative_arrival=15.326, absolute_arrival=2069498.492, current_time=2069498.488, wait_time=0.005
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 787/1000 (ID: req_786)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 788: relative_arrival=15.391, absolute_arrival=2069498.557, current_time=2069498.493, wait_time=0.064
[2025-07-25 00:04:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:17] Prefill batch. #new-seq: 1, #new-token: 250, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 788/1000 (ID: req_787)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 789: relative_arrival=15.395, absolute_arrival=2069498.562, current_time=2069498.558, wait_time=0.004
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 789/1000 (ID: req_788)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 790: relative_arrival=15.455, absolute_arrival=2069498.622, current_time=2069498.562, wait_time=0.060
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 790/1000 (ID: req_789)
[2025-07-25 00:04:17] [__main__] [INFO] Progress: 790/1000 requests sent in 15.5s
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 791: relative_arrival=15.561, absolute_arrival=2069498.727, current_time=2069498.623, wait_time=0.105
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 791/1000 (ID: req_790)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 792: relative_arrival=15.586, absolute_arrival=2069498.752, current_time=2069498.728, wait_time=0.024
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 792/1000 (ID: req_791)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 793: relative_arrival=15.665, absolute_arrival=2069498.832, current_time=2069498.753, wait_time=0.078
[2025-07-25 00:04:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:17] Decode batch. #running-req: 20, #token: 6393, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1361.35, #queue-req: 0,
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_137 received DONE after 128 chunks
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_137 completed: 496 chars, 128 chunks, TTFT=62.0ms
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_130 received DONE after 158 chunks
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_130 completed: 615 chars, 158 chunks, TTFT=84.1ms
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_154 to http://localhost:30000/generate at 1753373057.5813751
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_154 with payload: {'text': 'Random prompt 154 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_155 to http://localhost:30000/generate at 1753373057.582191
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_155 with payload: {'text': 'Random prompt 155 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 160, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:17] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_154
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_154
[2025-07-25 00:04:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:17] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 793/1000 (ID: req_792)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 794: relative_arrival=15.682, absolute_arrival=2069498.848, current_time=2069498.833, wait_time=0.016
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_155
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_155
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_138 received DONE after 127 chunks
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_138 completed: 492 chars, 127 chunks, TTFT=53.1ms
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_156 to http://localhost:30000/generate at 1753373057.5966754
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_156 with payload: {'text': 'Random prompt 156 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 84, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:17] Prefill batch. #new-seq: 2, #new-token: 564, #cached-token: 12, token usage: 0.04, #running-req: 17, #queue-req: 0,
[2025-07-25 00:04:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:17] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_156
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_156
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 794/1000 (ID: req_793)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 795: relative_arrival=15.688, absolute_arrival=2069498.854, current_time=2069498.850, wait_time=0.005
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 795/1000 (ID: req_794)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 796: relative_arrival=15.699, absolute_arrival=2069498.866, current_time=2069498.856, wait_time=0.010
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 796/1000 (ID: req_795)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 797: relative_arrival=15.717, absolute_arrival=2069498.884, current_time=2069498.867, wait_time=0.017
[2025-07-25 00:04:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:17] Prefill batch. #new-seq: 1, #new-token: 297, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_134 received DONE after 152 chunks
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_134 completed: 453 chars, 152 chunks, TTFT=54.8ms
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_157 to http://localhost:30000/generate at 1753373057.6368976
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_157 with payload: {'text': 'Random prompt 157 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:17] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_157
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_157
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 797/1000 (ID: req_796)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 798: relative_arrival=15.719, absolute_arrival=2069498.885, current_time=2069498.884, wait_time=0.001
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 798/1000 (ID: req_797)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 799: relative_arrival=15.738, absolute_arrival=2069498.905, current_time=2069498.886, wait_time=0.019
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 799/1000 (ID: req_798)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 800: relative_arrival=15.818, absolute_arrival=2069498.984, current_time=2069498.905, wait_time=0.079
[2025-07-25 00:04:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:17] Prefill batch. #new-seq: 1, #new-token: 320, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 800/1000 (ID: req_799)
[2025-07-25 00:04:17] [__main__] [INFO] Progress: 800/1000 requests sent in 15.8s
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 801: relative_arrival=15.822, absolute_arrival=2069498.989, current_time=2069498.985, wait_time=0.003
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 801/1000 (ID: req_800)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 802: relative_arrival=15.854, absolute_arrival=2069499.020, current_time=2069498.989, wait_time=0.031
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 802/1000 (ID: req_801)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 803: relative_arrival=15.901, absolute_arrival=2069499.068, current_time=2069499.021, wait_time=0.047
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 803/1000 (ID: req_802)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 804: relative_arrival=15.959, absolute_arrival=2069499.125, current_time=2069499.069, wait_time=0.056
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 804/1000 (ID: req_803)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 805: relative_arrival=16.023, absolute_arrival=2069499.190, current_time=2069499.126, wait_time=0.063
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_139 received DONE after 141 chunks
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_139 completed: 404 chars, 141 chunks, TTFT=59.3ms
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_158 to http://localhost:30000/generate at 1753373057.9379394
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_158 with payload: {'text': 'Random prompt 158 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:17] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_158
[2025-07-25 00:04:17] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_158
[2025-07-25 00:04:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:17] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 805/1000 (ID: req_804)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 806: relative_arrival=16.038, absolute_arrival=2069499.204, current_time=2069499.190, wait_time=0.014
[2025-07-25 00:04:17] [__main__] [INFO] Sending request 806/1000 (ID: req_805)
[2025-07-25 00:04:17] [__main__] [DEBUG] Request 807: relative_arrival=16.114, absolute_arrival=2069499.280, current_time=2069499.206, wait_time=0.074
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 807/1000 (ID: req_806)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 808: relative_arrival=16.142, absolute_arrival=2069499.309, current_time=2069499.281, wait_time=0.027
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 808/1000 (ID: req_807)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 809: relative_arrival=16.146, absolute_arrival=2069499.312, current_time=2069499.309, wait_time=0.003
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 809/1000 (ID: req_808)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 810: relative_arrival=16.158, absolute_arrival=2069499.325, current_time=2069499.313, wait_time=0.012
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 810/1000 (ID: req_809)
[2025-07-25 00:04:18] [__main__] [INFO] Progress: 810/1000 requests sent in 16.2s
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 811: relative_arrival=16.184, absolute_arrival=2069499.350, current_time=2069499.326, wait_time=0.024
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_141 received DONE after 110 chunks
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_141 completed: 423 chars, 110 chunks, TTFT=63.4ms
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_159 to http://localhost:30000/generate at 1753373058.09201
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_159 with payload: {'text': 'Random prompt 159 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:18] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_159
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_159
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 811/1000 (ID: req_810)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 812: relative_arrival=16.190, absolute_arrival=2069499.356, current_time=2069499.351, wait_time=0.005
[2025-07-25 00:04:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:18] Prefill batch. #new-seq: 1, #new-token: 312, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 812/1000 (ID: req_811)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 813: relative_arrival=16.210, absolute_arrival=2069499.376, current_time=2069499.357, wait_time=0.020
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 813/1000 (ID: req_812)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 814: relative_arrival=16.232, absolute_arrival=2069499.398, current_time=2069499.377, wait_time=0.021
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 814/1000 (ID: req_813)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 815: relative_arrival=16.235, absolute_arrival=2069499.402, current_time=2069499.399, wait_time=0.003
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 815/1000 (ID: req_814)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 816: relative_arrival=16.252, absolute_arrival=2069499.419, current_time=2069499.403, wait_time=0.016
[2025-07-25 00:04:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:18] Decode batch. #running-req: 20, #token: 5938, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1241.40, #queue-req: 0,
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 816/1000 (ID: req_815)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 817: relative_arrival=16.282, absolute_arrival=2069499.448, current_time=2069499.420, wait_time=0.028
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_136 received DONE after 174 chunks
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_136 completed: 679 chars, 174 chunks, TTFT=46.4ms
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_160 to http://localhost:30000/generate at 1753373058.1817257
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_160 with payload: {'text': 'Random prompt 160 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:18] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_160
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_160
[2025-07-25 00:04:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:18] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_144 received DONE after 99 chunks
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_144 completed: 380 chars, 99 chunks, TTFT=57.3ms
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_161 to http://localhost:30000/generate at 1753373058.2050896
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_161 with payload: {'text': 'Random prompt 161 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 817/1000 (ID: req_816)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 818: relative_arrival=16.295, absolute_arrival=2069499.462, current_time=2069499.449, wait_time=0.013
[2025-07-25 00:04:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:18] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_161
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_161
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 818/1000 (ID: req_817)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 819: relative_arrival=16.296, absolute_arrival=2069499.462, current_time=2069499.463, wait_time=-0.001
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 819/1000 (ID: req_818)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 820: relative_arrival=16.296, absolute_arrival=2069499.462, current_time=2069499.464, wait_time=-0.001
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 820/1000 (ID: req_819)
[2025-07-25 00:04:18] [__main__] [INFO] Progress: 820/1000 requests sent in 16.3s
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 821: relative_arrival=16.305, absolute_arrival=2069499.471, current_time=2069499.464, wait_time=0.007
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 821/1000 (ID: req_820)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 822: relative_arrival=16.357, absolute_arrival=2069499.523, current_time=2069499.473, wait_time=0.050
[2025-07-25 00:04:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:18] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 822/1000 (ID: req_821)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 823: relative_arrival=16.362, absolute_arrival=2069499.529, current_time=2069499.525, wait_time=0.004
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 823/1000 (ID: req_822)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 824: relative_arrival=16.382, absolute_arrival=2069499.549, current_time=2069499.529, wait_time=0.019
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 824/1000 (ID: req_823)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 825: relative_arrival=16.387, absolute_arrival=2069499.554, current_time=2069499.550, wait_time=0.004
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 825/1000 (ID: req_824)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 826: relative_arrival=16.395, absolute_arrival=2069499.561, current_time=2069499.554, wait_time=0.007
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 826/1000 (ID: req_825)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 827: relative_arrival=16.433, absolute_arrival=2069499.599, current_time=2069499.563, wait_time=0.036
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 827/1000 (ID: req_826)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 828: relative_arrival=16.459, absolute_arrival=2069499.625, current_time=2069499.600, wait_time=0.025
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 828/1000 (ID: req_827)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 829: relative_arrival=16.461, absolute_arrival=2069499.627, current_time=2069499.626, wait_time=0.001
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 829/1000 (ID: req_828)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 830: relative_arrival=16.472, absolute_arrival=2069499.638, current_time=2069499.628, wait_time=0.010
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 830/1000 (ID: req_829)
[2025-07-25 00:04:18] [__main__] [INFO] Progress: 830/1000 requests sent in 16.5s
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 831: relative_arrival=16.473, absolute_arrival=2069499.639, current_time=2069499.639, wait_time=0.000
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 831/1000 (ID: req_830)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 832: relative_arrival=16.486, absolute_arrival=2069499.652, current_time=2069499.639, wait_time=0.013
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 832/1000 (ID: req_831)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 833: relative_arrival=16.507, absolute_arrival=2069499.674, current_time=2069499.653, wait_time=0.021
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 833/1000 (ID: req_832)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 834: relative_arrival=16.510, absolute_arrival=2069499.676, current_time=2069499.675, wait_time=0.002
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 834/1000 (ID: req_833)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 835: relative_arrival=16.517, absolute_arrival=2069499.683, current_time=2069499.677, wait_time=0.006
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 835/1000 (ID: req_834)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 836: relative_arrival=16.527, absolute_arrival=2069499.693, current_time=2069499.684, wait_time=0.010
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 836/1000 (ID: req_835)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 837: relative_arrival=16.577, absolute_arrival=2069499.744, current_time=2069499.694, wait_time=0.050
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 837/1000 (ID: req_836)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 838: relative_arrival=16.677, absolute_arrival=2069499.844, current_time=2069499.745, wait_time=0.099
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 838/1000 (ID: req_837)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 839: relative_arrival=16.678, absolute_arrival=2069499.845, current_time=2069499.844, wait_time=0.000
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 839/1000 (ID: req_838)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 840: relative_arrival=16.707, absolute_arrival=2069499.873, current_time=2069499.846, wait_time=0.027
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 840/1000 (ID: req_839)
[2025-07-25 00:04:18] [__main__] [INFO] Progress: 840/1000 requests sent in 16.7s
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 841: relative_arrival=16.716, absolute_arrival=2069499.883, current_time=2069499.875, wait_time=0.008
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 841/1000 (ID: req_840)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 842: relative_arrival=16.726, absolute_arrival=2069499.893, current_time=2069499.883, wait_time=0.010
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 842/1000 (ID: req_841)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 843: relative_arrival=16.754, absolute_arrival=2069499.921, current_time=2069499.894, wait_time=0.027
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 843/1000 (ID: req_842)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 844: relative_arrival=16.804, absolute_arrival=2069499.971, current_time=2069499.922, wait_time=0.049
[2025-07-25 00:04:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:18] Decode batch. #running-req: 20, #token: 6609, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1489.54, #queue-req: 0,
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_143 received DONE after 137 chunks
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_143 completed: 532 chars, 137 chunks, TTFT=69.6ms
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_162 to http://localhost:30000/generate at 1753373058.7180414
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_162 with payload: {'text': 'Random prompt 162 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:18] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_162
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_162
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 844/1000 (ID: req_843)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 845: relative_arrival=16.865, absolute_arrival=2069500.031, current_time=2069499.972, wait_time=0.059
[2025-07-25 00:04:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:18] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 845/1000 (ID: req_844)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 846: relative_arrival=16.882, absolute_arrival=2069500.048, current_time=2069500.033, wait_time=0.015
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 846/1000 (ID: req_845)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 847: relative_arrival=16.891, absolute_arrival=2069500.057, current_time=2069500.049, wait_time=0.008
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 847/1000 (ID: req_846)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 848: relative_arrival=16.922, absolute_arrival=2069500.088, current_time=2069500.058, wait_time=0.030
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_142 received DONE after 152 chunks
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_142 completed: 604 chars, 152 chunks, TTFT=45.5ms
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_163 to http://localhost:30000/generate at 1753373058.8402011
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_163 with payload: {'text': 'Random prompt 163 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 159, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:18] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_163
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_163
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 848/1000 (ID: req_847)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 849: relative_arrival=16.927, absolute_arrival=2069500.094, current_time=2069500.089, wait_time=0.005
[2025-07-25 00:04:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:18] Prefill batch. #new-seq: 1, #new-token: 262, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 849/1000 (ID: req_848)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 850: relative_arrival=16.944, absolute_arrival=2069500.110, current_time=2069500.094, wait_time=0.016
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_156 received DONE after 85 chunks
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_156 completed: 324 chars, 85 chunks, TTFT=108.2ms
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_164 to http://localhost:30000/generate at 1753373058.8566506
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_164 with payload: {'text': 'Random prompt 164 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:18] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_164
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_164
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 850/1000 (ID: req_849)
[2025-07-25 00:04:18] [__main__] [INFO] Progress: 850/1000 requests sent in 16.9s
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 851: relative_arrival=16.953, absolute_arrival=2069500.119, current_time=2069500.111, wait_time=0.008
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 851/1000 (ID: req_850)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 852: relative_arrival=16.974, absolute_arrival=2069500.141, current_time=2069500.120, wait_time=0.021
[2025-07-25 00:04:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:18] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 852/1000 (ID: req_851)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 853: relative_arrival=16.980, absolute_arrival=2069500.146, current_time=2069500.143, wait_time=0.003
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 853/1000 (ID: req_852)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 854: relative_arrival=16.984, absolute_arrival=2069500.150, current_time=2069500.147, wait_time=0.003
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 854/1000 (ID: req_853)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 855: relative_arrival=17.034, absolute_arrival=2069500.201, current_time=2069500.152, wait_time=0.049
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 855/1000 (ID: req_854)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 856: relative_arrival=17.036, absolute_arrival=2069500.203, current_time=2069500.201, wait_time=0.001
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 856/1000 (ID: req_855)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 857: relative_arrival=17.050, absolute_arrival=2069500.217, current_time=2069500.204, wait_time=0.013
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 857/1000 (ID: req_856)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 858: relative_arrival=17.055, absolute_arrival=2069500.222, current_time=2069500.218, wait_time=0.004
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 858/1000 (ID: req_857)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 859: relative_arrival=17.056, absolute_arrival=2069500.223, current_time=2069500.223, wait_time=0.000
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 859/1000 (ID: req_858)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 860: relative_arrival=17.057, absolute_arrival=2069500.223, current_time=2069500.225, wait_time=-0.002
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 860/1000 (ID: req_859)
[2025-07-25 00:04:18] [__main__] [INFO] Progress: 860/1000 requests sent in 17.1s
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 861: relative_arrival=17.061, absolute_arrival=2069500.227, current_time=2069500.225, wait_time=0.002
[2025-07-25 00:04:18] [__main__] [INFO] Sending request 861/1000 (ID: req_860)
[2025-07-25 00:04:18] [__main__] [DEBUG] Request 862: relative_arrival=17.101, absolute_arrival=2069500.268, current_time=2069500.228, wait_time=0.040
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_140 received DONE after 171 chunks
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_140 completed: 506 chars, 171 chunks, TTFT=74.8ms
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_165 to http://localhost:30000/generate at 1753373058.9961276
[2025-07-25 00:04:18] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_165 with payload: {'text': 'Random prompt 165 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:18] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_165
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_165
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] Prefill batch. #new-seq: 1, #new-token: 339, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 862/1000 (ID: req_861)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 863: relative_arrival=17.108, absolute_arrival=2069500.274, current_time=2069500.269, wait_time=0.005
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 863/1000 (ID: req_862)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 864: relative_arrival=17.168, absolute_arrival=2069500.334, current_time=2069500.275, wait_time=0.059
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_147 received DONE after 149 chunks
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_147 completed: 579 chars, 149 chunks, TTFT=58.4ms
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_166 to http://localhost:30000/generate at 1753373059.0868955
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_166 with payload: {'text': 'Random prompt 166 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 171, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_166
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_166
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] Prefill batch. #new-seq: 1, #new-token: 207, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 864/1000 (ID: req_863)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 865: relative_arrival=17.185, absolute_arrival=2069500.352, current_time=2069500.335, wait_time=0.017
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 865/1000 (ID: req_864)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 866: relative_arrival=17.197, absolute_arrival=2069500.363, current_time=2069500.353, wait_time=0.011
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 866/1000 (ID: req_865)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 867: relative_arrival=17.214, absolute_arrival=2069500.380, current_time=2069500.364, wait_time=0.017
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 867/1000 (ID: req_866)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 868: relative_arrival=17.229, absolute_arrival=2069500.395, current_time=2069500.381, wait_time=0.014
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 868/1000 (ID: req_867)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 869: relative_arrival=17.257, absolute_arrival=2069500.423, current_time=2069500.396, wait_time=0.028
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_159 received DONE after 69 chunks
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_159 completed: 204 chars, 69 chunks, TTFT=59.1ms
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_167 to http://localhost:30000/generate at 1753373059.1593387
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_167 with payload: {'text': 'Random prompt 167 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 129, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_167
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_167
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 869/1000 (ID: req_868)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 870: relative_arrival=17.264, absolute_arrival=2069500.430, current_time=2069500.424, wait_time=0.006
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 870/1000 (ID: req_869)
[2025-07-25 00:04:19] [__main__] [INFO] Progress: 870/1000 requests sent in 17.3s
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 871: relative_arrival=17.272, absolute_arrival=2069500.439, current_time=2069500.431, wait_time=0.008
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 871/1000 (ID: req_870)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 872: relative_arrival=17.317, absolute_arrival=2069500.484, current_time=2069500.439, wait_time=0.044
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 872/1000 (ID: req_871)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 873: relative_arrival=17.376, absolute_arrival=2069500.542, current_time=2069500.485, wait_time=0.057
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 873/1000 (ID: req_872)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 874: relative_arrival=17.420, absolute_arrival=2069500.587, current_time=2069500.543, wait_time=0.044
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 874/1000 (ID: req_873)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 875: relative_arrival=17.431, absolute_arrival=2069500.598, current_time=2069500.589, wait_time=0.009
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_146 received DONE after 167 chunks
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_146 completed: 652 chars, 167 chunks, TTFT=79.4ms
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_168 to http://localhost:30000/generate at 1753373059.3492975
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_168 with payload: {'text': 'Random prompt 168 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_168
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_168
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] Decode batch. #running-req: 20, #token: 6260, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1229.42, #queue-req: 0,
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 875/1000 (ID: req_874)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 876: relative_arrival=17.462, absolute_arrival=2069500.628, current_time=2069500.598, wait_time=0.030
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 876/1000 (ID: req_875)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 877: relative_arrival=17.475, absolute_arrival=2069500.641, current_time=2069500.630, wait_time=0.011
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_145 received DONE after 177 chunks
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_145 completed: 178 chars, 177 chunks, TTFT=44.8ms
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_169 to http://localhost:30000/generate at 1753373059.394553
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_169 with payload: {'text': 'Random prompt 169 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 101, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_169
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_169
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 877/1000 (ID: req_876)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 878: relative_arrival=17.488, absolute_arrival=2069500.655, current_time=2069500.642, wait_time=0.013
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_161 received DONE after 81 chunks
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_161 completed: 307 chars, 81 chunks, TTFT=60.5ms
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_170 to http://localhost:30000/generate at 1753373059.4107552
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_170 with payload: {'text': 'Random prompt 170 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 878/1000 (ID: req_877)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 879: relative_arrival=17.493, absolute_arrival=2069500.659, current_time=2069500.655, wait_time=0.004
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_170
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_170
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 879/1000 (ID: req_878)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 880: relative_arrival=17.511, absolute_arrival=2069500.677, current_time=2069500.660, wait_time=0.018
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 880/1000 (ID: req_879)
[2025-07-25 00:04:19] [__main__] [INFO] Progress: 880/1000 requests sent in 17.5s
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 881: relative_arrival=17.515, absolute_arrival=2069500.681, current_time=2069500.679, wait_time=0.002
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] Prefill batch. #new-seq: 1, #new-token: 299, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 881/1000 (ID: req_880)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 882: relative_arrival=17.523, absolute_arrival=2069500.689, current_time=2069500.682, wait_time=0.007
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 882/1000 (ID: req_881)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 883: relative_arrival=17.562, absolute_arrival=2069500.728, current_time=2069500.691, wait_time=0.037
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 883/1000 (ID: req_882)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 884: relative_arrival=17.566, absolute_arrival=2069500.733, current_time=2069500.729, wait_time=0.003
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 884/1000 (ID: req_883)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 885: relative_arrival=17.568, absolute_arrival=2069500.734, current_time=2069500.734, wait_time=-0.000
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 885/1000 (ID: req_884)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 886: relative_arrival=17.569, absolute_arrival=2069500.736, current_time=2069500.735, wait_time=0.001
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 886/1000 (ID: req_885)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 887: relative_arrival=17.626, absolute_arrival=2069500.792, current_time=2069500.736, wait_time=0.056
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_152 received DONE after 154 chunks
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_152 completed: 600 chars, 154 chunks, TTFT=50.8ms
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_171 to http://localhost:30000/generate at 1753373059.5059927
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_171 with payload: {'text': 'Random prompt 171 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_171
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_171
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_150 received DONE after 156 chunks
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_150 completed: 463 chars, 156 chunks, TTFT=80.1ms
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_172 to http://localhost:30000/generate at 1753373059.5502412
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_172 with payload: {'text': 'Random prompt 172 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 887/1000 (ID: req_886)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 888: relative_arrival=17.640, absolute_arrival=2069500.806, current_time=2069500.793, wait_time=0.013
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_172
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_172
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] Prefill batch. #new-seq: 1, #new-token: 256, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 888/1000 (ID: req_887)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 889: relative_arrival=17.650, absolute_arrival=2069500.817, current_time=2069500.807, wait_time=0.009
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 889/1000 (ID: req_888)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 890: relative_arrival=17.684, absolute_arrival=2069500.850, current_time=2069500.818, wait_time=0.032
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_148 received DONE after 174 chunks
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_148 completed: 692 chars, 174 chunks, TTFT=43.5ms
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_173 to http://localhost:30000/generate at 1753373059.598115
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_173 with payload: {'text': 'Random prompt 173 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_153 received DONE after 152 chunks
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_153 completed: 604 chars, 152 chunks, TTFT=54.7ms
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_174 to http://localhost:30000/generate at 1753373059.600148
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_174 with payload: {'text': 'Random prompt 174 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_173
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_173
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_174
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_174
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 6, token usage: 0.04, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 890/1000 (ID: req_889)
[2025-07-25 00:04:19] [__main__] [INFO] Progress: 890/1000 requests sent in 17.7s
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 891: relative_arrival=17.720, absolute_arrival=2069500.886, current_time=2069500.851, wait_time=0.035
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 891/1000 (ID: req_890)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 892: relative_arrival=17.728, absolute_arrival=2069500.894, current_time=2069500.887, wait_time=0.008
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 892/1000 (ID: req_891)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 893: relative_arrival=17.751, absolute_arrival=2069500.918, current_time=2069500.895, wait_time=0.023
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 893/1000 (ID: req_892)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 894: relative_arrival=17.781, absolute_arrival=2069500.947, current_time=2069500.918, wait_time=0.029
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 894/1000 (ID: req_893)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 895: relative_arrival=17.802, absolute_arrival=2069500.969, current_time=2069500.948, wait_time=0.021
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_149 received DONE after 176 chunks
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_149 completed: 700 chars, 176 chunks, TTFT=46.5ms
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_175 to http://localhost:30000/generate at 1753373059.7147927
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_175 with payload: {'text': 'Random prompt 175 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_175
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_175
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 895/1000 (ID: req_894)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 896: relative_arrival=17.806, absolute_arrival=2069500.972, current_time=2069500.969, wait_time=0.003
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 896/1000 (ID: req_895)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 897: relative_arrival=17.847, absolute_arrival=2069501.014, current_time=2069500.973, wait_time=0.041
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 897/1000 (ID: req_896)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 898: relative_arrival=17.863, absolute_arrival=2069501.029, current_time=2069501.014, wait_time=0.015
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 898/1000 (ID: req_897)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 899: relative_arrival=17.869, absolute_arrival=2069501.036, current_time=2069501.030, wait_time=0.006
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 899/1000 (ID: req_898)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 900: relative_arrival=17.880, absolute_arrival=2069501.047, current_time=2069501.038, wait_time=0.009
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 900/1000 (ID: req_899)
[2025-07-25 00:04:19] [__main__] [INFO] Progress: 900/1000 requests sent in 17.9s
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 901: relative_arrival=17.881, absolute_arrival=2069501.048, current_time=2069501.048, wait_time=-0.000
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 901/1000 (ID: req_900)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 902: relative_arrival=17.884, absolute_arrival=2069501.050, current_time=2069501.048, wait_time=0.002
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 902/1000 (ID: req_901)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 903: relative_arrival=17.913, absolute_arrival=2069501.079, current_time=2069501.052, wait_time=0.028
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 903/1000 (ID: req_902)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 904: relative_arrival=17.913, absolute_arrival=2069501.079, current_time=2069501.081, wait_time=-0.001
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 904/1000 (ID: req_903)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 905: relative_arrival=17.924, absolute_arrival=2069501.090, current_time=2069501.081, wait_time=0.010
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_151 received DONE after 172 chunks
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_151 completed: 684 chars, 172 chunks, TTFT=80.4ms
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_176 to http://localhost:30000/generate at 1753373059.8447402
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_176 with payload: {'text': 'Random prompt 176 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 905/1000 (ID: req_904)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 906: relative_arrival=17.939, absolute_arrival=2069501.105, current_time=2069501.091, wait_time=0.014
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_176
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_176
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] Prefill batch. #new-seq: 1, #new-token: 302, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 906/1000 (ID: req_905)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 907: relative_arrival=17.940, absolute_arrival=2069501.106, current_time=2069501.106, wait_time=0.001
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 907/1000 (ID: req_906)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 908: relative_arrival=18.012, absolute_arrival=2069501.178, current_time=2069501.107, wait_time=0.072
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_154 received DONE after 144 chunks
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_154 completed: 572 chars, 144 chunks, TTFT=94.4ms
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_177 to http://localhost:30000/generate at 1753373059.9314747
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_177 with payload: {'text': 'Random prompt 177 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_177
[2025-07-25 00:04:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_177
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 908/1000 (ID: req_907)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 909: relative_arrival=18.017, absolute_arrival=2069501.184, current_time=2069501.180, wait_time=0.004
[2025-07-25 00:04:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:19] Prefill batch. #new-seq: 1, #new-token: 224, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 909/1000 (ID: req_908)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 910: relative_arrival=18.024, absolute_arrival=2069501.191, current_time=2069501.184, wait_time=0.006
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 910/1000 (ID: req_909)
[2025-07-25 00:04:19] [__main__] [INFO] Progress: 910/1000 requests sent in 18.0s
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 911: relative_arrival=18.032, absolute_arrival=2069501.198, current_time=2069501.192, wait_time=0.006
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 911/1000 (ID: req_910)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 912: relative_arrival=18.037, absolute_arrival=2069501.203, current_time=2069501.199, wait_time=0.004
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 912/1000 (ID: req_911)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 913: relative_arrival=18.037, absolute_arrival=2069501.203, current_time=2069501.205, wait_time=-0.001
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 913/1000 (ID: req_912)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 914: relative_arrival=18.063, absolute_arrival=2069501.229, current_time=2069501.205, wait_time=0.025
[2025-07-25 00:04:19] [__main__] [INFO] Sending request 914/1000 (ID: req_913)
[2025-07-25 00:04:19] [__main__] [DEBUG] Request 915: relative_arrival=18.131, absolute_arrival=2069501.298, current_time=2069501.231, wait_time=0.067
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 915/1000 (ID: req_914)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 916: relative_arrival=18.136, absolute_arrival=2069501.303, current_time=2069501.299, wait_time=0.004
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 916/1000 (ID: req_915)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 917: relative_arrival=18.158, absolute_arrival=2069501.324, current_time=2069501.305, wait_time=0.020
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 917/1000 (ID: req_916)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 918: relative_arrival=18.185, absolute_arrival=2069501.352, current_time=2069501.326, wait_time=0.025
[2025-07-25 00:04:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:20] Decode batch. #running-req: 20, #token: 5851, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1067.95, #queue-req: 0,
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 918/1000 (ID: req_917)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 919: relative_arrival=18.223, absolute_arrival=2069501.389, current_time=2069501.354, wait_time=0.035
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 919/1000 (ID: req_918)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 920: relative_arrival=18.234, absolute_arrival=2069501.400, current_time=2069501.391, wait_time=0.010
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_155 received DONE after 161 chunks
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_155 completed: 628 chars, 161 chunks, TTFT=93.7ms
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_178 to http://localhost:30000/generate at 1753373060.158321
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_178 with payload: {'text': 'Random prompt 178 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 920/1000 (ID: req_919)
[2025-07-25 00:04:20] [__main__] [INFO] Progress: 920/1000 requests sent in 18.2s
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 921: relative_arrival=18.241, absolute_arrival=2069501.407, current_time=2069501.402, wait_time=0.006
[2025-07-25 00:04:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:20] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_178
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_178
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 921/1000 (ID: req_920)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 922: relative_arrival=18.249, absolute_arrival=2069501.415, current_time=2069501.408, wait_time=0.008
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 922/1000 (ID: req_921)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 923: relative_arrival=18.274, absolute_arrival=2069501.440, current_time=2069501.416, wait_time=0.024
[2025-07-25 00:04:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:20] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 923/1000 (ID: req_922)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 924: relative_arrival=18.308, absolute_arrival=2069501.474, current_time=2069501.442, wait_time=0.032
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 924/1000 (ID: req_923)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 925: relative_arrival=18.312, absolute_arrival=2069501.478, current_time=2069501.475, wait_time=0.003
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 925/1000 (ID: req_924)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 926: relative_arrival=18.321, absolute_arrival=2069501.488, current_time=2069501.479, wait_time=0.009
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 926/1000 (ID: req_925)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 927: relative_arrival=18.367, absolute_arrival=2069501.534, current_time=2069501.490, wait_time=0.044
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 927/1000 (ID: req_926)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 928: relative_arrival=18.400, absolute_arrival=2069501.567, current_time=2069501.536, wait_time=0.031
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_164 received DONE after 86 chunks
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_164 completed: 337 chars, 86 chunks, TTFT=59.8ms
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_179 to http://localhost:30000/generate at 1753373060.2970808
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_179 with payload: {'text': 'Random prompt 179 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:20] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_179
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_179
[2025-07-25 00:04:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:20] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 928/1000 (ID: req_927)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 929: relative_arrival=18.484, absolute_arrival=2069501.651, current_time=2069501.569, wait_time=0.082
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 929/1000 (ID: req_928)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 930: relative_arrival=18.512, absolute_arrival=2069501.679, current_time=2069501.652, wait_time=0.027
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_157 received DONE after 178 chunks
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_157 completed: 530 chars, 178 chunks, TTFT=78.6ms
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_180 to http://localhost:30000/generate at 1753373060.4155598
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_180 with payload: {'text': 'Random prompt 180 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 187, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:20] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_180
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_180
[2025-07-25 00:04:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:20] Prefill batch. #new-seq: 1, #new-token: 212, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 930/1000 (ID: req_929)
[2025-07-25 00:04:20] [__main__] [INFO] Progress: 930/1000 requests sent in 18.5s
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 931: relative_arrival=18.522, absolute_arrival=2069501.689, current_time=2069501.680, wait_time=0.008
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 931/1000 (ID: req_930)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 932: relative_arrival=18.540, absolute_arrival=2069501.707, current_time=2069501.691, wait_time=0.016
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 932/1000 (ID: req_931)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 933: relative_arrival=18.562, absolute_arrival=2069501.728, current_time=2069501.707, wait_time=0.021
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_168 received DONE after 66 chunks
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_168 completed: 67 chars, 66 chunks, TTFT=46.1ms
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_181 to http://localhost:30000/generate at 1753373060.4709153
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_181 with payload: {'text': 'Random prompt 181 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:20] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_181
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_181
[2025-07-25 00:04:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:20] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 933/1000 (ID: req_932)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 934: relative_arrival=18.563, absolute_arrival=2069501.730, current_time=2069501.729, wait_time=0.001
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 934/1000 (ID: req_933)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 935: relative_arrival=18.579, absolute_arrival=2069501.746, current_time=2069501.731, wait_time=0.014
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 935/1000 (ID: req_934)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 936: relative_arrival=18.604, absolute_arrival=2069501.770, current_time=2069501.747, wait_time=0.024
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 936/1000 (ID: req_935)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 937: relative_arrival=18.607, absolute_arrival=2069501.774, current_time=2069501.772, wait_time=0.002
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 937/1000 (ID: req_936)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 938: relative_arrival=18.638, absolute_arrival=2069501.804, current_time=2069501.775, wait_time=0.029
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_162 received DONE after 108 chunks
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_162 completed: 428 chars, 108 chunks, TTFT=58.6ms
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_182 to http://localhost:30000/generate at 1753373060.5454938
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_182 with payload: {'text': 'Random prompt 182 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:20] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_182
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_182
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 938/1000 (ID: req_937)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 939: relative_arrival=18.655, absolute_arrival=2069501.822, current_time=2069501.805, wait_time=0.017
[2025-07-25 00:04:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:20] Prefill batch. #new-seq: 1, #new-token: 362, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 939/1000 (ID: req_938)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 940: relative_arrival=18.716, absolute_arrival=2069501.883, current_time=2069501.822, wait_time=0.060
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 940/1000 (ID: req_939)
[2025-07-25 00:04:20] [__main__] [INFO] Progress: 940/1000 requests sent in 18.7s
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 941: relative_arrival=18.717, absolute_arrival=2069501.883, current_time=2069501.883, wait_time=0.000
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 941/1000 (ID: req_940)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 942: relative_arrival=18.723, absolute_arrival=2069501.890, current_time=2069501.885, wait_time=0.005
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 942/1000 (ID: req_941)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 943: relative_arrival=18.742, absolute_arrival=2069501.908, current_time=2069501.890, wait_time=0.018
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 943/1000 (ID: req_942)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 944: relative_arrival=18.749, absolute_arrival=2069501.915, current_time=2069501.909, wait_time=0.006
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 944/1000 (ID: req_943)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 945: relative_arrival=18.774, absolute_arrival=2069501.940, current_time=2069501.916, wait_time=0.024
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 945/1000 (ID: req_944)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 946: relative_arrival=18.802, absolute_arrival=2069501.969, current_time=2069501.941, wait_time=0.028
[2025-07-25 00:04:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:20] Decode batch. #running-req: 20, #token: 6225, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1301.30, #queue-req: 0,
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_158 received DONE after 177 chunks
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_158 completed: 691 chars, 177 chunks, TTFT=42.7ms
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_183 to http://localhost:30000/generate at 1753373060.7190046
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_183 with payload: {'text': 'Random prompt 183 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:20] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_183
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_183
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 946/1000 (ID: req_945)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 947: relative_arrival=18.804, absolute_arrival=2069501.971, current_time=2069501.969, wait_time=0.001
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 947/1000 (ID: req_946)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 948: relative_arrival=18.819, absolute_arrival=2069501.985, current_time=2069501.972, wait_time=0.014
[2025-07-25 00:04:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:20] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 948/1000 (ID: req_947)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 949: relative_arrival=18.833, absolute_arrival=2069501.999, current_time=2069501.986, wait_time=0.014
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 949/1000 (ID: req_948)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 950: relative_arrival=18.842, absolute_arrival=2069502.009, current_time=2069502.000, wait_time=0.008
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 950/1000 (ID: req_949)
[2025-07-25 00:04:20] [__main__] [INFO] Progress: 950/1000 requests sent in 18.8s
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 951: relative_arrival=18.896, absolute_arrival=2069502.063, current_time=2069502.011, wait_time=0.052
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 951/1000 (ID: req_950)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 952: relative_arrival=18.931, absolute_arrival=2069502.098, current_time=2069502.063, wait_time=0.034
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 952/1000 (ID: req_951)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 953: relative_arrival=18.955, absolute_arrival=2069502.122, current_time=2069502.099, wait_time=0.023
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_160 received DONE after 171 chunks
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_160 completed: 680 chars, 171 chunks, TTFT=75.9ms
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 953/1000 (ID: req_952)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 954: relative_arrival=18.980, absolute_arrival=2069502.147, current_time=2069502.124, wait_time=0.022
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_184 to http://localhost:30000/generate at 1753373060.8827875
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_184 with payload: {'text': 'Random prompt 184 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:20] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_184
[2025-07-25 00:04:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_184
[2025-07-25 00:04:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:20] Prefill batch. #new-seq: 1, #new-token: 191, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 954/1000 (ID: req_953)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 955: relative_arrival=18.993, absolute_arrival=2069502.159, current_time=2069502.148, wait_time=0.012
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 955/1000 (ID: req_954)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 956: relative_arrival=19.043, absolute_arrival=2069502.210, current_time=2069502.160, wait_time=0.050
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 956/1000 (ID: req_955)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 957: relative_arrival=19.067, absolute_arrival=2069502.234, current_time=2069502.211, wait_time=0.023
[2025-07-25 00:04:20] [__main__] [INFO] Sending request 957/1000 (ID: req_956)
[2025-07-25 00:04:20] [__main__] [DEBUG] Request 958: relative_arrival=19.093, absolute_arrival=2069502.260, current_time=2069502.235, wait_time=0.025
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 958/1000 (ID: req_957)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 959: relative_arrival=19.133, absolute_arrival=2069502.299, current_time=2069502.262, wait_time=0.038
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_169 received DONE after 102 chunks
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_169 completed: 404 chars, 102 chunks, TTFT=72.5ms
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_185 to http://localhost:30000/generate at 1753373061.0357964
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_185 with payload: {'text': 'Random prompt 185 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_185
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_185
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] Prefill batch. #new-seq: 1, #new-token: 294, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 959/1000 (ID: req_958)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 960: relative_arrival=19.139, absolute_arrival=2069502.306, current_time=2069502.301, wait_time=0.005
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 960/1000 (ID: req_959)
[2025-07-25 00:04:21] [__main__] [INFO] Progress: 960/1000 requests sent in 19.1s
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 961: relative_arrival=19.172, absolute_arrival=2069502.339, current_time=2069502.307, wait_time=0.031
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 961/1000 (ID: req_960)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 962: relative_arrival=19.176, absolute_arrival=2069502.343, current_time=2069502.339, wait_time=0.003
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 962/1000 (ID: req_961)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 963: relative_arrival=19.185, absolute_arrival=2069502.351, current_time=2069502.344, wait_time=0.007
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 963/1000 (ID: req_962)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 964: relative_arrival=19.193, absolute_arrival=2069502.360, current_time=2069502.353, wait_time=0.007
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_173 received DONE after 98 chunks
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_173 completed: 375 chars, 98 chunks, TTFT=67.2ms
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_177 received DONE after 79 chunks
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_177 completed: 300 chars, 79 chunks, TTFT=45.0ms
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_186 to http://localhost:30000/generate at 1753373061.1140313
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_186 with payload: {'text': 'Random prompt 186 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_187 to http://localhost:30000/generate at 1753373061.1149132
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_187 with payload: {'text': 'Random prompt 187 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 964/1000 (ID: req_963)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 965: relative_arrival=19.270, absolute_arrival=2069502.436, current_time=2069502.361, wait_time=0.076
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_186
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_186
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_187
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_187
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] Prefill batch. #new-seq: 2, #new-token: 601, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 965/1000 (ID: req_964)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 966: relative_arrival=19.309, absolute_arrival=2069502.475, current_time=2069502.438, wait_time=0.038
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 966/1000 (ID: req_965)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 967: relative_arrival=19.333, absolute_arrival=2069502.499, current_time=2069502.476, wait_time=0.023
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 967/1000 (ID: req_966)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 968: relative_arrival=19.359, absolute_arrival=2069502.525, current_time=2069502.501, wait_time=0.025
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_167 received DONE after 130 chunks
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_167 completed: 502 chars, 130 chunks, TTFT=54.5ms
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_188 to http://localhost:30000/generate at 1753373061.26789
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_188 with payload: {'text': 'Random prompt 188 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_188
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_188
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] Prefill batch. #new-seq: 1, #new-token: 261, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 968/1000 (ID: req_967)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 969: relative_arrival=19.375, absolute_arrival=2069502.542, current_time=2069502.526, wait_time=0.016
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 969/1000 (ID: req_968)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 970: relative_arrival=19.434, absolute_arrival=2069502.601, current_time=2069502.543, wait_time=0.058
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] Decode batch. #running-req: 20, #token: 6699, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1236.82, #queue-req: 0,
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 970/1000 (ID: req_969)
[2025-07-25 00:04:21] [__main__] [INFO] Progress: 970/1000 requests sent in 19.4s
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 971: relative_arrival=19.448, absolute_arrival=2069502.614, current_time=2069502.602, wait_time=0.013
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 971/1000 (ID: req_970)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 972: relative_arrival=19.458, absolute_arrival=2069502.624, current_time=2069502.615, wait_time=0.009
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 972/1000 (ID: req_971)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 973: relative_arrival=19.461, absolute_arrival=2069502.628, current_time=2069502.625, wait_time=0.002
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 973/1000 (ID: req_972)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 974: relative_arrival=19.492, absolute_arrival=2069502.658, current_time=2069502.629, wait_time=0.030
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 974/1000 (ID: req_973)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 975: relative_arrival=19.518, absolute_arrival=2069502.685, current_time=2069502.660, wait_time=0.025
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_163 received DONE after 160 chunks
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_163 completed: 636 chars, 160 chunks, TTFT=73.2ms
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_189 to http://localhost:30000/generate at 1753373061.4434474
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_189 with payload: {'text': 'Random prompt 189 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 975/1000 (ID: req_974)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 976: relative_arrival=19.528, absolute_arrival=2069502.695, current_time=2069502.686, wait_time=0.008
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_189
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_189
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 976/1000 (ID: req_975)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 977: relative_arrival=19.529, absolute_arrival=2069502.695, current_time=2069502.696, wait_time=-0.001
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 977/1000 (ID: req_976)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 978: relative_arrival=19.565, absolute_arrival=2069502.732, current_time=2069502.696, wait_time=0.035
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 978/1000 (ID: req_977)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 979: relative_arrival=19.565, absolute_arrival=2069502.732, current_time=2069502.733, wait_time=-0.001
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 979/1000 (ID: req_978)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 980: relative_arrival=19.590, absolute_arrival=2069502.756, current_time=2069502.733, wait_time=0.023
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 980/1000 (ID: req_979)
[2025-07-25 00:04:21] [__main__] [INFO] Progress: 980/1000 requests sent in 19.6s
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 981: relative_arrival=19.660, absolute_arrival=2069502.827, current_time=2069502.757, wait_time=0.070
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 981/1000 (ID: req_980)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 982: relative_arrival=19.672, absolute_arrival=2069502.838, current_time=2069502.828, wait_time=0.010
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 982/1000 (ID: req_981)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 983: relative_arrival=19.677, absolute_arrival=2069502.843, current_time=2069502.839, wait_time=0.005
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 983/1000 (ID: req_982)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 984: relative_arrival=19.701, absolute_arrival=2069502.868, current_time=2069502.844, wait_time=0.023
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 984/1000 (ID: req_983)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 985: relative_arrival=19.735, absolute_arrival=2069502.902, current_time=2069502.869, wait_time=0.033
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 985/1000 (ID: req_984)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 986: relative_arrival=19.751, absolute_arrival=2069502.918, current_time=2069502.903, wait_time=0.015
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_170 received DONE after 144 chunks
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_170 completed: 427 chars, 144 chunks, TTFT=64.4ms
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_190 to http://localhost:30000/generate at 1753373061.6721544
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_190 with payload: {'text': 'Random prompt 190 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 986/1000 (ID: req_985)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 987: relative_arrival=19.819, absolute_arrival=2069502.986, current_time=2069502.919, wait_time=0.067
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_190
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_190
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] Prefill batch. #new-seq: 1, #new-token: 149, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_165 received DONE after 170 chunks
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_165 completed: 487 chars, 170 chunks, TTFT=59.7ms
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_191 to http://localhost:30000/generate at 1753373061.7180948
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_191 with payload: {'text': 'Random prompt 191 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 139, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_191
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_191
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_175 received DONE after 134 chunks
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_175 completed: 519 chars, 134 chunks, TTFT=43.0ms
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_192 to http://localhost:30000/generate at 1753373061.734584
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_192 with payload: {'text': 'Random prompt 192 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_192
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_192
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 987/1000 (ID: req_986)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 988: relative_arrival=19.820, absolute_arrival=2069502.987, current_time=2069502.987, wait_time=-0.000
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 988/1000 (ID: req_987)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 989: relative_arrival=19.834, absolute_arrival=2069503.001, current_time=2069502.987, wait_time=0.013
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 989/1000 (ID: req_988)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 990: relative_arrival=19.860, absolute_arrival=2069503.026, current_time=2069503.002, wait_time=0.024
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] Prefill batch. #new-seq: 1, #new-token: 356, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 990/1000 (ID: req_989)
[2025-07-25 00:04:21] [__main__] [INFO] Progress: 990/1000 requests sent in 19.9s
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 991: relative_arrival=19.900, absolute_arrival=2069503.066, current_time=2069503.028, wait_time=0.038
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 991/1000 (ID: req_990)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 992: relative_arrival=19.903, absolute_arrival=2069503.070, current_time=2069503.067, wait_time=0.003
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 992/1000 (ID: req_991)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 993: relative_arrival=19.936, absolute_arrival=2069503.102, current_time=2069503.071, wait_time=0.031
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_166 received DONE after 172 chunks
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_166 completed: 672 chars, 172 chunks, TTFT=42.3ms
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_172 received DONE after 146 chunks
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_172 completed: 568 chars, 146 chunks, TTFT=50.6ms
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_193 to http://localhost:30000/generate at 1753373061.8586998
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_193 with payload: {'text': 'Random prompt 193 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_194 to http://localhost:30000/generate at 1753373061.8595812
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_194 with payload: {'text': 'Random prompt 194 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 70, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 993/1000 (ID: req_992)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 994: relative_arrival=19.952, absolute_arrival=2069503.118, current_time=2069503.103, wait_time=0.016
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_193
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_193
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_194
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_194
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] Prefill batch. #new-seq: 2, #new-token: 499, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 994/1000 (ID: req_993)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 995: relative_arrival=19.962, absolute_arrival=2069503.128, current_time=2069503.120, wait_time=0.009
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_174 received DONE after 146 chunks
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_174 completed: 580 chars, 146 chunks, TTFT=73.2ms
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_195 to http://localhost:30000/generate at 1753373061.8804848
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_195 with payload: {'text': 'Random prompt 195 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_195
[2025-07-25 00:04:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_195
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 995/1000 (ID: req_994)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 996: relative_arrival=19.965, absolute_arrival=2069503.131, current_time=2069503.129, wait_time=0.002
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 996/1000 (ID: req_995)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 997: relative_arrival=20.005, absolute_arrival=2069503.171, current_time=2069503.132, wait_time=0.039
[2025-07-25 00:04:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:21] Prefill batch. #new-seq: 1, #new-token: 215, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 997/1000 (ID: req_996)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 998: relative_arrival=20.008, absolute_arrival=2069503.175, current_time=2069503.173, wait_time=0.002
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 998/1000 (ID: req_997)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 999: relative_arrival=20.016, absolute_arrival=2069503.182, current_time=2069503.175, wait_time=0.007
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 999/1000 (ID: req_998)
[2025-07-25 00:04:21] [__main__] [DEBUG] Request 1000: relative_arrival=20.022, absolute_arrival=2069503.189, current_time=2069503.183, wait_time=0.006
[2025-07-25 00:04:21] [__main__] [INFO] Sending request 1000/1000 (ID: req_999)
[2025-07-25 00:04:21] [__main__] [INFO] Progress: 1000/1000 requests sent in 20.0s
[2025-07-25 00:04:21] [__main__] [INFO] All requests sent. Waiting for 1000 requests to complete...
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] Decode batch. #running-req: 20, #token: 6365, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1197.54, #queue-req: 0,
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_184 received DONE after 78 chunks
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_184 completed: 296 chars, 78 chunks, TTFT=54.8ms
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_196 to http://localhost:30000/generate at 1753373062.140374
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_196 with payload: {'text': 'Random prompt 196 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_196
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_196
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] Prefill batch. #new-seq: 1, #new-token: 311, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_181 received DONE after 109 chunks
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_181 completed: 108 chars, 109 chunks, TTFT=47.6ms
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_197 to http://localhost:30000/generate at 1753373062.1949875
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_197 with payload: {'text': 'Random prompt 197 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_197
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_197
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_187 received DONE after 74 chunks
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_187 completed: 292 chars, 74 chunks, TTFT=75.3ms
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_198 to http://localhost:30000/generate at 1753373062.333872
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_198 with payload: {'text': 'Random prompt 198 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 160, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_198
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_198
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] Prefill batch. #new-seq: 1, #new-token: 352, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_176 received DONE after 165 chunks
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_176 completed: 644 chars, 165 chunks, TTFT=46.3ms
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_179 received DONE after 134 chunks
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_179 completed: 532 chars, 134 chunks, TTFT=42.9ms
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_199 to http://localhost:30000/generate at 1753373062.436863
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_199 with payload: {'text': 'Random prompt 199 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_200 to http://localhost:30000/generate at 1753373062.4373803
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_200 with payload: {'text': 'Random prompt 200 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_199
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_199
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_200
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_200
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] Prefill batch. #new-seq: 2, #new-token: 614, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_171 received DONE after 191 chunks
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_171 completed: 760 chars, 191 chunks, TTFT=45.0ms
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_201 to http://localhost:30000/generate at 1753373062.5796156
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_201 with payload: {'text': 'Random prompt 201 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_201
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_201
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] Decode batch. #running-req: 20, #token: 6988, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1224.49, #queue-req: 0,
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_178 received DONE after 162 chunks
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_178 completed: 478 chars, 162 chunks, TTFT=60.2ms
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_202 to http://localhost:30000/generate at 1753373062.7487707
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_202 with payload: {'text': 'Random prompt 202 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_202
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_202
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_182 received DONE after 146 chunks
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_182 completed: 427 chars, 146 chunks, TTFT=59.5ms
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_203 to http://localhost:30000/generate at 1753373062.868893
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_203 with payload: {'text': 'Random prompt 203 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 105, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_203
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_203
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_190 received DONE after 74 chunks
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_190 completed: 288 chars, 74 chunks, TTFT=46.8ms
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_204 to http://localhost:30000/generate at 1753373062.9372888
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_204 with payload: {'text': 'Random prompt 204 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_204
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_204
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] Prefill batch. #new-seq: 1, #new-token: 280, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_188 received DONE after 104 chunks
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_188 completed: 400 chars, 104 chunks, TTFT=47.8ms
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_205 to http://localhost:30000/generate at 1753373062.9479284
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_205 with payload: {'text': 'Random prompt 205 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_205
[2025-07-25 00:04:22] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_205
[2025-07-25 00:04:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:22] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 6, token usage: 0.06, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_194 received DONE after 71 chunks
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_194 completed: 267 chars, 71 chunks, TTFT=88.2ms
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_206 to http://localhost:30000/generate at 1753373063.0638146
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_206 with payload: {'text': 'Random prompt 206 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_206
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_206
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] Decode batch. #running-req: 20, #token: 6961, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1291.48, #queue-req: 0,
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_180 received DONE after 188 chunks
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_180 completed: 748 chars, 188 chunks, TTFT=57.6ms
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_207 to http://localhost:30000/generate at 1753373063.40262
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_207 with payload: {'text': 'Random prompt 207 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 121, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_207
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_207
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] Prefill batch. #new-seq: 1, #new-token: 295, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_192 received DONE after 109 chunks
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_192 completed: 319 chars, 109 chunks, TTFT=67.7ms
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_208 to http://localhost:30000/generate at 1753373063.4914982
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_208 with payload: {'text': 'Random prompt 208 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_208
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_208
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] Prefill batch. #new-seq: 1, #new-token: 126, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_186 received DONE after 153 chunks
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_186 completed: 608 chars, 153 chunks, TTFT=76.4ms
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_209 to http://localhost:30000/generate at 1753373063.5747092
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_209 with payload: {'text': 'Random prompt 209 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_209
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_209
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_201 received DONE after 68 chunks
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_201 completed: 67 chars, 68 chunks, TTFT=41.8ms
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_210 to http://localhost:30000/generate at 1753373063.6359975
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_210 with payload: {'text': 'Random prompt 210 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_210
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_210
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_183 received DONE after 184 chunks
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_183 completed: 547 chars, 184 chunks, TTFT=59.8ms
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_211 to http://localhost:30000/generate at 1753373063.6598032
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_211 with payload: {'text': 'Random prompt 211 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_211
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_211
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] Prefill batch. #new-seq: 1, #new-token: 302, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_199 received DONE after 82 chunks
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_199 completed: 309 chars, 82 chunks, TTFT=76.5ms
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_212 to http://localhost:30000/generate at 1753373063.7785609
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_212 with payload: {'text': 'Random prompt 212 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_212
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_212
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_202 received DONE after 68 chunks
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_202 completed: 256 chars, 68 chunks, TTFT=45.9ms
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_213 to http://localhost:30000/generate at 1753373063.870091
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_213 with payload: {'text': 'Random prompt 213 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_213
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_213
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] Decode batch. #running-req: 20, #token: 6648, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1175.35, #queue-req: 0,
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_189 received DONE after 156 chunks
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_189 completed: 607 chars, 156 chunks, TTFT=43.5ms
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_214 to http://localhost:30000/generate at 1753373063.988142
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_214 with payload: {'text': 'Random prompt 214 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_214
[2025-07-25 00:04:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_214
[2025-07-25 00:04:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:23] Prefill batch. #new-seq: 1, #new-token: 307, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_191 received DONE after 140 chunks
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_191 completed: 411 chars, 140 chunks, TTFT=72.1ms
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_215 to http://localhost:30000/generate at 1753373064.0545647
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_215 with payload: {'text': 'Random prompt 215 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:24] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_215
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_215
[2025-07-25 00:04:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:24] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_185 received DONE after 185 chunks
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_185 completed: 724 chars, 185 chunks, TTFT=47.5ms
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_216 to http://localhost:30000/generate at 1753373064.066849
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_216 with payload: {'text': 'Random prompt 216 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:24] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_216
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_216
[2025-07-25 00:04:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:24] Prefill batch. #new-seq: 1, #new-token: 208, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_193 received DONE after 144 chunks
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_193 completed: 560 chars, 144 chunks, TTFT=95.7ms
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_217 to http://localhost:30000/generate at 1753373064.235032
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_217 with payload: {'text': 'Random prompt 217 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:24] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_217
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_217
[2025-07-25 00:04:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:24] Prefill batch. #new-seq: 1, #new-token: 316, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:24] Decode batch. #running-req: 20, #token: 6717, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1351.67, #queue-req: 0,
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_203 received DONE after 106 chunks
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_203 completed: 312 chars, 106 chunks, TTFT=49.4ms
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_218 to http://localhost:30000/generate at 1753373064.5520616
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_218 with payload: {'text': 'Random prompt 218 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:24] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_218
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_218
[2025-07-25 00:04:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:24] Prefill batch. #new-seq: 1, #new-token: 291, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_195 received DONE after 177 chunks
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_195 completed: 692 chars, 177 chunks, TTFT=74.1ms
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_219 to http://localhost:30000/generate at 1753373064.6928701
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_219 with payload: {'text': 'Random prompt 219 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:24] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_219
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_219
[2025-07-25 00:04:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:24] Prefill batch. #new-seq: 1, #new-token: 343, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_198 received DONE after 161 chunks
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_198 completed: 589 chars, 161 chunks, TTFT=59.4ms
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_220 to http://localhost:30000/generate at 1753373064.8813753
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_220 with payload: {'text': 'Random prompt 220 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:24] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_220
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_220
[2025-07-25 00:04:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:24] Prefill batch. #new-seq: 1, #new-token: 293, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_204 received DONE after 128 chunks
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_204 completed: 508 chars, 128 chunks, TTFT=66.9ms
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_221 to http://localhost:30000/generate at 1753373064.9479578
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_221 with payload: {'text': 'Random prompt 221 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:24] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_221
[2025-07-25 00:04:24] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_221
[2025-07-25 00:04:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:24] Prefill batch. #new-seq: 1, #new-token: 271, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_200 received DONE after 162 chunks
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_200 completed: 644 chars, 162 chunks, TTFT=75.9ms
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_222 to http://localhost:30000/generate at 1753373065.026692
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_222 with payload: {'text': 'Random prompt 222 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_222
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_222
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] Prefill batch. #new-seq: 1, #new-token: 149, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_208 received DONE after 100 chunks
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_208 completed: 396 chars, 100 chunks, TTFT=45.6ms
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_223 to http://localhost:30000/generate at 1753373065.1099355
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_223 with payload: {'text': 'Random prompt 223 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_223
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_223
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] Prefill batch. #new-seq: 1, #new-token: 219, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_212 received DONE after 86 chunks
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_212 completed: 328 chars, 86 chunks, TTFT=47.9ms
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_224 to http://localhost:30000/generate at 1753373065.122602
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_224 with payload: {'text': 'Random prompt 224 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 118, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_224
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_224
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] Prefill batch. #new-seq: 1, #new-token: 193, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] Decode batch. #running-req: 20, #token: 6449, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1168.66, #queue-req: 0,
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_196 received DONE after 190 chunks
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_196 completed: 562 chars, 190 chunks, TTFT=62.1ms
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_225 to http://localhost:30000/generate at 1753373065.2361097
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_225 with payload: {'text': 'Random prompt 225 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_225
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_225
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_197 received DONE after 189 chunks
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_197 completed: 713 chars, 189 chunks, TTFT=58.3ms
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_226 to http://localhost:30000/generate at 1753373065.246428
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_226 with payload: {'text': 'Random prompt 226 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_216 received DONE after 76 chunks
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_216 completed: 300 chars, 76 chunks, TTFT=55.0ms
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_227 to http://localhost:30000/generate at 1753373065.2487473
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_227 with payload: {'text': 'Random prompt 227 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] Prefill batch. #new-seq: 1, #new-token: 188, #cached-token: 6, token usage: 0.04, #running-req: 17, #queue-req: 0,
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_226
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_226
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_227
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_227
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] Prefill batch. #new-seq: 2, #new-token: 600, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_207 received DONE after 122 chunks
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_207 completed: 363 chars, 122 chunks, TTFT=59.0ms
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_228 to http://localhost:30000/generate at 1753373065.449537
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_228 with payload: {'text': 'Random prompt 228 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_228
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_228
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] Prefill batch. #new-seq: 1, #new-token: 353, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_206 received DONE after 152 chunks
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_206 completed: 592 chars, 152 chunks, TTFT=53.1ms
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_229 to http://localhost:30000/generate at 1753373065.527581
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_229 with payload: {'text': 'Random prompt 229 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_229
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_229
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_215 received DONE after 93 chunks
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_215 completed: 354 chars, 93 chunks, TTFT=63.8ms
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_230 to http://localhost:30000/generate at 1753373065.5715406
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_230 with payload: {'text': 'Random prompt 230 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 178, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_230
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_230
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] Prefill batch. #new-seq: 1, #new-token: 329, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_205 received DONE after 164 chunks
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_205 completed: 652 chars, 164 chunks, TTFT=59.5ms
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_231 to http://localhost:30000/generate at 1753373065.6459434
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_231 with payload: {'text': 'Random prompt 231 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_231
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_231
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] Prefill batch. #new-seq: 1, #new-token: 254, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_210 received DONE after 120 chunks
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_210 completed: 464 chars, 120 chunks, TTFT=78.9ms
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_232 to http://localhost:30000/generate at 1753373065.6914723
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_232 with payload: {'text': 'Random prompt 232 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 91, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_232
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_232
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] Prefill batch. #new-seq: 1, #new-token: 273, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_211 received DONE after 123 chunks
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_211 completed: 488 chars, 123 chunks, TTFT=64.4ms
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_233 to http://localhost:30000/generate at 1753373065.7610538
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_233 with payload: {'text': 'Random prompt 233 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_233
[2025-07-25 00:04:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_233
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:25] Decode batch. #running-req: 20, #token: 6351, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1094.70, #queue-req: 0,
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_221 received DONE after 84 chunks
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_221 completed: 320 chars, 84 chunks, TTFT=48.0ms
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_234 to http://localhost:30000/generate at 1753373066.3034225
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_234 with payload: {'text': 'Random prompt 234 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_219 received DONE after 100 chunks
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_219 completed: 295 chars, 100 chunks, TTFT=49.2ms
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_235 to http://localhost:30000/generate at 1753373066.3053186
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_235 with payload: {'text': 'Random prompt 235 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_234
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_234
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_235
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_235
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] Prefill batch. #new-seq: 2, #new-token: 485, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_214 received DONE after 154 chunks
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_214 completed: 612 chars, 154 chunks, TTFT=48.4ms
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_236 to http://localhost:30000/generate at 1753373066.4263248
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_236 with payload: {'text': 'Random prompt 236 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_236
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_236
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] Decode batch. #running-req: 19, #token: 6552, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1468.77, #queue-req: 0,
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_213 received DONE after 167 chunks
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_213 completed: 651 chars, 167 chunks, TTFT=41.8ms
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_237 to http://localhost:30000/generate at 1753373066.5101
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_237 with payload: {'text': 'Random prompt 237 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_237
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_237
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_217 received DONE after 152 chunks
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_217 completed: 592 chars, 152 chunks, TTFT=47.9ms
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_238 to http://localhost:30000/generate at 1753373066.6186006
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_238 with payload: {'text': 'Random prompt 238 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_238
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_238
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_209 received DONE after 193 chunks
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_209 completed: 768 chars, 193 chunks, TTFT=47.8ms
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_239 to http://localhost:30000/generate at 1753373066.6939313
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_239 with payload: {'text': 'Random prompt 239 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_239
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_239
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_233 received DONE after 69 chunks
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_233 completed: 260 chars, 69 chunks, TTFT=43.2ms
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_240 to http://localhost:30000/generate at 1753373066.7547507
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_240 with payload: {'text': 'Random prompt 240 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_240
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_240
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] Prefill batch. #new-seq: 1, #new-token: 366, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_227 received DONE after 100 chunks
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_227 completed: 383 chars, 100 chunks, TTFT=87.7ms
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_241 to http://localhost:30000/generate at 1753373066.8586981
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_241 with payload: {'text': 'Random prompt 241 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_241
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_241
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] Prefill batch. #new-seq: 1, #new-token: 369, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_218 received DONE after 149 chunks
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_218 completed: 592 chars, 149 chunks, TTFT=49.9ms
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_222 received DONE after 120 chunks
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_222 completed: 119 chars, 120 chunks, TTFT=43.3ms
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_242 to http://localhost:30000/generate at 1753373066.9859269
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_242 with payload: {'text': 'Random prompt 242 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_243 to http://localhost:30000/generate at 1753373066.9867263
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_243 with payload: {'text': 'Random prompt 243 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_242
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_242
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_243
[2025-07-25 00:04:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_243
[2025-07-25 00:04:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:26] Prefill batch. #new-seq: 2, #new-token: 579, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_224 received DONE after 119 chunks
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_224 completed: 460 chars, 119 chunks, TTFT=57.5ms
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_244 to http://localhost:30000/generate at 1753373067.0797546
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_244 with payload: {'text': 'Random prompt 244 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:27] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_244
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_244
[2025-07-25 00:04:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:27] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_231 received DONE after 94 chunks
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_231 completed: 359 chars, 94 chunks, TTFT=46.9ms
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_245 to http://localhost:30000/generate at 1753373067.1259794
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_245 with payload: {'text': 'Random prompt 245 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_232 received DONE after 92 chunks
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_232 completed: 351 chars, 92 chunks, TTFT=51.5ms
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_246 to http://localhost:30000/generate at 1753373067.1278105
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_246 with payload: {'text': 'Random prompt 246 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:27] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_245
[2025-07-25 00:04:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:27] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_245
[2025-07-25 00:04:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:27] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 6, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_246
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_246
[2025-07-25 00:04:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:27] Prefill batch. #new-seq: 1, #new-token: 235, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_226 received DONE after 116 chunks
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_226 completed: 339 chars, 116 chunks, TTFT=89.8ms
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_247 to http://localhost:30000/generate at 1753373067.1732538
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_247 with payload: {'text': 'Random prompt 247 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:27] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_247
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_247
[2025-07-25 00:04:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:27] Prefill batch. #new-seq: 1, #new-token: 373, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:27] Decode batch. #running-req: 20, #token: 6329, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1004.97, #queue-req: 0,
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_229 received DONE after 117 chunks
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_229 completed: 451 chars, 117 chunks, TTFT=49.9ms
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_248 to http://localhost:30000/generate at 1753373067.4337838
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_248 with payload: {'text': 'Random prompt 248 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 182, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:27] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_248
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_248
[2025-07-25 00:04:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:27] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_225 received DONE after 147 chunks
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_225 completed: 572 chars, 147 chunks, TTFT=74.3ms
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_249 to http://localhost:30000/generate at 1753373067.6466274
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_249 with payload: {'text': 'Random prompt 249 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:27] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_249
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_249
[2025-07-25 00:04:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:27] Prefill batch. #new-seq: 1, #new-token: 343, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:27] Decode batch. #running-req: 20, #token: 7103, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1455.33, #queue-req: 0,
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_220 received DONE after 187 chunks
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_220 completed: 744 chars, 187 chunks, TTFT=48.7ms
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_250 to http://localhost:30000/generate at 1753373067.9344149
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_250 with payload: {'text': 'Random prompt 250 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:27] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_250
[2025-07-25 00:04:27] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_250
[2025-07-25 00:04:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:27] Prefill batch. #new-seq: 1, #new-token: 201, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_223 received DONE after 186 chunks
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_223 completed: 740 chars, 186 chunks, TTFT=66.8ms
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_251 to http://localhost:30000/generate at 1753373068.092305
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_251 with payload: {'text': 'Random prompt 251 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:28] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_251
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_251
[2025-07-25 00:04:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:28] Prefill batch. #new-seq: 1, #new-token: 224, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_239 received DONE after 89 chunks
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_239 completed: 352 chars, 89 chunks, TTFT=44.7ms
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_252 to http://localhost:30000/generate at 1753373068.1052952
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_252 with payload: {'text': 'Random prompt 252 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 79, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:28] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_252
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_252
[2025-07-25 00:04:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:28] Prefill batch. #new-seq: 1, #new-token: 343, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_235 received DONE after 112 chunks
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_235 completed: 432 chars, 112 chunks, TTFT=66.4ms
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_253 to http://localhost:30000/generate at 1753373068.1374078
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_253 with payload: {'text': 'Random prompt 253 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:28] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_253
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_253
[2025-07-25 00:04:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:28] Prefill batch. #new-seq: 1, #new-token: 206, #cached-token: 6, token usage: 0.06, #running-req: 21, #queue-req: 0,
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_247 received DONE after 69 chunks
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_247 completed: 260 chars, 69 chunks, TTFT=61.0ms
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_254 to http://localhost:30000/generate at 1753373068.2231274
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_254 with payload: {'text': 'Random prompt 254 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:28] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_254
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_254
[2025-07-25 00:04:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:28] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_246 received DONE after 82 chunks
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_246 completed: 312 chars, 82 chunks, TTFT=95.4ms
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_230 received DONE after 179 chunks
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_230 completed: 529 chars, 179 chunks, TTFT=57.7ms
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_255 to http://localhost:30000/generate at 1753373068.4068842
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_255 with payload: {'text': 'Random prompt 255 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_256 to http://localhost:30000/generate at 1753373068.407668
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_256 with payload: {'text': 'Random prompt 256 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:28] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:28] Decode batch. #running-req: 20, #token: 6217, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1287.98, #queue-req: 0,
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_255
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_255
[2025-07-25 00:04:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:28] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_256
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_256
[2025-07-25 00:04:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:28] Prefill batch. #new-seq: 2, #new-token: 633, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_228 received DONE after 191 chunks
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_228 completed: 760 chars, 191 chunks, TTFT=59.8ms
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_257 to http://localhost:30000/generate at 1753373068.5366542
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_257 with payload: {'text': 'Random prompt 257 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:28] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_257
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_257
[2025-07-25 00:04:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:28] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_237 received DONE after 126 chunks
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_237 completed: 500 chars, 126 chunks, TTFT=43.3ms
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_258 to http://localhost:30000/generate at 1753373068.6054153
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_258 with payload: {'text': 'Random prompt 258 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:28] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_258
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_258
[2025-07-25 00:04:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:28] Prefill batch. #new-seq: 1, #new-token: 271, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_234 received DONE after 148 chunks
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_234 completed: 576 chars, 148 chunks, TTFT=68.1ms
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_259 to http://localhost:30000/generate at 1753373068.7667158
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_259 with payload: {'text': 'Random prompt 259 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 138, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:28] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_259
[2025-07-25 00:04:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_259
[2025-07-25 00:04:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:28] Prefill batch. #new-seq: 1, #new-token: 150, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] Decode batch. #running-req: 20, #token: 7246, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1281.98, #queue-req: 0,
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_236 received DONE after 176 chunks
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_236 completed: 688 chars, 176 chunks, TTFT=41.8ms
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_260 to http://localhost:30000/generate at 1753373069.208829
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_260 with payload: {'text': 'Random prompt 260 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 98, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_260
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_260
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_252 received DONE after 80 chunks
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_252 completed: 229 chars, 80 chunks, TTFT=82.6ms
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_261 to http://localhost:30000/generate at 1753373069.3350554
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_261 with payload: {'text': 'Random prompt 261 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_245 received DONE after 145 chunks
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_245 completed: 426 chars, 145 chunks, TTFT=71.8ms
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_262 to http://localhost:30000/generate at 1753373069.3373911
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_262 with payload: {'text': 'Random prompt 262 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 104, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_261
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_261
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_262
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_262
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] Prefill batch. #new-seq: 2, #new-token: 540, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_253 received DONE after 81 chunks
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_253 completed: 320 chars, 81 chunks, TTFT=55.8ms
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_263 to http://localhost:30000/generate at 1753373069.347141
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_263 with payload: {'text': 'Random prompt 263 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_263
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_263
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 6, token usage: 0.06, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_241 received DONE after 164 chunks
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_241 completed: 652 chars, 164 chunks, TTFT=60.3ms
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_264 to http://localhost:30000/generate at 1753373069.487063
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_264 with payload: {'text': 'Random prompt 264 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_264
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_264
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_240 received DONE after 176 chunks
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_240 completed: 506 chars, 176 chunks, TTFT=48.9ms
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_265 to http://localhost:30000/generate at 1753373069.5780673
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_265 with payload: {'text': 'Random prompt 265 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_265
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_265
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] Prefill batch. #new-seq: 1, #new-token: 315, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_242 received DONE after 164 chunks
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_242 completed: 652 chars, 164 chunks, TTFT=64.0ms
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_266 to http://localhost:30000/generate at 1753373069.6225512
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_266 with payload: {'text': 'Random prompt 266 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_266
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_266
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] Prefill batch. #new-seq: 1, #new-token: 304, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_244 received DONE after 162 chunks
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_244 completed: 163 chars, 162 chunks, TTFT=48.8ms
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_267 to http://localhost:30000/generate at 1753373069.6884634
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_267 with payload: {'text': 'Random prompt 267 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_267
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_267
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] Prefill batch. #new-seq: 1, #new-token: 305, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] Decode batch. #running-req: 20, #token: 6445, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1101.55, #queue-req: 0,
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_238 received DONE after 189 chunks
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_238 completed: 752 chars, 189 chunks, TTFT=57.6ms
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_268 to http://localhost:30000/generate at 1753373069.7550914
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_268 with payload: {'text': 'Random prompt 268 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_268
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_268
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] Prefill batch. #new-seq: 1, #new-token: 217, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_258 received DONE after 73 chunks
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_258 completed: 276 chars, 73 chunks, TTFT=57.6ms
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_269 to http://localhost:30000/generate at 1753373069.8157136
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_269 with payload: {'text': 'Random prompt 269 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 101, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_269
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_269
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] Prefill batch. #new-seq: 1, #new-token: 200, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_243 received DONE after 173 chunks
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_243 completed: 675 chars, 173 chunks, TTFT=63.4ms
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_270 to http://localhost:30000/generate at 1753373069.8283782
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_270 with payload: {'text': 'Random prompt 270 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_270
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_270
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_256 received DONE after 91 chunks
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_256 completed: 347 chars, 91 chunks, TTFT=74.3ms
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_271 to http://localhost:30000/generate at 1753373069.9697046
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_271 with payload: {'text': 'Random prompt 271 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 174, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_271
[2025-07-25 00:04:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_271
[2025-07-25 00:04:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:29] Prefill batch. #new-seq: 1, #new-token: 333, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_249 received DONE after 144 chunks
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_249 completed: 572 chars, 144 chunks, TTFT=59.4ms
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_272 to http://localhost:30000/generate at 1753373070.049089
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_272 with payload: {'text': 'Random prompt 272 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_272
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_272
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] Prefill batch. #new-seq: 1, #new-token: 347, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_251 received DONE after 127 chunks
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_251 completed: 492 chars, 127 chunks, TTFT=67.1ms
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_273 to http://localhost:30000/generate at 1753373070.2491932
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_273 with payload: {'text': 'Random prompt 273 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_273
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_273
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_248 received DONE after 183 chunks
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_248 completed: 520 chars, 183 chunks, TTFT=60.2ms
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_274 to http://localhost:30000/generate at 1753373070.40206
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_274 with payload: {'text': 'Random prompt 274 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_274
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_274
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] Decode batch. #running-req: 20, #token: 6058, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1201.55, #queue-req: 0,
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] Prefill batch. #new-seq: 1, #new-token: 256, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_255 received DONE after 120 chunks
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_255 completed: 431 chars, 120 chunks, TTFT=75.3ms
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_275 to http://localhost:30000/generate at 1753373070.4166212
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_275 with payload: {'text': 'Random prompt 275 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_275
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_275
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] Prefill batch. #new-seq: 1, #new-token: 254, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_257 received DONE after 128 chunks
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_257 completed: 508 chars, 128 chunks, TTFT=48.9ms
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_276 to http://localhost:30000/generate at 1753373070.6354425
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_276 with payload: {'text': 'Random prompt 276 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 95, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_276
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_276
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_264 received DONE after 66 chunks
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_264 completed: 191 chars, 66 chunks, TTFT=60.5ms
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_277 to http://localhost:30000/generate at 1753373070.6488369
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_277 with payload: {'text': 'Random prompt 277 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] Prefill batch. #new-seq: 1, #new-token: 329, #cached-token: 6, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_277
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_277
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_250 received DONE after 167 chunks
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_250 completed: 651 chars, 167 chunks, TTFT=44.4ms
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_278 to http://localhost:30000/generate at 1753373070.7436454
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_278 with payload: {'text': 'Random prompt 278 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 82, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_278
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_278
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_254 received DONE after 153 chunks
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_254 completed: 596 chars, 153 chunks, TTFT=45.2ms
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_279 to http://localhost:30000/generate at 1753373070.7558644
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_279 with payload: {'text': 'Random prompt 279 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] Prefill batch. #new-seq: 1, #new-token: 305, #cached-token: 6, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_279
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_279
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] Prefill batch. #new-seq: 1, #new-token: 329, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_265 received DONE after 74 chunks
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_265 completed: 209 chars, 74 chunks, TTFT=49.1ms
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_280 to http://localhost:30000/generate at 1753373070.9143827
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_280 with payload: {'text': 'Random prompt 280 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_280
[2025-07-25 00:04:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_280
[2025-07-25 00:04:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:30] Prefill batch. #new-seq: 1, #new-token: 353, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_260 received DONE after 99 chunks
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_260 completed: 292 chars, 99 chunks, TTFT=47.3ms
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_281 to http://localhost:30000/generate at 1753373071.0180883
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_281 with payload: {'text': 'Random prompt 281 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 154, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_281
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_281
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] Prefill batch. #new-seq: 1, #new-token: 212, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_259 received DONE after 139 chunks
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_259 completed: 540 chars, 139 chunks, TTFT=43.5ms
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_282 to http://localhost:30000/generate at 1753373071.114531
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_282 with payload: {'text': 'Random prompt 282 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 136, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] Decode batch. #running-req: 20, #token: 6586, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1107.18, #queue-req: 0,
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_282
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_282
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] Prefill batch. #new-seq: 1, #new-token: 221, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_262 received DONE after 105 chunks
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_262 completed: 403 chars, 105 chunks, TTFT=85.2ms
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_283 to http://localhost:30000/generate at 1753373071.2367985
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_283 with payload: {'text': 'Random prompt 283 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_283
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_283
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] Prefill batch. #new-seq: 1, #new-token: 149, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_273 received DONE after 70 chunks
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_273 completed: 207 chars, 70 chunks, TTFT=60.4ms
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_284 to http://localhost:30000/generate at 1753373071.4182792
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_284 with payload: {'text': 'Random prompt 284 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_284
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_284
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] Prefill batch. #new-seq: 1, #new-token: 273, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_269 received DONE after 102 chunks
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_269 completed: 404 chars, 102 chunks, TTFT=65.1ms
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_285 to http://localhost:30000/generate at 1753373071.5094914
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_285 with payload: {'text': 'Random prompt 285 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_263 received DONE after 123 chunks
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_263 completed: 475 chars, 123 chunks, TTFT=83.7ms
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_286 to http://localhost:30000/generate at 1753373071.5113475
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_286 with payload: {'text': 'Random prompt 286 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_285
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_285
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_286
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_286
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] Prefill batch. #new-seq: 2, #new-token: 378, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_266 received DONE after 115 chunks
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_266 completed: 338 chars, 115 chunks, TTFT=47.1ms
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_287 to http://localhost:30000/generate at 1753373071.5875032
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_287 with payload: {'text': 'Random prompt 287 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_287
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_287
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] Prefill batch. #new-seq: 1, #new-token: 264, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_275 received DONE after 78 chunks
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_275 completed: 296 chars, 78 chunks, TTFT=54.9ms
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_288 to http://localhost:30000/generate at 1753373071.715374
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_288 with payload: {'text': 'Random prompt 288 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_288
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_288
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] Prefill batch. #new-seq: 1, #new-token: 198, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] Decode batch. #running-req: 20, #token: 6738, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1221.25, #queue-req: 0,
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_267 received DONE after 126 chunks
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_267 completed: 375 chars, 126 chunks, TTFT=47.8ms
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_289 to http://localhost:30000/generate at 1753373071.812071
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_289 with payload: {'text': 'Random prompt 289 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_289
[2025-07-25 00:04:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_289
[2025-07-25 00:04:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:31] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_278 received DONE after 83 chunks
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_278 completed: 246 chars, 83 chunks, TTFT=80.9ms
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_290 to http://localhost:30000/generate at 1753373072.071824
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_290 with payload: {'text': 'Random prompt 290 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_268 received DONE after 142 chunks
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_268 completed: 552 chars, 142 chunks, TTFT=42.8ms
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_291 to http://localhost:30000/generate at 1753373072.0727842
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_291 with payload: {'text': 'Random prompt 291 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_290
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_290
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] Prefill batch. #new-seq: 1, #new-token: 133, #cached-token: 6, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_291
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_291
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_261 received DONE after 167 chunks
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_261 completed: 498 chars, 167 chunks, TTFT=87.4ms
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_292 to http://localhost:30000/generate at 1753373072.203351
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_292 with payload: {'text': 'Random prompt 292 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 137, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_292
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_292
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_276 received DONE after 96 chunks
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_276 completed: 380 chars, 96 chunks, TTFT=79.7ms
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_293 to http://localhost:30000/generate at 1753373072.2477026
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_293 with payload: {'text': 'Random prompt 293 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_293
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_293
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] Prefill batch. #new-seq: 1, #new-token: 217, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_283 received DONE after 66 chunks
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_283 completed: 65 chars, 66 chunks, TTFT=43.6ms
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_294 to http://localhost:30000/generate at 1753373072.3015988
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_294 with payload: {'text': 'Random prompt 294 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_294
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_294
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_270 received DONE after 154 chunks
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_270 completed: 612 chars, 154 chunks, TTFT=61.6ms
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_295 to http://localhost:30000/generate at 1753373072.3791323
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_295 with payload: {'text': 'Random prompt 295 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_295
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_295
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] Prefill batch. #new-seq: 1, #new-token: 259, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] Decode batch. #running-req: 20, #token: 6201, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1180.23, #queue-req: 0,
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_274 received DONE after 127 chunks
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_274 completed: 492 chars, 127 chunks, TTFT=65.7ms
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_296 to http://localhost:30000/generate at 1753373072.5165615
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_296 with payload: {'text': 'Random prompt 296 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_296
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_296
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] Prefill batch. #new-seq: 1, #new-token: 322, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_272 received DONE after 165 chunks
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_272 completed: 494 chars, 165 chunks, TTFT=60.4ms
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_297 to http://localhost:30000/generate at 1753373072.726189
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_297 with payload: {'text': 'Random prompt 297 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_297
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_297
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_286 received DONE after 76 chunks
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_286 completed: 300 chars, 76 chunks, TTFT=59.0ms
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_298 to http://localhost:30000/generate at 1753373072.7399712
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_298 with payload: {'text': 'Random prompt 298 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_298
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_298
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] Prefill batch. #new-seq: 1, #new-token: 285, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_288 received DONE after 69 chunks
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_288 completed: 272 chars, 69 chunks, TTFT=43.5ms
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_271 received DONE after 175 chunks
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_271 completed: 518 chars, 175 chunks, TTFT=48.1ms
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_299 to http://localhost:30000/generate at 1753373072.8445642
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_299 with payload: {'text': 'Random prompt 299 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 154, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_300 to http://localhost:30000/generate at 1753373072.844856
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_300 with payload: {'text': 'Random prompt 300 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_299
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_299
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 6, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_300
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_300
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 6, token usage: 0.04, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_279 received DONE after 129 chunks
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_279 completed: 365 chars, 129 chunks, TTFT=78.8ms
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_301 to http://localhost:30000/generate at 1753373072.8899899
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_301 with payload: {'text': 'Random prompt 301 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_301
[2025-07-25 00:04:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_301
[2025-07-25 00:04:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:32] Prefill batch. #new-seq: 1, #new-token: 261, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_289 received DONE after 75 chunks
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_289 completed: 296 chars, 75 chunks, TTFT=58.8ms
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_302 to http://localhost:30000/generate at 1753373073.0809014
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_302 with payload: {'text': 'Random prompt 302 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] Decode batch. #running-req: 20, #token: 5540, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1228.06, #queue-req: 0,
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_302
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_302
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] Prefill batch. #new-seq: 1, #new-token: 264, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_284 received DONE after 107 chunks
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_284 completed: 412 chars, 107 chunks, TTFT=47.6ms
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_303 to http://localhost:30000/generate at 1753373073.2044902
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_303 with payload: {'text': 'Random prompt 303 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_303
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_303
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] Prefill batch. #new-seq: 1, #new-token: 288, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_280 received DONE after 144 chunks
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_280 completed: 425 chars, 144 chunks, TTFT=60.9ms
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_304 to http://localhost:30000/generate at 1753373073.2918932
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_304 with payload: {'text': 'Random prompt 304 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_304
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_304
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] Prefill batch. #new-seq: 1, #new-token: 311, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_282 received DONE after 137 chunks
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_282 completed: 544 chars, 137 chunks, TTFT=44.4ms
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_305 to http://localhost:30000/generate at 1753373073.3694375
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_305 with payload: {'text': 'Random prompt 305 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_305
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_305
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_287 received DONE after 110 chunks
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_287 completed: 438 chars, 110 chunks, TTFT=48.3ms
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_306 to http://localhost:30000/generate at 1753373073.4364123
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_306 with payload: {'text': 'Random prompt 306 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_306
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_306
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] Prefill batch. #new-seq: 1, #new-token: 257, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_291 received DONE after 82 chunks
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_291 completed: 83 chars, 82 chunks, TTFT=65.2ms
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_307 to http://localhost:30000/generate at 1753373073.5249903
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_307 with payload: {'text': 'Random prompt 307 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_307
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_307
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] Prefill batch. #new-seq: 1, #new-token: 208, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_281 received DONE after 155 chunks
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_281 completed: 604 chars, 155 chunks, TTFT=53.5ms
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_308 to http://localhost:30000/generate at 1753373073.6111042
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_308 with payload: {'text': 'Random prompt 308 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_308
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_308
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] Prefill batch. #new-seq: 1, #new-token: 329, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_285 received DONE after 131 chunks
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_285 completed: 520 chars, 131 chunks, TTFT=60.9ms
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_309 to http://localhost:30000/generate at 1753373073.7369862
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_309 with payload: {'text': 'Random prompt 309 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_309
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_309
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] Prefill batch. #new-seq: 1, #new-token: 194, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] Decode batch. #running-req: 19, #token: 6084, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1126.22, #queue-req: 0,
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_277 received DONE after 191 chunks
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_277 completed: 547 chars, 191 chunks, TTFT=76.8ms
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_310 to http://localhost:30000/generate at 1753373073.8691494
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_310 with payload: {'text': 'Random prompt 310 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_310
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_310
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] Prefill batch. #new-seq: 1, #new-token: 238, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_295 received DONE after 91 chunks
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_295 completed: 336 chars, 91 chunks, TTFT=47.6ms
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_311 to http://localhost:30000/generate at 1753373073.8923838
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_311 with payload: {'text': 'Random prompt 311 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 179, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_311
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_311
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] Prefill batch. #new-seq: 1, #new-token: 145, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_296 received DONE after 86 chunks
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_296 completed: 253 chars, 86 chunks, TTFT=48.8ms
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_312 to http://localhost:30000/generate at 1753373073.9889297
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_312 with payload: {'text': 'Random prompt 312 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_312
[2025-07-25 00:04:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_312
[2025-07-25 00:04:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:33] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_300 received DONE after 69 chunks
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_300 completed: 272 chars, 69 chunks, TTFT=90.8ms
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_313 to http://localhost:30000/generate at 1753373074.0471635
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_313 with payload: {'text': 'Random prompt 313 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:34] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_313
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_313
[2025-07-25 00:04:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:34] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_290 received DONE after 116 chunks
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_290 completed: 456 chars, 116 chunks, TTFT=63.5ms
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_314 to http://localhost:30000/generate at 1753373074.1035373
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_314 with payload: {'text': 'Random prompt 314 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:34] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_314
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_314
[2025-07-25 00:04:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:34] Prefill batch. #new-seq: 1, #new-token: 339, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_297 received DONE after 78 chunks
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_297 completed: 308 chars, 78 chunks, TTFT=68.6ms
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_315 to http://localhost:30000/generate at 1753373074.1252189
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_315 with payload: {'text': 'Random prompt 315 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:34] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_315
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_315
[2025-07-25 00:04:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:34] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_302 received DONE after 72 chunks
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_302 completed: 258 chars, 72 chunks, TTFT=46.0ms
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_316 to http://localhost:30000/generate at 1753373074.37245
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_316 with payload: {'text': 'Random prompt 316 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 131, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:34] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_316
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_316
[2025-07-25 00:04:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:34] Prefill batch. #new-seq: 1, #new-token: 230, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:34] Decode batch. #running-req: 20, #token: 6372, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1106.78, #queue-req: 0,
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_292 received DONE after 138 chunks
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_292 completed: 411 chars, 138 chunks, TTFT=49.7ms
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_317 to http://localhost:30000/generate at 1753373074.593174
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_317 with payload: {'text': 'Random prompt 317 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:34] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_317
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_317
[2025-07-25 00:04:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:34] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_293 received DONE after 153 chunks
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_293 completed: 608 chars, 153 chunks, TTFT=58.6ms
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_318 to http://localhost:30000/generate at 1753373074.8215568
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_318 with payload: {'text': 'Random prompt 318 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:34] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_318
[2025-07-25 00:04:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_318
[2025-07-25 00:04:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:34] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] Decode batch. #running-req: 20, #token: 6338, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1504.57, #queue-req: 0,
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_294 received DONE after 167 chunks
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_294 completed: 652 chars, 167 chunks, TTFT=49.0ms
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_319 to http://localhost:30000/generate at 1753373075.0381331
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_319 with payload: {'text': 'Random prompt 319 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_319
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_319
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_310 received DONE after 75 chunks
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_310 completed: 284 chars, 75 chunks, TTFT=74.6ms
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_320 to http://localhost:30000/generate at 1753373075.0833497
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_320 with payload: {'text': 'Random prompt 320 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 96, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_320
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_320
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_298 received DONE after 146 chunks
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_298 completed: 430 chars, 146 chunks, TTFT=62.7ms
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_321 to http://localhost:30000/generate at 1753373075.1758027
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_321 with payload: {'text': 'Random prompt 321 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 84, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_321
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_321
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] Prefill batch. #new-seq: 1, #new-token: 308, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_308 received DONE after 108 chunks
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_308 completed: 306 chars, 108 chunks, TTFT=59.7ms
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_322 to http://localhost:30000/generate at 1753373075.3418896
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_322 with payload: {'text': 'Random prompt 322 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_322
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_322
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] Prefill batch. #new-seq: 1, #new-token: 294, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_299 received DONE after 155 chunks
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_299 completed: 603 chars, 155 chunks, TTFT=66.2ms
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_323 to http://localhost:30000/generate at 1753373075.3982544
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_323 with payload: {'text': 'Random prompt 323 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_323
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_323
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_303 received DONE after 134 chunks
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_303 completed: 532 chars, 134 chunks, TTFT=58.6ms
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_324 to http://localhost:30000/generate at 1753373075.4187217
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_324 with payload: {'text': 'Random prompt 324 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_324
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_324
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] Prefill batch. #new-seq: 1, #new-token: 370, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] Decode batch. #running-req: 20, #token: 6853, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1194.04, #queue-req: 0,
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_304 received DONE after 156 chunks
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_304 completed: 463 chars, 156 chunks, TTFT=48.9ms
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_325 to http://localhost:30000/generate at 1753373075.7992678
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_325 with payload: {'text': 'Random prompt 325 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_325
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_325
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] Prefill batch. #new-seq: 1, #new-token: 314, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_301 received DONE after 185 chunks
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_301 completed: 724 chars, 185 chunks, TTFT=53.8ms
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_326 to http://localhost:30000/generate at 1753373075.8553548
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_326 with payload: {'text': 'Random prompt 326 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_326
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_326
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] Prefill batch. #new-seq: 1, #new-token: 267, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_306 received DONE after 156 chunks
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_306 completed: 620 chars, 156 chunks, TTFT=48.8ms
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_327 to http://localhost:30000/generate at 1753373075.9436734
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_327 with payload: {'text': 'Random prompt 327 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_327
[2025-07-25 00:04:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_327
[2025-07-25 00:04:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:35] Prefill batch. #new-seq: 1, #new-token: 282, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_318 received DONE after 75 chunks
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_318 completed: 284 chars, 75 chunks, TTFT=55.5ms
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_328 to http://localhost:30000/generate at 1753373076.0348384
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_328 with payload: {'text': 'Random prompt 328 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_328
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_328
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] Prefill batch. #new-seq: 1, #new-token: 233, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_314 received DONE after 123 chunks
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_314 completed: 451 chars, 123 chunks, TTFT=78.8ms
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_329 to http://localhost:30000/generate at 1753373076.0470865
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_329 with payload: {'text': 'Random prompt 329 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_329
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_329
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_312 received DONE after 135 chunks
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_312 completed: 136 chars, 135 chunks, TTFT=42.4ms
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_330 to http://localhost:30000/generate at 1753373076.1693907
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_330 with payload: {'text': 'Random prompt 330 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 135, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_330
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_330
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] Prefill batch. #new-seq: 1, #new-token: 217, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_305 received DONE after 176 chunks
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_305 completed: 672 chars, 176 chunks, TTFT=50.3ms
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_331 to http://localhost:30000/generate at 1753373076.2538278
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_331 with payload: {'text': 'Random prompt 331 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_307 received DONE after 168 chunks
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_307 completed: 528 chars, 168 chunks, TTFT=47.9ms
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_332 to http://localhost:30000/generate at 1753373076.25571
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_332 with payload: {'text': 'Random prompt 332 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_331
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_331
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_332
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_332
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_319 received DONE after 73 chunks
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_319 completed: 275 chars, 73 chunks, TTFT=46.2ms
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_333 to http://localhost:30000/generate at 1753373076.2679708
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_333 with payload: {'text': 'Random prompt 333 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_333
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_333
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] Prefill batch. #new-seq: 2, #new-token: 448, #cached-token: 12, token usage: 0.05, #running-req: 17, #queue-req: 0,
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] Decode batch. #running-req: 20, #token: 6272, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1105.99, #queue-req: 0,
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_316 received DONE after 132 chunks
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_316 completed: 511 chars, 132 chunks, TTFT=47.0ms
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_334 to http://localhost:30000/generate at 1753373076.450937
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_334 with payload: {'text': 'Random prompt 334 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_334
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_334
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_315 received DONE after 147 chunks
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_315 completed: 584 chars, 147 chunks, TTFT=67.6ms
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_335 to http://localhost:30000/generate at 1753373076.4953249
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_335 with payload: {'text': 'Random prompt 335 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_335
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_335
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_309 received DONE after 169 chunks
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_309 completed: 672 chars, 169 chunks, TTFT=53.7ms
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_336 to http://localhost:30000/generate at 1753373076.5427463
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_336 with payload: {'text': 'Random prompt 336 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_336
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_336
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] Prefill batch. #new-seq: 1, #new-token: 344, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_321 received DONE after 85 chunks
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_321 completed: 324 chars, 85 chunks, TTFT=60.3ms
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_337 to http://localhost:30000/generate at 1753373076.6490524
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_337 with payload: {'text': 'Random prompt 337 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_337
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_337
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] Prefill batch. #new-seq: 1, #new-token: 305, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_320 received DONE after 97 chunks
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_320 completed: 347 chars, 97 chunks, TTFT=49.0ms
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_338 to http://localhost:30000/generate at 1753373076.7502077
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_338 with payload: {'text': 'Random prompt 338 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_338
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_338
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] Prefill batch. #new-seq: 1, #new-token: 247, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_313 received DONE after 170 chunks
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_313 completed: 588 chars, 170 chunks, TTFT=62.8ms
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_339 to http://localhost:30000/generate at 1753373076.856511
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_339 with payload: {'text': 'Random prompt 339 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_339
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_339
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] Prefill batch. #new-seq: 1, #new-token: 150, #cached-token: 6, token usage: 0.04, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_311 received DONE after 180 chunks
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_311 completed: 181 chars, 180 chunks, TTFT=54.6ms
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_340 to http://localhost:30000/generate at 1753373076.868249
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_340 with payload: {'text': 'Random prompt 340 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_340
[2025-07-25 00:04:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_340
[2025-07-25 00:04:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:36] Prefill batch. #new-seq: 1, #new-token: 252, #cached-token: 5, token usage: 0.04, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_323 received DONE after 93 chunks
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_323 completed: 355 chars, 93 chunks, TTFT=80.0ms
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_341 to http://localhost:30000/generate at 1753373077.0067353
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_341 with payload: {'text': 'Random prompt 341 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:37] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_341
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_341
[2025-07-25 00:04:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:37] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:37] Decode batch. #running-req: 20, #token: 5798, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1146.03, #queue-req: 0,
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_317 received DONE after 159 chunks
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_317 completed: 632 chars, 159 chunks, TTFT=44.4ms
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_342 to http://localhost:30000/generate at 1753373077.172299
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_342 with payload: {'text': 'Random prompt 342 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:37] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_342
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_342
[2025-07-25 00:04:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:37] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_326 received DONE after 88 chunks
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_326 completed: 336 chars, 88 chunks, TTFT=58.2ms
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_343 to http://localhost:30000/generate at 1753373077.3489177
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_343 with payload: {'text': 'Random prompt 343 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:37] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_343
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_343
[2025-07-25 00:04:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:37] Prefill batch. #new-seq: 1, #new-token: 236, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_325 received DONE after 108 chunks
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_325 completed: 317 chars, 108 chunks, TTFT=62.9ms
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_344 to http://localhost:30000/generate at 1753373077.5899966
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_344 with payload: {'text': 'Random prompt 344 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 159, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:37] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_344
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_344
[2025-07-25 00:04:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:37] Prefill batch. #new-seq: 1, #new-token: 227, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:37] Decode batch. #running-req: 20, #token: 6124, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1452.47, #queue-req: 0,
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_332 received DONE after 94 chunks
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_332 completed: 97 chars, 94 chunks, TTFT=87.7ms
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_345 to http://localhost:30000/generate at 1753373077.7338839
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_345 with payload: {'text': 'Random prompt 345 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 118, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:37] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_345
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_345
[2025-07-25 00:04:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:37] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_338 received DONE after 74 chunks
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_338 completed: 280 chars, 74 chunks, TTFT=53.3ms
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_346 to http://localhost:30000/generate at 1753373077.8484652
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_346 with payload: {'text': 'Random prompt 346 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:37] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_346
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_346
[2025-07-25 00:04:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:37] Prefill batch. #new-seq: 1, #new-token: 288, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_339 received DONE after 69 chunks
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_339 completed: 70 chars, 69 chunks, TTFT=69.3ms
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_347 to http://localhost:30000/generate at 1753373077.8606164
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_347 with payload: {'text': 'Random prompt 347 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:37] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_347
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_347
[2025-07-25 00:04:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:37] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_336 received DONE after 91 chunks
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_336 completed: 265 chars, 91 chunks, TTFT=51.5ms
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_348 to http://localhost:30000/generate at 1753373077.9480808
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_348 with payload: {'text': 'Random prompt 348 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:37] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_348
[2025-07-25 00:04:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_348
[2025-07-25 00:04:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:37] Prefill batch. #new-seq: 1, #new-token: 221, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_329 received DONE after 129 chunks
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_329 completed: 500 chars, 129 chunks, TTFT=55.2ms
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_349 to http://localhost:30000/generate at 1753373078.1071389
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_349 with payload: {'text': 'Random prompt 349 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_349
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_349
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] Prefill batch. #new-seq: 1, #new-token: 285, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_322 received DONE after 177 chunks
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_322 completed: 692 chars, 177 chunks, TTFT=61.6ms
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_350 to http://localhost:30000/generate at 1753373078.2237325
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_350 with payload: {'text': 'Random prompt 350 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_350
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_350
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] Decode batch. #running-req: 20, #token: 6406, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1229.21, #queue-req: 0,
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_330 received DONE after 136 chunks
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_330 completed: 540 chars, 136 chunks, TTFT=43.5ms
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_351 to http://localhost:30000/generate at 1753373078.3327863
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_351 with payload: {'text': 'Random prompt 351 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 138, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_351
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_351
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] Prefill batch. #new-seq: 1, #new-token: 344, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_340 received DONE after 98 chunks
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_340 completed: 375 chars, 98 chunks, TTFT=61.8ms
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_352 to http://localhost:30000/generate at 1753373078.3450465
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_352 with payload: {'text': 'Random prompt 352 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_352
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_352
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] Prefill batch. #new-seq: 1, #new-token: 294, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_328 received DONE after 149 chunks
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_328 completed: 580 chars, 149 chunks, TTFT=64.1ms
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_353 to http://localhost:30000/generate at 1753373078.463863
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_353 with payload: {'text': 'Random prompt 353 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_353
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_353
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_324 received DONE after 190 chunks
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_324 completed: 545 chars, 190 chunks, TTFT=68.9ms
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_354 to http://localhost:30000/generate at 1753373078.510225
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_354 with payload: {'text': 'Random prompt 354 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_354
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_354
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_327 received DONE after 166 chunks
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_327 completed: 648 chars, 166 chunks, TTFT=48.4ms
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_355 to http://localhost:30000/generate at 1753373078.6565402
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_355 with payload: {'text': 'Random prompt 355 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_355
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_355
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_331 received DONE after 157 chunks
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_331 completed: 612 chars, 157 chunks, TTFT=89.4ms
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_356 to http://localhost:30000/generate at 1753373078.792165
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_356 with payload: {'text': 'Random prompt 356 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 179, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_356
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_356
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_335 received DONE after 148 chunks
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_335 completed: 149 chars, 148 chunks, TTFT=48.7ms
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_357 to http://localhost:30000/generate at 1753373078.852464
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_357 with payload: {'text': 'Random prompt 357 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 118, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_357
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_357
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] Prefill batch. #new-seq: 1, #new-token: 275, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_341 received DONE after 124 chunks
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_341 completed: 492 chars, 124 chunks, TTFT=53.0ms
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_358 to http://localhost:30000/generate at 1753373078.9530463
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_358 with payload: {'text': 'Random prompt 358 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] Decode batch. #running-req: 20, #token: 5628, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1182.24, #queue-req: 0,
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_358
[2025-07-25 00:04:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_358
[2025-07-25 00:04:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:38] Prefill batch. #new-seq: 1, #new-token: 366, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_337 received DONE after 152 chunks
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_337 completed: 604 chars, 152 chunks, TTFT=58.6ms
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_359 to http://localhost:30000/generate at 1753373079.0684521
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_359 with payload: {'text': 'Random prompt 359 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:39] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_359
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_359
[2025-07-25 00:04:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:39] Prefill batch. #new-seq: 1, #new-token: 272, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_349 received DONE after 70 chunks
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_349 completed: 276 chars, 70 chunks, TTFT=49.6ms
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_360 to http://localhost:30000/generate at 1753373079.2522082
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_360 with payload: {'text': 'Random prompt 360 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 181, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:39] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_360
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_360
[2025-07-25 00:04:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:39] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_333 received DONE after 193 chunks
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_333 completed: 755 chars, 193 chunks, TTFT=78.8ms
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_361 to http://localhost:30000/generate at 1753373079.3594074
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_361 with payload: {'text': 'Random prompt 361 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 91, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:39] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_361
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_361
[2025-07-25 00:04:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:39] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_334 received DONE after 190 chunks
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_334 completed: 193 chars, 190 chunks, TTFT=45.7ms
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_362 to http://localhost:30000/generate at 1753373079.473308
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_362 with payload: {'text': 'Random prompt 362 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:39] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_362
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_362
[2025-07-25 00:04:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:39] Prefill batch. #new-seq: 1, #new-token: 242, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:39] Decode batch. #running-req: 20, #token: 6332, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1284.29, #queue-req: 0,
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_346 received DONE after 109 chunks
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_346 completed: 420 chars, 109 chunks, TTFT=66.0ms
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_363 to http://localhost:30000/generate at 1753373079.6184452
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_363 with payload: {'text': 'Random prompt 363 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:39] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_363
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_363
[2025-07-25 00:04:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:39] Prefill batch. #new-seq: 1, #new-token: 265, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_345 received DONE after 119 chunks
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_345 completed: 353 chars, 119 chunks, TTFT=47.3ms
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_347 received DONE after 112 chunks
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_347 completed: 441 chars, 112 chunks, TTFT=58.1ms
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_364 to http://localhost:30000/generate at 1753373079.6755927
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_364 with payload: {'text': 'Random prompt 364 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_365 to http://localhost:30000/generate at 1753373079.6765156
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_365 with payload: {'text': 'Random prompt 365 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:39] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_364
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_364
[2025-07-25 00:04:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:39] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_365
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_365
[2025-07-25 00:04:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:39] Prefill batch. #new-seq: 2, #new-token: 590, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_343 received DONE after 158 chunks
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_343 completed: 616 chars, 158 chunks, TTFT=43.9ms
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_366 to http://localhost:30000/generate at 1753373079.8600125
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_366 with payload: {'text': 'Random prompt 366 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:39] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_366
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_366
[2025-07-25 00:04:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:39] Prefill batch. #new-seq: 1, #new-token: 371, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_342 received DONE after 176 chunks
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_342 completed: 700 chars, 176 chunks, TTFT=43.7ms
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_367 to http://localhost:30000/generate at 1753373079.953576
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_367 with payload: {'text': 'Random prompt 367 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 180, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:39] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_367
[2025-07-25 00:04:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_367
[2025-07-25 00:04:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:39] Prefill batch. #new-seq: 1, #new-token: 357, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_344 received DONE after 160 chunks
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_344 completed: 624 chars, 160 chunks, TTFT=43.0ms
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_368 to http://localhost:30000/generate at 1753373080.1677506
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_368 with payload: {'text': 'Random prompt 368 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_368
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_368
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] Prefill batch. #new-seq: 1, #new-token: 175, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] Decode batch. #running-req: 20, #token: 6714, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1225.25, #queue-req: 0,
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_352 received DONE after 121 chunks
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_352 completed: 362 chars, 121 chunks, TTFT=66.3ms
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_369 to http://localhost:30000/generate at 1753373080.2750027
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_369 with payload: {'text': 'Random prompt 369 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_369
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_369
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_354 received DONE after 127 chunks
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_354 completed: 126 chars, 127 chunks, TTFT=46.6ms
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_370 to http://localhost:30000/generate at 1753373080.4680166
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_370 with payload: {'text': 'Random prompt 370 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_370
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_370
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_358 received DONE after 100 chunks
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_358 completed: 377 chars, 100 chunks, TTFT=48.2ms
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_371 to http://localhost:30000/generate at 1753373080.4804423
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_371 with payload: {'text': 'Random prompt 371 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_371
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_371
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_351 received DONE after 139 chunks
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_351 completed: 552 chars, 139 chunks, TTFT=67.7ms
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_372 to http://localhost:30000/generate at 1753373080.5661054
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_372 with payload: {'text': 'Random prompt 372 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 173, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_372
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_372
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] Prefill batch. #new-seq: 1, #new-token: 149, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_357 received DONE after 119 chunks
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_357 completed: 460 chars, 119 chunks, TTFT=57.9ms
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_373 to http://localhost:30000/generate at 1753373080.7203455
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_373 with payload: {'text': 'Random prompt 373 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_373
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_373
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] Prefill batch. #new-seq: 1, #new-token: 300, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_361 received DONE after 92 chunks
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_361 completed: 261 chars, 92 chunks, TTFT=59.0ms
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_374 to http://localhost:30000/generate at 1753373080.821256
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_374 with payload: {'text': 'Random prompt 374 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 96, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_374
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_374
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] Decode batch. #running-req: 20, #token: 5978, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1308.28, #queue-req: 0,
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_353 received DONE after 158 chunks
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_353 completed: 615 chars, 158 chunks, TTFT=47.6ms
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_375 to http://localhost:30000/generate at 1753373080.9411533
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_375 with payload: {'text': 'Random prompt 375 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_375
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_375
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] Prefill batch. #new-seq: 1, #new-token: 207, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_365 received DONE after 82 chunks
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_365 completed: 234 chars, 82 chunks, TTFT=70.4ms
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_376 to http://localhost:30000/generate at 1753373080.953779
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_376 with payload: {'text': 'Random prompt 376 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 121, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_376
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_376
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] Prefill batch. #new-seq: 1, #new-token: 341, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_348 received DONE after 191 chunks
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_348 completed: 748 chars, 191 chunks, TTFT=44.9ms
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_377 to http://localhost:30000/generate at 1753373080.984735
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_377 with payload: {'text': 'Random prompt 377 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:40] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_377
[2025-07-25 00:04:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_377
[2025-07-25 00:04:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:41] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 6, token usage: 0.05, #running-req: 21, #queue-req: 0,
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_350 received DONE after 176 chunks
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_350 completed: 724 chars, 176 chunks, TTFT=54.8ms
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_378 to http://localhost:30000/generate at 1753373081.0937304
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_378 with payload: {'text': 'Random prompt 378 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 110, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:41] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_378
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_378
[2025-07-25 00:04:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:41] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_359 received DONE after 141 chunks
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_359 completed: 560 chars, 141 chunks, TTFT=57.9ms
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_379 to http://localhost:30000/generate at 1753373081.3045115
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_379 with payload: {'text': 'Random prompt 379 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:41] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_379
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_379
[2025-07-25 00:04:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:41] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_355 received DONE after 177 chunks
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_355 completed: 527 chars, 177 chunks, TTFT=58.9ms
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_380 to http://localhost:30000/generate at 1753373081.4590108
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_380 with payload: {'text': 'Random prompt 380 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:41] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_380
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_380
[2025-07-25 00:04:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:41] Decode batch. #running-req: 20, #token: 5778, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1246.03, #queue-req: 0,
[2025-07-25 00:04:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:41] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_368 received DONE after 88 chunks
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_368 completed: 335 chars, 88 chunks, TTFT=42.9ms
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_381 to http://localhost:30000/generate at 1753373081.5553346
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_381 with payload: {'text': 'Random prompt 381 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:41] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_381
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_381
[2025-07-25 00:04:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:41] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_356 received DONE after 180 chunks
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_356 completed: 183 chars, 180 chunks, TTFT=44.4ms
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_382 to http://localhost:30000/generate at 1753373081.6443825
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_382 with payload: {'text': 'Random prompt 382 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:41] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_382
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_382
[2025-07-25 00:04:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:41] Prefill batch. #new-seq: 1, #new-token: 286, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_362 received DONE after 145 chunks
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_362 completed: 576 chars, 145 chunks, TTFT=43.7ms
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_383 to http://localhost:30000/generate at 1753373081.7709384
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_383 with payload: {'text': 'Random prompt 383 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:41] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_383
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_383
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_369 received DONE after 95 chunks
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_369 completed: 372 chars, 95 chunks, TTFT=43.7ms
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_384 to http://localhost:30000/generate at 1753373081.7831469
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_384 with payload: {'text': 'Random prompt 384 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:41] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_384
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_384
[2025-07-25 00:04:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:41] Prefill batch. #new-seq: 2, #new-token: 663, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_371 received DONE after 88 chunks
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_371 completed: 91 chars, 88 chunks, TTFT=55.3ms
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_385 to http://localhost:30000/generate at 1753373081.9204636
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_385 with payload: {'text': 'Random prompt 385 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:41] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_385
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_385
[2025-07-25 00:04:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:41] Prefill batch. #new-seq: 1, #new-token: 331, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_363 received DONE after 146 chunks
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_363 completed: 567 chars, 146 chunks, TTFT=59.2ms
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_386 to http://localhost:30000/generate at 1753373081.9984965
[2025-07-25 00:04:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_386 with payload: {'text': 'Random prompt 386 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_386
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_386
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] Decode batch. #running-req: 20, #token: 6680, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1169.80, #queue-req: 0,
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_360 received DONE after 182 chunks
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_360 completed: 724 chars, 182 chunks, TTFT=54.9ms
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_387 to http://localhost:30000/generate at 1753373082.1698987
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_387 with payload: {'text': 'Random prompt 387 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_387
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_387
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] Prefill batch. #new-seq: 1, #new-token: 171, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_364 received DONE after 159 chunks
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_364 completed: 601 chars, 159 chunks, TTFT=71.2ms
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_388 to http://localhost:30000/generate at 1753373082.2285573
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_388 with payload: {'text': 'Random prompt 388 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_388
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_388
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_366 received DONE after 157 chunks
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_366 completed: 702 chars, 157 chunks, TTFT=50.7ms
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_389 to http://localhost:30000/generate at 1753373082.3669817
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_389 with payload: {'text': 'Random prompt 389 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_389
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_389
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_374 received DONE after 97 chunks
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_374 completed: 384 chars, 97 chunks, TTFT=43.7ms
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_390 to http://localhost:30000/generate at 1753373082.3917174
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_390 with payload: {'text': 'Random prompt 390 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_390
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_390
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] Prefill batch. #new-seq: 1, #new-token: 380, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] Decode batch. #running-req: 20, #token: 6980, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1322.55, #queue-req: 0,
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_373 received DONE after 128 chunks
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_373 completed: 355 chars, 128 chunks, TTFT=58.6ms
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_391 to http://localhost:30000/generate at 1753373082.7708113
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_391 with payload: {'text': 'Random prompt 391 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_391
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_391
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_367 received DONE after 181 chunks
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_367 completed: 511 chars, 181 chunks, TTFT=61.0ms
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_392 to http://localhost:30000/generate at 1753373082.8160112
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_392 with payload: {'text': 'Random prompt 392 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_392
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_392
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] Prefill batch. #new-seq: 1, #new-token: 220, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_380 received DONE after 86 chunks
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_380 completed: 340 chars, 86 chunks, TTFT=44.7ms
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_378 received DONE after 111 chunks
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_378 completed: 313 chars, 111 chunks, TTFT=59.7ms
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_393 to http://localhost:30000/generate at 1753373082.8320363
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_393 with payload: {'text': 'Random prompt 393 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 131, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_394 to http://localhost:30000/generate at 1753373082.8327453
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_394 with payload: {'text': 'Random prompt 394 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_393
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_393
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_394
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_394
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] Prefill batch. #new-seq: 2, #new-token: 536, #cached-token: 12, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_376 received DONE after 122 chunks
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_376 completed: 484 chars, 122 chunks, TTFT=80.5ms
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_395 to http://localhost:30000/generate at 1753373082.9503887
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_395 with payload: {'text': 'Random prompt 395 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_395
[2025-07-25 00:04:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_395
[2025-07-25 00:04:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:42] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_377 received DONE after 131 chunks
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_377 completed: 517 chars, 131 chunks, TTFT=54.1ms
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_396 to http://localhost:30000/generate at 1753373083.0915537
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_396 with payload: {'text': 'Random prompt 396 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_396
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_396
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] Prefill batch. #new-seq: 1, #new-token: 345, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_372 received DONE after 174 chunks
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_372 completed: 692 chars, 174 chunks, TTFT=42.4ms
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_397 to http://localhost:30000/generate at 1753373083.3415992
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_397 with payload: {'text': 'Random prompt 397 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 96, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_397
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_397
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] Prefill batch. #new-seq: 1, #new-token: 235, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_383 received DONE after 98 chunks
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_383 completed: 291 chars, 98 chunks, TTFT=81.7ms
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_398 to http://localhost:30000/generate at 1753373083.3537846
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_398 with payload: {'text': 'Random prompt 398 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_398
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_398
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] Decode batch. #running-req: 20, #token: 6879, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1135.11, #queue-req: 0,
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_381 received DONE after 115 chunks
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_381 completed: 456 chars, 115 chunks, TTFT=58.6ms
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_399 to http://localhost:30000/generate at 1753373083.4570935
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_399 with payload: {'text': 'Random prompt 399 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 154, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_399
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_399
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_387 received DONE after 82 chunks
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_387 completed: 311 chars, 82 chunks, TTFT=43.9ms
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_400 to http://localhost:30000/generate at 1753373083.523088
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_400 with payload: {'text': 'Random prompt 400 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_400
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_400
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 4, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_370 received DONE after 189 chunks
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_370 completed: 739 chars, 189 chunks, TTFT=64.5ms
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_401 to http://localhost:30000/generate at 1753373083.5838408
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_401 with payload: {'text': 'Random prompt 401 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_401
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_401
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] Prefill batch. #new-seq: 1, #new-token: 356, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_379 received DONE after 141 chunks
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_379 completed: 560 chars, 141 chunks, TTFT=54.3ms
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_402 to http://localhost:30000/generate at 1753373083.651734
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_402 with payload: {'text': 'Random prompt 402 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_402
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_402
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] Prefill batch. #new-seq: 1, #new-token: 254, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_385 received DONE after 107 chunks
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_385 completed: 299 chars, 107 chunks, TTFT=59.5ms
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_403 to http://localhost:30000/generate at 1753373083.7250757
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_403 with payload: {'text': 'Random prompt 403 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_403
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_403
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] Prefill batch. #new-seq: 1, #new-token: 337, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_375 received DONE after 176 chunks
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_375 completed: 687 chars, 176 chunks, TTFT=63.4ms
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_404 to http://localhost:30000/generate at 1753373083.8658273
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_404 with payload: {'text': 'Random prompt 404 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_404
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_404
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] Prefill batch. #new-seq: 1, #new-token: 207, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_390 received DONE after 95 chunks
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_390 completed: 94 chars, 95 chunks, TTFT=68.3ms
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_405 to http://localhost:30000/generate at 1753373083.9749537
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_405 with payload: {'text': 'Random prompt 405 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_405
[2025-07-25 00:04:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_405
[2025-07-25 00:04:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:43] Prefill batch. #new-seq: 1, #new-token: 354, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_391 received DONE after 74 chunks
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_391 completed: 279 chars, 74 chunks, TTFT=46.7ms
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_406 to http://localhost:30000/generate at 1753373084.079008
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_406 with payload: {'text': 'Random prompt 406 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_406
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_406
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] Decode batch. #running-req: 20, #token: 6933, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1116.93, #queue-req: 0,
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_384 received DONE after 149 chunks
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_384 completed: 592 chars, 149 chunks, TTFT=69.5ms
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_407 to http://localhost:30000/generate at 1753373084.2491848
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_407 with payload: {'text': 'Random prompt 407 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_407
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_407
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_392 received DONE after 87 chunks
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_392 completed: 344 chars, 87 chunks, TTFT=67.6ms
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_408 to http://localhost:30000/generate at 1753373084.3113747
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_408 with payload: {'text': 'Random prompt 408 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 139, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_408
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_408
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] Prefill batch. #new-seq: 1, #new-token: 357, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_389 received DONE after 123 chunks
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_389 completed: 350 chars, 123 chunks, TTFT=82.3ms
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_409 to http://localhost:30000/generate at 1753373084.4274902
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_409 with payload: {'text': 'Random prompt 409 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_409
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_409
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_394 received DONE after 108 chunks
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_394 completed: 428 chars, 108 chunks, TTFT=75.2ms
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_410 to http://localhost:30000/generate at 1753373084.6227136
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_410 with payload: {'text': 'Random prompt 410 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_410
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_410
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] Prefill batch. #new-seq: 1, #new-token: 208, #cached-token: 5, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_386 received DONE after 164 chunks
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_386 completed: 652 chars, 164 chunks, TTFT=44.1ms
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_411 to http://localhost:30000/generate at 1753373084.6680553
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_411 with payload: {'text': 'Random prompt 411 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_411
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_411
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] Decode batch. #running-req: 20, #token: 6241, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1273.02, #queue-req: 0,
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_382 received DONE after 189 chunks
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_382 completed: 740 chars, 189 chunks, TTFT=59.5ms
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_412 to http://localhost:30000/generate at 1753373084.7755332
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_412 with payload: {'text': 'Random prompt 412 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_402 received DONE after 70 chunks
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_402 completed: 276 chars, 70 chunks, TTFT=42.3ms
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_413 to http://localhost:30000/generate at 1753373084.7774158
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_413 with payload: {'text': 'Random prompt 413 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_412
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_412
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_413
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_413
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] Prefill batch. #new-seq: 2, #new-token: 640, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_400 received DONE after 86 chunks
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_400 completed: 328 chars, 86 chunks, TTFT=44.1ms
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_414 to http://localhost:30000/generate at 1753373084.9462419
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_414 with payload: {'text': 'Random prompt 414 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 132, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_414
[2025-07-25 00:04:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_414
[2025-07-25 00:04:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:44] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_401 received DONE after 86 chunks
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_401 completed: 325 chars, 86 chunks, TTFT=49.4ms
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_415 to http://localhost:30000/generate at 1753373085.013796
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_415 with payload: {'text': 'Random prompt 415 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_397 received DONE after 97 chunks
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_397 completed: 282 chars, 97 chunks, TTFT=62.1ms
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_416 to http://localhost:30000/generate at 1753373085.0157595
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_416 with payload: {'text': 'Random prompt 416 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:45] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_415
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_415
[2025-07-25 00:04:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:45] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_416
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_416
[2025-07-25 00:04:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:45] Prefill batch. #new-seq: 2, #new-token: 440, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_393 received DONE after 132 chunks
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_393 completed: 385 chars, 132 chunks, TTFT=76.1ms
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_417 to http://localhost:30000/generate at 1753373085.0703957
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_417 with payload: {'text': 'Random prompt 417 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:45] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_417
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_417
[2025-07-25 00:04:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:45] Prefill batch. #new-seq: 1, #new-token: 209, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_396 received DONE after 120 chunks
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_396 completed: 343 chars, 120 chunks, TTFT=60.0ms
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_418 to http://localhost:30000/generate at 1753373085.1516237
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_418 with payload: {'text': 'Random prompt 418 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:45] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_418
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_418
[2025-07-25 00:04:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:45] Prefill batch. #new-seq: 1, #new-token: 297, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_388 received DONE after 189 chunks
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_388 completed: 752 chars, 189 chunks, TTFT=60.1ms
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_419 to http://localhost:30000/generate at 1753373085.3770714
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_419 with payload: {'text': 'Random prompt 419 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:45] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_419
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_419
[2025-07-25 00:04:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:45] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:45] Decode batch. #running-req: 20, #token: 6783, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1136.50, #queue-req: 0,
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_398 received DONE after 144 chunks
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_398 completed: 572 chars, 144 chunks, TTFT=59.5ms
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_420 to http://localhost:30000/generate at 1753373085.7126637
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_420 with payload: {'text': 'Random prompt 420 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 104, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:45] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_420
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_420
[2025-07-25 00:04:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:45] Prefill batch. #new-seq: 1, #new-token: 329, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_395 received DONE after 171 chunks
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_395 completed: 680 chars, 171 chunks, TTFT=61.3ms
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_421 to http://localhost:30000/generate at 1753373085.7250216
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_421 with payload: {'text': 'Random prompt 421 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 129, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:45] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_421
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_421
[2025-07-25 00:04:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:45] Prefill batch. #new-seq: 1, #new-token: 328, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_413 received DONE after 72 chunks
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_413 completed: 271 chars, 72 chunks, TTFT=77.3ms
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_411 received DONE after 79 chunks
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_411 completed: 312 chars, 79 chunks, TTFT=51.4ms
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_422 to http://localhost:30000/generate at 1753373085.934811
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_422 with payload: {'text': 'Random prompt 422 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_423 to http://localhost:30000/generate at 1753373085.9355636
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_423 with payload: {'text': 'Random prompt 423 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:45] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_422
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_422
[2025-07-25 00:04:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:45] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_423
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_423
[2025-07-25 00:04:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:45] Prefill batch. #new-seq: 2, #new-token: 400, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_399 received DONE after 155 chunks
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_399 completed: 616 chars, 155 chunks, TTFT=48.2ms
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_424 to http://localhost:30000/generate at 1753373085.9919174
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_424 with payload: {'text': 'Random prompt 424 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:45] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_424
[2025-07-25 00:04:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_424
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] Prefill batch. #new-seq: 1, #new-token: 140, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_405 received DONE after 126 chunks
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_405 completed: 500 chars, 126 chunks, TTFT=61.1ms
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_425 to http://localhost:30000/generate at 1753373086.039462
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_425 with payload: {'text': 'Random prompt 425 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_425
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_425
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] Decode batch. #running-req: 20, #token: 6304, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1234.02, #queue-req: 0,
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_410 received DONE after 91 chunks
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_410 completed: 346 chars, 91 chunks, TTFT=46.1ms
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_426 to http://localhost:30000/generate at 1753373086.1439633
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_426 with payload: {'text': 'Random prompt 426 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_426
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_426
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] Prefill batch. #new-seq: 1, #new-token: 238, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_416 received DONE after 70 chunks
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_416 completed: 264 chars, 70 chunks, TTFT=69.0ms
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_427 to http://localhost:30000/generate at 1753373086.1560748
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_427 with payload: {'text': 'Random prompt 427 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_427
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_427
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] Prefill batch. #new-seq: 1, #new-token: 352, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_404 received DONE after 150 chunks
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_404 completed: 584 chars, 150 chunks, TTFT=44.1ms
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_428 to http://localhost:30000/generate at 1753373086.3252084
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_428 with payload: {'text': 'Random prompt 428 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_403 received DONE after 159 chunks
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_403 completed: 158 chars, 159 chunks, TTFT=48.9ms
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_429 to http://localhost:30000/generate at 1753373086.3270774
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_429 with payload: {'text': 'Random prompt 429 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_428
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_428
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_429
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_429
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] Prefill batch. #new-seq: 2, #new-token: 370, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_417 received DONE after 81 chunks
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_417 completed: 320 chars, 81 chunks, TTFT=51.1ms
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_430 to http://localhost:30000/generate at 1753373086.3812718
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_430 with payload: {'text': 'Random prompt 430 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_430
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_430
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_412 received DONE after 100 chunks
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_412 completed: 396 chars, 100 chunks, TTFT=79.1ms
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_431 to http://localhost:30000/generate at 1753373086.4760392
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_431 with payload: {'text': 'Random prompt 431 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_431
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_431
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] Prefill batch. #new-seq: 1, #new-token: 320, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_408 received DONE after 140 chunks
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_408 completed: 141 chars, 140 chunks, TTFT=61.3ms
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_432 to http://localhost:30000/generate at 1753373086.638703
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_432 with payload: {'text': 'Random prompt 432 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_432
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_432
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] Decode batch. #running-req: 20, #token: 6152, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1207.22, #queue-req: 0,
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_406 received DONE after 173 chunks
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_406 completed: 675 chars, 173 chunks, TTFT=43.9ms
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_433 to http://localhost:30000/generate at 1753373086.8712127
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_433 with payload: {'text': 'Random prompt 433 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_433
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_433
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_407 received DONE after 168 chunks
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_407 completed: 664 chars, 168 chunks, TTFT=46.7ms
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_434 to http://localhost:30000/generate at 1753373086.97867
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_434 with payload: {'text': 'Random prompt 434 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 82, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_434
[2025-07-25 00:04:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_434
[2025-07-25 00:04:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:46] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_414 received DONE after 133 chunks
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_414 completed: 515 chars, 133 chunks, TTFT=48.8ms
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_418 received DONE after 123 chunks
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_418 completed: 488 chars, 123 chunks, TTFT=60.3ms
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_435 to http://localhost:30000/generate at 1753373087.086661
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_435 with payload: {'text': 'Random prompt 435 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_436 to http://localhost:30000/generate at 1753373087.087467
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_436 with payload: {'text': 'Random prompt 436 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_435
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_435
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_436
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_436
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_422 received DONE after 70 chunks
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_422 completed: 276 chars, 70 chunks, TTFT=67.9ms
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_437 to http://localhost:30000/generate at 1753373087.1012897
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_437 with payload: {'text': 'Random prompt 437 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 154, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] Prefill batch. #new-seq: 2, #new-token: 449, #cached-token: 12, token usage: 0.04, #running-req: 17, #queue-req: 0,
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_437
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_437
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] Prefill batch. #new-seq: 1, #new-token: 336, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_426 received DONE after 66 chunks
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_426 completed: 248 chars, 66 chunks, TTFT=66.9ms
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_438 to http://localhost:30000/generate at 1753373087.2276828
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_438 with payload: {'text': 'Random prompt 438 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_438
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_438
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] Prefill batch. #new-seq: 1, #new-token: 306, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_409 received DONE after 176 chunks
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_409 completed: 700 chars, 176 chunks, TTFT=45.2ms
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_439 to http://localhost:30000/generate at 1753373087.3163881
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_439 with payload: {'text': 'Random prompt 439 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 150, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_439
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_439
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] Prefill batch. #new-seq: 1, #new-token: 146, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_423 received DONE after 84 chunks
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_423 completed: 320 chars, 84 chunks, TTFT=67.3ms
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_440 to http://localhost:30000/generate at 1753373087.3893046
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_440 with payload: {'text': 'Random prompt 440 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_440
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_440
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] Decode batch. #running-req: 19, #token: 5895, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1178.71, #queue-req: 0,
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_420 received DONE after 105 chunks
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_420 completed: 394 chars, 105 chunks, TTFT=68.7ms
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_441 to http://localhost:30000/generate at 1753373087.4959526
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_441 with payload: {'text': 'Random prompt 441 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 76, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_441
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_441
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] Prefill batch. #new-seq: 1, #new-token: 378, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_421 received DONE after 130 chunks
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_421 completed: 516 chars, 130 chunks, TTFT=66.5ms
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_442 to http://localhost:30000/generate at 1753373087.8265681
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_442 with payload: {'text': 'Random prompt 442 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 150, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_442
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_442
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] Prefill batch. #new-seq: 1, #new-token: 221, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_415 received DONE after 185 chunks
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_415 completed: 723 chars, 185 chunks, TTFT=71.1ms
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_443 to http://localhost:30000/generate at 1753373087.9597769
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_443 with payload: {'text': 'Random prompt 443 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 121, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_443
[2025-07-25 00:04:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_443
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] Decode batch. #running-req: 20, #token: 5998, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1476.42, #queue-req: 0,
[2025-07-25 00:04:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:47] Prefill batch. #new-seq: 1, #new-token: 220, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_435 received DONE after 69 chunks
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_435 completed: 260 chars, 69 chunks, TTFT=87.3ms
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_444 to http://localhost:30000/generate at 1753373088.1520934
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_444 with payload: {'text': 'Random prompt 444 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:48] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_444
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_444
[2025-07-25 00:04:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:48] Prefill batch. #new-seq: 1, #new-token: 333, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_430 received DONE after 123 chunks
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_430 completed: 476 chars, 123 chunks, TTFT=53.7ms
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_445 to http://localhost:30000/generate at 1753373088.257361
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_445 with payload: {'text': 'Random prompt 445 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_434 received DONE after 83 chunks
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_434 completed: 316 chars, 83 chunks, TTFT=43.0ms
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_446 to http://localhost:30000/generate at 1753373088.259332
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_446 with payload: {'text': 'Random prompt 446 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:48] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_445
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_445
[2025-07-25 00:04:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:48] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_446
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_446
[2025-07-25 00:04:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:48] Prefill batch. #new-seq: 2, #new-token: 746, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_419 received DONE after 185 chunks
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_419 completed: 527 chars, 185 chunks, TTFT=60.1ms
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_447 to http://localhost:30000/generate at 1753373088.2817922
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_447 with payload: {'text': 'Random prompt 447 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 171, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:48] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_447
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_447
[2025-07-25 00:04:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:48] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_431 received DONE after 131 chunks
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_431 completed: 508 chars, 131 chunks, TTFT=47.8ms
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_448 to http://localhost:30000/generate at 1753373088.5023324
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_448 with payload: {'text': 'Random prompt 448 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:48] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_448
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_448
[2025-07-25 00:04:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:48] Prefill batch. #new-seq: 1, #new-token: 221, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:48] Decode batch. #running-req: 20, #token: 6791, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1216.63, #queue-req: 0,
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_428 received DONE after 147 chunks
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_428 completed: 571 chars, 147 chunks, TTFT=61.8ms
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_432 received DONE after 128 chunks
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_432 completed: 508 chars, 128 chunks, TTFT=58.2ms
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_449 to http://localhost:30000/generate at 1753373088.6383574
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_449 with payload: {'text': 'Random prompt 449 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_450 to http://localhost:30000/generate at 1753373088.6391292
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_450 with payload: {'text': 'Random prompt 450 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_438 received DONE after 91 chunks
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_438 completed: 347 chars, 91 chunks, TTFT=59.5ms
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_451 to http://localhost:30000/generate at 1753373088.640967
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_451 with payload: {'text': 'Random prompt 451 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:48] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_449
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_449
[2025-07-25 00:04:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:48] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:48] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_451
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_451
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_450
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_450
[2025-07-25 00:04:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:48] Prefill batch. #new-seq: 3, #new-token: 741, #cached-token: 16, token usage: 0.04, #running-req: 17, #queue-req: 0,
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_441 received DONE after 77 chunks
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_441 completed: 223 chars, 77 chunks, TTFT=60.2ms
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_452 to http://localhost:30000/generate at 1753373088.6599987
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_452 with payload: {'text': 'Random prompt 452 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:48] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_452
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_452
[2025-07-25 00:04:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:48] Prefill batch. #new-seq: 1, #new-token: 235, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_436 received DONE after 104 chunks
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_436 completed: 399 chars, 104 chunks, TTFT=86.6ms
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_453 to http://localhost:30000/generate at 1753373088.800644
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_453 with payload: {'text': 'Random prompt 453 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 137, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:48] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_453
[2025-07-25 00:04:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_453
[2025-07-25 00:04:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:48] Prefill batch. #new-seq: 1, #new-token: 357, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_425 received DONE after 189 chunks
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_425 completed: 678 chars, 189 chunks, TTFT=51.6ms
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_454 to http://localhost:30000/generate at 1753373089.0519397
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_454 with payload: {'text': 'Random prompt 454 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_424 received DONE after 191 chunks
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_424 completed: 192 chars, 191 chunks, TTFT=49.1ms
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_455 to http://localhost:30000/generate at 1753373089.0538611
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_455 with payload: {'text': 'Random prompt 455 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:49] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:49] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_454
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_454
[2025-07-25 00:04:49] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:49] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_455
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_455
[2025-07-25 00:04:49] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:49] Prefill batch. #new-seq: 2, #new-token: 405, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_429 received DONE after 176 chunks
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_429 completed: 688 chars, 176 chunks, TTFT=60.0ms
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_427 received DONE after 187 chunks
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_427 completed: 744 chars, 187 chunks, TTFT=64.7ms
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_456 to http://localhost:30000/generate at 1753373089.1390727
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_456 with payload: {'text': 'Random prompt 456 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_457 to http://localhost:30000/generate at 1753373089.1397946
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_457 with payload: {'text': 'Random prompt 457 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:49] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:49] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_456
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_456
[2025-07-25 00:04:49] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:49] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_457
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_457
[2025-07-25 00:04:49] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:49] Prefill batch. #new-seq: 2, #new-token: 373, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_433 received DONE after 150 chunks
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_433 completed: 590 chars, 150 chunks, TTFT=43.7ms
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_458 to http://localhost:30000/generate at 1753373089.2791884
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_458 with payload: {'text': 'Random prompt 458 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:49] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:49] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:49] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:49] Decode batch. #running-req: 20, #token: 5862, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1177.00, #queue-req: 0,
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_458
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_458
[2025-07-25 00:04:49] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:49] Prefill batch. #new-seq: 1, #new-token: 140, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_437 received DONE after 155 chunks
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_437 completed: 592 chars, 155 chunks, TTFT=83.5ms
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_459 to http://localhost:30000/generate at 1753373089.542438
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_459 with payload: {'text': 'Random prompt 459 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:49] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:49] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_459
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_459
[2025-07-25 00:04:49] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:49] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_439 received DONE after 151 chunks
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_439 completed: 587 chars, 151 chunks, TTFT=44.4ms
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_460 to http://localhost:30000/generate at 1753373089.635054
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_460 with payload: {'text': 'Random prompt 460 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:49] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:49] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_460
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_460
[2025-07-25 00:04:49] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:49] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_445 received DONE after 88 chunks
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_445 completed: 252 chars, 88 chunks, TTFT=104.9ms
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_461 to http://localhost:30000/generate at 1753373089.694466
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_461 with payload: {'text': 'Random prompt 461 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:49] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:49] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_461
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_461
[2025-07-25 00:04:49] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:49] Prefill batch. #new-seq: 1, #new-token: 291, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:49] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:49] Decode batch. #running-req: 20, #token: 6158, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1373.18, #queue-req: 0,
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_443 received DONE after 122 chunks
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_443 completed: 472 chars, 122 chunks, TTFT=44.6ms
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_462 to http://localhost:30000/generate at 1753373089.8826125
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_462 with payload: {'text': 'Random prompt 462 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:49] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:49] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_462
[2025-07-25 00:04:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_462
[2025-07-25 00:04:49] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:49] Prefill batch. #new-seq: 1, #new-token: 316, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_454 received DONE after 69 chunks
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_454 completed: 260 chars, 69 chunks, TTFT=67.6ms
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_463 to http://localhost:30000/generate at 1753373090.0942662
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_463 with payload: {'text': 'Random prompt 463 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_463
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_463
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] Prefill batch. #new-seq: 1, #new-token: 274, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_442 received DONE after 151 chunks
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_442 completed: 587 chars, 151 chunks, TTFT=43.6ms
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_464 to http://localhost:30000/generate at 1753373090.1825693
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_464 with payload: {'text': 'Random prompt 464 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_464
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_464
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] Prefill batch. #new-seq: 1, #new-token: 371, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_440 received DONE after 189 chunks
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_440 completed: 739 chars, 189 chunks, TTFT=42.2ms
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_465 to http://localhost:30000/generate at 1753373090.287646
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_465 with payload: {'text': 'Random prompt 465 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 70, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_465
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_465
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] Prefill batch. #new-seq: 1, #new-token: 221, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] Decode batch. #running-req: 20, #token: 6864, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1316.87, #queue-req: 0,
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_450 received DONE after 129 chunks
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_450 completed: 363 chars, 129 chunks, TTFT=101.9ms
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_466 to http://localhost:30000/generate at 1753373090.6043227
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_466 with payload: {'text': 'Random prompt 466 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_466
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_466
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] Prefill batch. #new-seq: 1, #new-token: 198, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_458 received DONE after 93 chunks
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_458 completed: 92 chars, 93 chunks, TTFT=41.0ms
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_467 to http://localhost:30000/generate at 1753373090.6179192
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_467 with payload: {'text': 'Random prompt 467 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_467
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_467
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] Prefill batch. #new-seq: 1, #new-token: 347, #cached-token: 6, token usage: 0.06, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_446 received DONE after 154 chunks
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_446 completed: 444 chars, 154 chunks, TTFT=103.0ms
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_468 to http://localhost:30000/generate at 1753373090.7002175
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_468 with payload: {'text': 'Random prompt 468 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_468
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_468
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_451 received DONE after 144 chunks
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_451 completed: 529 chars, 144 chunks, TTFT=99.9ms
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_469 to http://localhost:30000/generate at 1753373090.8700714
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_469 with payload: {'text': 'Random prompt 469 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_469
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_469
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_453 received DONE after 138 chunks
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_453 completed: 396 chars, 138 chunks, TTFT=61.3ms
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_470 to http://localhost:30000/generate at 1753373090.8820112
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_470 with payload: {'text': 'Random prompt 470 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 137, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_470
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_470
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_444 received DONE after 176 chunks
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_444 completed: 504 chars, 176 chunks, TTFT=49.5ms
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_471 to http://localhost:30000/generate at 1753373090.962659
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_471 with payload: {'text': 'Random prompt 471 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 159, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_471
[2025-07-25 00:04:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_471
[2025-07-25 00:04:50] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:50] Prefill batch. #new-seq: 1, #new-token: 373, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_447 received DONE after 172 chunks
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_447 completed: 495 chars, 172 chunks, TTFT=91.0ms
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_472 to http://localhost:30000/generate at 1753373091.0230134
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_472 with payload: {'text': 'Random prompt 472 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_472
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_472
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_449 received DONE after 152 chunks
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_449 completed: 592 chars, 152 chunks, TTFT=102.6ms
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_473 to http://localhost:30000/generate at 1753373091.0735424
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_473 with payload: {'text': 'Random prompt 473 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_473
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_473
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] Prefill batch. #new-seq: 1, #new-token: 353, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] Decode batch. #running-req: 20, #token: 6332, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1113.35, #queue-req: 0,
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_462 received DONE after 79 chunks
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_462 completed: 232 chars, 79 chunks, TTFT=58.0ms
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_474 to http://localhost:30000/generate at 1753373091.195941
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_474 with payload: {'text': 'Random prompt 474 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_474
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_474
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] Prefill batch. #new-seq: 1, #new-token: 260, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_448 received DONE after 186 chunks
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_448 completed: 740 chars, 186 chunks, TTFT=44.1ms
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_475 to http://localhost:30000/generate at 1753373091.4296758
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_475 with payload: {'text': 'Random prompt 475 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_452 received DONE after 176 chunks
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_452 completed: 562 chars, 176 chunks, TTFT=85.8ms
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_465 received DONE after 71 chunks
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_465 completed: 268 chars, 71 chunks, TTFT=42.7ms
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_476 to http://localhost:30000/generate at 1753373091.4318922
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_476 with payload: {'text': 'Random prompt 476 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_477 to http://localhost:30000/generate at 1753373091.4325523
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_477 with payload: {'text': 'Random prompt 477 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_475
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_475
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_477
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_477
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_476
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_476
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] Prefill batch. #new-seq: 3, #new-token: 790, #cached-token: 18, token usage: 0.04, #running-req: 17, #queue-req: 0,
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_460 received DONE after 115 chunks
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_460 completed: 444 chars, 115 chunks, TTFT=44.5ms
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_478 to http://localhost:30000/generate at 1753373091.4513705
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_478 with payload: {'text': 'Random prompt 478 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_478
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_478
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] Prefill batch. #new-seq: 1, #new-token: 373, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_457 received DONE after 152 chunks
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_457 completed: 590 chars, 152 chunks, TTFT=60.0ms
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_479 to http://localhost:30000/generate at 1753373091.5862052
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_479 with payload: {'text': 'Random prompt 479 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_479
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_479
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] Prefill batch. #new-seq: 1, #new-token: 259, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_456 received DONE after 153 chunks
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_456 completed: 605 chars, 153 chunks, TTFT=60.9ms
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_480 to http://localhost:30000/generate at 1753373091.597916
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_480 with payload: {'text': 'Random prompt 480 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_480
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_480
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] Decode batch. #running-req: 20, #token: 6646, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1179.20, #queue-req: 0,
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_459 received DONE after 149 chunks
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_459 completed: 580 chars, 149 chunks, TTFT=53.6ms
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_481 to http://localhost:30000/generate at 1753373091.9600005
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_481 with payload: {'text': 'Random prompt 481 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 79, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_481
[2025-07-25 00:04:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_481
[2025-07-25 00:04:51] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:51] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_455 received DONE after 184 chunks
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_455 completed: 720 chars, 184 chunks, TTFT=65.6ms
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_482 to http://localhost:30000/generate at 1753373092.0068097
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_482 with payload: {'text': 'Random prompt 482 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:52] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:52] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_482
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_482
[2025-07-25 00:04:52] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:52] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_461 received DONE after 148 chunks
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_461 completed: 588 chars, 148 chunks, TTFT=59.6ms
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_483 to http://localhost:30000/generate at 1753373092.1134477
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_483 with payload: {'text': 'Random prompt 483 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:52] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:52] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_483
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_483
[2025-07-25 00:04:52] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:52] Prefill batch. #new-seq: 1, #new-token: 286, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:52] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:52] Decode batch. #running-req: 20, #token: 7096, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1388.66, #queue-req: 0,
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_463 received DONE after 149 chunks
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_463 completed: 592 chars, 149 chunks, TTFT=57.6ms
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_484 to http://localhost:30000/generate at 1753373092.4974966
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_484 with payload: {'text': 'Random prompt 484 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:52] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:52] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_484
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_484
[2025-07-25 00:04:52] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:52] Prefill batch. #new-seq: 1, #new-token: 275, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_467 received DONE after 117 chunks
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_467 completed: 464 chars, 117 chunks, TTFT=63.4ms
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_485 to http://localhost:30000/generate at 1753373092.544235
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_485 with payload: {'text': 'Random prompt 485 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:52] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:52] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_485
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_485
[2025-07-25 00:04:52] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:52] Prefill batch. #new-seq: 1, #new-token: 356, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_474 received DONE after 107 chunks
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_474 completed: 386 chars, 107 chunks, TTFT=57.2ms
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_486 to http://localhost:30000/generate at 1753373092.8455002
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_486 with payload: {'text': 'Random prompt 486 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:52] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:52] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_486
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_486
[2025-07-25 00:04:52] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:52] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_473 received DONE after 117 chunks
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_473 completed: 464 chars, 117 chunks, TTFT=52.5ms
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_487 to http://localhost:30000/generate at 1753373092.8694906
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_487 with payload: {'text': 'Random prompt 487 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:52] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:52] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_487
[2025-07-25 00:04:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_487
[2025-07-25 00:04:52] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:52] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 6, token usage: 0.06, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] Decode batch. #running-req: 20, #token: 7137, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1314.96, #queue-req: 0,
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_483 received DONE after 66 chunks
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_483 completed: 247 chars, 66 chunks, TTFT=48.5ms
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_488 to http://localhost:30000/generate at 1753373093.0653145
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_488 with payload: {'text': 'Random prompt 488 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_488
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_488
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_470 received DONE after 138 chunks
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_470 completed: 545 chars, 138 chunks, TTFT=61.7ms
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_489 to http://localhost:30000/generate at 1753373093.0797462
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_489 with payload: {'text': 'Random prompt 489 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 121, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_489
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_489
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] Prefill batch. #new-seq: 1, #new-token: 353, #cached-token: 6, token usage: 0.06, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_481 received DONE after 80 chunks
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_481 completed: 304 chars, 80 chunks, TTFT=52.3ms
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_490 to http://localhost:30000/generate at 1753373093.2079313
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_490 with payload: {'text': 'Random prompt 490 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_490
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_490
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 5, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_464 received DONE after 193 chunks
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_464 completed: 768 chars, 193 chunks, TTFT=62.1ms
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_491 to http://localhost:30000/generate at 1753373093.303054
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_491 with payload: {'text': 'Random prompt 491 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 112, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_491
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_491
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_479 received DONE after 121 chunks
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_479 completed: 481 chars, 121 chunks, TTFT=67.8ms
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_492 to http://localhost:30000/generate at 1753373093.447784
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_492 with payload: {'text': 'Random prompt 492 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_492
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_492
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] Prefill batch. #new-seq: 1, #new-token: 196, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_471 received DONE after 160 chunks
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_471 completed: 636 chars, 160 chunks, TTFT=61.4ms
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_468 received DONE after 176 chunks
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_468 completed: 700 chars, 176 chunks, TTFT=42.9ms
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_493 to http://localhost:30000/generate at 1753373093.546512
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_493 with payload: {'text': 'Random prompt 493 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_494 to http://localhost:30000/generate at 1753373093.5472791
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_494 with payload: {'text': 'Random prompt 494 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_493
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_493
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_494
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_494
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_469 received DONE after 165 chunks
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_469 completed: 164 chars, 165 chunks, TTFT=69.2ms
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_495 to http://localhost:30000/generate at 1753373093.5607016
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_495 with payload: {'text': 'Random prompt 495 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 150, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] Prefill batch. #new-seq: 2, #new-token: 417, #cached-token: 12, token usage: 0.05, #running-req: 17, #queue-req: 0,
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_495
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_495
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] Prefill batch. #new-seq: 1, #new-token: 216, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] Decode batch. #running-req: 20, #token: 6639, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1125.74, #queue-req: 0,
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_466 received DONE after 190 chunks
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_466 completed: 756 chars, 190 chunks, TTFT=67.5ms
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_496 to http://localhost:30000/generate at 1753373093.7443545
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_496 with payload: {'text': 'Random prompt 496 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_496
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_496
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] Prefill batch. #new-seq: 1, #new-token: 275, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_475 received DONE after 150 chunks
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_475 completed: 596 chars, 150 chunks, TTFT=116.2ms
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_497 to http://localhost:30000/generate at 1753373093.8695152
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_497 with payload: {'text': 'Random prompt 497 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_472 received DONE after 177 chunks
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_472 completed: 701 chars, 177 chunks, TTFT=52.0ms
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_498 to http://localhost:30000/generate at 1753373093.8716342
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_498 with payload: {'text': 'Random prompt 498 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 113, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_497
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_497
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] Prefill batch. #new-seq: 1, #new-token: 145, #cached-token: 6, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_498
[2025-07-25 00:04:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_498
[2025-07-25 00:04:53] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:53] Prefill batch. #new-seq: 1, #new-token: 375, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_477 received DONE after 163 chunks
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_477 completed: 445 chars, 163 chunks, TTFT=113.5ms
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_499 to http://localhost:30000/generate at 1753373094.0886402
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_499 with payload: {'text': 'Random prompt 499 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_499
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_499
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] Prefill batch. #new-seq: 1, #new-token: 378, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_478 received DONE after 167 chunks
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_478 completed: 664 chars, 167 chunks, TTFT=104.1ms
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_500 to http://localhost:30000/generate at 1753373094.1676655
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_500 with payload: {'text': 'Random prompt 500 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_482 received DONE after 135 chunks
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_482 completed: 536 chars, 135 chunks, TTFT=52.3ms
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_501 to http://localhost:30000/generate at 1753373094.169989
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_501 with payload: {'text': 'Random prompt 501 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_500
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_500
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_501
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_501
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_476 received DONE after 168 chunks
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_476 completed: 656 chars, 168 chunks, TTFT=114.2ms
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_502 to http://localhost:30000/generate at 1753373094.183392
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_502 with payload: {'text': 'Random prompt 502 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] Prefill batch. #new-seq: 2, #new-token: 570, #cached-token: 8, token usage: 0.05, #running-req: 17, #queue-req: 0,
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_502
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_502
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] Prefill batch. #new-seq: 1, #new-token: 206, #cached-token: 4, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_484 received DONE after 107 chunks
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_484 completed: 316 chars, 107 chunks, TTFT=53.6ms
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_480 received DONE after 170 chunks
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_480 completed: 676 chars, 170 chunks, TTFT=66.1ms
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_503 to http://localhost:30000/generate at 1753373094.3272038
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_503 with payload: {'text': 'Random prompt 503 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_504 to http://localhost:30000/generate at 1753373094.3279917
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_504 with payload: {'text': 'Random prompt 504 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 113, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_503
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_503
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] Prefill batch. #new-seq: 1, #new-token: 333, #cached-token: 6, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_504
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_504
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] Prefill batch. #new-seq: 1, #new-token: 300, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] Decode batch. #running-req: 20, #token: 5817, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1061.80, #queue-req: 0,
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_485 received DONE after 111 chunks
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_485 completed: 316 chars, 111 chunks, TTFT=58.9ms
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_505 to http://localhost:30000/generate at 1753373094.4711297
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_505 with payload: {'text': 'Random prompt 505 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_505
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_505
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_493 received DONE after 73 chunks
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_493 completed: 292 chars, 73 chunks, TTFT=88.9ms
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_506 to http://localhost:30000/generate at 1753373094.7959425
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_506 with payload: {'text': 'Random prompt 506 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 138, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_490 received DONE after 94 chunks
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_490 completed: 274 chars, 94 chunks, TTFT=56.2ms
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_507 to http://localhost:30000/generate at 1753373094.7976973
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_507 with payload: {'text': 'Random prompt 507 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 132, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_506
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_506
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_507
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_507
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_486 received DONE after 115 chunks
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_486 completed: 456 chars, 115 chunks, TTFT=76.4ms
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_508 to http://localhost:30000/generate at 1753373094.8111591
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_508 with payload: {'text': 'Random prompt 508 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] Prefill batch. #new-seq: 2, #new-token: 694, #cached-token: 12, token usage: 0.05, #running-req: 17, #queue-req: 0,
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_508
[2025-07-25 00:04:54] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_508
[2025-07-25 00:04:54] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:54] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_488 received DONE after 114 chunks
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_488 completed: 456 chars, 114 chunks, TTFT=72.2ms
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_492 received DONE after 93 chunks
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_492 completed: 360 chars, 93 chunks, TTFT=43.3ms
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_509 to http://localhost:30000/generate at 1753373095.0416498
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_509 with payload: {'text': 'Random prompt 509 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_510 to http://localhost:30000/generate at 1753373095.0424142
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_510 with payload: {'text': 'Random prompt 510 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:55] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_509
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_509
[2025-07-25 00:04:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:55] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_510
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_510
[2025-07-25 00:04:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:55] Decode batch. #running-req: 18, #token: 6230, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1334.54, #queue-req: 0,
[2025-07-25 00:04:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:55] Prefill batch. #new-seq: 2, #new-token: 594, #cached-token: 11, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_489 received DONE after 121 chunks
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_489 completed: 349 chars, 121 chunks, TTFT=70.5ms
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_511 to http://localhost:30000/generate at 1753373095.17251
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_511 with payload: {'text': 'Random prompt 511 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:55] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_511
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_511
[2025-07-25 00:04:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:55] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_491 received DONE after 112 chunks
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_491 completed: 435 chars, 112 chunks, TTFT=51.5ms
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_512 to http://localhost:30000/generate at 1753373095.2294369
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_512 with payload: {'text': 'Random prompt 512 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:55] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_512
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_512
[2025-07-25 00:04:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:55] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_502 received DONE after 67 chunks
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_502 completed: 268 chars, 67 chunks, TTFT=87.3ms
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_513 to http://localhost:30000/generate at 1753373095.3515973
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_513 with payload: {'text': 'Random prompt 513 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 66, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:55] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_513
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_513
[2025-07-25 00:04:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:55] Prefill batch. #new-seq: 1, #new-token: 347, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_487 received DONE after 153 chunks
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_487 completed: 599 chars, 153 chunks, TTFT=56.2ms
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_514 to http://localhost:30000/generate at 1753373095.4942064
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_514 with payload: {'text': 'Random prompt 514 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 89, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:55] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_514
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_514
[2025-07-25 00:04:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:55] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:55] Decode batch. #running-req: 20, #token: 7207, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1221.53, #queue-req: 0,
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_498 received DONE after 113 chunks
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_498 completed: 327 chars, 113 chunks, TTFT=75.9ms
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_515 to http://localhost:30000/generate at 1753373095.7512188
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_515 with payload: {'text': 'Random prompt 515 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:55] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_515
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_515
[2025-07-25 00:04:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:55] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_497 received DONE after 123 chunks
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_497 completed: 480 chars, 123 chunks, TTFT=68.1ms
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_516 to http://localhost:30000/generate at 1753373095.8979254
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_516 with payload: {'text': 'Random prompt 516 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_494 received DONE after 141 chunks
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_494 completed: 409 chars, 141 chunks, TTFT=88.2ms
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_517 to http://localhost:30000/generate at 1753373095.8994572
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_517 with payload: {'text': 'Random prompt 517 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 179, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:55] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_516
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_516
[2025-07-25 00:04:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:55] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_517
[2025-07-25 00:04:55] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_517
[2025-07-25 00:04:55] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:55] Prefill batch. #new-seq: 2, #new-token: 554, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_495 received DONE after 150 chunks
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_495 completed: 433 chars, 150 chunks, TTFT=79.5ms
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_518 to http://localhost:30000/generate at 1753373096.0512772
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_518 with payload: {'text': 'Random prompt 518 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 95, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_518
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_518
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] Prefill batch. #new-seq: 1, #new-token: 378, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_503 received DONE after 109 chunks
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_503 completed: 432 chars, 109 chunks, TTFT=77.6ms
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_519 to http://localhost:30000/generate at 1753373096.063364
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_519 with payload: {'text': 'Random prompt 519 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_519
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_519
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 6, token usage: 0.06, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_496 received DONE after 143 chunks
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_496 completed: 423 chars, 143 chunks, TTFT=59.5ms
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_520 to http://localhost:30000/generate at 1753373096.1589475
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_520 with payload: {'text': 'Random prompt 520 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_520
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_520
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 5, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_504 received DONE after 114 chunks
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_504 completed: 452 chars, 114 chunks, TTFT=87.1ms
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_521 to http://localhost:30000/generate at 1753373096.2034783
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_521 with payload: {'text': 'Random prompt 521 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_521
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_521
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] Prefill batch. #new-seq: 1, #new-token: 223, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_501 received DONE after 125 chunks
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_501 completed: 500 chars, 125 chunks, TTFT=96.0ms
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_522 to http://localhost:30000/generate at 1753373096.299989
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_522 with payload: {'text': 'Random prompt 522 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_522
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_522
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] Prefill batch. #new-seq: 1, #new-token: 373, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_505 received DONE after 116 chunks
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_505 completed: 447 chars, 116 chunks, TTFT=42.7ms
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_523 to http://localhost:30000/generate at 1753373096.3680885
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_523 with payload: {'text': 'Random prompt 523 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_523
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_523
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] Prefill batch. #new-seq: 1, #new-token: 341, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_500 received DONE after 130 chunks
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_500 completed: 132 chars, 130 chunks, TTFT=98.2ms
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_524 to http://localhost:30000/generate at 1753373096.4128685
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_524 with payload: {'text': 'Random prompt 524 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_524
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_524
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] Decode batch. #running-req: 19, #token: 6877, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1042.14, #queue-req: 0,
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_513 received DONE after 67 chunks
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_513 completed: 194 chars, 67 chunks, TTFT=61.4ms
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_525 to http://localhost:30000/generate at 1753373096.5178638
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_525 with payload: {'text': 'Random prompt 525 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_525
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_525
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] Prefill batch. #new-seq: 1, #new-token: 245, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_515 received DONE after 66 chunks
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_515 completed: 69 chars, 66 chunks, TTFT=41.5ms
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_526 to http://localhost:30000/generate at 1753373096.8625078
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_526 with payload: {'text': 'Random prompt 526 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 100, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_526
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_526
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] Prefill batch. #new-seq: 1, #new-token: 231, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_514 received DONE after 90 chunks
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Request req_514 completed: 91 chars, 90 chunks, TTFT=43.6ms
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_527 to http://localhost:30000/generate at 1753373096.9479775
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_527 with payload: {'text': 'Random prompt 527 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_527
[2025-07-25 00:04:56] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_527
[2025-07-25 00:04:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:56] Prefill batch. #new-seq: 1, #new-token: 195, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_507 received DONE after 133 chunks
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_507 completed: 132 chars, 133 chunks, TTFT=101.6ms
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_499 received DONE after 175 chunks
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_499 completed: 175 chars, 175 chunks, TTFT=60.9ms
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_528 to http://localhost:30000/generate at 1753373097.0358293
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_528 with payload: {'text': 'Random prompt 528 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_529 to http://localhost:30000/generate at 1753373097.03655
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_529 with payload: {'text': 'Random prompt 529 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] Decode batch. #running-req: 20, #token: 6504, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1378.80, #queue-req: 0,
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_528
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_528
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_529
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_529
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] Prefill batch. #new-seq: 2, #new-token: 486, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_506 received DONE after 139 chunks
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_506 completed: 552 chars, 139 chunks, TTFT=103.3ms
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_530 to http://localhost:30000/generate at 1753373097.1473055
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_530 with payload: {'text': 'Random prompt 530 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 104, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_530
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_530
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 5, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_508 received DONE after 143 chunks
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_508 completed: 568 chars, 143 chunks, TTFT=99.8ms
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_531 to http://localhost:30000/generate at 1753373097.227462
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_531 with payload: {'text': 'Random prompt 531 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_531
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_531
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] Prefill batch. #new-seq: 1, #new-token: 381, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_520 received DONE after 73 chunks
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_520 completed: 287 chars, 73 chunks, TTFT=50.5ms
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_532 to http://localhost:30000/generate at 1753373097.3831112
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_532 with payload: {'text': 'Random prompt 532 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_532
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_532
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] Prefill batch. #new-seq: 1, #new-token: 380, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_523 received DONE after 78 chunks
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_523 completed: 218 chars, 78 chunks, TTFT=52.6ms
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_533 to http://localhost:30000/generate at 1753373097.600387
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_533 with payload: {'text': 'Random prompt 533 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_533
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_533
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] Prefill batch. #new-seq: 1, #new-token: 267, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_518 received DONE after 96 chunks
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_518 completed: 97 chars, 96 chunks, TTFT=72.1ms
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_534 to http://localhost:30000/generate at 1753373097.6798906
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_534 with payload: {'text': 'Random prompt 534 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_534
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_534
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] Prefill batch. #new-seq: 1, #new-token: 322, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] Decode batch. #running-req: 19, #token: 7198, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1162.85, #queue-req: 0,
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_509 received DONE after 163 chunks
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_509 completed: 468 chars, 163 chunks, TTFT=76.1ms
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_511 received DONE after 157 chunks
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_511 completed: 612 chars, 157 chunks, TTFT=43.8ms
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_535 to http://localhost:30000/generate at 1753373097.757893
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_535 with payload: {'text': 'Random prompt 535 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_536 to http://localhost:30000/generate at 1753373097.758669
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_536 with payload: {'text': 'Random prompt 536 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_535
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_535
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] Prefill batch. #new-seq: 1, #new-token: 367, #cached-token: 6, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_536
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_536
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] Prefill batch. #new-seq: 1, #new-token: 343, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_510 received DONE after 169 chunks
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Request req_510 completed: 660 chars, 169 chunks, TTFT=75.3ms
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_537 to http://localhost:30000/generate at 1753373097.898891
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_537 with payload: {'text': 'Random prompt 537 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_537
[2025-07-25 00:04:57] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_537
[2025-07-25 00:04:57] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:57] Prefill batch. #new-seq: 1, #new-token: 188, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_525 received DONE after 98 chunks
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_525 completed: 376 chars, 98 chunks, TTFT=44.6ms
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_538 to http://localhost:30000/generate at 1753373098.0788038
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_538 with payload: {'text': 'Random prompt 538 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_538
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_538
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_522 received DONE after 110 chunks
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_522 completed: 436 chars, 110 chunks, TTFT=49.6ms
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_539 to http://localhost:30000/generate at 1753373098.1255658
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_539 with payload: {'text': 'Random prompt 539 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 131, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_539
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_539
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_512 received DONE after 187 chunks
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_512 completed: 562 chars, 187 chunks, TTFT=53.9ms
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_540 to http://localhost:30000/generate at 1753373098.2985902
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_540 with payload: {'text': 'Random prompt 540 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_540
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_540
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] Prefill batch. #new-seq: 1, #new-token: 370, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] Decode batch. #running-req: 20, #token: 6992, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1184.63, #queue-req: 0,
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_516 received DONE after 148 chunks
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_516 completed: 588 chars, 148 chunks, TTFT=75.5ms
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_541 to http://localhost:30000/generate at 1753373098.418553
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_541 with payload: {'text': 'Random prompt 541 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_541
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_541
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] Prefill batch. #new-seq: 1, #new-token: 280, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_524 received DONE after 127 chunks
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_524 completed: 361 chars, 127 chunks, TTFT=61.3ms
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_542 to http://localhost:30000/generate at 1753373098.484504
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_542 with payload: {'text': 'Random prompt 542 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 137, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_542
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_542
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_526 received DONE after 101 chunks
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_526 completed: 400 chars, 101 chunks, TTFT=42.4ms
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_543 to http://localhost:30000/generate at 1753373098.5696507
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_543 with payload: {'text': 'Random prompt 543 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_543
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_543
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] Prefill batch. #new-seq: 1, #new-token: 297, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_527 received DONE after 104 chunks
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_527 completed: 400 chars, 104 chunks, TTFT=44.1ms
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_544 to http://localhost:30000/generate at 1753373098.6973073
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_544 with payload: {'text': 'Random prompt 544 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 187, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_544
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_544
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_530 received DONE after 105 chunks
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_530 completed: 395 chars, 105 chunks, TTFT=62.2ms
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_545 to http://localhost:30000/generate at 1753373098.8884134
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_545 with payload: {'text': 'Random prompt 545 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_545
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_545
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] Prefill batch. #new-seq: 1, #new-token: 217, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_517 received DONE after 180 chunks
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Request req_517 completed: 679 chars, 180 chunks, TTFT=74.0ms
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_546 to http://localhost:30000/generate at 1753373098.9495711
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_546 with payload: {'text': 'Random prompt 546 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_546
[2025-07-25 00:04:58] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_546
[2025-07-25 00:04:58] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:58] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] Decode batch. #running-req: 20, #token: 6789, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1217.70, #queue-req: 0,
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_535 received DONE after 81 chunks
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_535 completed: 82 chars, 81 chunks, TTFT=72.6ms
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_547 to http://localhost:30000/generate at 1753373099.0825167
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_547 with payload: {'text': 'Random prompt 547 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_547
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_547
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] Prefill batch. #new-seq: 1, #new-token: 297, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_519 received DONE after 184 chunks
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_519 completed: 720 chars, 184 chunks, TTFT=64.6ms
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_548 to http://localhost:30000/generate at 1753373099.1462657
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_548 with payload: {'text': 'Random prompt 548 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 70, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_548
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_548
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_536 received DONE after 88 chunks
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_536 completed: 252 chars, 88 chunks, TTFT=83.8ms
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_549 to http://localhost:30000/generate at 1753373099.2276652
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_549 with payload: {'text': 'Random prompt 549 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_549
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_549
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] Prefill batch. #new-seq: 1, #new-token: 323, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_521 received DONE after 185 chunks
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_521 completed: 724 chars, 185 chunks, TTFT=53.6ms
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_550 to http://localhost:30000/generate at 1753373099.2940843
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_550 with payload: {'text': 'Random prompt 550 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_550
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_550
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] Prefill batch. #new-seq: 1, #new-token: 259, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_533 received DONE after 100 chunks
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_533 completed: 396 chars, 100 chunks, TTFT=48.3ms
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_529 received DONE after 134 chunks
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_529 completed: 532 chars, 134 chunks, TTFT=68.3ms
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_551 to http://localhost:30000/generate at 1753373099.307545
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_551 with payload: {'text': 'Random prompt 551 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_552 to http://localhost:30000/generate at 1753373099.3082516
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_552 with payload: {'text': 'Random prompt 552 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_551
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_551
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_552
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_552
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] Prefill batch. #new-seq: 2, #new-token: 611, #cached-token: 10, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_538 received DONE after 88 chunks
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_538 completed: 348 chars, 88 chunks, TTFT=47.5ms
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_553 to http://localhost:30000/generate at 1753373099.5666897
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_553 with payload: {'text': 'Random prompt 553 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_553
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_553
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] Prefill batch. #new-seq: 1, #new-token: 269, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_531 received DONE after 143 chunks
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_531 completed: 531 chars, 143 chunks, TTFT=63.2ms
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_554 to http://localhost:30000/generate at 1753373099.6442692
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_554 with payload: {'text': 'Random prompt 554 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_554
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_554
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_534 received DONE after 118 chunks
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_534 completed: 335 chars, 118 chunks, TTFT=48.8ms
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_555 to http://localhost:30000/generate at 1753373099.7125337
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_555 with payload: {'text': 'Random prompt 555 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 91, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_555
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_555
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] Prefill batch. #new-seq: 1, #new-token: 228, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] Decode batch. #running-req: 20, #token: 6409, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1070.53, #queue-req: 0,
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_541 received DONE after 79 chunks
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_541 completed: 312 chars, 79 chunks, TTFT=48.7ms
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_556 to http://localhost:30000/generate at 1753373099.7988062
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_556 with payload: {'text': 'Random prompt 556 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_556
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_556
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_528 received DONE after 168 chunks
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Request req_528 completed: 665 chars, 168 chunks, TTFT=68.9ms
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_557 to http://localhost:30000/generate at 1753373099.9072187
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_557 with payload: {'text': 'Random prompt 557 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_557
[2025-07-25 00:04:59] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_557
[2025-07-25 00:04:59] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:04:59] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_532 received DONE after 157 chunks
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_532 completed: 624 chars, 157 chunks, TTFT=61.9ms
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_558 to http://localhost:30000/generate at 1753373100.0378668
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_558 with payload: {'text': 'Random prompt 558 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:00] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_558
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_558
[2025-07-25 00:05:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:00] Prefill batch. #new-seq: 1, #new-token: 318, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_543 received DONE after 98 chunks
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_543 completed: 376 chars, 98 chunks, TTFT=48.1ms
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_559 to http://localhost:30000/generate at 1753373100.2013233
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_559 with payload: {'text': 'Random prompt 559 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 179, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:00] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_559
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_559
[2025-07-25 00:05:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:00] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_539 received DONE after 132 chunks
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_539 completed: 512 chars, 132 chunks, TTFT=47.6ms
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_560 to http://localhost:30000/generate at 1753373100.3152514
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_560 with payload: {'text': 'Random prompt 560 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:00] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_560
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_560
[2025-07-25 00:05:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:00] Prefill batch. #new-seq: 1, #new-token: 306, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_548 received DONE after 71 chunks
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_548 completed: 280 chars, 71 chunks, TTFT=51.4ms
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_561 to http://localhost:30000/generate at 1753373100.3589842
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_561 with payload: {'text': 'Random prompt 561 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:00] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_561
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_561
[2025-07-25 00:05:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:00] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:00] Decode batch. #running-req: 20, #token: 6028, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1232.88, #queue-req: 0,
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_537 received DONE after 152 chunks
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_537 completed: 604 chars, 152 chunks, TTFT=43.3ms
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_562 to http://localhost:30000/generate at 1753373100.428128
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_562 with payload: {'text': 'Random prompt 562 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:00] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_562
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_562
[2025-07-25 00:05:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:00] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_542 received DONE after 138 chunks
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_542 completed: 536 chars, 138 chunks, TTFT=45.3ms
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_563 to http://localhost:30000/generate at 1753373100.7283034
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_563 with payload: {'text': 'Random prompt 563 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:00] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_563
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_563
[2025-07-25 00:05:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:00] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_540 received DONE after 156 chunks
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_540 completed: 620 chars, 156 chunks, TTFT=52.5ms
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_564 to http://localhost:30000/generate at 1753373100.8491426
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_564 with payload: {'text': 'Random prompt 564 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:00] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_564
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_564
[2025-07-25 00:05:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:00] Prefill batch. #new-seq: 1, #new-token: 215, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_545 received DONE after 127 chunks
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Request req_545 completed: 491 chars, 127 chunks, TTFT=43.5ms
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_565 to http://localhost:30000/generate at 1753373100.9574594
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_565 with payload: {'text': 'Random prompt 565 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 118, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:00] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_565
[2025-07-25 00:05:00] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_565
[2025-07-25 00:05:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:00] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:00] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:00] Decode batch. #running-req: 19, #token: 6395, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1388.12, #queue-req: 0,
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_554 received DONE after 94 chunks
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_554 completed: 268 chars, 94 chunks, TTFT=50.2ms
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_566 to http://localhost:30000/generate at 1753373101.0967038
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_566 with payload: {'text': 'Random prompt 566 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:01] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_566
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_566
[2025-07-25 00:05:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:01] Prefill batch. #new-seq: 1, #new-token: 226, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_555 received DONE after 92 chunks
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_555 completed: 364 chars, 92 chunks, TTFT=44.3ms
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_567 to http://localhost:30000/generate at 1753373101.109799
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_567 with payload: {'text': 'Random prompt 567 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 76, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:01] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_567
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_567
[2025-07-25 00:05:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:01] Prefill batch. #new-seq: 1, #new-token: 237, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_547 received DONE after 135 chunks
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_547 completed: 524 chars, 135 chunks, TTFT=47.7ms
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_568 to http://localhost:30000/generate at 1753373101.2810266
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_568 with payload: {'text': 'Random prompt 568 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:01] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_568
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_568
[2025-07-25 00:05:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:01] Prefill batch. #new-seq: 1, #new-token: 357, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_551 received DONE after 142 chunks
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_551 completed: 564 chars, 142 chunks, TTFT=83.0ms
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_569 to http://localhost:30000/generate at 1753373101.5196521
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_569 with payload: {'text': 'Random prompt 569 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:01] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_569
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_569
[2025-07-25 00:05:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:01] Prefill batch. #new-seq: 1, #new-token: 214, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_549 received DONE after 146 chunks
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_549 completed: 420 chars, 146 chunks, TTFT=48.7ms
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_570 to http://localhost:30000/generate at 1753373101.5329745
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_570 with payload: {'text': 'Random prompt 570 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 139, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:01] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_570
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_570
[2025-07-25 00:05:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:01] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:01] Decode batch. #running-req: 20, #token: 6358, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1253.83, #queue-req: 0,
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_546 received DONE after 168 chunks
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_546 completed: 656 chars, 168 chunks, TTFT=43.1ms
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_571 to http://localhost:30000/generate at 1753373101.6614156
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_571 with payload: {'text': 'Random prompt 571 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:01] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_571
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_571
[2025-07-25 00:05:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:01] Prefill batch. #new-seq: 1, #new-token: 326, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_544 received DONE after 188 chunks
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_544 completed: 748 chars, 188 chunks, TTFT=48.5ms
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_572 to http://localhost:30000/generate at 1753373101.7398105
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_572 with payload: {'text': 'Random prompt 572 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_557 received DONE after 118 chunks
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_557 completed: 468 chars, 118 chunks, TTFT=40.2ms
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_573 to http://localhost:30000/generate at 1753373101.7419662
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_573 with payload: {'text': 'Random prompt 573 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 174, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:01] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_572
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_572
[2025-07-25 00:05:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:01] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_573
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_573
[2025-07-25 00:05:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:01] Prefill batch. #new-seq: 2, #new-token: 511, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_561 received DONE after 95 chunks
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Request req_561 completed: 364 chars, 95 chunks, TTFT=53.0ms
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_574 to http://localhost:30000/generate at 1753373101.8520877
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_574 with payload: {'text': 'Random prompt 574 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:01] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_574
[2025-07-25 00:05:01] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_574
[2025-07-25 00:05:01] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:01] Prefill batch. #new-seq: 1, #new-token: 346, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_552 received DONE after 170 chunks
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_552 completed: 676 chars, 170 chunks, TTFT=82.2ms
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_575 to http://localhost:30000/generate at 1753373102.018222
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_575 with payload: {'text': 'Random prompt 575 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 76, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_575
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_575
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_556 received DONE after 143 chunks
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_556 completed: 568 chars, 143 chunks, TTFT=43.1ms
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_576 to http://localhost:30000/generate at 1753373102.0298152
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_576 with payload: {'text': 'Random prompt 576 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_576
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_576
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] Prefill batch. #new-seq: 2, #new-token: 531, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_560 received DONE after 110 chunks
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_560 completed: 436 chars, 110 chunks, TTFT=49.5ms
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_577 to http://localhost:30000/generate at 1753373102.042069
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_577 with payload: {'text': 'Random prompt 577 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_577
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_577
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] Prefill batch. #new-seq: 1, #new-token: 362, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] Decode batch. #running-req: 20, #token: 6315, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1184.55, #queue-req: 0,
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_550 received DONE after 187 chunks
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_550 completed: 744 chars, 187 chunks, TTFT=69.0ms
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_578 to http://localhost:30000/generate at 1753373102.3027682
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_578 with payload: {'text': 'Random prompt 578 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_578
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_578
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_563 received DONE after 100 chunks
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_563 completed: 103 chars, 100 chunks, TTFT=44.1ms
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_579 to http://localhost:30000/generate at 1753373102.3620386
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_579 with payload: {'text': 'Random prompt 579 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_579
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_579
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] Prefill batch. #new-seq: 1, #new-token: 191, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_567 received DONE after 77 chunks
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_567 completed: 292 chars, 77 chunks, TTFT=56.4ms
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_580 to http://localhost:30000/generate at 1753373102.3752143
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_580 with payload: {'text': 'Random prompt 580 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_580
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_580
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] Prefill batch. #new-seq: 1, #new-token: 244, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_553 received DONE after 178 chunks
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_553 completed: 638 chars, 178 chunks, TTFT=47.2ms
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_581 to http://localhost:30000/generate at 1753373102.4614415
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_581 with payload: {'text': 'Random prompt 581 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_581
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_581
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] Prefill batch. #new-seq: 1, #new-token: 376, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_558 received DONE after 173 chunks
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_558 completed: 688 chars, 173 chunks, TTFT=59.8ms
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_582 to http://localhost:30000/generate at 1753373102.7865155
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_582 with payload: {'text': 'Random prompt 582 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_582
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_582
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] Prefill batch. #new-seq: 1, #new-token: 251, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_565 received DONE after 119 chunks
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Request req_565 completed: 460 chars, 119 chunks, TTFT=47.6ms
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_583 to http://localhost:30000/generate at 1753373102.8840716
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_583 with payload: {'text': 'Random prompt 583 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_583
[2025-07-25 00:05:02] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_583
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] Prefill batch. #new-seq: 1, #new-token: 209, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:02] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:02] Decode batch. #running-req: 20, #token: 6759, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1235.80, #queue-req: 0,
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_562 received DONE after 165 chunks
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_562 completed: 644 chars, 165 chunks, TTFT=42.6ms
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_584 to http://localhost:30000/generate at 1753373103.0054247
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_584 with payload: {'text': 'Random prompt 584 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_584
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_584
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_559 received DONE after 180 chunks
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_559 completed: 510 chars, 180 chunks, TTFT=59.0ms
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_585 to http://localhost:30000/generate at 1753373103.0848212
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_585 with payload: {'text': 'Random prompt 585 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_585
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_585
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_571 received DONE after 87 chunks
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_571 completed: 254 chars, 87 chunks, TTFT=59.9ms
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_586 to http://localhost:30000/generate at 1753373103.0972366
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_586 with payload: {'text': 'Random prompt 586 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_586
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_586
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] Prefill batch. #new-seq: 1, #new-token: 145, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_576 received DONE after 68 chunks
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_576 completed: 255 chars, 68 chunks, TTFT=84.7ms
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_587 to http://localhost:30000/generate at 1753373103.1699157
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_587 with payload: {'text': 'Random prompt 587 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_587
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_587
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_575 received DONE after 77 chunks
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_575 completed: 217 chars, 77 chunks, TTFT=96.5ms
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_588 to http://localhost:30000/generate at 1753373103.3020155
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_588 with payload: {'text': 'Random prompt 588 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_588
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_588
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_574 received DONE after 93 chunks
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_574 completed: 263 chars, 93 chunks, TTFT=61.7ms
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_589 to http://localhost:30000/generate at 1753373103.3884954
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_589 with payload: {'text': 'Random prompt 589 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_589
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_589
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_566 received DONE after 150 chunks
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_566 completed: 584 chars, 150 chunks, TTFT=65.7ms
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_590 to http://localhost:30000/generate at 1753373103.5442393
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_590 with payload: {'text': 'Random prompt 590 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_590
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_590
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] Prefill batch. #new-seq: 1, #new-token: 162, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_569 received DONE after 123 chunks
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_569 completed: 488 chars, 123 chunks, TTFT=66.5ms
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_591 to http://localhost:30000/generate at 1753373103.55242
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_591 with payload: {'text': 'Random prompt 591 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_591
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_591
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] Decode batch. #running-req: 20, #token: 6080, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1150.55, #queue-req: 0,
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_564 received DONE after 170 chunks
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_564 completed: 663 chars, 170 chunks, TTFT=43.1ms
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_592 to http://localhost:30000/generate at 1753373103.6467042
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_592 with payload: {'text': 'Random prompt 592 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_592
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_592
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_568 received DONE after 145 chunks
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_568 completed: 144 chars, 145 chunks, TTFT=61.4ms
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_593 to http://localhost:30000/generate at 1753373103.7061489
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_593 with payload: {'text': 'Random prompt 593 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_593
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_593
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] Prefill batch. #new-seq: 1, #new-token: 214, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_570 received DONE after 140 chunks
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_570 completed: 475 chars, 140 chunks, TTFT=61.0ms
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_594 to http://localhost:30000/generate at 1753373103.8622837
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_594 with payload: {'text': 'Random prompt 594 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_594
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_594
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_580 received DONE after 95 chunks
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Request req_580 completed: 364 chars, 95 chunks, TTFT=55.4ms
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_595 to http://localhost:30000/generate at 1753373103.918419
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_595 with payload: {'text': 'Random prompt 595 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 138, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_595
[2025-07-25 00:05:03] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_595
[2025-07-25 00:05:03] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:03] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] Decode batch. #running-req: 20, #token: 6243, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1361.82, #queue-req: 0,
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_581 received DONE after 115 chunks
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_581 completed: 437 chars, 115 chunks, TTFT=61.4ms
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_596 to http://localhost:30000/generate at 1753373104.2548566
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_596 with payload: {'text': 'Random prompt 596 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_596
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_596
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] Prefill batch. #new-seq: 1, #new-token: 296, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_572 received DONE after 159 chunks
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_572 completed: 620 chars, 159 chunks, TTFT=70.8ms
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_597 to http://localhost:30000/generate at 1753373104.310547
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_597 with payload: {'text': 'Random prompt 597 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_597
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_597
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_585 received DONE after 82 chunks
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_585 completed: 312 chars, 82 chunks, TTFT=64.1ms
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_577 received DONE after 147 chunks
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_577 completed: 584 chars, 147 chunks, TTFT=83.2ms
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_598 to http://localhost:30000/generate at 1753373104.404434
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_598 with payload: {'text': 'Random prompt 598 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_599 to http://localhost:30000/generate at 1753373104.4051046
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_599 with payload: {'text': 'Random prompt 599 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 178, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_598
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_598
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_599
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_599
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] Prefill batch. #new-seq: 2, #new-token: 310, #cached-token: 12, token usage: 0.04, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_579 received DONE after 135 chunks
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_579 completed: 523 chars, 135 chunks, TTFT=64.8ms
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_600 to http://localhost:30000/generate at 1753373104.5161371
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_600 with payload: {'text': 'Random prompt 600 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 89, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_600
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_600
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 4, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_573 received DONE after 175 chunks
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_573 completed: 696 chars, 175 chunks, TTFT=68.6ms
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_601 to http://localhost:30000/generate at 1753373104.5872996
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_601 with payload: {'text': 'Random prompt 601 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 105, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_601
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_601
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] Prefill batch. #new-seq: 1, #new-token: 196, #cached-token: 6, token usage: 0.04, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_578 received DONE after 143 chunks
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_578 completed: 556 chars, 143 chunks, TTFT=43.7ms
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_602 to http://localhost:30000/generate at 1753373104.599123
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_602 with payload: {'text': 'Random prompt 602 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_602
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_602
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 6, token usage: 0.04, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] Decode batch. #running-req: 20, #token: 5517, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1259.19, #queue-req: 0,
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_593 received DONE after 78 chunks
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_593 completed: 296 chars, 78 chunks, TTFT=43.0ms
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_603 to http://localhost:30000/generate at 1753373104.8697972
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_603 with payload: {'text': 'Random prompt 603 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_592 received DONE after 81 chunks
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_592 completed: 308 chars, 81 chunks, TTFT=44.2ms
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_604 to http://localhost:30000/generate at 1753373104.871715
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_604 with payload: {'text': 'Random prompt 604 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_603
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_603
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 6, token usage: 0.04, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_604
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_604
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 6, token usage: 0.04, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_583 received DONE after 129 chunks
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Request req_583 completed: 512 chars, 129 chunks, TTFT=43.6ms
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_605 to http://localhost:30000/generate at 1753373104.965456
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_605 with payload: {'text': 'Random prompt 605 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_605
[2025-07-25 00:05:04] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_605
[2025-07-25 00:05:04] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:04] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 6, token usage: 0.04, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_587 received DONE after 117 chunks
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_587 completed: 452 chars, 117 chunks, TTFT=43.9ms
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_606 to http://localhost:30000/generate at 1753373105.024371
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_606 with payload: {'text': 'Random prompt 606 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_606
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_606
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 6, token usage: 0.04, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_582 received DONE after 141 chunks
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_582 completed: 548 chars, 141 chunks, TTFT=44.0ms
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_607 to http://localhost:30000/generate at 1753373105.0828986
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_607 with payload: {'text': 'Random prompt 607 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_607
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_607
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] Prefill batch. #new-seq: 1, #new-token: 218, #cached-token: 6, token usage: 0.04, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_588 received DONE after 120 chunks
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_588 completed: 463 chars, 120 chunks, TTFT=46.1ms
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_608 to http://localhost:30000/generate at 1753373105.212423
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_608 with payload: {'text': 'Random prompt 608 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_608
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_608
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] Prefill batch. #new-seq: 1, #new-token: 254, #cached-token: 6, token usage: 0.04, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] Decode batch. #running-req: 20, #token: 5686, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1284.52, #queue-req: 0,
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_597 received DONE after 75 chunks
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_597 completed: 284 chars, 75 chunks, TTFT=52.1ms
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_609 to http://localhost:30000/generate at 1753373105.4740365
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_609 with payload: {'text': 'Random prompt 609 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_609
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_609
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] Prefill batch. #new-seq: 1, #new-token: 302, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_586 received DONE after 154 chunks
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_586 completed: 600 chars, 154 chunks, TTFT=55.0ms
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_610 to http://localhost:30000/generate at 1753373105.518657
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_610 with payload: {'text': 'Random prompt 610 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_610
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_610
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_598 received DONE after 76 chunks
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_598 completed: 300 chars, 76 chunks, TTFT=59.1ms
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_611 to http://localhost:30000/generate at 1753373105.6116893
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_611 with payload: {'text': 'Random prompt 611 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_611
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_611
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] Prefill batch. #new-seq: 1, #new-token: 330, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_589 received DONE after 157 chunks
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_589 completed: 612 chars, 157 chunks, TTFT=46.0ms
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_612 to http://localhost:30000/generate at 1753373105.822388
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_612 with payload: {'text': 'Random prompt 612 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 132, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_612
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_612
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] Prefill batch. #new-seq: 1, #new-token: 286, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_596 received DONE after 100 chunks
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_596 completed: 293 chars, 100 chunks, TTFT=61.3ms
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_613 to http://localhost:30000/generate at 1753373105.8348048
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_613 with payload: {'text': 'Random prompt 613 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_613
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_613
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] Prefill batch. #new-seq: 1, #new-token: 146, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_600 received DONE after 90 chunks
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_600 completed: 356 chars, 90 chunks, TTFT=43.6ms
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_614 to http://localhost:30000/generate at 1753373105.9370058
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_614 with payload: {'text': 'Random prompt 614 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_614
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_614
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] Prefill batch. #new-seq: 1, #new-token: 349, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_590 received DONE after 154 chunks
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Request req_590 completed: 600 chars, 154 chunks, TTFT=64.0ms
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_615 to http://localhost:30000/generate at 1753373105.9936805
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_615 with payload: {'text': 'Random prompt 615 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 150, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:05] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:05] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_615
[2025-07-25 00:05:05] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_615
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] Prefill batch. #new-seq: 1, #new-token: 361, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_602 received DONE after 94 chunks
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_602 completed: 372 chars, 94 chunks, TTFT=52.2ms
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_604 received DONE after 74 chunks
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_604 completed: 280 chars, 74 chunks, TTFT=64.0ms
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_584 received DONE after 191 chunks
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_584 completed: 760 chars, 191 chunks, TTFT=48.5ms
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_616 to http://localhost:30000/generate at 1753373106.0986898
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_616 with payload: {'text': 'Random prompt 616 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_617 to http://localhost:30000/generate at 1753373106.0994828
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_617 with payload: {'text': 'Random prompt 617 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_618 to http://localhost:30000/generate at 1753373106.1001348
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_618 with payload: {'text': 'Random prompt 618 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 135, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_616
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_616
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_618
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_618
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_617
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_617
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] Prefill batch. #new-seq: 3, #new-token: 669, #cached-token: 18, token usage: 0.04, #running-req: 16, #queue-req: 0,
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_595 received DONE after 139 chunks
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_595 completed: 552 chars, 139 chunks, TTFT=53.2ms
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_619 to http://localhost:30000/generate at 1753373106.118707
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_619 with payload: {'text': 'Random prompt 619 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_619
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_619
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] Decode batch. #running-req: 20, #token: 5938, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1023.66, #queue-req: 0,
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_606 received DONE after 74 chunks
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_606 completed: 279 chars, 74 chunks, TTFT=43.5ms
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_620 to http://localhost:30000/generate at 1753373106.266227
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_620 with payload: {'text': 'Random prompt 620 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 124, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_620
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_620
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_601 received DONE after 106 chunks
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_601 completed: 420 chars, 106 chunks, TTFT=62.0ms
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_621 to http://localhost:30000/generate at 1753373106.3480582
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_621 with payload: {'text': 'Random prompt 621 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_621
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_621
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] Prefill batch. #new-seq: 1, #new-token: 179, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_594 received DONE after 158 chunks
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_594 completed: 450 chars, 158 chunks, TTFT=61.5ms
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_622 to http://localhost:30000/generate at 1753373106.4432852
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_622 with payload: {'text': 'Random prompt 622 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 136, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_622
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_622
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] Prefill batch. #new-seq: 1, #new-token: 220, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_591 received DONE after 192 chunks
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_591 completed: 752 chars, 192 chunks, TTFT=64.8ms
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_623 to http://localhost:30000/generate at 1753373106.6467323
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_623 with payload: {'text': 'Random prompt 623 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 187, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_623
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_623
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] Prefill batch. #new-seq: 1, #new-token: 249, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_603 received DONE after 110 chunks
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_603 completed: 423 chars, 110 chunks, TTFT=63.0ms
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_624 to http://localhost:30000/generate at 1753373106.7024193
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_624 with payload: {'text': 'Random prompt 624 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_624
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_624
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] Prefill batch. #new-seq: 1, #new-token: 283, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_608 received DONE after 95 chunks
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Request req_608 completed: 363 chars, 95 chunks, TTFT=44.0ms
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_625 to http://localhost:30000/generate at 1753373106.785884
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_625 with payload: {'text': 'Random prompt 625 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_625
[2025-07-25 00:05:06] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_625
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] Prefill batch. #new-seq: 1, #new-token: 220, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:06] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:06] Decode batch. #running-req: 20, #token: 5905, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1259.37, #queue-req: 0,
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_605 received DONE after 131 chunks
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_605 completed: 508 chars, 131 chunks, TTFT=43.0ms
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_626 to http://localhost:30000/generate at 1753373107.062474
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_626 with payload: {'text': 'Random prompt 626 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:07] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_626
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_626
[2025-07-25 00:05:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:07] Prefill batch. #new-seq: 1, #new-token: 244, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_599 received DONE after 179 chunks
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_599 completed: 709 chars, 179 chunks, TTFT=58.6ms
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_627 to http://localhost:30000/generate at 1753373107.2560902
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_627 with payload: {'text': 'Random prompt 627 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:07] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_627
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_627
[2025-07-25 00:05:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:07] Prefill batch. #new-seq: 1, #new-token: 316, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:07] Decode batch. #running-req: 20, #token: 6572, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1481.05, #queue-req: 0,
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_621 received DONE after 73 chunks
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_621 completed: 275 chars, 73 chunks, TTFT=43.7ms
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_628 to http://localhost:30000/generate at 1753373107.408143
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_628 with payload: {'text': 'Random prompt 628 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 76, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:07] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_628
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_628
[2025-07-25 00:05:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:07] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_613 received DONE after 107 chunks
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_613 completed: 106 chars, 107 chunks, TTFT=60.9ms
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_629 to http://localhost:30000/generate at 1753373107.5412807
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_629 with payload: {'text': 'Random prompt 629 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:07] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_629
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_629
[2025-07-25 00:05:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:07] Prefill batch. #new-seq: 1, #new-token: 190, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_609 received DONE after 134 chunks
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_609 completed: 381 chars, 134 chunks, TTFT=49.4ms
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_630 to http://localhost:30000/generate at 1753373107.6247232
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_630 with payload: {'text': 'Random prompt 630 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:07] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_630
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_630
[2025-07-25 00:05:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:07] Prefill batch. #new-seq: 1, #new-token: 309, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_614 received DONE after 108 chunks
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_614 completed: 319 chars, 108 chunks, TTFT=63.2ms
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_631 to http://localhost:30000/generate at 1753373107.6483572
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_631 with payload: {'text': 'Random prompt 631 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:07] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_631
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_631
[2025-07-25 00:05:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:07] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_607 received DONE after 167 chunks
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_607 completed: 664 chars, 167 chunks, TTFT=43.4ms
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_632 to http://localhost:30000/generate at 1753373107.7349122
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_632 with payload: {'text': 'Random prompt 632 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:07] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_632
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_632
[2025-07-25 00:05:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:07] Prefill batch. #new-seq: 1, #new-token: 256, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_612 received DONE after 133 chunks
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_612 completed: 515 chars, 133 chunks, TTFT=69.3ms
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_633 to http://localhost:30000/generate at 1753373107.9696143
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_633 with payload: {'text': 'Random prompt 633 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_611 received DONE after 148 chunks
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Request req_611 completed: 575 chars, 148 chunks, TTFT=49.3ms
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_634 to http://localhost:30000/generate at 1753373107.9716752
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_634 with payload: {'text': 'Random prompt 634 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:07] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_633
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_633
[2025-07-25 00:05:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:07] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_634
[2025-07-25 00:05:07] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_634
[2025-07-25 00:05:07] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:07] Prefill batch. #new-seq: 2, #new-token: 414, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_624 received DONE after 87 chunks
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_624 completed: 344 chars, 87 chunks, TTFT=52.3ms
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_635 to http://localhost:30000/generate at 1753373108.0250425
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_635 with payload: {'text': 'Random prompt 635 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_635
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_635
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] Prefill batch. #new-seq: 1, #new-token: 240, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] Decode batch. #running-req: 19, #token: 6198, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1163.38, #queue-req: 0,
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_620 received DONE after 125 chunks
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_620 completed: 496 chars, 125 chunks, TTFT=42.6ms
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_636 to http://localhost:30000/generate at 1753373108.1786337
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_636 with payload: {'text': 'Random prompt 636 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_636
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_636
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] Prefill batch. #new-seq: 1, #new-token: 261, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_618 received DONE after 136 chunks
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_618 completed: 495 chars, 136 chunks, TTFT=102.1ms
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_637 to http://localhost:30000/generate at 1753373108.2675614
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_637 with payload: {'text': 'Random prompt 637 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 84, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_637
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_637
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_610 received DONE after 178 chunks
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_610 completed: 705 chars, 178 chunks, TTFT=52.2ms
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_638 to http://localhost:30000/generate at 1753373108.390367
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_638 with payload: {'text': 'Random prompt 638 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_638
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_638
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] Prefill batch. #new-seq: 1, #new-token: 194, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_615 received DONE after 151 chunks
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_615 completed: 446 chars, 151 chunks, TTFT=60.7ms
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_639 to http://localhost:30000/generate at 1753373108.4026015
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_639 with payload: {'text': 'Random prompt 639 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_639
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_639
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_617 received DONE after 150 chunks
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_617 completed: 584 chars, 150 chunks, TTFT=103.0ms
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_640 to http://localhost:30000/generate at 1753373108.5115817
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_640 with payload: {'text': 'Random prompt 640 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_640
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_640
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_626 received DONE after 91 chunks
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_626 completed: 348 chars, 91 chunks, TTFT=55.4ms
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_641 to http://localhost:30000/generate at 1753373108.554184
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_641 with payload: {'text': 'Random prompt 641 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_641
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_641
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] Prefill batch. #new-seq: 1, #new-token: 208, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_622 received DONE after 137 chunks
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_622 completed: 531 chars, 137 chunks, TTFT=42.8ms
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_642 to http://localhost:30000/generate at 1753373108.6033318
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_642 with payload: {'text': 'Random prompt 642 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 131, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_642
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_642
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] Prefill batch. #new-seq: 1, #new-token: 179, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_619 received DONE after 159 chunks
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_619 completed: 620 chars, 159 chunks, TTFT=93.2ms
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_643 to http://localhost:30000/generate at 1753373108.6910837
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_643 with payload: {'text': 'Random prompt 643 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_643
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_643
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] Prefill batch. #new-seq: 1, #new-token: 209, #cached-token: 6, token usage: 0.04, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_628 received DONE after 77 chunks
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Request req_628 completed: 301 chars, 77 chunks, TTFT=43.3ms
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_644 to http://localhost:30000/generate at 1753373108.714573
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_644 with payload: {'text': 'Random prompt 644 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_644
[2025-07-25 00:05:08] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_644
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 6, token usage: 0.04, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:08] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:08] Decode batch. #running-req: 20, #token: 5450, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1110.71, #queue-req: 0,
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_616 received DONE after 192 chunks
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_616 completed: 760 chars, 192 chunks, TTFT=103.8ms
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_645 to http://localhost:30000/generate at 1753373109.133159
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_645 with payload: {'text': 'Random prompt 645 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:09] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_645
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_645
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_625 received DONE after 153 chunks
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_625 completed: 596 chars, 153 chunks, TTFT=54.4ms
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_646 to http://localhost:30000/generate at 1753373109.1450052
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_646 with payload: {'text': 'Random prompt 646 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:09] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_646
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_646
[2025-07-25 00:05:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:09] Prefill batch. #new-seq: 2, #new-token: 630, #cached-token: 12, token usage: 0.04, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:09] Decode batch. #running-req: 20, #token: 6172, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1506.66, #queue-req: 0,
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_631 received DONE after 109 chunks
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_631 completed: 432 chars, 109 chunks, TTFT=68.1ms
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_647 to http://localhost:30000/generate at 1753373109.3728497
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_647 with payload: {'text': 'Random prompt 647 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:09] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_647
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_647
[2025-07-25 00:05:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:09] Prefill batch. #new-seq: 1, #new-token: 299, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_627 received DONE after 134 chunks
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_627 completed: 532 chars, 134 chunks, TTFT=59.8ms
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_648 to http://localhost:30000/generate at 1753373109.3868518
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_648 with payload: {'text': 'Random prompt 648 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:09] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_648
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_648
[2025-07-25 00:05:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:09] Prefill batch. #new-seq: 1, #new-token: 327, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_635 received DONE after 95 chunks
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_635 completed: 364 chars, 95 chunks, TTFT=50.3ms
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_649 to http://localhost:30000/generate at 1753373109.5342047
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_649 with payload: {'text': 'Random prompt 649 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_629 received DONE after 123 chunks
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_629 completed: 476 chars, 123 chunks, TTFT=43.6ms
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_650 to http://localhost:30000/generate at 1753373109.536199
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_650 with payload: {'text': 'Random prompt 650 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:09] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_649
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_649
[2025-07-25 00:05:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:09] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_650
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_650
[2025-07-25 00:05:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:09] Prefill batch. #new-seq: 2, #new-token: 401, #cached-token: 11, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_623 received DONE after 188 chunks
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_623 completed: 736 chars, 188 chunks, TTFT=57.5ms
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_651 to http://localhost:30000/generate at 1753373109.6328044
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_651 with payload: {'text': 'Random prompt 651 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_637 received DONE after 85 chunks
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_637 completed: 324 chars, 85 chunks, TTFT=46.5ms
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_652 to http://localhost:30000/generate at 1753373109.6346729
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_652 with payload: {'text': 'Random prompt 652 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 98, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:09] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_651
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_651
[2025-07-25 00:05:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:09] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_652
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_652
[2025-07-25 00:05:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:09] Prefill batch. #new-seq: 2, #new-token: 538, #cached-token: 12, token usage: 0.04, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_644 received DONE after 76 chunks
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Request req_644 completed: 287 chars, 76 chunks, TTFT=53.3ms
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_653 to http://localhost:30000/generate at 1753373109.860266
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_653 with payload: {'text': 'Random prompt 653 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 110, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:09] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_653
[2025-07-25 00:05:09] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_653
[2025-07-25 00:05:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:09] Prefill batch. #new-seq: 1, #new-token: 316, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:09] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:09] Decode batch. #running-req: 20, #token: 6346, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1195.03, #queue-req: 0,
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_636 received DONE after 116 chunks
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_636 completed: 460 chars, 116 chunks, TTFT=47.6ms
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_654 to http://localhost:30000/generate at 1753373110.0241508
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_654 with payload: {'text': 'Random prompt 654 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_654
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_654
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] Prefill batch. #new-seq: 1, #new-token: 236, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_632 received DONE after 150 chunks
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_632 completed: 584 chars, 150 chunks, TTFT=46.1ms
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_655 to http://localhost:30000/generate at 1753373110.1093726
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_655 with payload: {'text': 'Random prompt 655 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_655
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_655
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_630 received DONE after 162 chunks
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_630 completed: 612 chars, 162 chunks, TTFT=80.0ms
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_656 to http://localhost:30000/generate at 1753373110.2405388
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_656 with payload: {'text': 'Random prompt 656 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 135, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_656
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_656
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] Prefill batch. #new-seq: 1, #new-token: 198, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_646 received DONE after 81 chunks
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_646 completed: 308 chars, 81 chunks, TTFT=65.6ms
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_657 to http://localhost:30000/generate at 1753373110.422028
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_657 with payload: {'text': 'Random prompt 657 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_657
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_657
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] Prefill batch. #new-seq: 1, #new-token: 218, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] Decode batch. #running-req: 20, #token: 6345, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1373.12, #queue-req: 0,
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_640 received DONE after 134 chunks
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_640 completed: 532 chars, 134 chunks, TTFT=44.5ms
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_658 to http://localhost:30000/generate at 1753373110.5669243
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_658 with payload: {'text': 'Random prompt 658 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_658
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_658
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_642 received DONE after 132 chunks
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_642 completed: 524 chars, 132 chunks, TTFT=48.0ms
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_659 to http://localhost:30000/generate at 1753373110.5911312
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_659 with payload: {'text': 'Random prompt 659 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 121, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_659
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_659
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] Prefill batch. #new-seq: 1, #new-token: 271, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_633 received DONE after 167 chunks
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_633 completed: 664 chars, 167 chunks, TTFT=67.9ms
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_650 received DONE after 70 chunks
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_650 completed: 276 chars, 70 chunks, TTFT=67.0ms
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_660 to http://localhost:30000/generate at 1753373110.6244657
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_660 with payload: {'text': 'Random prompt 660 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_661 to http://localhost:30000/generate at 1753373110.6251996
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_661 with payload: {'text': 'Random prompt 661 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_660
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_660
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_661
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_661
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] Prefill batch. #new-seq: 2, #new-token: 596, #cached-token: 10, token usage: 0.05, #running-req: 21, #queue-req: 0,
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_634 received DONE after 184 chunks
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_634 completed: 720 chars, 184 chunks, TTFT=65.6ms
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_662 to http://localhost:30000/generate at 1753373110.9209173
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_662 with payload: {'text': 'Random prompt 662 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 182, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_662
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_662
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] Prefill batch. #new-seq: 1, #new-token: 280, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_643 received DONE after 145 chunks
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Request req_643 completed: 563 chars, 145 chunks, TTFT=73.4ms
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_663 to http://localhost:30000/generate at 1753373110.9331653
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_663 with payload: {'text': 'Random prompt 663 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_663
[2025-07-25 00:05:10] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_663
[2025-07-25 00:05:10] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:10] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_652 received DONE after 99 chunks
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_652 completed: 392 chars, 99 chunks, TTFT=75.9ms
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_664 to http://localhost:30000/generate at 1753373111.1811135
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_664 with payload: {'text': 'Random prompt 664 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:11] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_664
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_664
[2025-07-25 00:05:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:11] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:11] Decode batch. #running-req: 19, #token: 6308, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1185.66, #queue-req: 0,
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_654 received DONE after 76 chunks
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_654 completed: 288 chars, 76 chunks, TTFT=43.4ms
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_665 to http://localhost:30000/generate at 1753373111.2260664
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_665 with payload: {'text': 'Random prompt 665 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 173, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:11] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_665
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_665
[2025-07-25 00:05:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:11] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_641 received DONE after 173 chunks
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_641 completed: 676 chars, 173 chunks, TTFT=50.9ms
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_666 to http://localhost:30000/generate at 1753373111.27414
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_666 with payload: {'text': 'Random prompt 666 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 91, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:11] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_666
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_666
[2025-07-25 00:05:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:11] Prefill batch. #new-seq: 1, #new-token: 188, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_651 received DONE after 104 chunks
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_651 completed: 400 chars, 104 chunks, TTFT=77.8ms
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_667 to http://localhost:30000/generate at 1753373111.2895353
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_667 with payload: {'text': 'Random prompt 667 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:11] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_667
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_667
[2025-07-25 00:05:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:11] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_639 received DONE after 184 chunks
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_639 completed: 720 chars, 184 chunks, TTFT=54.8ms
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_668 to http://localhost:30000/generate at 1753373111.361824
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_668 with payload: {'text': 'Random prompt 668 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 79, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:11] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_668
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_668
[2025-07-25 00:05:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:11] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_638 received DONE after 192 chunks
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_638 completed: 752 chars, 192 chunks, TTFT=63.6ms
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_669 to http://localhost:30000/generate at 1753373111.4814434
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_669 with payload: {'text': 'Random prompt 669 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:11] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_669
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_669
[2025-07-25 00:05:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:11] Prefill batch. #new-seq: 1, #new-token: 198, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_653 received DONE after 111 chunks
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_653 completed: 314 chars, 111 chunks, TTFT=60.0ms
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_670 to http://localhost:30000/generate at 1753373111.651562
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_670 with payload: {'text': 'Random prompt 670 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 113, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:11] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_670
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_670
[2025-07-25 00:05:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:11] Prefill batch. #new-seq: 1, #new-token: 171, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_645 received DONE after 162 chunks
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Request req_645 completed: 465 chars, 162 chunks, TTFT=77.4ms
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_671 to http://localhost:30000/generate at 1753373111.757747
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_671 with payload: {'text': 'Random prompt 671 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:11] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_671
[2025-07-25 00:05:11] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_671
[2025-07-25 00:05:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:11] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:11] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:11] Decode batch. #running-req: 20, #token: 6059, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1200.07, #queue-req: 0,
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_649 received DONE after 156 chunks
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_649 completed: 608 chars, 156 chunks, TTFT=68.9ms
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_648 received DONE after 165 chunks
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_648 completed: 473 chars, 165 chunks, TTFT=67.8ms
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_672 to http://localhost:30000/generate at 1753373112.0062044
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_672 with payload: {'text': 'Random prompt 672 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_673 to http://localhost:30000/generate at 1753373112.006933
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_673 with payload: {'text': 'Random prompt 673 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_672
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_672
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_673
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_673
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] Prefill batch. #new-seq: 2, #new-token: 405, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_657 received DONE after 104 chunks
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_657 completed: 400 chars, 104 chunks, TTFT=43.3ms
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_674 to http://localhost:30000/generate at 1753373112.1046674
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_674 with payload: {'text': 'Random prompt 674 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_674
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_674
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] Prefill batch. #new-seq: 1, #new-token: 230, #cached-token: 6, token usage: 0.04, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_647 received DONE after 171 chunks
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_647 completed: 508 chars, 171 chunks, TTFT=71.6ms
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_675 to http://localhost:30000/generate at 1753373112.1157913
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_675 with payload: {'text': 'Random prompt 675 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_675
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_675
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 6, token usage: 0.04, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_656 received DONE after 136 chunks
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_656 completed: 527 chars, 136 chunks, TTFT=43.9ms
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_676 to http://localhost:30000/generate at 1753373112.389924
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_676 with payload: {'text': 'Random prompt 676 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_676
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_676
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_658 received DONE after 116 chunks
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_658 completed: 460 chars, 116 chunks, TTFT=80.3ms
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_677 to http://localhost:30000/generate at 1753373112.4591963
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_677 with payload: {'text': 'Random prompt 677 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_677
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_677
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] Prefill batch. #new-seq: 1, #new-token: 227, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] Decode batch. #running-req: 19, #token: 5799, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1284.07, #queue-req: 0,
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_659 received DONE after 122 chunks
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_659 completed: 472 chars, 122 chunks, TTFT=87.1ms
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_678 to http://localhost:30000/generate at 1753373112.556337
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_678 with payload: {'text': 'Random prompt 678 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_678
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_678
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] Prefill batch. #new-seq: 1, #new-token: 373, #cached-token: 6, token usage: 0.04, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_668 received DONE after 80 chunks
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_668 completed: 303 chars, 80 chunks, TTFT=43.8ms
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_679 to http://localhost:30000/generate at 1753373112.568032
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_679 with payload: {'text': 'Random prompt 679 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_679
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_679
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] Prefill batch. #new-seq: 1, #new-token: 347, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_661 received DONE after 131 chunks
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_661 completed: 368 chars, 131 chunks, TTFT=82.0ms
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_680 to http://localhost:30000/generate at 1753373112.727735
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_680 with payload: {'text': 'Random prompt 680 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_680
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_680
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] Prefill batch. #new-seq: 1, #new-token: 335, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_666 received DONE after 92 chunks
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_666 completed: 352 chars, 92 chunks, TTFT=67.3ms
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_681 to http://localhost:30000/generate at 1753373112.7413213
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_681 with payload: {'text': 'Random prompt 681 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_681
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_681
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] Prefill batch. #new-seq: 1, #new-token: 192, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_660 received DONE after 142 chunks
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Request req_660 completed: 564 chars, 142 chunks, TTFT=82.8ms
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_682 to http://localhost:30000/generate at 1753373112.916704
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_682 with payload: {'text': 'Random prompt 682 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_682
[2025-07-25 00:05:12] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_682
[2025-07-25 00:05:12] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:12] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_663 received DONE after 129 chunks
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_663 completed: 499 chars, 129 chunks, TTFT=58.0ms
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_683 to http://localhost:30000/generate at 1753373113.0108395
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_683 with payload: {'text': 'Random prompt 683 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:13] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_683
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_683
[2025-07-25 00:05:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:13] Prefill batch. #new-seq: 1, #new-token: 296, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_655 received DONE after 185 chunks
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_655 completed: 723 chars, 185 chunks, TTFT=42.6ms
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_684 to http://localhost:30000/generate at 1753373113.0881598
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_684 with payload: {'text': 'Random prompt 684 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:13] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_684
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_684
[2025-07-25 00:05:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:13] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:13] Decode batch. #running-req: 20, #token: 6243, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1152.07, #queue-req: 0,
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_670 received DONE after 114 chunks
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_670 completed: 439 chars, 114 chunks, TTFT=41.4ms
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_685 to http://localhost:30000/generate at 1753373113.425542
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_685 with payload: {'text': 'Random prompt 685 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 174, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:13] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_685
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_685
[2025-07-25 00:05:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:13] Prefill batch. #new-seq: 1, #new-token: 268, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_676 received DONE after 75 chunks
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_676 completed: 283 chars, 75 chunks, TTFT=43.5ms
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_686 to http://localhost:30000/generate at 1753373113.576764
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_686 with payload: {'text': 'Random prompt 686 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 182, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:13] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_686
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_686
[2025-07-25 00:05:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:13] Prefill batch. #new-seq: 1, #new-token: 271, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_675 received DONE after 104 chunks
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_675 completed: 303 chars, 104 chunks, TTFT=62.8ms
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_687 to http://localhost:30000/generate at 1753373113.7304285
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_687 with payload: {'text': 'Random prompt 687 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:13] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_687
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_687
[2025-07-25 00:05:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:13] Decode batch. #running-req: 20, #token: 6588, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1451.69, #queue-req: 0,
[2025-07-25 00:05:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:13] Prefill batch. #new-seq: 1, #new-token: 197, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_662 received DONE after 183 chunks
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_662 completed: 716 chars, 183 chunks, TTFT=67.0ms
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_688 to http://localhost:30000/generate at 1753373113.817611
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_688 with payload: {'text': 'Random prompt 688 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:13] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_688
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_688
[2025-07-25 00:05:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:13] Prefill batch. #new-seq: 1, #new-token: 322, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_678 received DONE after 87 chunks
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_678 completed: 344 chars, 87 chunks, TTFT=70.9ms
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_689 to http://localhost:30000/generate at 1753373113.9351099
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_689 with payload: {'text': 'Random prompt 689 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:13] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_689
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_689
[2025-07-25 00:05:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:13] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_665 received DONE after 174 chunks
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Request req_665 completed: 692 chars, 174 chunks, TTFT=48.8ms
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_690 to http://localhost:30000/generate at 1753373113.9946723
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_690 with payload: {'text': 'Random prompt 690 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:13] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:13] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_690
[2025-07-25 00:05:13] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_690
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] Prefill batch. #new-seq: 1, #new-token: 209, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_669 received DONE after 170 chunks
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_669 completed: 664 chars, 170 chunks, TTFT=43.2ms
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_691 to http://localhost:30000/generate at 1753373114.1293378
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_691 with payload: {'text': 'Random prompt 691 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_691
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_691
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] Prefill batch. #new-seq: 1, #new-token: 234, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_667 received DONE after 184 chunks
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_667 completed: 732 chars, 184 chunks, TTFT=55.2ms
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_692 to http://localhost:30000/generate at 1753373114.1928363
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_692 with payload: {'text': 'Random prompt 692 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_692
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_692
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] Prefill batch. #new-seq: 1, #new-token: 255, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_664 received DONE after 192 chunks
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_664 completed: 752 chars, 192 chunks, TTFT=45.7ms
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_693 to http://localhost:30000/generate at 1753373114.2661417
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_693 with payload: {'text': 'Random prompt 693 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_693
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_693
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_677 received DONE after 117 chunks
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_677 completed: 451 chars, 117 chunks, TTFT=45.1ms
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_694 to http://localhost:30000/generate at 1753373114.3497221
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_694 with payload: {'text': 'Random prompt 694 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_694
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_694
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_684 received DONE after 82 chunks
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_684 completed: 229 chars, 82 chunks, TTFT=51.8ms
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_695 to http://localhost:30000/generate at 1753373114.3620563
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_695 with payload: {'text': 'Random prompt 695 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_695
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_695
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] Prefill batch. #new-seq: 1, #new-token: 281, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] Decode batch. #running-req: 20, #token: 6289, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1096.02, #queue-req: 0,
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_680 received DONE after 109 chunks
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_680 completed: 432 chars, 109 chunks, TTFT=71.4ms
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_696 to http://localhost:30000/generate at 1753373114.4909577
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_696 with payload: {'text': 'Random prompt 696 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_696
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_696
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_671 received DONE after 177 chunks
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_671 completed: 526 chars, 177 chunks, TTFT=48.7ms
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_697 to http://localhost:30000/generate at 1753373114.6002252
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_697 with payload: {'text': 'Random prompt 697 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_697
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_697
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] Prefill batch. #new-seq: 1, #new-token: 274, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_673 received DONE after 168 chunks
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_673 completed: 668 chars, 168 chunks, TTFT=55.8ms
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_698 to http://localhost:30000/generate at 1753373114.7383776
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_698 with payload: {'text': 'Random prompt 698 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 187, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_698
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_698
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_674 received DONE after 166 chunks
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_674 completed: 648 chars, 166 chunks, TTFT=63.6ms
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_699 to http://localhost:30000/generate at 1753373114.798105
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_699 with payload: {'text': 'Random prompt 699 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_699
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_699
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] Prefill batch. #new-seq: 1, #new-token: 248, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_672 received DONE after 176 chunks
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Request req_672 completed: 688 chars, 176 chunks, TTFT=56.5ms
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_700 to http://localhost:30000/generate at 1753373114.882586
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_700 with payload: {'text': 'Random prompt 700 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_700
[2025-07-25 00:05:14] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_700
[2025-07-25 00:05:14] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:14] Prefill batch. #new-seq: 1, #new-token: 263, #cached-token: 4, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_679 received DONE after 154 chunks
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_679 completed: 435 chars, 154 chunks, TTFT=71.0ms
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_701 to http://localhost:30000/generate at 1753373115.0570207
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_701 with payload: {'text': 'Random prompt 701 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_701
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_701
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] Decode batch. #running-req: 19, #token: 5732, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1248.27, #queue-req: 0,
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_682 received DONE after 147 chunks
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_682 completed: 571 chars, 147 chunks, TTFT=43.0ms
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_702 to http://localhost:30000/generate at 1753373115.236546
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_702 with payload: {'text': 'Random prompt 702 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 104, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_702
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_702
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_690 received DONE after 87 chunks
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_690 completed: 331 chars, 87 chunks, TTFT=44.8ms
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_703 to http://localhost:30000/generate at 1753373115.380504
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_703 with payload: {'text': 'Random prompt 703 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 129, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_703
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_703
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_695 received DONE after 74 chunks
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_695 completed: 292 chars, 74 chunks, TTFT=61.7ms
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_704 to http://localhost:30000/generate at 1753373115.5001662
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_704 with payload: {'text': 'Random prompt 704 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_704
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_704
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_696 received DONE after 68 chunks
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_696 completed: 256 chars, 68 chunks, TTFT=43.7ms
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_705 to http://localhost:30000/generate at 1753373115.5118508
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_705 with payload: {'text': 'Random prompt 705 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_705
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_705
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] Prefill batch. #new-seq: 1, #new-token: 379, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_693 received DONE after 84 chunks
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_693 completed: 320 chars, 84 chunks, TTFT=43.2ms
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_706 to http://localhost:30000/generate at 1753373115.6177013
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_706 with payload: {'text': 'Random prompt 706 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_706
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_706
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] Prefill batch. #new-seq: 1, #new-token: 208, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] Decode batch. #running-req: 20, #token: 5683, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1294.04, #queue-req: 0,
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_683 received DONE after 170 chunks
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_683 completed: 676 chars, 170 chunks, TTFT=49.0ms
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_707 to http://localhost:30000/generate at 1753373115.7151637
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_707 with payload: {'text': 'Random prompt 707 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_707
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_707
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_681 received DONE after 190 chunks
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_681 completed: 744 chars, 190 chunks, TTFT=61.3ms
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_708 to http://localhost:30000/generate at 1753373115.7690563
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_708 with payload: {'text': 'Random prompt 708 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_708
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_708
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] Prefill batch. #new-seq: 1, #new-token: 190, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_687 received DONE after 127 chunks
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_687 completed: 491 chars, 127 chunks, TTFT=45.6ms
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_709 to http://localhost:30000/generate at 1753373115.8389559
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_709 with payload: {'text': 'Random prompt 709 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_709
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_709
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] Prefill batch. #new-seq: 1, #new-token: 300, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_697 received DONE after 82 chunks
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Request req_697 completed: 227 chars, 82 chunks, TTFT=59.4ms
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_710 to http://localhost:30000/generate at 1753373115.943661
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_710 with payload: {'text': 'Random prompt 710 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_710
[2025-07-25 00:05:15] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_710
[2025-07-25 00:05:15] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:15] Prefill batch. #new-seq: 1, #new-token: 321, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_692 received DONE after 116 chunks
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_692 completed: 448 chars, 116 chunks, TTFT=55.9ms
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_711 to http://localhost:30000/generate at 1753373116.1076705
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_711 with payload: {'text': 'Random prompt 711 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_711
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_711
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_688 received DONE after 143 chunks
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_688 completed: 405 chars, 143 chunks, TTFT=50.0ms
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_694 received DONE after 112 chunks
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_694 completed: 432 chars, 112 chunks, TTFT=64.8ms
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_712 to http://localhost:30000/generate at 1753373116.1863585
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_712 with payload: {'text': 'Random prompt 712 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_713 to http://localhost:30000/generate at 1753373116.1870944
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_713 with payload: {'text': 'Random prompt 713 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_712
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_712
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_713
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_713
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] Prefill batch. #new-seq: 2, #new-token: 477, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_691 received DONE after 129 chunks
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_691 completed: 500 chars, 129 chunks, TTFT=46.1ms
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_714 to http://localhost:30000/generate at 1753373116.2866445
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_714 with payload: {'text': 'Random prompt 714 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_714
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_714
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] Prefill batch. #new-seq: 1, #new-token: 214, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_685 received DONE after 175 chunks
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_685 completed: 626 chars, 175 chunks, TTFT=48.5ms
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_715 to http://localhost:30000/generate at 1753373116.3263946
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_715 with payload: {'text': 'Random prompt 715 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_715
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_715
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] Prefill batch. #new-seq: 1, #new-token: 363, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] Decode batch. #running-req: 20, #token: 5982, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1084.57, #queue-req: 0,
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_686 received DONE after 183 chunks
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_686 completed: 728 chars, 183 chunks, TTFT=50.0ms
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_716 to http://localhost:30000/generate at 1753373116.5839992
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_716 with payload: {'text': 'Random prompt 716 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_716
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_716
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] Prefill batch. #new-seq: 1, #new-token: 338, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_689 received DONE after 163 chunks
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_689 completed: 636 chars, 163 chunks, TTFT=43.7ms
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_717 to http://localhost:30000/generate at 1753373116.628772
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_717 with payload: {'text': 'Random prompt 717 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_717
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_717
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] Prefill batch. #new-seq: 1, #new-token: 372, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_705 received DONE after 79 chunks
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_705 completed: 78 chars, 79 chunks, TTFT=62.8ms
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_718 to http://localhost:30000/generate at 1753373116.8402398
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_718 with payload: {'text': 'Random prompt 718 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_718
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_718
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_702 received DONE after 105 chunks
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_702 completed: 416 chars, 105 chunks, TTFT=54.8ms
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_719 to http://localhost:30000/generate at 1753373116.9757137
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_719 with payload: {'text': 'Random prompt 719 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 95, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_699 received DONE after 135 chunks
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_699 completed: 536 chars, 135 chunks, TTFT=55.3ms
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_720 to http://localhost:30000/generate at 1753373116.9775062
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_720 with payload: {'text': 'Random prompt 720 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 82, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_719
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_719
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_720
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_720
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_701 received DONE after 120 chunks
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Request req_701 completed: 476 chars, 120 chunks, TTFT=43.0ms
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_721 to http://localhost:30000/generate at 1753373116.990644
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_721 with payload: {'text': 'Random prompt 721 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:16] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:16] Prefill batch. #new-seq: 2, #new-token: 678, #cached-token: 11, token usage: 0.05, #running-req: 17, #queue-req: 0,
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_721
[2025-07-25 00:05:16] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_721
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] Decode batch. #running-req: 17, #token: 6099, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1336.56, #queue-req: 0,
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_707 received DONE after 93 chunks
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_707 completed: 368 chars, 93 chunks, TTFT=59.8ms
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_722 to http://localhost:30000/generate at 1753373117.2590067
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_722 with payload: {'text': 'Random prompt 722 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_722
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_722
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_711 received DONE after 73 chunks
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_711 completed: 276 chars, 73 chunks, TTFT=59.4ms
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_710 received DONE after 84 chunks
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_710 completed: 251 chars, 84 chunks, TTFT=60.7ms
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_723 to http://localhost:30000/generate at 1753373117.3193963
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_723 with payload: {'text': 'Random prompt 723 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_724 to http://localhost:30000/generate at 1753373117.3201344
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_724 with payload: {'text': 'Random prompt 724 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_723
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_723
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_724
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_724
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] Prefill batch. #new-seq: 2, #new-token: 587, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_714 received DONE after 72 chunks
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_714 completed: 284 chars, 72 chunks, TTFT=42.5ms
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_725 to http://localhost:30000/generate at 1753373117.4484937
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_725 with payload: {'text': 'Random prompt 725 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_725
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_725
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] Prefill batch. #new-seq: 1, #new-token: 341, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_704 received DONE after 121 chunks
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_704 completed: 480 chars, 121 chunks, TTFT=63.7ms
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_726 to http://localhost:30000/generate at 1753373117.5554416
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_726 with payload: {'text': 'Random prompt 726 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 129, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_726
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_726
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_703 received DONE after 130 chunks
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_703 completed: 504 chars, 130 chunks, TTFT=43.0ms
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_727 to http://localhost:30000/generate at 1753373117.5675182
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_727 with payload: {'text': 'Random prompt 727 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_727
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_727
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] Prefill batch. #new-seq: 1, #new-token: 329, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] Decode batch. #running-req: 20, #token: 6632, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1127.16, #queue-req: 0,
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_716 received DONE after 72 chunks
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_716 completed: 207 chars, 72 chunks, TTFT=50.9ms
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_728 to http://localhost:30000/generate at 1753373117.7833874
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_728 with payload: {'text': 'Random prompt 728 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_728
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_728
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_698 received DONE after 188 chunks
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_698 completed: 736 chars, 188 chunks, TTFT=43.3ms
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_729 to http://localhost:30000/generate at 1753373117.827426
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_729 with payload: {'text': 'Random prompt 729 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_729
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_729
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_700 received DONE after 189 chunks
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Request req_700 completed: 752 chars, 189 chunks, TTFT=47.4ms
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_730 to http://localhost:30000/generate at 1753373117.96478
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_730 with payload: {'text': 'Random prompt 730 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_730
[2025-07-25 00:05:17] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_730
[2025-07-25 00:05:17] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:17] Prefill batch. #new-seq: 1, #new-token: 168, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_706 received DONE after 147 chunks
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_706 completed: 455 chars, 147 chunks, TTFT=43.9ms
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_731 to http://localhost:30000/generate at 1753373118.0617008
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_731 with payload: {'text': 'Random prompt 731 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_731
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_731
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_708 received DONE after 144 chunks
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_708 completed: 572 chars, 144 chunks, TTFT=42.0ms
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_732 to http://localhost:30000/generate at 1753373118.1526098
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_732 with payload: {'text': 'Random prompt 732 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 131, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_732
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_732
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] Prefill batch. #new-seq: 1, #new-token: 295, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_713 received DONE after 124 chunks
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_713 completed: 480 chars, 124 chunks, TTFT=69.9ms
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_733 to http://localhost:30000/generate at 1753373118.2563956
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_733 with payload: {'text': 'Random prompt 733 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_733
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_733
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] Prefill batch. #new-seq: 1, #new-token: 259, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_709 received DONE after 148 chunks
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_709 completed: 422 chars, 148 chunks, TTFT=50.0ms
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_734 to http://localhost:30000/generate at 1753373118.299753
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_734 with payload: {'text': 'Random prompt 734 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_734
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_734
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] Prefill batch. #new-seq: 1, #new-token: 217, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_721 received DONE after 81 chunks
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_721 completed: 307 chars, 81 chunks, TTFT=92.2ms
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_735 to http://localhost:30000/generate at 1753373118.3968263
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_735 with payload: {'text': 'Random prompt 735 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] Decode batch. #running-req: 20, #token: 6087, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1171.53, #queue-req: 0,
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_735
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_735
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_720 received DONE after 83 chunks
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_720 completed: 328 chars, 83 chunks, TTFT=102.6ms
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_736 to http://localhost:30000/generate at 1753373118.4207664
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_736 with payload: {'text': 'Random prompt 736 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_736
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_736
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] Prefill batch. #new-seq: 1, #new-token: 226, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_719 received DONE after 96 chunks
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_719 completed: 278 chars, 96 chunks, TTFT=104.6ms
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_737 to http://localhost:30000/generate at 1753373118.6346662
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_737 with payload: {'text': 'Random prompt 737 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 89, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_737
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_737
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_723 received DONE after 78 chunks
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_723 completed: 220 chars, 78 chunks, TTFT=75.9ms
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_738 to http://localhost:30000/generate at 1753373118.6792238
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_738 with payload: {'text': 'Random prompt 738 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_738
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_738
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] Prefill batch. #new-seq: 1, #new-token: 238, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_725 received DONE after 73 chunks
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_725 completed: 206 chars, 73 chunks, TTFT=51.9ms
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_739 to http://localhost:30000/generate at 1753373118.723372
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_739 with payload: {'text': 'Random prompt 739 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_739
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_739
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_712 received DONE after 165 chunks
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Request req_712 completed: 643 chars, 165 chunks, TTFT=70.6ms
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_740 to http://localhost:30000/generate at 1753373118.9508483
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_740 with payload: {'text': 'Random prompt 740 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_740
[2025-07-25 00:05:18] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_740
[2025-07-25 00:05:18] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:18] Prefill batch. #new-seq: 1, #new-token: 245, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_722 received DONE after 104 chunks
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_722 completed: 409 chars, 104 chunks, TTFT=42.9ms
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_741 to http://localhost:30000/generate at 1753373119.0356898
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_741 with payload: {'text': 'Random prompt 741 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:19] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_741
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_741
[2025-07-25 00:05:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:19] Prefill batch. #new-seq: 1, #new-token: 202, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:19] Decode batch. #running-req: 19, #token: 6365, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1177.54, #queue-req: 0,
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_717 received DONE after 154 chunks
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_717 completed: 689 chars, 154 chunks, TTFT=61.2ms
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_742 to http://localhost:30000/generate at 1753373119.1830616
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_742 with payload: {'text': 'Random prompt 742 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:19] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_742
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_742
[2025-07-25 00:05:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:19] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_715 received DONE after 192 chunks
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_715 completed: 569 chars, 192 chunks, TTFT=58.6ms
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_743 to http://localhost:30000/generate at 1753373119.4320114
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_743 with payload: {'text': 'Random prompt 743 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:19] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_743
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_743
[2025-07-25 00:05:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:19] Prefill batch. #new-seq: 1, #new-token: 254, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_734 received DONE after 82 chunks
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_734 completed: 243 chars, 82 chunks, TTFT=54.7ms
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_744 to http://localhost:30000/generate at 1753373119.5790489
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_744 with payload: {'text': 'Random prompt 744 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:19] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_744
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_744
[2025-07-25 00:05:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:19] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_730 received DONE after 104 chunks
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_730 completed: 400 chars, 104 chunks, TTFT=44.8ms
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_745 to http://localhost:30000/generate at 1753373119.6408165
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_745 with payload: {'text': 'Random prompt 745 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:19] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_745
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_745
[2025-07-25 00:05:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:19] Decode batch. #running-req: 20, #token: 6001, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1390.08, #queue-req: 0,
[2025-07-25 00:05:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:19] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_726 received DONE after 130 chunks
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_726 completed: 503 chars, 130 chunks, TTFT=64.7ms
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_746 to http://localhost:30000/generate at 1753373119.6517758
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_746 with payload: {'text': 'Random prompt 746 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 66, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:19] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_746
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_746
[2025-07-25 00:05:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:19] Prefill batch. #new-seq: 1, #new-token: 223, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_724 received DONE after 154 chunks
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_724 completed: 597 chars, 154 chunks, TTFT=75.1ms
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_747 to http://localhost:30000/generate at 1753373119.8596523
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_747 with payload: {'text': 'Random prompt 747 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:19] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_747
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_747
[2025-07-25 00:05:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:19] Prefill batch. #new-seq: 1, #new-token: 264, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_718 received DONE after 191 chunks
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Request req_718 completed: 747 chars, 191 chunks, TTFT=45.7ms
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_748 to http://localhost:30000/generate at 1753373119.9752135
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_748 with payload: {'text': 'Random prompt 748 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:19] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_748
[2025-07-25 00:05:19] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_748
[2025-07-25 00:05:19] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:19] Prefill batch. #new-seq: 1, #new-token: 357, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_737 received DONE after 90 chunks
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_737 completed: 344 chars, 90 chunks, TTFT=51.6ms
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_749 to http://localhost:30000/generate at 1753373120.0668569
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_749 with payload: {'text': 'Random prompt 749 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 82, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_749
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_749
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] Prefill batch. #new-seq: 1, #new-token: 285, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_729 received DONE after 144 chunks
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_729 completed: 560 chars, 144 chunks, TTFT=47.5ms
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_750 to http://localhost:30000/generate at 1753373120.1727767
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_750 with payload: {'text': 'Random prompt 750 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_750
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_750
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 5, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_733 received DONE after 120 chunks
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_733 completed: 464 chars, 120 chunks, TTFT=49.6ms
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_751 to http://localhost:30000/generate at 1753373120.2179313
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_751 with payload: {'text': 'Random prompt 751 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_751
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_751
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] Prefill batch. #new-seq: 1, #new-token: 366, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_732 received DONE after 132 chunks
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_732 completed: 524 chars, 132 chunks, TTFT=48.6ms
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_752 to http://localhost:30000/generate at 1753373120.3273342
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_752 with payload: {'text': 'Random prompt 752 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 66, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_752
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_752
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] Prefill batch. #new-seq: 1, #new-token: 286, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] Decode batch. #running-req: 19, #token: 6756, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1102.41, #queue-req: 0,
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_736 received DONE after 123 chunks
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_736 completed: 476 chars, 123 chunks, TTFT=63.7ms
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_753 to http://localhost:30000/generate at 1753373120.4194098
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_753 with payload: {'text': 'Random prompt 753 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 95, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_753
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_753
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_738 received DONE after 112 chunks
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_738 completed: 434 chars, 112 chunks, TTFT=47.3ms
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_731 received DONE after 145 chunks
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_731 completed: 551 chars, 145 chunks, TTFT=60.2ms
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_754 to http://localhost:30000/generate at 1753373120.4946005
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_754 with payload: {'text': 'Random prompt 754 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_755 to http://localhost:30000/generate at 1753373120.4953253
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_755 with payload: {'text': 'Random prompt 755 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_754
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_754
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_755
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_755
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] Prefill batch. #new-seq: 2, #new-token: 489, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_743 received DONE after 66 chunks
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_743 completed: 247 chars, 66 chunks, TTFT=46.2ms
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_756 to http://localhost:30000/generate at 1753373120.5945435
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_756 with payload: {'text': 'Random prompt 756 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 187, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_756
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_756
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] Prefill batch. #new-seq: 1, #new-token: 284, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_728 received DONE after 169 chunks
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_728 completed: 659 chars, 169 chunks, TTFT=44.8ms
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_757 to http://localhost:30000/generate at 1753373120.6054635
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_757 with payload: {'text': 'Random prompt 757 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_757
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_757
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] Prefill batch. #new-seq: 1, #new-token: 262, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_739 received DONE after 118 chunks
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_739 completed: 366 chars, 118 chunks, TTFT=51.8ms
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_758 to http://localhost:30000/generate at 1753373120.6921375
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_758 with payload: {'text': 'Random prompt 758 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_758
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_758
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] Prefill batch. #new-seq: 1, #new-token: 354, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_727 received DONE after 193 chunks
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_727 completed: 549 chars, 193 chunks, TTFT=62.5ms
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_759 to http://localhost:30000/generate at 1753373120.8222034
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_759 with payload: {'text': 'Random prompt 759 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_759
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_759
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] Prefill batch. #new-seq: 1, #new-token: 327, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_746 received DONE after 67 chunks
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Request req_746 completed: 264 chars, 67 chunks, TTFT=66.9ms
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_760 to http://localhost:30000/generate at 1753373120.8893344
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_760 with payload: {'text': 'Random prompt 760 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_760
[2025-07-25 00:05:20] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_760
[2025-07-25 00:05:20] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:20] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] Decode batch. #running-req: 20, #token: 6672, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1111.38, #queue-req: 0,
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_735 received DONE after 178 chunks
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_735 completed: 506 chars, 178 chunks, TTFT=81.6ms
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_761 to http://localhost:30000/generate at 1753373121.3066256
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_761 with payload: {'text': 'Random prompt 761 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_761
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_761
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] Prefill batch. #new-seq: 1, #new-token: 205, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_752 received DONE after 67 chunks
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_752 completed: 245 chars, 67 chunks, TTFT=49.8ms
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_762 to http://localhost:30000/generate at 1753373121.4170182
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_762 with payload: {'text': 'Random prompt 762 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_762
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_762
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_749 received DONE after 83 chunks
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_749 completed: 232 chars, 83 chunks, TTFT=51.4ms
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_763 to http://localhost:30000/generate at 1753373121.4615908
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_763 with payload: {'text': 'Random prompt 763 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_763
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_763
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] Prefill batch. #new-seq: 1, #new-token: 316, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_747 received DONE after 98 chunks
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_747 completed: 388 chars, 98 chunks, TTFT=48.4ms
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_764 to http://localhost:30000/generate at 1753373121.5316823
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_764 with payload: {'text': 'Random prompt 764 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_764
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_764
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_744 received DONE after 118 chunks
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_744 completed: 455 chars, 118 chunks, TTFT=45.8ms
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_765 to http://localhost:30000/generate at 1753373121.6047225
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_765 with payload: {'text': 'Random prompt 765 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_765
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_765
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] Prefill batch. #new-seq: 1, #new-token: 271, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_741 received DONE after 159 chunks
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_741 completed: 632 chars, 159 chunks, TTFT=44.4ms
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_766 to http://localhost:30000/generate at 1753373121.672375
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_766 with payload: {'text': 'Random prompt 766 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_766
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_766
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] Prefill batch. #new-seq: 1, #new-token: 320, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] Decode batch. #running-req: 20, #token: 6631, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1211.11, #queue-req: 0,
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_740 received DONE after 171 chunks
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_740 completed: 613 chars, 171 chunks, TTFT=44.2ms
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_767 to http://localhost:30000/generate at 1753373121.7896621
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_767 with payload: {'text': 'Random prompt 767 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_767
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_767
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] Prefill batch. #new-seq: 1, #new-token: 350, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_751 received DONE after 93 chunks
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_751 completed: 357 chars, 93 chunks, TTFT=54.2ms
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_768 to http://localhost:30000/generate at 1753373121.8011484
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_768 with payload: {'text': 'Random prompt 768 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 112, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_768
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_768
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] Prefill batch. #new-seq: 1, #new-token: 213, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_745 received DONE after 127 chunks
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_745 completed: 504 chars, 127 chunks, TTFT=70.7ms
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_769 to http://localhost:30000/generate at 1753373121.8433828
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_769 with payload: {'text': 'Random prompt 769 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_769
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_769
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] Prefill batch. #new-seq: 1, #new-token: 335, #cached-token: 6, token usage: 0.05, #running-req: 21, #queue-req: 0,
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_742 received DONE after 163 chunks
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Request req_742 completed: 468 chars, 163 chunks, TTFT=49.4ms
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_770 to http://localhost:30000/generate at 1753373121.9717715
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_770 with payload: {'text': 'Random prompt 770 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_770
[2025-07-25 00:05:21] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_770
[2025-07-25 00:05:21] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:21] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_758 received DONE after 79 chunks
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_758 completed: 80 chars, 79 chunks, TTFT=51.0ms
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_771 to http://localhost:30000/generate at 1753373122.0319629
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_771 with payload: {'text': 'Random prompt 771 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:22] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_771
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_771
[2025-07-25 00:05:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:22] Prefill batch. #new-seq: 1, #new-token: 342, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_753 received DONE after 96 chunks
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_753 completed: 367 chars, 96 chunks, TTFT=44.6ms
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_772 to http://localhost:30000/generate at 1753373122.1233833
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_772 with payload: {'text': 'Random prompt 772 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 178, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:22] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_772
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_772
[2025-07-25 00:05:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:22] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:22] Decode batch. #running-req: 20, #token: 6410, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1202.71, #queue-req: 0,
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_750 received DONE after 134 chunks
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_750 completed: 520 chars, 134 chunks, TTFT=45.9ms
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_773 to http://localhost:30000/generate at 1753373122.4514349
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_773 with payload: {'text': 'Random prompt 773 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:22] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_773
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_773
[2025-07-25 00:05:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:22] Prefill batch. #new-seq: 1, #new-token: 227, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_757 received DONE after 127 chunks
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_757 completed: 456 chars, 127 chunks, TTFT=69.2ms
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_774 to http://localhost:30000/generate at 1753373122.6597
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_774 with payload: {'text': 'Random prompt 774 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:22] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_774
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_774
[2025-07-25 00:05:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:22] Prefill batch. #new-seq: 1, #new-token: 329, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_748 received DONE after 162 chunks
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_748 completed: 465 chars, 162 chunks, TTFT=50.5ms
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_775 to http://localhost:30000/generate at 1753373122.6843789
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_775 with payload: {'text': 'Random prompt 775 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 104, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:22] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_775
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_775
[2025-07-25 00:05:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:22] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_762 received DONE after 78 chunks
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_762 completed: 296 chars, 78 chunks, TTFT=45.4ms
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_776 to http://localhost:30000/generate at 1753373122.763894
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_776 with payload: {'text': 'Random prompt 776 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:22] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_776
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_776
[2025-07-25 00:05:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:22] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_760 received DONE after 123 chunks
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_760 completed: 475 chars, 123 chunks, TTFT=44.3ms
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_777 to http://localhost:30000/generate at 1753373122.8597238
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_777 with payload: {'text': 'Random prompt 777 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:22] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_777
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_777
[2025-07-25 00:05:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:22] Prefill batch. #new-seq: 1, #new-token: 310, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_764 received DONE after 84 chunks
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Request req_764 completed: 83 chars, 84 chunks, TTFT=45.0ms
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_778 to http://localhost:30000/generate at 1753373122.951509
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_778 with payload: {'text': 'Random prompt 778 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:22] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_778
[2025-07-25 00:05:22] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_778
[2025-07-25 00:05:22] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:22] Prefill batch. #new-seq: 1, #new-token: 309, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_759 received DONE after 135 chunks
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_759 completed: 383 chars, 135 chunks, TTFT=49.8ms
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_779 to http://localhost:30000/generate at 1753373123.031926
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_779 with payload: {'text': 'Random prompt 779 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_779
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_779
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] Decode batch. #running-req: 19, #token: 6299, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1213.73, #queue-req: 0,
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] Prefill batch. #new-seq: 1, #new-token: 289, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_755 received DONE after 168 chunks
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_755 completed: 668 chars, 168 chunks, TTFT=57.5ms
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_780 to http://localhost:30000/generate at 1753373123.268903
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_780 with payload: {'text': 'Random prompt 780 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_780
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_780
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] Prefill batch. #new-seq: 1, #new-token: 304, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_765 received DONE after 107 chunks
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_765 completed: 434 chars, 107 chunks, TTFT=50.3ms
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_781 to http://localhost:30000/generate at 1753373123.3738906
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_781 with payload: {'text': 'Random prompt 781 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 179, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_781
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_781
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] Prefill batch. #new-seq: 1, #new-token: 264, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_763 received DONE after 127 chunks
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_763 completed: 361 chars, 127 chunks, TTFT=53.0ms
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_782 to http://localhost:30000/generate at 1753373123.5643115
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_782 with payload: {'text': 'Random prompt 782 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_782
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_782
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] Prefill batch. #new-seq: 1, #new-token: 190, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_754 received DONE after 190 chunks
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_754 completed: 743 chars, 190 chunks, TTFT=58.3ms
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_783 to http://localhost:30000/generate at 1753373123.6266017
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_783 with payload: {'text': 'Random prompt 783 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_768 received DONE after 113 chunks
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_768 completed: 436 chars, 113 chunks, TTFT=94.7ms
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_784 to http://localhost:30000/generate at 1753373123.628489
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_784 with payload: {'text': 'Random prompt 784 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_783
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_783
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_784
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_784
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] Prefill batch. #new-seq: 2, #new-token: 386, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_769 received DONE after 115 chunks
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_769 completed: 456 chars, 115 chunks, TTFT=62.3ms
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_785 to http://localhost:30000/generate at 1753373123.6496568
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_785 with payload: {'text': 'Random prompt 785 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 179, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_785
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_785
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] Decode batch. #running-req: 18, #token: 5596, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1261.91, #queue-req: 0,
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] Prefill batch. #new-seq: 1, #new-token: 358, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_756 received DONE after 188 chunks
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_756 completed: 509 chars, 188 chunks, TTFT=70.2ms
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_786 to http://localhost:30000/generate at 1753373123.681629
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_786 with payload: {'text': 'Random prompt 786 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_786
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_786
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] Prefill batch. #new-seq: 1, #new-token: 274, #cached-token: 6, token usage: 0.05, #running-req: 21, #queue-req: 0,
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_767 received DONE after 126 chunks
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_767 completed: 125 chars, 126 chunks, TTFT=79.7ms
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_787 to http://localhost:30000/generate at 1753373123.8876808
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_787 with payload: {'text': 'Random prompt 787 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_787
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_787
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] Prefill batch. #new-seq: 1, #new-token: 228, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_770 received DONE after 124 chunks
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Request req_770 completed: 492 chars, 124 chunks, TTFT=44.6ms
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_788 to http://localhost:30000/generate at 1753373123.9723516
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_788 with payload: {'text': 'Random prompt 788 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_788
[2025-07-25 00:05:23] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_788
[2025-07-25 00:05:23] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:23] Prefill batch. #new-seq: 1, #new-token: 243, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_761 received DONE after 173 chunks
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_761 completed: 675 chars, 173 chunks, TTFT=43.6ms
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_789 to http://localhost:30000/generate at 1753373124.1916041
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_789 with payload: {'text': 'Random prompt 789 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:24] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_789
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_789
[2025-07-25 00:05:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:24] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_766 received DONE after 159 chunks
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_766 completed: 632 chars, 159 chunks, TTFT=50.6ms
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_790 to http://localhost:30000/generate at 1753373124.2845106
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_790 with payload: {'text': 'Random prompt 790 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:24] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_790
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_790
[2025-07-25 00:05:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:24] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:24] Decode batch. #running-req: 20, #token: 6440, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1179.09, #queue-req: 0,
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_775 received DONE after 105 chunks
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_775 completed: 404 chars, 105 chunks, TTFT=61.1ms
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_780 received DONE after 70 chunks
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_780 completed: 199 chars, 70 chunks, TTFT=50.8ms
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_791 to http://localhost:30000/generate at 1753373124.4159737
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_791 with payload: {'text': 'Random prompt 791 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_792 to http://localhost:30000/generate at 1753373124.416397
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_792 with payload: {'text': 'Random prompt 792 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:24] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_791
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_791
[2025-07-25 00:05:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:24] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_792
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_792
[2025-07-25 00:05:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:24] Prefill batch. #new-seq: 2, #new-token: 530, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_778 received DONE after 98 chunks
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_778 completed: 388 chars, 98 chunks, TTFT=49.4ms
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_793 to http://localhost:30000/generate at 1753373124.5515802
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_793 with payload: {'text': 'Random prompt 793 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:24] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_793
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_793
[2025-07-25 00:05:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:24] Prefill batch. #new-seq: 1, #new-token: 282, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_771 received DONE after 165 chunks
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_771 completed: 472 chars, 165 chunks, TTFT=50.2ms
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_794 to http://localhost:30000/generate at 1753373124.6658309
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_794 with payload: {'text': 'Random prompt 794 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:24] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_794
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_794
[2025-07-25 00:05:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:24] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_777 received DONE after 121 chunks
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_777 completed: 348 chars, 121 chunks, TTFT=61.0ms
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_795 to http://localhost:30000/generate at 1753373124.8360057
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_795 with payload: {'text': 'Random prompt 795 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:24] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_795
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_795
[2025-07-25 00:05:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:24] Prefill batch. #new-seq: 1, #new-token: 348, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_772 received DONE after 179 chunks
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Request req_772 completed: 699 chars, 179 chunks, TTFT=44.9ms
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_796 to http://localhost:30000/generate at 1753373124.9532
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_796 with payload: {'text': 'Random prompt 796 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:24] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_796
[2025-07-25 00:05:24] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_796
[2025-07-25 00:05:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:24] Decode batch. #running-req: 19, #token: 6204, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1280.43, #queue-req: 0,
[2025-07-25 00:05:24] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:24] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_788 received DONE after 74 chunks
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_788 completed: 292 chars, 74 chunks, TTFT=43.6ms
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_797 to http://localhost:30000/generate at 1753373125.119893
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_797 with payload: {'text': 'Random prompt 797 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:25] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_797
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_797
[2025-07-25 00:05:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:25] Prefill batch. #new-seq: 1, #new-token: 270, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_776 received DONE after 153 chunks
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_776 completed: 594 chars, 153 chunks, TTFT=43.1ms
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_798 to http://localhost:30000/generate at 1753373125.2365856
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_798 with payload: {'text': 'Random prompt 798 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:25] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_798
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_798
[2025-07-25 00:05:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:25] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_774 received DONE after 166 chunks
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_774 completed: 475 chars, 166 chunks, TTFT=81.4ms
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_799 to http://localhost:30000/generate at 1753373125.390384
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_799 with payload: {'text': 'Random prompt 799 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 66, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:25] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_799
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_799
[2025-07-25 00:05:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:25] Prefill batch. #new-seq: 1, #new-token: 361, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_773 received DONE after 187 chunks
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_773 completed: 731 chars, 187 chunks, TTFT=43.3ms
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_800 to http://localhost:30000/generate at 1753373125.483836
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_800 with payload: {'text': 'Random prompt 800 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:25] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_800
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_800
[2025-07-25 00:05:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:25] Prefill batch. #new-seq: 1, #new-token: 308, #cached-token: 4, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_782 received DONE after 124 chunks
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_782 completed: 480 chars, 124 chunks, TTFT=45.2ms
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_801 to http://localhost:30000/generate at 1753373125.6016192
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_801 with payload: {'text': 'Random prompt 801 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:25] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_801
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_801
[2025-07-25 00:05:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:25] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:25] Decode batch. #running-req: 19, #token: 6628, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1180.48, #queue-req: 0,
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_790 received DONE after 84 chunks
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_790 completed: 332 chars, 84 chunks, TTFT=43.6ms
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_802 to http://localhost:30000/generate at 1753373125.6468325
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_802 with payload: {'text': 'Random prompt 802 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:25] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_802
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_802
[2025-07-25 00:05:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:25] Prefill batch. #new-seq: 1, #new-token: 273, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_794 received DONE after 70 chunks
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_794 completed: 272 chars, 70 chunks, TTFT=45.0ms
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_803 to http://localhost:30000/generate at 1753373125.7919452
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_803 with payload: {'text': 'Random prompt 803 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 102, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:25] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_803
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_803
[2025-07-25 00:05:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:25] Prefill batch. #new-seq: 1, #new-token: 280, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_779 received DONE after 173 chunks
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Request req_779 completed: 688 chars, 173 chunks, TTFT=60.6ms
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_804 to http://localhost:30000/generate at 1753373125.858032
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_804 with payload: {'text': 'Random prompt 804 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:25] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_804
[2025-07-25 00:05:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_804
[2025-07-25 00:05:25] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:25] Prefill batch. #new-seq: 1, #new-token: 234, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_786 received DONE after 146 chunks
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_786 completed: 580 chars, 146 chunks, TTFT=77.2ms
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_805 to http://localhost:30000/generate at 1753373126.0341628
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_805 with payload: {'text': 'Random prompt 805 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_805
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_805
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] Prefill batch. #new-seq: 1, #new-token: 314, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_783 received DONE after 147 chunks
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_783 completed: 572 chars, 147 chunks, TTFT=89.5ms
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_806 to http://localhost:30000/generate at 1753373126.0460422
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_806 with payload: {'text': 'Random prompt 806 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_806
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_806
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] Prefill batch. #new-seq: 1, #new-token: 364, #cached-token: 6, token usage: 0.06, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_784 received DONE after 149 chunks
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_784 completed: 579 chars, 149 chunks, TTFT=87.5ms
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_807 to http://localhost:30000/generate at 1753373126.1348193
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_807 with payload: {'text': 'Random prompt 807 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_807
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_807
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_795 received DONE after 76 chunks
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_795 completed: 300 chars, 76 chunks, TTFT=61.3ms
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_808 to http://localhost:30000/generate at 1753373126.1463523
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_808 with payload: {'text': 'Random prompt 808 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_808
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_808
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] Prefill batch. #new-seq: 2, #new-token: 603, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_787 received DONE after 144 chunks
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_787 completed: 560 chars, 144 chunks, TTFT=43.5ms
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_809 to http://localhost:30000/generate at 1753373126.2690296
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_809 with payload: {'text': 'Random prompt 809 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_809
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_809
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] Decode batch. #running-req: 20, #token: 7107, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1098.99, #queue-req: 0,
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_781 received DONE after 180 chunks
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_781 completed: 704 chars, 180 chunks, TTFT=49.2ms
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_810 to http://localhost:30000/generate at 1753373126.377872
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_810 with payload: {'text': 'Random prompt 810 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_810
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_810
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] Prefill batch. #new-seq: 1, #new-token: 378, #cached-token: 5, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_789 received DONE after 131 chunks
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_789 completed: 130 chars, 131 chunks, TTFT=62.4ms
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_811 to http://localhost:30000/generate at 1753373126.4245255
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_811 with payload: {'text': 'Random prompt 811 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_811
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_811
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] Prefill batch. #new-seq: 1, #new-token: 340, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_797 received DONE after 74 chunks
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_797 completed: 283 chars, 74 chunks, TTFT=60.7ms
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_812 to http://localhost:30000/generate at 1753373126.4472268
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_812 with payload: {'text': 'Random prompt 812 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 98, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_812
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_812
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.06, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_798 received DONE after 74 chunks
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_798 completed: 292 chars, 74 chunks, TTFT=61.0ms
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_813 to http://localhost:30000/generate at 1753373126.59172
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_813 with payload: {'text': 'Random prompt 813 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_813
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_813
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] Prefill batch. #new-seq: 1, #new-token: 361, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_799 received DONE after 67 chunks
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_799 completed: 264 chars, 67 chunks, TTFT=62.4ms
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_814 to http://localhost:30000/generate at 1753373126.647465
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_814 with payload: {'text': 'Random prompt 814 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_814
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_814
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] Prefill batch. #new-seq: 1, #new-token: 348, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_792 received DONE after 131 chunks
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_792 completed: 508 chars, 131 chunks, TTFT=66.8ms
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_815 to http://localhost:30000/generate at 1753373126.7049139
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_815 with payload: {'text': 'Random prompt 815 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_815
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_815
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_785 received DONE after 180 chunks
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_785 completed: 508 chars, 180 chunks, TTFT=98.0ms
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_816 to http://localhost:30000/generate at 1753373126.774074
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_816 with payload: {'text': 'Random prompt 816 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 102, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_816
[2025-07-25 00:05:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_816
[2025-07-25 00:05:26] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:26] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] Decode batch. #running-req: 20, #token: 7008, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1116.82, #queue-req: 0,
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_793 received DONE after 152 chunks
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_793 completed: 592 chars, 152 chunks, TTFT=48.0ms
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_791 received DONE after 159 chunks
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_791 completed: 620 chars, 159 chunks, TTFT=67.4ms
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_817 to http://localhost:30000/generate at 1753373127.1253912
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_817 with payload: {'text': 'Random prompt 817 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_818 to http://localhost:30000/generate at 1753373127.126151
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_818 with payload: {'text': 'Random prompt 818 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_817
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_817
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_818
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_818
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] Prefill batch. #new-seq: 2, #new-token: 366, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_802 received DONE after 110 chunks
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_802 completed: 394 chars, 110 chunks, TTFT=52.1ms
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_819 to http://localhost:30000/generate at 1753373127.4744213
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_819 with payload: {'text': 'Random prompt 819 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 113, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_819
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_819
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_809 received DONE after 78 chunks
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_809 completed: 295 chars, 78 chunks, TTFT=44.1ms
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_803 received DONE after 103 chunks
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_803 completed: 408 chars, 103 chunks, TTFT=47.8ms
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_820 to http://localhost:30000/generate at 1753373127.5218391
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_820 with payload: {'text': 'Random prompt 820 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_821 to http://localhost:30000/generate at 1753373127.522677
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_821 with payload: {'text': 'Random prompt 821 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_820
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_820
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_821
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_821
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] Prefill batch. #new-seq: 1, #new-token: 332, #cached-token: 5, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 5, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_808 received DONE after 87 chunks
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_808 completed: 337 chars, 87 chunks, TTFT=67.1ms
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_822 to http://localhost:30000/generate at 1753373127.6141932
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_822 with payload: {'text': 'Random prompt 822 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_822
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_822
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] Prefill batch. #new-seq: 1, #new-token: 211, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_796 received DONE after 157 chunks
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_796 completed: 445 chars, 157 chunks, TTFT=62.0ms
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_823 to http://localhost:30000/generate at 1753373127.627081
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_823 with payload: {'text': 'Random prompt 823 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_823
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_823
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] Prefill batch. #new-seq: 1, #new-token: 227, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_807 received DONE after 89 chunks
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_807 completed: 253 chars, 89 chunks, TTFT=78.5ms
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_824 to http://localhost:30000/generate at 1753373127.6625397
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_824 with payload: {'text': 'Random prompt 824 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_824
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_824
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] Prefill batch. #new-seq: 1, #new-token: 263, #cached-token: 6, token usage: 0.05, #running-req: 21, #queue-req: 0,
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] Decode batch. #running-req: 20, #token: 5950, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1151.88, #queue-req: 0,
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_813 received DONE after 68 chunks
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_813 completed: 196 chars, 68 chunks, TTFT=61.9ms
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_825 to http://localhost:30000/generate at 1753373127.7600174
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_825 with payload: {'text': 'Random prompt 825 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 132, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_825
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_825
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] Prefill batch. #new-seq: 1, #new-token: 361, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_804 received DONE after 110 chunks
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_804 completed: 402 chars, 110 chunks, TTFT=45.7ms
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_826 to http://localhost:30000/generate at 1753373127.7838635
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_826 with payload: {'text': 'Random prompt 826 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_826
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_826
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] Prefill batch. #new-seq: 1, #new-token: 214, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_814 received DONE after 76 chunks
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Request req_814 completed: 217 chars, 76 chunks, TTFT=63.8ms
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_827 to http://localhost:30000/generate at 1753373127.9418452
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_827 with payload: {'text': 'Random prompt 827 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_827
[2025-07-25 00:05:27] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_827
[2025-07-25 00:05:27] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:27] Prefill batch. #new-seq: 1, #new-token: 214, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_812 received DONE after 99 chunks
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_812 completed: 380 chars, 99 chunks, TTFT=64.0ms
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_828 to http://localhost:30000/generate at 1753373128.1106458
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_828 with payload: {'text': 'Random prompt 828 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:28] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_828
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_828
[2025-07-25 00:05:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:28] Prefill batch. #new-seq: 1, #new-token: 314, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_801 received DONE after 159 chunks
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_801 completed: 620 chars, 159 chunks, TTFT=46.7ms
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_829 to http://localhost:30000/generate at 1753373128.3222938
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_829 with payload: {'text': 'Random prompt 829 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 101, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:28] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_829
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_829
[2025-07-25 00:05:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:28] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:28] Decode batch. #running-req: 20, #token: 6743, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1266.19, #queue-req: 0,
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_816 received DONE after 103 chunks
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_816 completed: 408 chars, 103 chunks, TTFT=60.3ms
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_830 to http://localhost:30000/generate at 1753373128.4115243
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_830 with payload: {'text': 'Random prompt 830 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:28] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_830
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_830
[2025-07-25 00:05:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:28] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_806 received DONE after 150 chunks
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_806 completed: 596 chars, 150 chunks, TTFT=69.5ms
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_831 to http://localhost:30000/generate at 1753373128.5813665
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_831 with payload: {'text': 'Random prompt 831 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:28] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_831
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_831
[2025-07-25 00:05:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:28] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_800 received DONE after 187 chunks
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_800 completed: 704 chars, 187 chunks, TTFT=49.4ms
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_832 to http://localhost:30000/generate at 1753373128.6553273
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_832 with payload: {'text': 'Random prompt 832 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 139, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:28] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_832
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_832
[2025-07-25 00:05:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:28] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_805 received DONE after 164 chunks
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_805 completed: 469 chars, 164 chunks, TTFT=68.7ms
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_833 to http://localhost:30000/generate at 1753373128.8013322
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_833 with payload: {'text': 'Random prompt 833 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 160, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:28] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_833
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_833
[2025-07-25 00:05:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:28] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_810 received DONE after 150 chunks
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_810 completed: 575 chars, 150 chunks, TTFT=53.0ms
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_834 to http://localhost:30000/generate at 1753373128.8608406
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_834 with payload: {'text': 'Random prompt 834 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_826 received DONE after 70 chunks
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_826 completed: 207 chars, 70 chunks, TTFT=64.1ms
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_835 to http://localhost:30000/generate at 1753373128.863256
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_835 with payload: {'text': 'Random prompt 835 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:28] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_834
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_834
[2025-07-25 00:05:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:28] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_835
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_835
[2025-07-25 00:05:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:28] Prefill batch. #new-seq: 2, #new-token: 485, #cached-token: 12, token usage: 0.04, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_821 received DONE after 81 chunks
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_821 completed: 320 chars, 81 chunks, TTFT=73.4ms
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_836 to http://localhost:30000/generate at 1753373128.8845243
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_836 with payload: {'text': 'Random prompt 836 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:28] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_836
[2025-07-25 00:05:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_836
[2025-07-25 00:05:28] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:28] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] Decode batch. #running-req: 20, #token: 6257, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1198.70, #queue-req: 0,
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_820 received DONE after 91 chunks
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_820 completed: 265 chars, 91 chunks, TTFT=71.6ms
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_837 to http://localhost:30000/generate at 1753373129.0824108
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_837 with payload: {'text': 'Random prompt 837 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_837
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_837
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] Prefill batch. #new-seq: 1, #new-token: 218, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_811 received DONE after 163 chunks
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_811 completed: 485 chars, 163 chunks, TTFT=81.6ms
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_838 to http://localhost:30000/generate at 1753373129.1410306
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_838 with payload: {'text': 'Random prompt 838 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_838
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_838
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] Prefill batch. #new-seq: 1, #new-token: 274, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_819 received DONE after 114 chunks
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_819 completed: 355 chars, 114 chunks, TTFT=48.9ms
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_839 to http://localhost:30000/generate at 1753373129.390022
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_839 with payload: {'text': 'Random prompt 839 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_839
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_839
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] Prefill batch. #new-seq: 1, #new-token: 287, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_818 received DONE after 145 chunks
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_818 completed: 146 chars, 145 chunks, TTFT=60.0ms
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_840 to http://localhost:30000/generate at 1753373129.4948263
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_840 with payload: {'text': 'Random prompt 840 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 112, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_840
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_840
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] Decode batch. #running-req: 20, #token: 6431, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1338.90, #queue-req: 0,
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_815 received DONE after 189 chunks
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_815 completed: 693 chars, 189 chunks, TTFT=49.7ms
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_841 to http://localhost:30000/generate at 1753373129.6848278
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_841 with payload: {'text': 'Random prompt 841 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_841
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_841
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] Prefill batch. #new-seq: 1, #new-token: 295, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_817 received DONE after 163 chunks
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_817 completed: 648 chars, 163 chunks, TTFT=60.6ms
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_842 to http://localhost:30000/generate at 1753373129.7677267
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_842 with payload: {'text': 'Random prompt 842 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_842
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_842
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] Prefill batch. #new-seq: 1, #new-token: 171, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_825 received DONE after 133 chunks
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_825 completed: 391 chars, 133 chunks, TTFT=81.5ms
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_843 to http://localhost:30000/generate at 1753373129.8646536
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_843 with payload: {'text': 'Random prompt 843 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_843
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_843
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] Prefill batch. #new-seq: 1, #new-token: 371, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_822 received DONE after 144 chunks
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_822 completed: 560 chars, 144 chunks, TTFT=69.1ms
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_829 received DONE after 102 chunks
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_829 completed: 391 chars, 102 chunks, TTFT=46.8ms
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_844 to http://localhost:30000/generate at 1753373129.9568822
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_844 with payload: {'text': 'Random prompt 844 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_845 to http://localhost:30000/generate at 1753373129.9576738
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_845 with payload: {'text': 'Random prompt 845 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 95, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_844
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_844
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_845
[2025-07-25 00:05:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_845
[2025-07-25 00:05:29] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:29] Prefill batch. #new-seq: 2, #new-token: 394, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_824 received DONE after 147 chunks
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_824 completed: 527 chars, 147 chunks, TTFT=54.3ms
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_846 to http://localhost:30000/generate at 1753373130.0137095
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_846 with payload: {'text': 'Random prompt 846 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:30] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_846
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_846
[2025-07-25 00:05:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:30] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_836 received DONE after 81 chunks
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_836 completed: 320 chars, 81 chunks, TTFT=81.3ms
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_847 to http://localhost:30000/generate at 1753373130.1905904
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_847 with payload: {'text': 'Random prompt 847 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 89, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:30] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_847
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_847
[2025-07-25 00:05:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:30] Prefill batch. #new-seq: 1, #new-token: 380, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_823 received DONE after 164 chunks
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_823 completed: 640 chars, 164 chunks, TTFT=81.0ms
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_848 to http://localhost:30000/generate at 1753373130.2948995
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_848 with payload: {'text': 'Random prompt 848 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 178, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:30] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:30] Decode batch. #running-req: 20, #token: 5715, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1183.01, #queue-req: 0,
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_848
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_848
[2025-07-25 00:05:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:30] Prefill batch. #new-seq: 1, #new-token: 254, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_828 received DONE after 167 chunks
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_828 completed: 478 chars, 167 chunks, TTFT=60.6ms
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_849 to http://localhost:30000/generate at 1753373130.696312
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_849 with payload: {'text': 'Random prompt 849 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:30] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_849
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_849
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_837 received DONE after 108 chunks
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_837 completed: 329 chars, 108 chunks, TTFT=42.0ms
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_850 to http://localhost:30000/generate at 1753373130.708717
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_850 with payload: {'text': 'Random prompt 850 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 101, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:30] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_850
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_850
[2025-07-25 00:05:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:30] Prefill batch. #new-seq: 2, #new-token: 421, #cached-token: 11, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_831 received DONE after 142 chunks
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_831 completed: 551 chars, 142 chunks, TTFT=56.2ms
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_851 to http://localhost:30000/generate at 1753373130.8201458
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_851 with payload: {'text': 'Random prompt 851 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:30] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_851
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_851
[2025-07-25 00:05:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:30] Prefill batch. #new-seq: 1, #new-token: 317, #cached-token: 6, token usage: 0.04, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_839 received DONE after 94 chunks
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_839 completed: 275 chars, 94 chunks, TTFT=49.5ms
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_852 to http://localhost:30000/generate at 1753373130.8330603
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_852 with payload: {'text': 'Random prompt 852 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 174, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_832 received DONE after 140 chunks
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_832 completed: 544 chars, 140 chunks, TTFT=43.3ms
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_853 to http://localhost:30000/generate at 1753373130.834607
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_853 with payload: {'text': 'Random prompt 853 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:30] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_852
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_852
[2025-07-25 00:05:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:30] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_853
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_853
[2025-07-25 00:05:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:30] Prefill batch. #new-seq: 2, #new-token: 534, #cached-token: 12, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:30] Decode batch. #running-req: 20, #token: 5768, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1263.95, #queue-req: 0,
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_827 received DONE after 189 chunks
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_827 completed: 582 chars, 189 chunks, TTFT=54.0ms
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_854 to http://localhost:30000/generate at 1753373130.9364567
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_854 with payload: {'text': 'Random prompt 854 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 182, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:30] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_854
[2025-07-25 00:05:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_854
[2025-07-25 00:05:30] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:30] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_835 received DONE after 149 chunks
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_835 completed: 592 chars, 149 chunks, TTFT=89.5ms
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_855 to http://localhost:30000/generate at 1753373131.2130885
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_855 with payload: {'text': 'Random prompt 855 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 96, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_855
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_855
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_846 received DONE after 81 chunks
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_846 completed: 307 chars, 81 chunks, TTFT=50.6ms
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_856 to http://localhost:30000/generate at 1753373131.2253022
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_856 with payload: {'text': 'Random prompt 856 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_856
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_856
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_840 received DONE after 113 chunks
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_840 completed: 448 chars, 113 chunks, TTFT=43.2ms
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_857 to http://localhost:30000/generate at 1753373131.2574446
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_857 with payload: {'text': 'Random prompt 857 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_857
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_857
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] Prefill batch. #new-seq: 1, #new-token: 246, #cached-token: 6, token usage: 0.05, #running-req: 21, #queue-req: 0,
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_833 received DONE after 161 chunks
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_833 completed: 640 chars, 161 chunks, TTFT=43.9ms
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_858 to http://localhost:30000/generate at 1753373131.3908567
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_858 with payload: {'text': 'Random prompt 858 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_858
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_858
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] Prefill batch. #new-seq: 1, #new-token: 270, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_830 received DONE after 190 chunks
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_830 completed: 743 chars, 190 chunks, TTFT=55.8ms
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_859 to http://localhost:30000/generate at 1753373131.4688094
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_859 with payload: {'text': 'Random prompt 859 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_859
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_859
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_845 received DONE after 96 chunks
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_845 completed: 380 chars, 96 chunks, TTFT=69.9ms
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_860 to http://localhost:30000/generate at 1753373131.5296826
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_860 with payload: {'text': 'Random prompt 860 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_860
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_860
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] Prefill batch. #new-seq: 1, #new-token: 325, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] Decode batch. #running-req: 20, #token: 6154, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1177.95, #queue-req: 0,
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_834 received DONE after 169 chunks
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_834 completed: 656 chars, 169 chunks, TTFT=91.8ms
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_861 to http://localhost:30000/generate at 1753373131.6201675
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_861 with payload: {'text': 'Random prompt 861 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_861
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_861
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] Prefill batch. #new-seq: 1, #new-token: 241, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_841 received DONE after 120 chunks
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_841 completed: 357 chars, 120 chunks, TTFT=52.1ms
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_847 received DONE after 90 chunks
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_847 completed: 356 chars, 90 chunks, TTFT=60.9ms
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_862 to http://localhost:30000/generate at 1753373131.6796477
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_862 with payload: {'text': 'Random prompt 862 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_863 to http://localhost:30000/generate at 1753373131.680406
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_863 with payload: {'text': 'Random prompt 863 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_862
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_862
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] Prefill batch. #new-seq: 1, #new-token: 259, #cached-token: 6, token usage: 0.04, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_863
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_863
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] Prefill batch. #new-seq: 1, #new-token: 238, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_842 received DONE after 121 chunks
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_842 completed: 468 chars, 121 chunks, TTFT=44.4ms
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_864 to http://localhost:30000/generate at 1753373131.799302
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_864 with payload: {'text': 'Random prompt 864 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_864
[2025-07-25 00:05:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_864
[2025-07-25 00:05:31] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:31] Prefill batch. #new-seq: 1, #new-token: 228, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_838 received DONE after 184 chunks
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_838 completed: 713 chars, 184 chunks, TTFT=49.9ms
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_865 to http://localhost:30000/generate at 1753373132.076844
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_865 with payload: {'text': 'Random prompt 865 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:32] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_865
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_865
[2025-07-25 00:05:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:32] Prefill batch. #new-seq: 1, #new-token: 268, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_843 received DONE after 143 chunks
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_843 completed: 543 chars, 143 chunks, TTFT=61.4ms
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_866 to http://localhost:30000/generate at 1753373132.2040935
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_866 with payload: {'text': 'Random prompt 866 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 70, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:32] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_866
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_866
[2025-07-25 00:05:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:32] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:32] Decode batch. #running-req: 19, #token: 5758, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1233.15, #queue-req: 0,
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_850 received DONE after 102 chunks
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_850 completed: 404 chars, 102 chunks, TTFT=55.9ms
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_867 to http://localhost:30000/generate at 1753373132.4088645
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_867 with payload: {'text': 'Random prompt 867 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:32] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_867
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_867
[2025-07-25 00:05:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:32] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_855 received DONE after 97 chunks
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_855 completed: 371 chars, 97 chunks, TTFT=69.4ms
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_868 to http://localhost:30000/generate at 1753373132.7357037
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_868 with payload: {'text': 'Random prompt 868 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:32] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_868
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_868
[2025-07-25 00:05:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:32] Decode batch. #running-req: 19, #token: 6233, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1560.17, #queue-req: 0,
[2025-07-25 00:05:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:32] Prefill batch. #new-seq: 1, #new-token: 346, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_844 received DONE after 186 chunks
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_844 completed: 728 chars, 186 chunks, TTFT=70.6ms
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_869 to http://localhost:30000/generate at 1753373132.8658357
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_869 with payload: {'text': 'Random prompt 869 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:32] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_869
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_869
[2025-07-25 00:05:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:32] Prefill batch. #new-seq: 1, #new-token: 367, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_862 received DONE after 88 chunks
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_862 completed: 348 chars, 88 chunks, TTFT=71.2ms
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_870 to http://localhost:30000/generate at 1753373132.972418
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_870 with payload: {'text': 'Random prompt 870 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:32] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_870
[2025-07-25 00:05:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_870
[2025-07-25 00:05:32] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:32] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_848 received DONE after 179 chunks
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_848 completed: 519 chars, 179 chunks, TTFT=43.9ms
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_871 to http://localhost:30000/generate at 1753373133.0720532
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_871 with payload: {'text': 'Random prompt 871 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 91, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_871
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_871
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] Prefill batch. #new-seq: 1, #new-token: 194, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_849 received DONE after 148 chunks
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_849 completed: 413 chars, 148 chunks, TTFT=68.3ms
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_872 to http://localhost:30000/generate at 1753373133.084171
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_872 with payload: {'text': 'Random prompt 872 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 129, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_872
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_872
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] Prefill batch. #new-seq: 1, #new-token: 290, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_857 received DONE after 124 chunks
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_857 completed: 480 chars, 124 chunks, TTFT=53.5ms
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_873 to http://localhost:30000/generate at 1753373133.213002
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_873 with payload: {'text': 'Random prompt 873 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_873
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_873
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] Prefill batch. #new-seq: 1, #new-token: 230, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_866 received DONE after 71 chunks
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_866 completed: 266 chars, 71 chunks, TTFT=43.1ms
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_874 to http://localhost:30000/generate at 1753373133.2849188
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_874 with payload: {'text': 'Random prompt 874 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_874
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_874
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] Decode batch. #running-req: 20, #token: 6653, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1158.16, #queue-req: 0,
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_851 received DONE after 169 chunks
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_851 completed: 660 chars, 169 chunks, TTFT=68.9ms
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_875 to http://localhost:30000/generate at 1753373133.5185215
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_875 with payload: {'text': 'Random prompt 875 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_875
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_875
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_853 received DONE after 173 chunks
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_853 completed: 494 chars, 173 chunks, TTFT=83.9ms
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_876 to http://localhost:30000/generate at 1753373133.5914683
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_876 with payload: {'text': 'Random prompt 876 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_876
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_876
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] Prefill batch. #new-seq: 1, #new-token: 308, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_852 received DONE after 175 chunks
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_852 completed: 683 chars, 175 chunks, TTFT=85.3ms
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_877 to http://localhost:30000/generate at 1753373133.6360395
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_877 with payload: {'text': 'Random prompt 877 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 129, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_877
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_877
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] Prefill batch. #new-seq: 1, #new-token: 294, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_863 received DONE after 135 chunks
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_863 completed: 523 chars, 135 chunks, TTFT=76.4ms
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_878 to http://localhost:30000/generate at 1753373133.7633972
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_878 with payload: {'text': 'Random prompt 878 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 102, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_878
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_878
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_867 received DONE after 86 chunks
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_867 completed: 290 chars, 86 chunks, TTFT=56.1ms
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_879 to http://localhost:30000/generate at 1753373133.7763686
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_879 with payload: {'text': 'Random prompt 879 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 136, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_879
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_879
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_856 received DONE after 162 chunks
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_856 completed: 644 chars, 162 chunks, TTFT=82.8ms
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_880 to http://localhost:30000/generate at 1753373133.861949
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_880 with payload: {'text': 'Random prompt 880 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_880
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_880
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_854 received DONE after 183 chunks
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_854 completed: 716 chars, 183 chunks, TTFT=55.0ms
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_881 to http://localhost:30000/generate at 1753373133.8736007
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_881 with payload: {'text': 'Random prompt 881 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_881
[2025-07-25 00:05:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_881
[2025-07-25 00:05:33] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:33] Prefill batch. #new-seq: 1, #new-token: 298, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_861 received DONE after 149 chunks
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_861 completed: 580 chars, 149 chunks, TTFT=60.9ms
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_882 to http://localhost:30000/generate at 1753373134.0152369
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_882 with payload: {'text': 'Random prompt 882 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_859 received DONE after 158 chunks
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_859 completed: 615 chars, 158 chunks, TTFT=43.7ms
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_883 to http://localhost:30000/generate at 1753373134.01761
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_883 with payload: {'text': 'Random prompt 883 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:34] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_882
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_882
[2025-07-25 00:05:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:34] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_883
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_883
[2025-07-25 00:05:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:34] Prefill batch. #new-seq: 2, #new-token: 282, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:34] Decode batch. #running-req: 20, #token: 5952, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1113.93, #queue-req: 0,
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_860 received DONE after 164 chunks
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_860 completed: 469 chars, 164 chunks, TTFT=60.6ms
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_868 received DONE after 82 chunks
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_868 completed: 229 chars, 82 chunks, TTFT=61.5ms
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_884 to http://localhost:30000/generate at 1753373134.1658683
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_884 with payload: {'text': 'Random prompt 884 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 84, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_885 to http://localhost:30000/generate at 1753373134.1666677
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_885 with payload: {'text': 'Random prompt 885 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:34] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_884
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_884
[2025-07-25 00:05:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:34] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_885
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_885
[2025-07-25 00:05:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:34] Prefill batch. #new-seq: 2, #new-token: 501, #cached-token: 12, token usage: 0.04, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_858 received DONE after 173 chunks
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_858 completed: 586 chars, 173 chunks, TTFT=59.2ms
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_886 to http://localhost:30000/generate at 1753373134.2103603
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_886 with payload: {'text': 'Random prompt 886 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:34] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_886
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_886
[2025-07-25 00:05:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:34] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 6, token usage: 0.04, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_871 received DONE after 92 chunks
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_871 completed: 364 chars, 92 chunks, TTFT=63.2ms
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_887 to http://localhost:30000/generate at 1753373134.5869727
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_887 with payload: {'text': 'Random prompt 887 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 96, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:34] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_887
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_887
[2025-07-25 00:05:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:34] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:34] Decode batch. #running-req: 20, #token: 6086, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1382.15, #queue-req: 0,
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_864 received DONE after 191 chunks
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_864 completed: 597 chars, 191 chunks, TTFT=55.0ms
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_888 to http://localhost:30000/generate at 1753373134.7423346
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_888 with payload: {'text': 'Random prompt 888 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:34] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_888
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_888
[2025-07-25 00:05:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:34] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_865 received DONE after 185 chunks
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_865 completed: 736 chars, 185 chunks, TTFT=59.1ms
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_889 to http://localhost:30000/generate at 1753373134.9426727
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_889 with payload: {'text': 'Random prompt 889 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:34] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_889
[2025-07-25 00:05:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_889
[2025-07-25 00:05:34] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:34] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_872 received DONE after 130 chunks
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_872 completed: 385 chars, 130 chunks, TTFT=60.6ms
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_886 received DONE after 66 chunks
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_886 completed: 248 chars, 66 chunks, TTFT=58.6ms
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_890 to http://localhost:30000/generate at 1753373135.1154635
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_890 with payload: {'text': 'Random prompt 890 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_891 to http://localhost:30000/generate at 1753373135.1162574
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_891 with payload: {'text': 'Random prompt 891 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_890
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_890
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_891
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_891
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] Prefill batch. #new-seq: 2, #new-token: 656, #cached-token: 10, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] Decode batch. #running-req: 20, #token: 6227, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1357.01, #queue-req: 0,
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_878 received DONE after 103 chunks
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_878 completed: 405 chars, 103 chunks, TTFT=64.6ms
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_892 to http://localhost:30000/generate at 1753373135.3399842
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_892 with payload: {'text': 'Random prompt 892 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_892
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_892
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] Prefill batch. #new-seq: 1, #new-token: 338, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_869 received DONE after 158 chunks
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_869 completed: 628 chars, 158 chunks, TTFT=50.6ms
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_893 to http://localhost:30000/generate at 1753373135.3634706
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_893 with payload: {'text': 'Random prompt 893 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_893
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_893
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] Prefill batch. #new-seq: 1, #new-token: 227, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_884 received DONE after 85 chunks
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_884 completed: 241 chars, 85 chunks, TTFT=60.3ms
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_894 to http://localhost:30000/generate at 1753373135.4460173
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_894 with payload: {'text': 'Random prompt 894 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 135, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_894
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_894
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] Prefill batch. #new-seq: 1, #new-token: 296, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_875 received DONE after 134 chunks
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_875 completed: 520 chars, 134 chunks, TTFT=42.7ms
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_895 to http://localhost:30000/generate at 1753373135.6458943
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_895 with payload: {'text': 'Random prompt 895 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_895
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_895
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_877 received DONE after 130 chunks
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_877 completed: 385 chars, 130 chunks, TTFT=59.6ms
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_896 to http://localhost:30000/generate at 1753373135.691086
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_896 with payload: {'text': 'Random prompt 896 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_870 received DONE after 170 chunks
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_870 completed: 656 chars, 170 chunks, TTFT=44.3ms
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_897 to http://localhost:30000/generate at 1753373135.6928625
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_897 with payload: {'text': 'Random prompt 897 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_896
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_896
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] Prefill batch. #new-seq: 1, #new-token: 200, #cached-token: 6, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_897
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_897
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] Prefill batch. #new-seq: 1, #new-token: 355, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_874 received DONE after 159 chunks
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_874 completed: 629 chars, 159 chunks, TTFT=45.7ms
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_898 to http://localhost:30000/generate at 1753373135.8239293
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_898 with payload: {'text': 'Random prompt 898 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_898
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_898
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_876 received DONE after 141 chunks
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_876 completed: 560 chars, 141 chunks, TTFT=50.8ms
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_899 to http://localhost:30000/generate at 1753373135.882769
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_899 with payload: {'text': 'Random prompt 899 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_899
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_899
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_879 received DONE after 137 chunks
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_879 completed: 531 chars, 137 chunks, TTFT=55.0ms
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_900 to http://localhost:30000/generate at 1753373135.967431
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_900 with payload: {'text': 'Random prompt 900 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 135, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_900
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_900
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 4, token usage: 0.04, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_873 received DONE after 173 chunks
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_873 completed: 675 chars, 173 chunks, TTFT=42.8ms
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_901 to http://localhost:30000/generate at 1753373135.9907665
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_901 with payload: {'text': 'Random prompt 901 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:35] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:35] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_901
[2025-07-25 00:05:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_901
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 4, token usage: 0.04, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] Decode batch. #running-req: 20, #token: 5454, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1051.02, #queue-req: 0,
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_885 received DONE after 124 chunks
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_885 completed: 479 chars, 124 chunks, TTFT=59.4ms
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_902 to http://localhost:30000/generate at 1753373136.1236103
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_902 with payload: {'text': 'Random prompt 902 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_902
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_902
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 6, token usage: 0.04, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_887 received DONE after 97 chunks
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_887 completed: 372 chars, 97 chunks, TTFT=42.9ms
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_903 to http://localhost:30000/generate at 1753373136.1473098
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_903 with payload: {'text': 'Random prompt 903 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_903
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_903
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] Prefill batch. #new-seq: 1, #new-token: 274, #cached-token: 6, token usage: 0.04, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_880 received DONE after 153 chunks
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_880 completed: 608 chars, 153 chunks, TTFT=65.9ms
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_904 to http://localhost:30000/generate at 1753373136.3110852
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_904 with payload: {'text': 'Random prompt 904 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 159, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_904
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_904
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] Prefill batch. #new-seq: 1, #new-token: 233, #cached-token: 6, token usage: 0.04, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_882 received DONE after 146 chunks
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_882 completed: 577 chars, 146 chunks, TTFT=60.9ms
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_905 to http://localhost:30000/generate at 1753373136.3315122
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_905 with payload: {'text': 'Random prompt 905 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_905
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_905
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] Prefill batch. #new-seq: 1, #new-token: 354, #cached-token: 6, token usage: 0.04, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_890 received DONE after 78 chunks
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_890 completed: 218 chars, 78 chunks, TTFT=84.1ms
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_906 to http://localhost:30000/generate at 1753373136.5017612
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_906 with payload: {'text': 'Random prompt 906 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 187, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_906
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_906
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] Prefill batch. #new-seq: 1, #new-token: 334, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_883 received DONE after 162 chunks
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_883 completed: 631 chars, 162 chunks, TTFT=58.6ms
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_907 to http://localhost:30000/generate at 1753373136.6175137
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_907 with payload: {'text': 'Random prompt 907 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_907
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_907
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] Prefill batch. #new-seq: 1, #new-token: 213, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] Decode batch. #running-req: 20, #token: 5467, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1215.62, #queue-req: 0,
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_881 received DONE after 177 chunks
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_881 completed: 692 chars, 177 chunks, TTFT=62.9ms
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_908 to http://localhost:30000/generate at 1753373136.7148595
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_908 with payload: {'text': 'Random prompt 908 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_908
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_908
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] Prefill batch. #new-seq: 1, #new-token: 192, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_893 received DONE after 91 chunks
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_893 completed: 347 chars, 91 chunks, TTFT=64.1ms
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_909 to http://localhost:30000/generate at 1753373136.9078531
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_909 with payload: {'text': 'Random prompt 909 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_909
[2025-07-25 00:05:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_909
[2025-07-25 00:05:36] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:36] Prefill batch. #new-seq: 1, #new-token: 222, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_901 received DONE after 66 chunks
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_901 completed: 69 chars, 66 chunks, TTFT=55.2ms
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_910 to http://localhost:30000/generate at 1753373137.0412757
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_910 with payload: {'text': 'Random prompt 910 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:37] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_910
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_910
[2025-07-25 00:05:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:37] Prefill batch. #new-seq: 1, #new-token: 277, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_891 received DONE after 116 chunks
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_891 completed: 340 chars, 116 chunks, TTFT=83.2ms
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_911 to http://localhost:30000/generate at 1753373137.064576
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_911 with payload: {'text': 'Random prompt 911 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:37] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_911
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_911
[2025-07-25 00:05:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:37] Prefill batch. #new-seq: 1, #new-token: 195, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_897 received DONE after 89 chunks
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_897 completed: 88 chars, 89 chunks, TTFT=76.3ms
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_912 to http://localhost:30000/generate at 1753373137.1927958
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_912 with payload: {'text': 'Random prompt 912 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:37] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_912
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_912
[2025-07-25 00:05:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:37] Prefill batch. #new-seq: 1, #new-token: 285, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_903 received DONE after 70 chunks
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_903 completed: 276 chars, 70 chunks, TTFT=61.1ms
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_913 to http://localhost:30000/generate at 1753373137.283281
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_913 with payload: {'text': 'Random prompt 913 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:37] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_913
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_913
[2025-07-25 00:05:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:37] Prefill batch. #new-seq: 1, #new-token: 230, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_888 received DONE after 158 chunks
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_888 completed: 616 chars, 158 chunks, TTFT=42.6ms
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_914 to http://localhost:30000/generate at 1753373137.3395302
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_914 with payload: {'text': 'Random prompt 914 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 121, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:37] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_914
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_914
[2025-07-25 00:05:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:37] Decode batch. #running-req: 19, #token: 5588, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1230.98, #queue-req: 0,
[2025-07-25 00:05:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:37] Prefill batch. #new-seq: 1, #new-token: 266, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_898 received DONE after 110 chunks
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_898 completed: 436 chars, 110 chunks, TTFT=43.1ms
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_915 to http://localhost:30000/generate at 1753373137.6043873
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_915 with payload: {'text': 'Random prompt 915 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:37] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_915
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_915
[2025-07-25 00:05:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:37] Prefill batch. #new-seq: 1, #new-token: 237, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_894 received DONE after 136 chunks
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_894 completed: 405 chars, 136 chunks, TTFT=59.4ms
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_916 to http://localhost:30000/generate at 1753373137.6906772
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_916 with payload: {'text': 'Random prompt 916 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:37] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_916
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_916
[2025-07-25 00:05:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:37] Prefill batch. #new-seq: 1, #new-token: 201, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_905 received DONE after 91 chunks
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_905 completed: 90 chars, 91 chunks, TTFT=66.9ms
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_917 to http://localhost:30000/generate at 1753373137.7757792
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_917 with payload: {'text': 'Random prompt 917 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:37] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_917
[2025-07-25 00:05:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_917
[2025-07-25 00:05:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:37] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:37] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:37] Decode batch. #running-req: 20, #token: 6344, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1326.40, #queue-req: 0,
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_896 received DONE after 144 chunks
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_896 completed: 433 chars, 144 chunks, TTFT=68.0ms
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_918 to http://localhost:30000/generate at 1753373138.0281923
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_918 with payload: {'text': 'Random prompt 918 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_918
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_918
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] Prefill batch. #new-seq: 1, #new-token: 321, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_889 received DONE after 192 chunks
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_889 completed: 764 chars, 192 chunks, TTFT=46.9ms
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_919 to http://localhost:30000/generate at 1753373138.0729096
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_919 with payload: {'text': 'Random prompt 919 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_919
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_919
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_892 received DONE after 167 chunks
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_892 completed: 476 chars, 167 chunks, TTFT=80.8ms
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_920 to http://localhost:30000/generate at 1753373138.1280797
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_920 with payload: {'text': 'Random prompt 920 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_920
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_920
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] Prefill batch. #new-seq: 1, #new-token: 348, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_900 received DONE after 136 chunks
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_900 completed: 540 chars, 136 chunks, TTFT=75.1ms
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_921 to http://localhost:30000/generate at 1753373138.201111
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_921 with payload: {'text': 'Random prompt 921 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 64, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_921
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_921
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] Prefill batch. #new-seq: 1, #new-token: 250, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_909 received DONE after 84 chunks
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_909 completed: 332 chars, 84 chunks, TTFT=54.2ms
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_922 to http://localhost:30000/generate at 1753373138.2968528
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_922 with payload: {'text': 'Random prompt 922 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_895 received DONE after 159 chunks
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_895 completed: 620 chars, 159 chunks, TTFT=47.7ms
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_923 to http://localhost:30000/generate at 1753373138.2990856
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_923 with payload: {'text': 'Random prompt 923 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 110, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_922
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_922
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] Prefill batch. #new-seq: 1, #new-token: 354, #cached-token: 6, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_923
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_923
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] Prefill batch. #new-seq: 1, #new-token: 330, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_907 received DONE after 112 chunks
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_907 completed: 431 chars, 112 chunks, TTFT=55.4ms
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_924 to http://localhost:30000/generate at 1753373138.46188
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_924 with payload: {'text': 'Random prompt 924 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_924
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_924
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] Prefill batch. #new-seq: 1, #new-token: 234, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_908 received DONE after 107 chunks
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_908 completed: 412 chars, 107 chunks, TTFT=57.8ms
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_925 to http://localhost:30000/generate at 1753373138.4743173
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_925 with payload: {'text': 'Random prompt 925 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 76, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_925
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_925
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_899 received DONE after 165 chunks
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_899 completed: 643 chars, 165 chunks, TTFT=43.1ms
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_926 to http://localhost:30000/generate at 1753373138.6206052
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_926 with payload: {'text': 'Random prompt 926 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 139, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_926
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_926
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] Prefill batch. #new-seq: 1, #new-token: 194, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] Decode batch. #running-req: 20, #token: 6344, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1070.67, #queue-req: 0,
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_902 received DONE after 162 chunks
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_902 completed: 631 chars, 162 chunks, TTFT=76.1ms
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_927 to http://localhost:30000/generate at 1753373138.7925076
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_927 with payload: {'text': 'Random prompt 927 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_910 received DONE after 104 chunks
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_910 completed: 400 chars, 104 chunks, TTFT=78.8ms
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_928 to http://localhost:30000/generate at 1753373138.794514
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_928 with payload: {'text': 'Random prompt 928 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_927
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_927
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_928
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_928
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] Prefill batch. #new-seq: 2, #new-token: 551, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_904 received DONE after 160 chunks
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_904 completed: 621 chars, 160 chunks, TTFT=76.6ms
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_929 to http://localhost:30000/generate at 1753373138.9510987
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_929 with payload: {'text': 'Random prompt 929 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_929
[2025-07-25 00:05:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_929
[2025-07-25 00:05:38] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:38] Prefill batch. #new-seq: 1, #new-token: 191, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_913 received DONE after 112 chunks
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_913 completed: 431 chars, 112 chunks, TTFT=57.6ms
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_930 to http://localhost:30000/generate at 1753373139.116553
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_930 with payload: {'text': 'Random prompt 930 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 138, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:39] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_930
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_930
[2025-07-25 00:05:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:39] Prefill batch. #new-seq: 1, #new-token: 162, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_921 received DONE after 65 chunks
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_921 completed: 243 chars, 65 chunks, TTFT=43.5ms
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_931 to http://localhost:30000/generate at 1753373139.250485
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_931 with payload: {'text': 'Random prompt 931 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 136, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:39] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_931
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_931
[2025-07-25 00:05:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:39] Prefill batch. #new-seq: 1, #new-token: 339, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:39] Decode batch. #running-req: 19, #token: 6600, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1312.86, #queue-req: 0,
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_914 received DONE after 122 chunks
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_914 completed: 484 chars, 122 chunks, TTFT=52.7ms
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_932 to http://localhost:30000/generate at 1753373139.3180976
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_932 with payload: {'text': 'Random prompt 932 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 136, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:39] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_932
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_932
[2025-07-25 00:05:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:39] Prefill batch. #new-seq: 1, #new-token: 377, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_906 received DONE after 188 chunks
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_906 completed: 748 chars, 188 chunks, TTFT=61.1ms
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_933 to http://localhost:30000/generate at 1753373139.539365
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_933 with payload: {'text': 'Random prompt 933 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:39] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_933
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_933
[2025-07-25 00:05:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:39] Prefill batch. #new-seq: 1, #new-token: 260, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_925 received DONE after 77 chunks
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_925 completed: 300 chars, 77 chunks, TTFT=54.2ms
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_934 to http://localhost:30000/generate at 1753373139.6654513
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_934 with payload: {'text': 'Random prompt 934 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:39] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_934
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_934
[2025-07-25 00:05:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:39] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 6, token usage: 0.06, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:39] Decode batch. #running-req: 20, #token: 7107, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1345.71, #queue-req: 0,
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_918 received DONE after 115 chunks
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_918 completed: 437 chars, 115 chunks, TTFT=50.3ms
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_911 received DONE after 177 chunks
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_911 completed: 692 chars, 177 chunks, TTFT=61.2ms
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_935 to http://localhost:30000/generate at 1753373139.9025884
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_935 with payload: {'text': 'Random prompt 935 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_936 to http://localhost:30000/generate at 1753373139.9033203
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_936 with payload: {'text': 'Random prompt 936 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:39] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_935
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_935
[2025-07-25 00:05:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:39] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_936
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_936
[2025-07-25 00:05:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:39] Prefill batch. #new-seq: 2, #new-token: 325, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_919 received DONE after 118 chunks
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_919 completed: 455 chars, 118 chunks, TTFT=55.9ms
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_937 to http://localhost:30000/generate at 1753373139.993811
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_937 with payload: {'text': 'Random prompt 937 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:39] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_937
[2025-07-25 00:05:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_937
[2025-07-25 00:05:39] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:39] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_917 received DONE after 141 chunks
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_917 completed: 538 chars, 141 chunks, TTFT=62.9ms
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_938 to http://localhost:30000/generate at 1753373140.075674
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_938 with payload: {'text': 'Random prompt 938 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_923 received DONE after 111 chunks
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_923 completed: 422 chars, 111 chunks, TTFT=82.2ms
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_939 to http://localhost:30000/generate at 1753373140.078025
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_939 with payload: {'text': 'Random prompt 939 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_938
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_938
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_939
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_939
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_929 received DONE after 73 chunks
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_929 completed: 276 chars, 73 chunks, TTFT=52.2ms
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_940 to http://localhost:30000/generate at 1753373140.0905197
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_940 with payload: {'text': 'Random prompt 940 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] Prefill batch. #new-seq: 2, #new-token: 428, #cached-token: 12, token usage: 0.05, #running-req: 17, #queue-req: 0,
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_940
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_940
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] Prefill batch. #new-seq: 1, #new-token: 196, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_915 received DONE after 157 chunks
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_915 completed: 611 chars, 157 chunks, TTFT=44.0ms
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_941 to http://localhost:30000/generate at 1753373140.2031074
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_941 with payload: {'text': 'Random prompt 941 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_941
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_941
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] Prefill batch. #new-seq: 1, #new-token: 267, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_912 received DONE after 193 chunks
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_912 completed: 755 chars, 193 chunks, TTFT=59.7ms
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_942 to http://localhost:30000/generate at 1753373140.3562703
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_942 with payload: {'text': 'Random prompt 942 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_942
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_942
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] Prefill batch. #new-seq: 1, #new-token: 292, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] Decode batch. #running-req: 20, #token: 6597, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1151.81, #queue-req: 0,
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_916 received DONE after 178 chunks
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_916 completed: 696 chars, 178 chunks, TTFT=43.8ms
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_943 to http://localhost:30000/generate at 1753373140.5848382
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_943 with payload: {'text': 'Random prompt 943 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_943
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_943
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] Prefill batch. #new-seq: 1, #new-token: 338, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_922 received DONE after 144 chunks
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_922 completed: 520 chars, 144 chunks, TTFT=72.1ms
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_944 to http://localhost:30000/generate at 1753373140.6091409
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_944 with payload: {'text': 'Random prompt 944 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_944
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_944
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_920 received DONE after 154 chunks
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_920 completed: 612 chars, 154 chunks, TTFT=54.8ms
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_945 to http://localhost:30000/generate at 1753373140.6418889
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_945 with payload: {'text': 'Random prompt 945 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_945
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_945
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 6, token usage: 0.05, #running-req: 21, #queue-req: 0,
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_927 received DONE after 127 chunks
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_927 completed: 457 chars, 127 chunks, TTFT=75.9ms
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_926 received DONE after 140 chunks
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_926 completed: 542 chars, 140 chunks, TTFT=43.1ms
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_946 to http://localhost:30000/generate at 1753373140.845867
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_946 with payload: {'text': 'Random prompt 946 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_947 to http://localhost:30000/generate at 1753373140.8465934
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_947 with payload: {'text': 'Random prompt 947 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_946
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_946
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_947
[2025-07-25 00:05:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_947
[2025-07-25 00:05:40] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:40] Prefill batch. #new-seq: 2, #new-token: 516, #cached-token: 12, token usage: 0.05, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_924 received DONE after 167 chunks
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_924 completed: 612 chars, 167 chunks, TTFT=63.2ms
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_948 to http://localhost:30000/generate at 1753373141.1099102
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_948 with payload: {'text': 'Random prompt 948 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_948
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_948
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] Prefill batch. #new-seq: 1, #new-token: 349, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_928 received DONE after 147 chunks
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_928 completed: 584 chars, 147 chunks, TTFT=74.0ms
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_949 to http://localhost:30000/generate at 1753373141.133808
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_949 with payload: {'text': 'Random prompt 949 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_949
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_949
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] Prefill batch. #new-seq: 1, #new-token: 278, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] Decode batch. #running-req: 20, #token: 6244, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1172.63, #queue-req: 0,
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_940 received DONE after 72 chunks
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_940 completed: 284 chars, 72 chunks, TTFT=81.2ms
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_950 to http://localhost:30000/generate at 1753373141.2847836
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_950 with payload: {'text': 'Random prompt 950 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_950
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_950
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] Prefill batch. #new-seq: 1, #new-token: 280, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_939 received DONE after 75 chunks
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_939 completed: 289 chars, 75 chunks, TTFT=87.8ms
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_951 to http://localhost:30000/generate at 1753373141.3512127
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_951 with payload: {'text': 'Random prompt 951 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_951
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_951
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] Prefill batch. #new-seq: 1, #new-token: 295, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_930 received DONE after 139 chunks
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_930 completed: 539 chars, 139 chunks, TTFT=43.5ms
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_952 to http://localhost:30000/generate at 1753373141.3965669
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_952 with payload: {'text': 'Random prompt 952 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_952
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_952
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_931 received DONE after 137 chunks
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_931 completed: 524 chars, 137 chunks, TTFT=50.5ms
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_953 to http://localhost:30000/generate at 1753373141.5172737
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_953 with payload: {'text': 'Random prompt 953 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_953
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_953
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] Prefill batch. #new-seq: 1, #new-token: 359, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_932 received DONE after 137 chunks
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_932 completed: 524 chars, 137 chunks, TTFT=54.0ms
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_954 to http://localhost:30000/generate at 1753373141.5749812
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_954 with payload: {'text': 'Random prompt 954 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_954
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_954
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] Prefill batch. #new-seq: 1, #new-token: 232, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_936 received DONE after 100 chunks
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_936 completed: 103 chars, 100 chunks, TTFT=60.1ms
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_955 to http://localhost:30000/generate at 1753373141.678549
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_955 with payload: {'text': 'Random prompt 955 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_955
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_955
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] Prefill batch. #new-seq: 1, #new-token: 223, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_933 received DONE after 142 chunks
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_933 completed: 507 chars, 142 chunks, TTFT=48.9ms
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_956 to http://localhost:30000/generate at 1753373141.9115644
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_956 with payload: {'text': 'Random prompt 956 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_956
[2025-07-25 00:05:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_956
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] Prefill batch. #new-seq: 1, #new-token: 258, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:41] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:41] Decode batch. #running-req: 19, #token: 6304, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1112.34, #queue-req: 0,
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_941 received DONE after 108 chunks
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_941 completed: 415 chars, 108 chunks, TTFT=62.1ms
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_957 to http://localhost:30000/generate at 1753373142.0263038
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_957 with payload: {'text': 'Random prompt 957 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 118, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_957
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_957
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_934 received DONE after 152 chunks
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_934 completed: 592 chars, 152 chunks, TTFT=46.4ms
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_958 to http://localhost:30000/generate at 1753373142.2059753
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_958 with payload: {'text': 'Random prompt 958 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_958
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_958
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] Prefill batch. #new-seq: 1, #new-token: 168, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_938 received DONE after 129 chunks
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_938 completed: 512 chars, 129 chunks, TTFT=90.1ms
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_959 to http://localhost:30000/generate at 1753373142.281799
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_959 with payload: {'text': 'Random prompt 959 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_959
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_959
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] Prefill batch. #new-seq: 1, #new-token: 314, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_947 received DONE after 84 chunks
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_947 completed: 83 chars, 84 chunks, TTFT=75.1ms
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_960 to http://localhost:30000/generate at 1753373142.2957373
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_960 with payload: {'text': 'Random prompt 960 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 79, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_960
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_960
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 5, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_950 received DONE after 76 chunks
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_950 completed: 223 chars, 76 chunks, TTFT=48.2ms
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_961 to http://localhost:30000/generate at 1753373142.5980525
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_961 with payload: {'text': 'Random prompt 961 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_961
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_961
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] Decode batch. #running-req: 20, #token: 6116, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1222.49, #queue-req: 0,
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] Prefill batch. #new-seq: 1, #new-token: 280, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_935 received DONE after 168 chunks
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_935 completed: 655 chars, 168 chunks, TTFT=60.7ms
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_962 to http://localhost:30000/generate at 1753373142.776512
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_962 with payload: {'text': 'Random prompt 962 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 171, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_962
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_962
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] Prefill batch. #new-seq: 1, #new-token: 188, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_945 received DONE after 131 chunks
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_945 completed: 134 chars, 131 chunks, TTFT=52.1ms
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_963 to http://localhost:30000/generate at 1753373142.83872
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_963 with payload: {'text': 'Random prompt 963 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 113, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_963
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_963
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] Prefill batch. #new-seq: 1, #new-token: 225, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_937 received DONE after 171 chunks
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_937 completed: 492 chars, 171 chunks, TTFT=50.9ms
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_964 to http://localhost:30000/generate at 1753373142.9197903
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_964 with payload: {'text': 'Random prompt 964 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 137, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_964
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_964
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] Prefill batch. #new-seq: 1, #new-token: 199, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_946 received DONE after 121 chunks
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_946 completed: 468 chars, 121 chunks, TTFT=75.8ms
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_965 to http://localhost:30000/generate at 1753373142.9323063
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_965 with payload: {'text': 'Random prompt 965 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 139, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_965
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_965
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] Prefill batch. #new-seq: 1, #new-token: 216, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_951 received DONE after 93 chunks
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_951 completed: 368 chars, 93 chunks, TTFT=50.6ms
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_966 to http://localhost:30000/generate at 1753373142.966865
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_966 with payload: {'text': 'Random prompt 966 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_966
[2025-07-25 00:05:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_966
[2025-07-25 00:05:42] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:42] Prefill batch. #new-seq: 1, #new-token: 309, #cached-token: 6, token usage: 0.05, #running-req: 21, #queue-req: 0,
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_948 received DONE after 107 chunks
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_948 completed: 299 chars, 107 chunks, TTFT=81.8ms
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_967 to http://localhost:30000/generate at 1753373143.0867054
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_967 with payload: {'text': 'Random prompt 967 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 110, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:43] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_967
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_967
[2025-07-25 00:05:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:43] Prefill batch. #new-seq: 1, #new-token: 201, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_942 received DONE after 165 chunks
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_942 completed: 492 chars, 165 chunks, TTFT=49.9ms
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_968 to http://localhost:30000/generate at 1753373143.21746
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_968 with payload: {'text': 'Random prompt 968 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:43] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_968
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_968
[2025-07-25 00:05:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:43] Prefill batch. #new-seq: 1, #new-token: 270, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_949 received DONE after 121 chunks
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_949 completed: 468 chars, 121 chunks, TTFT=70.5ms
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_969 to http://localhost:30000/generate at 1753373143.3346505
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_969 with payload: {'text': 'Random prompt 969 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:43] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_969
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_969
[2025-07-25 00:05:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:43] Prefill batch. #new-seq: 1, #new-token: 247, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_943 received DONE after 156 chunks
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_943 completed: 440 chars, 156 chunks, TTFT=81.9ms
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_970 to http://localhost:30000/generate at 1753373143.3803675
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_970 with payload: {'text': 'Random prompt 970 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:43] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_970
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_970
[2025-07-25 00:05:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:43] Prefill batch. #new-seq: 1, #new-token: 296, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:43] Decode batch. #running-req: 19, #token: 5702, token usage: 0.05, cuda graph: True, gen throughput (token/s): 960.80, #queue-req: 0,
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_944 received DONE after 166 chunks
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_944 completed: 646 chars, 166 chunks, TTFT=81.5ms
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_971 to http://localhost:30000/generate at 1753373143.5578392
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_971 with payload: {'text': 'Random prompt 971 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:43] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_971
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_971
[2025-07-25 00:05:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:43] Prefill batch. #new-seq: 1, #new-token: 365, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_960 received DONE after 80 chunks
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_960 completed: 316 chars, 80 chunks, TTFT=75.2ms
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_972 to http://localhost:30000/generate at 1753373143.7521095
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_972 with payload: {'text': 'Random prompt 972 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:43] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_972
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_972
[2025-07-25 00:05:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:43] Prefill batch. #new-seq: 1, #new-token: 313, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_952 received DONE after 142 chunks
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_952 completed: 552 chars, 142 chunks, TTFT=54.2ms
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_973 to http://localhost:30000/generate at 1753373143.9183836
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_973 with payload: {'text': 'Random prompt 973 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:43] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_973
[2025-07-25 00:05:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_973
[2025-07-25 00:05:43] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:43] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] Decode batch. #running-req: 20, #token: 6497, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1253.91, #queue-req: 0,
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_957 received DONE after 119 chunks
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_957 completed: 469 chars, 119 chunks, TTFT=46.6ms
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_974 to http://localhost:30000/generate at 1753373144.1054385
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_974 with payload: {'text': 'Random prompt 974 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 102, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_974
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_974
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] Prefill batch. #new-seq: 1, #new-token: 133, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_953 received DONE after 159 chunks
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_953 completed: 454 chars, 159 chunks, TTFT=67.1ms
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_975 to http://localhost:30000/generate at 1753373144.2875369
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_975 with payload: {'text': 'Random prompt 975 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_975
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_975
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] Prefill batch. #new-seq: 1, #new-token: 192, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_969 received DONE after 68 chunks
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_969 completed: 246 chars, 68 chunks, TTFT=51.7ms
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_976 to http://localhost:30000/generate at 1753373144.4280658
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_976 with payload: {'text': 'Random prompt 976 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_976
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_976
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_956 received DONE after 147 chunks
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_956 completed: 527 chars, 147 chunks, TTFT=54.4ms
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_977 to http://localhost:30000/generate at 1753373144.440032
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_977 with payload: {'text': 'Random prompt 977 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_977
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_977
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] Prefill batch. #new-seq: 2, #new-token: 415, #cached-token: 12, token usage: 0.04, #running-req: 18, #queue-req: 0,
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_970 received DONE after 68 chunks
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_970 completed: 256 chars, 68 chunks, TTFT=63.7ms
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_966 received DONE after 89 chunks
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_966 completed: 330 chars, 89 chunks, TTFT=68.5ms
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_978 to http://localhost:30000/generate at 1753373144.4532108
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_978 with payload: {'text': 'Random prompt 978 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_979 to http://localhost:30000/generate at 1753373144.453904
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_979 with payload: {'text': 'Random prompt 979 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_978
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_978
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_979
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_979
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] Prefill batch. #new-seq: 2, #new-token: 530, #cached-token: 12, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_961 received DONE after 117 chunks
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_961 completed: 452 chars, 117 chunks, TTFT=52.9ms
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_980 to http://localhost:30000/generate at 1753373144.699673
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_980 with payload: {'text': 'Random prompt 980 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_980
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_980
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] Prefill batch. #new-seq: 1, #new-token: 212, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] Decode batch. #running-req: 20, #token: 6128, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1112.59, #queue-req: 0,
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_958 received DONE after 146 chunks
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_958 completed: 568 chars, 146 chunks, TTFT=46.9ms
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_981 to http://localhost:30000/generate at 1753373144.8063703
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_981 with payload: {'text': 'Random prompt 981 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_981
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_981
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] Prefill batch. #new-seq: 1, #new-token: 322, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_955 received DONE after 184 chunks
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_955 completed: 720 chars, 184 chunks, TTFT=48.8ms
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_982 to http://localhost:30000/generate at 1753373144.8981519
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_982 with payload: {'text': 'Random prompt 982 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_982
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_982
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_963 received DONE after 114 chunks
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_963 completed: 439 chars, 114 chunks, TTFT=50.1ms
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_983 to http://localhost:30000/generate at 1753373144.912115
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_983 with payload: {'text': 'Random prompt 983 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_983
[2025-07-25 00:05:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_983
[2025-07-25 00:05:44] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:44] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_954 received DONE after 193 chunks
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_954 completed: 768 chars, 193 chunks, TTFT=57.9ms
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_984 to http://localhost:30000/generate at 1753373145.0046427
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_984 with payload: {'text': 'Random prompt 984 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:45] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_984
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_984
[2025-07-25 00:05:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:45] Prefill batch. #new-seq: 1, #new-token: 312, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_967 received DONE after 111 chunks
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_967 completed: 428 chars, 111 chunks, TTFT=49.6ms
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_985 to http://localhost:30000/generate at 1753373145.0795467
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_985 with payload: {'text': 'Random prompt 985 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:45] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_985
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_985
[2025-07-25 00:05:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:45] Prefill batch. #new-seq: 1, #new-token: 252, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_968 received DONE after 108 chunks
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_968 completed: 438 chars, 108 chunks, TTFT=54.7ms
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_986 to http://localhost:30000/generate at 1753373145.1761723
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_986 with payload: {'text': 'Random prompt 986 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:45] INFO:     127.0.0.1:45664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_986
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_986
[2025-07-25 00:05:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:45] Prefill batch. #new-seq: 1, #new-token: 301, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_959 received DONE after 166 chunks
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_959 completed: 475 chars, 166 chunks, TTFT=75.2ms
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_987 to http://localhost:30000/generate at 1753373145.321375
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_987 with payload: {'text': 'Random prompt 987 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:45] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_987
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_987
[2025-07-25 00:05:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:45] Prefill batch. #new-seq: 1, #new-token: 236, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_964 received DONE after 138 chunks
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_964 completed: 536 chars, 138 chunks, TTFT=68.9ms
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_988 to http://localhost:30000/generate at 1753373145.4652658
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_988 with payload: {'text': 'Random prompt 988 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:45] INFO:     127.0.0.1:45666 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_988
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_988
[2025-07-25 00:05:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:45] Prefill batch. #new-seq: 1, #new-token: 188, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_965 received DONE after 140 chunks
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_965 completed: 544 chars, 140 chunks, TTFT=84.6ms
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_989 to http://localhost:30000/generate at 1753373145.5098507
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_989 with payload: {'text': 'Random prompt 989 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:45] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_989
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_989
[2025-07-25 00:05:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:45] Prefill batch. #new-seq: 1, #new-token: 335, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:45] Decode batch. #running-req: 20, #token: 5411, token usage: 0.05, cuda graph: True, gen throughput (token/s): 974.91, #queue-req: 0,
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_972 received DONE after 100 chunks
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_972 completed: 287 chars, 100 chunks, TTFT=53.0ms
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_990 to http://localhost:30000/generate at 1753373145.5947459
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_990 with payload: {'text': 'Random prompt 990 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:45] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_990
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_990
[2025-07-25 00:05:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:45] Prefill batch. #new-seq: 1, #new-token: 331, #cached-token: 5, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_962 received DONE after 172 chunks
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_962 completed: 671 chars, 172 chunks, TTFT=44.4ms
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_991 to http://localhost:30000/generate at 1753373145.9196205
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_991 with payload: {'text': 'Random prompt 991 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 84, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:45] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_991
[2025-07-25 00:05:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_991
[2025-07-25 00:05:45] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:45] Prefill batch. #new-seq: 1, #new-token: 303, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_974 received DONE after 103 chunks
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_974 completed: 402 chars, 103 chunks, TTFT=48.0ms
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_992 to http://localhost:30000/generate at 1753373146.0075493
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_992 with payload: {'text': 'Random prompt 992 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:46] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_992
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_992
[2025-07-25 00:05:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:46] Prefill batch. #new-seq: 1, #new-token: 195, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:46] Decode batch. #running-req: 20, #token: 6441, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1282.58, #queue-req: 0,
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_973 received DONE after 131 chunks
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_973 completed: 508 chars, 131 chunks, TTFT=44.7ms
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_993 to http://localhost:30000/generate at 1753373146.2300005
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_993 with payload: {'text': 'Random prompt 993 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:46] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_993
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_993
[2025-07-25 00:05:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:46] Prefill batch. #new-seq: 1, #new-token: 276, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_976 received DONE after 98 chunks
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_976 completed: 388 chars, 98 chunks, TTFT=97.4ms
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_994 to http://localhost:30000/generate at 1753373146.2551289
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_994 with payload: {'text': 'Random prompt 994 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 160, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:46] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_994
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_994
[2025-07-25 00:05:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:46] Prefill batch. #new-seq: 1, #new-token: 218, #cached-token: 6, token usage: 0.05, #running-req: 20, #queue-req: 0,
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_980 received DONE after 89 chunks
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_980 completed: 340 chars, 89 chunks, TTFT=51.6ms
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_995 to http://localhost:30000/generate at 1753373146.3499506
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_995 with payload: {'text': 'Random prompt 995 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:46] INFO:     127.0.0.1:45536 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_995
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_995
[2025-07-25 00:05:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:46] Prefill batch. #new-seq: 1, #new-token: 149, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_985 received DONE after 75 chunks
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_985 completed: 287 chars, 75 chunks, TTFT=50.6ms
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_996 to http://localhost:30000/generate at 1753373146.4154549
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_996 with payload: {'text': 'Random prompt 996 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:46] INFO:     127.0.0.1:45588 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:46] Prefill batch. #new-seq: 1, #new-token: 360, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_996
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_996
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_984 received DONE after 82 chunks
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_984 completed: 229 chars, 82 chunks, TTFT=54.6ms
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_997 to http://localhost:30000/generate at 1753373146.5104175
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_997 with payload: {'text': 'Random prompt 997 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:46] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_997
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_997
[2025-07-25 00:05:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:46] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_971 received DONE after 171 chunks
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_971 completed: 649 chars, 171 chunks, TTFT=57.1ms
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_998 to http://localhost:30000/generate at 1753373146.625833
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_998 with payload: {'text': 'Random prompt 998 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:46] INFO:     127.0.0.1:45618 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_998
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_998
[2025-07-25 00:05:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:46] Prefill batch. #new-seq: 1, #new-token: 368, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_977 received DONE after 120 chunks
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_977 completed: 476 chars, 120 chunks, TTFT=85.5ms
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_999 to http://localhost:30000/generate at 1753373146.745401
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_999 with payload: {'text': 'Random prompt 999 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 100, 'ignore_eos': True}, 'stream': True}
[2025-07-25 00:05:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:46] INFO:     127.0.0.1:45676 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_999
[2025-07-25 00:05:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_999
[2025-07-25 00:05:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:46] Prefill batch. #new-seq: 1, #new-token: 239, #cached-token: 6, token usage: 0.05, #running-req: 19, #queue-req: 0,
[2025-07-25 00:05:46] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:46] Decode batch. #running-req: 20, #token: 6509, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1057.86, #queue-req: 0,
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_982 received DONE after 124 chunks
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_982 completed: 492 chars, 124 chunks, TTFT=68.6ms
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_983 received DONE after 127 chunks
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_983 completed: 504 chars, 127 chunks, TTFT=62.2ms
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_991 received DONE after 85 chunks
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_991 completed: 292 chars, 85 chunks, TTFT=53.6ms
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_987 received DONE after 129 chunks
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_987 completed: 512 chars, 129 chunks, TTFT=49.2ms
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_988 received DONE after 121 chunks
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_988 completed: 468 chars, 121 chunks, TTFT=46.0ms
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_979 received DONE after 173 chunks
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_979 completed: 469 chars, 173 chunks, TTFT=124.3ms
[2025-07-25 00:05:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:47] Decode batch. #running-req: 14, #token: 4799, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1439.10, #queue-req: 0,
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_975 received DONE after 185 chunks
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_975 completed: 736 chars, 185 chunks, TTFT=45.0ms
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_978 received DONE after 177 chunks
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_978 completed: 691 chars, 177 chunks, TTFT=125.1ms
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_993 received DONE after 82 chunks
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_993 completed: 312 chars, 82 chunks, TTFT=83.5ms
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_997 received DONE after 74 chunks
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_997 completed: 279 chars, 74 chunks, TTFT=48.0ms
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_981 received DONE after 168 chunks
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_981 completed: 668 chars, 168 chunks, TTFT=56.8ms
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_998 received DONE after 72 chunks
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_998 completed: 284 chars, 72 chunks, TTFT=56.9ms
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_986 received DONE after 158 chunks
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_986 completed: 628 chars, 158 chunks, TTFT=56.8ms
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_989 received DONE after 158 chunks
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_989 completed: 159 chars, 158 chunks, TTFT=63.5ms
[2025-07-25 00:05:47] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:47] Decode batch. #running-req: 6, #token: 2224, token usage: 0.02, cuda graph: True, gen throughput (token/s): 731.55, #queue-req: 0,
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_990 received DONE after 163 chunks
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_990 completed: 164 chars, 163 chunks, TTFT=62.7ms
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_999 received DONE after 101 chunks
[2025-07-25 00:05:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_999 completed: 400 chars, 101 chunks, TTFT=61.0ms
[2025-07-25 00:05:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_992 received DONE after 143 chunks
[2025-07-25 00:05:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_992 completed: 555 chars, 143 chunks, TTFT=51.2ms
[2025-07-25 00:05:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_995 received DONE after 149 chunks
[2025-07-25 00:05:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_995 completed: 580 chars, 149 chunks, TTFT=47.0ms
[2025-07-25 00:05:48] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:48] Decode batch. #running-req: 2, #token: 892, token usage: 0.01, cuda graph: True, gen throughput (token/s): 321.97, #queue-req: 0,
[2025-07-25 00:05:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_994 received DONE after 161 chunks
[2025-07-25 00:05:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_994 completed: 496 chars, 161 chunks, TTFT=73.0ms
[2025-07-25 00:05:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_996 received DONE after 187 chunks
[2025-07-25 00:05:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_996 completed: 188 chars, 187 chunks, TTFT=57.6ms
[2025-07-25 00:05:48] [__main__] [INFO] Completed 1000 requests, 1000 successful
[2025-07-25 00:05:48] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 50 results saved
[2025-07-25 00:05:48] [sglang_test_framework.core.metrics_collector] [INFO] Completed 100 requests, success rate: 100.0%
[2025-07-25 00:05:48] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 100 results saved
[2025-07-25 00:05:48] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 150 results saved
[2025-07-25 00:05:48] [sglang_test_framework.core.metrics_collector] [INFO] Completed 200 requests, success rate: 100.0%
[2025-07-25 00:05:48] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 200 results saved
[2025-07-25 00:05:48] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 250 results saved
[2025-07-25 00:05:48] [sglang_test_framework.core.metrics_collector] [INFO] Completed 300 requests, success rate: 100.0%
[2025-07-25 00:05:48] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 300 results saved
[2025-07-25 00:05:48] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 350 results saved
[2025-07-25 00:05:48] [sglang_test_framework.core.metrics_collector] [INFO] Completed 400 requests, success rate: 100.0%
[2025-07-25 00:05:48] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 400 results saved
[2025-07-25 00:05:48] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 450 results saved
[2025-07-25 00:05:48] [sglang_test_framework.core.metrics_collector] [INFO] Completed 500 requests, success rate: 100.0%
[2025-07-25 00:05:48] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 500 results saved
[2025-07-25 00:05:48] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 550 results saved
[2025-07-25 00:05:48] [sglang_test_framework.core.metrics_collector] [INFO] Completed 600 requests, success rate: 100.0%
[2025-07-25 00:05:48] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 600 results saved
[2025-07-25 00:05:49] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 650 results saved
[2025-07-25 00:05:49] [sglang_test_framework.core.metrics_collector] [INFO] Completed 700 requests, success rate: 100.0%
[2025-07-25 00:05:49] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 700 results saved
[2025-07-25 00:05:49] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 750 results saved
[2025-07-25 00:05:49] [sglang_test_framework.core.metrics_collector] [INFO] Completed 800 requests, success rate: 100.0%
[2025-07-25 00:05:49] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 800 results saved
[2025-07-25 00:05:49] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 850 results saved
[2025-07-25 00:05:49] [sglang_test_framework.core.metrics_collector] [INFO] Completed 900 requests, success rate: 100.0%
[2025-07-25 00:05:49] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 900 results saved
[2025-07-25 00:05:49] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 950 results saved
[2025-07-25 00:05:49] [sglang_test_framework.core.metrics_collector] [INFO] Completed 1000 requests, success rate: 100.0%
[2025-07-25 00:05:49] [sglang_test_framework.core.metrics_collector] [INFO] Incremental save completed: 1000 results saved
[2025-07-25 00:05:49] [sglang_test_framework.core.request_generator] [DEBUG] RequestSender session closed
[2025-07-25 00:05:49] [sglang_test_framework.core.metrics_collector] [INFO] Stopped metrics collection
[2025-07-25 00:05:49] [__main__] [INFO] Saving test results...
[2025-07-25 00:05:49] [sglang_test_framework.core.metrics_collector] [INFO] Exported metrics to /home/lg/sglang/results/new_test/test_1/metrics.json
[2025-07-25 00:05:49] [sglang_test_framework.core.metrics_collector] [INFO] Exported metrics to /home/lg/sglang/results/new_test/test_1/results.csv
[2025-07-25 00:05:49] [sglang_test_framework.core.result_manager] [INFO] Exported per-request metrics to /home/lg/sglang/results/new_test/test_1/results.csv
[2025-07-25 00:05:49] [sglang_test_framework.core.metrics_collector] [INFO] Generating metrics summary...
[2025-07-25 00:05:49] [sglang_test_framework.core.result_manager] [INFO] Results saved to /home/lg/sglang/results/new_test/test_1
[2025-07-25 00:05:49] [__main__] [INFO] Results saved to: /home/lg/sglang/results/new_test/test_1
[2025-07-25 00:05:49] [matplotlib.pyplot] [DEBUG] Loaded backend agg version v2.2.
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 5.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 5.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/StandardSymbolsPS.otf', name='Standard Symbols PS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Regular.ttf', name='Rasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-Bold.ttf', name='Liberation Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Manjari-Bold.otf', name='Manjari', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-tamil/Lohit-Tamil.ttf', name='Lohit Tamil', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/Rekha.ttf', name='Rekha', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-kalapi/Kalapi.ttf', name='Kalapi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMonoOblique.ttf', name='FreeMono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee-Bold.ttf', name='Sawasdee', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma-BoldOblique.ttf', name='Loma', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerifItalic.ttf', name='FreeSerif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush.ttf', name='Umpush', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf', name='Liberation Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-Italic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-Demi.otf', name='URW Gothic', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/MitraMono.ttf', name='Mitra ', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-Italic.otf', name='C059', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak-fonts/Samyak-Tamil.ttf', name='Samyak Tamil', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee-Oblique.ttf', name='Sawasdee', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Chilanka-Regular.otf', name='Chilanka', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Gubbi/Gubbi.ttf', name='Gubbi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-BoldItalic.otf', name='Nimbus Mono PS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc', name='Noto Sans CJK JP', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter-BoldOblique.ttf', name='Tlwg Typewriter', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst-one/KacstOne.ttf', name='KacstOne', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-gujarati/Lohit-Gujarati.ttf', name='Lohit Gujarati', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma-Bold.ttf', name='Loma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee-BoldOblique.ttf', name='Sawasdee', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/PadaukBook-Bold.ttf', name='Padauk Book', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-BI.ttf', name='Ubuntu Mono', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/NATS.ttf', name='NATS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Gargi/Gargi.ttf', name='Gargi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-LightItalic.ttf', name='Yrsa', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma.ttf', name='Loma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-BoldItalic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/abyssinica/AbyssinicaSIL-Regular.ttf', name='Abyssinica SIL', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-Demi.otf', name='URW Bookman', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tibetan-machine/TibetanMachineUni.ttf', name='Tibetan Machine Uni', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-Italic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf', name='Liberation Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 2.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSansOblique.ttf', name='FreeSans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/D050000L.otf', name='D050000L', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Italic.ttf', name='Liberation Sans Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerifBold.ttf', name='FreeSerif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-Italic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist.ttf', name='Tlwg Typist', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-deva-extra/chandas1-2.ttf', name='Chandas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-Light.ttf', name='Umpush', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Keraleeyam-Regular.ttf', name='Keraleeyam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMonoBoldOblique.ttf', name='FreeMono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoMono-Regular.ttf', name='Noto Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-Italic.otf', name='P052', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-M.ttf', name='Ubuntu', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-Regular.otf', name='Nimbus Sans Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/suranna.ttf', name='Suranna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSansBoldOblique.ttf', name='FreeSans', style='oblique', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-deva-extra/kalimati.ttf', name='Kalimati', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda-Bold.ttf', name='Garuda', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf', name='Liberation Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-telu-extra/vemana2000.ttf', name='Vemana2000', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-Regular.ttf', name='Liberation Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 2.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerif.ttf', name='FreeSerif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMonoBold.ttf', name='FreeMono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', name='Liberation Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 2.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-telugu/Lohit-Telugu.ttf', name='Lohit Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo-Bold.ttf', name='Tlwg Typo', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-Bold.ttf', name='Umpush', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Meera-Regular.ttf', name='Meera', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-SemiBold.ttf', name='Rasa', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree.ttf', name='Waree', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Sahadeva/sahadeva.ttf', name='Sahadeva', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/pagul/Pagul.ttf', name='Pagul', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Ramaraja-Regular.ttf', name='Ramaraja', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-BoldItalic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Suruma.ttf', name='Suruma', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree-Oblique.ttf', name='Waree', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/Ani.ttf', name='Ani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/Mukti.ttf', name='Mukti', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstTitleL.ttf', name='KacstTitleL', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-Oblique.ttf', name='Kinnari', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/Padauk-Bold.ttf', name='Padauk', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Dyuthi-Regular.ttf', name='Dyuthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-Oblique.otf', name='Nimbus Sans Narrow', style='oblique', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/PottiSreeramulu.ttf', name='Potti Sreeramulu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMono-Regular.ttf', name='Noto Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa-Oblique.ttf', name='Purisa', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi.ttf', name='Norasi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstTitle.ttf', name='KacstTitle', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/RaghuMalayalamSans-Regular.ttf', name='RaghuMalayalamSans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/NTR.ttf', name='NTR', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Medium.ttf', name='Yrsa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-Regular.ttf', name='Liberation Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-Italic.otf', name='Nimbus Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-telu-extra/Pothana2000.ttf', name='Pothana2000', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa.ttf', name='Purisa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-orya-extra/utkal.ttf', name='ori1Uni', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-Regular.otf', name='Nimbus Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo-Oblique.ttf', name='Tlwg Typo', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-Roman.otf', name='P052', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Bold.ttf', name='Liberation Sans Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-LightItalic.otf', name='URW Bookman', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstLetter.ttf', name='KacstLetter', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst-one/KacstOne-Bold.ttf', name='KacstOne', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Manjari-Thin.otf', name='Manjari', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter-Oblique.ttf', name='Tlwg Typewriter', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/padmaa.ttf', name='padmaa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Gayathri-Bold.otf', name='Gayathri', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstBook.ttf', name='KacstBook', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/padmaa-Medium-0.5.ttf', name='padmaa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda-Oblique.ttf', name='Garuda', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/TenaliRamakrishna-Regular.ttf', name='TenaliRamakrishna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-BoldItalic.otf', name='Nimbus Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda-BoldOblique.ttf', name='Garuda', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/Padauk-Regular.ttf', name='Padauk', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa-Bold.ttf', name='Purisa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-RI.ttf', name='Ubuntu Mono', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-Bold.ttf', name='Liberation Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman-Bold.ttf', name='Laksaman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda.ttf', name='Garuda', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-L.ttf', name='Ubuntu', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf', name='Liberation Sans Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-Oblique.ttf', name='Umpush', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-guru-extra/Saab.ttf', name='Saab', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstScreen.ttf', name='KacstScreen', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak-fonts/Samyak-Malayalam.ttf', name='Samyak Malayalam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman.ttf', name='Laksaman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-BoldItalic.ttf', name='Yrsa', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/LakkiReddy.ttf', name='LakkiReddy', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree-BoldOblique.ttf', name='Waree', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/Z003-MediumItalic.otf', name='Z003', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa-BoldOblique.ttf', name='Purisa', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/SreeKrushnadevaraya.ttf', name='Sree Krushnadevaraya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstOffice.ttf', name='KacstOffice', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-Light.otf', name='URW Bookman', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-Regular.otf', name='Nimbus Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-SemiBoldItalic.ttf', name='Yrsa', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/JamrulNormal.ttf', name='Jamrul', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-MediumItalic.ttf', name='Yrsa', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstNaskh.ttf', name='KacstNaskh', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf', name='Droid Sans Fallback', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/dhurjati.ttf', name='Dhurjati', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Navilu/Navilu.ttf', name='Navilu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/LikhanNormal.ttf', name='Likhan', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-MI.ttf', name='Ubuntu', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-SemiBold.ttf', name='Yrsa', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/ramabhadra.ttf', name='Ramabhadra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstPen.ttf', name='KacstPen', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/mry_KacstQurn.ttf', name='mry_KacstQurn', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-tamil-classical/Lohit-Tamil-Classical.ttf', name='Lohit Tamil Classical', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Uroob-Regular.ttf', name='Uroob', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-oriya/Lohit-Odia.ttf', name='Lohit Odia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Light.ttf', name='Rasa', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/padmaa-Bold.1.1.ttf', name='padmaa-Bold.1.1', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Manjari-Regular.otf', name='Manjari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter-Bold.ttf', name='Tlwg Typewriter', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-Bold.ttf', name='Liberation Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 2.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMono-Bold.ttf', name='Noto Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/mallanna.ttf', name='Mallanna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-Oblique.ttf', name='Norasi', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-R.ttf', name='Ubuntu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist-Bold.ttf', name='Tlwg Typist', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-BoldItalic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-C.ttf', name='Ubuntu Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono-BoldOblique.ttf', name='Tlwg Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo-BoldOblique.ttf', name='Tlwg Typo', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-assamese/Lohit-Assamese.ttf', name='Lohit Assamese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman-BoldItalic.ttf', name='Laksaman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-bengali/Lohit-Bengali.ttf', name='Lohit Bengali', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc', name='Noto Sans CJK JP', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Gurajada.ttf', name='Gurajada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-BoldOblique.ttf', name='Kinnari', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Peddana-Regular.ttf', name='Peddana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/sinhala/lklug.ttf', name='LKLUG', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMono.ttf', name='FreeMono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Sarai/Sarai.ttf', name='Sarai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Gayathri-Regular.otf', name='Gayathri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstFarsi.ttf', name='KacstFarsi', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-BoldItalic.otf', name='P052', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/PadaukBook-Regular.ttf', name='Padauk Book', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-DemiItalic.otf', name='URW Bookman', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist-BoldOblique.ttf', name='Tlwg Typist', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Nakula/nakula.ttf', name='Nakula', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-BdIta.otf', name='C059', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-R.ttf', name='Ubuntu Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-BoldItalic.ttf', name='Liberation Sans Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-BoldOblique.ttf', name='Umpush', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo.ttf', name='Tlwg Typo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Gidugu.ttf', name='Gidugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-Italic.ttf', name='Kinnari', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Suravaram.ttf', name='Suravaram', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSansBold.ttf', name='FreeSans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Regular.ttf', name='Yrsa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Gayathri-Thin.otf', name='Gayathri', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-BoldItalic.otf', name='Nimbus Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari.ttf', name='Kinnari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Bold.ttf', name='Rasa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-Bold.otf', name='Nimbus Sans Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/libreoffice/opens___.ttf', name='OpenSymbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-RI.ttf', name='Ubuntu', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Ponnala.ttf', name='Ponnala', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSerifCJK-Bold.ttc', name='Noto Serif CJK JP', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Rachana-Bold.ttf', name='Rachana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstDecorative.ttf', name='KacstDecorative', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Bold.ttf', name='Yrsa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-Bold.otf', name='Nimbus Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-devanagari/Lohit-Devanagari.ttf', name='Lohit Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma-Oblique.ttf', name='Loma', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/TimmanaRegular.ttf', name='Timmana', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist-Oblique.ttf', name='Tlwg Typist', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-Roman.otf', name='C059', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee.ttf', name='Sawasdee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman-Italic.ttf', name='Laksaman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSerifCJK-Regular.ttc', name='Noto Serif CJK JP', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-Book.otf', name='URW Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-B.ttf', name='Ubuntu Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-Bold.ttf', name='Norasi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/SyamalaRamana.ttf', name='Syamala Ramana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-BoldItalic.ttf', name='Norasi', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSans.ttf', name='FreeSans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono-Oblique.ttf', name='Tlwg Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-BookOblique.otf', name='URW Gothic', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Medium.ttf', name='Rasa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-Italic.otf', name='Nimbus Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstArt.ttf', name='KacstArt', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-Regular.ttf', name='Liberation Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-Italic.otf', name='Nimbus Mono PS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-Regular.otf', name='Nimbus Mono PS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-punjabi/Lohit-Gurmukhi.ttf', name='Lohit Gurmukhi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstQurn.ttf', name='KacstQurn', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-kannada/Lohit-Kannada.ttf', name='Lohit Kannada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-Th.ttf', name='Ubuntu', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-B.ttf', name='Ubuntu', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstPoster.ttf', name='KacstPoster', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak-fonts/Samyak-Gujarati.ttf', name='Samyak Gujarati', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-Bold.ttf', name='Liberation Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-Bold.otf', name='Nimbus Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/Muktibold.ttf', name='Mukti', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono-Bold.ttf', name='Tlwg Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/AnjaliOldLipi-Regular.ttf', name='AnjaliOldLipi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-khmeros-core/KhmerOSsys.ttf', name='Khmer OS System', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-BoldOblique.ttf', name='Norasi', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-BoldItalic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-Italic.ttf', name='Norasi', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono.ttf', name='Tlwg Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-LI.ttf', name='Ubuntu', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree-Bold.ttf', name='Waree', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstDigital.ttf', name='KacstDigital', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-deva-extra/samanata.ttf', name='Samanata', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-BoldOblique.otf', name='Nimbus Sans Narrow', style='oblique', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Karumbi-Regular.ttf', name='Karumbi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-LightOblique.ttf', name='Umpush', style='oblique', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-Bold.otf', name='P052', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-Italic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-malayalam/Lohit-Malayalam.ttf', name='Lohit Malayalam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/aakar-medium.ttf', name='aakar', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerifBoldItalic.ttf', name='FreeSerif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-Bold.otf', name='Nimbus Mono PS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-BoldItalic.ttf', name='Kinnari', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Mandali-Regular.ttf', name='Mandali', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-Italic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/RaviPrakash.ttf', name='RaviPrakash', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-khmeros-core/KhmerOS.ttf', name='Khmer OS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak/Samyak-Devanagari.ttf', name='Samyak Devanagari', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-DemiOblique.otf', name='URW Gothic', style='oblique', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Italic.ttf', name='Yrsa', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-Bold.otf', name='C059', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Rachana-Regular.ttf', name='Rachana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-BoldItalic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-BoldItalic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-Italic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-Bold.ttf', name='Kinnari', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Light.ttf', name='Yrsa', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter.ttf', name='Tlwg Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lao/Phetsarath_OT.ttf', name='Phetsarath OT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-BI.ttf', name='Ubuntu', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-Regular.ttf', name='Liberation Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to Liberation Sans ('/usr/share/fonts/truetype/liberation2/LiberationSans-Regular.ttf') with score of 2.050000.
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 5.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 5.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/StandardSymbolsPS.otf', name='Standard Symbols PS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Regular.ttf', name='Rasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-Bold.ttf', name='Liberation Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Manjari-Bold.otf', name='Manjari', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-tamil/Lohit-Tamil.ttf', name='Lohit Tamil', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/Rekha.ttf', name='Rekha', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-kalapi/Kalapi.ttf', name='Kalapi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMonoOblique.ttf', name='FreeMono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee-Bold.ttf', name='Sawasdee', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma-BoldOblique.ttf', name='Loma', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerifItalic.ttf', name='FreeSerif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush.ttf', name='Umpush', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf', name='Liberation Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-Italic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-Demi.otf', name='URW Gothic', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/MitraMono.ttf', name='Mitra ', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-Italic.otf', name='C059', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak-fonts/Samyak-Tamil.ttf', name='Samyak Tamil', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee-Oblique.ttf', name='Sawasdee', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Chilanka-Regular.otf', name='Chilanka', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Gubbi/Gubbi.ttf', name='Gubbi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-BoldItalic.otf', name='Nimbus Mono PS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc', name='Noto Sans CJK JP', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter-BoldOblique.ttf', name='Tlwg Typewriter', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst-one/KacstOne.ttf', name='KacstOne', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-gujarati/Lohit-Gujarati.ttf', name='Lohit Gujarati', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma-Bold.ttf', name='Loma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee-BoldOblique.ttf', name='Sawasdee', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/PadaukBook-Bold.ttf', name='Padauk Book', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-BI.ttf', name='Ubuntu Mono', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/NATS.ttf', name='NATS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Gargi/Gargi.ttf', name='Gargi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-LightItalic.ttf', name='Yrsa', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma.ttf', name='Loma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-BoldItalic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/abyssinica/AbyssinicaSIL-Regular.ttf', name='Abyssinica SIL', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-Demi.otf', name='URW Bookman', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tibetan-machine/TibetanMachineUni.ttf', name='Tibetan Machine Uni', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-Italic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf', name='Liberation Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 2.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSansOblique.ttf', name='FreeSans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/D050000L.otf', name='D050000L', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Italic.ttf', name='Liberation Sans Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerifBold.ttf', name='FreeSerif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-Italic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist.ttf', name='Tlwg Typist', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-deva-extra/chandas1-2.ttf', name='Chandas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-Light.ttf', name='Umpush', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Keraleeyam-Regular.ttf', name='Keraleeyam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMonoBoldOblique.ttf', name='FreeMono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoMono-Regular.ttf', name='Noto Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-Italic.otf', name='P052', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-M.ttf', name='Ubuntu', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-Regular.otf', name='Nimbus Sans Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/suranna.ttf', name='Suranna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSansBoldOblique.ttf', name='FreeSans', style='oblique', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-deva-extra/kalimati.ttf', name='Kalimati', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda-Bold.ttf', name='Garuda', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf', name='Liberation Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-telu-extra/vemana2000.ttf', name='Vemana2000', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-Regular.ttf', name='Liberation Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 2.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerif.ttf', name='FreeSerif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMonoBold.ttf', name='FreeMono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', name='Liberation Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 2.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-telugu/Lohit-Telugu.ttf', name='Lohit Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo-Bold.ttf', name='Tlwg Typo', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-Bold.ttf', name='Umpush', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Meera-Regular.ttf', name='Meera', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-SemiBold.ttf', name='Rasa', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree.ttf', name='Waree', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Sahadeva/sahadeva.ttf', name='Sahadeva', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/pagul/Pagul.ttf', name='Pagul', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Ramaraja-Regular.ttf', name='Ramaraja', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-BoldItalic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Suruma.ttf', name='Suruma', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree-Oblique.ttf', name='Waree', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/Ani.ttf', name='Ani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/Mukti.ttf', name='Mukti', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstTitleL.ttf', name='KacstTitleL', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-Oblique.ttf', name='Kinnari', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/Padauk-Bold.ttf', name='Padauk', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Dyuthi-Regular.ttf', name='Dyuthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-Oblique.otf', name='Nimbus Sans Narrow', style='oblique', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/PottiSreeramulu.ttf', name='Potti Sreeramulu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMono-Regular.ttf', name='Noto Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa-Oblique.ttf', name='Purisa', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi.ttf', name='Norasi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstTitle.ttf', name='KacstTitle', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/RaghuMalayalamSans-Regular.ttf', name='RaghuMalayalamSans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/NTR.ttf', name='NTR', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Medium.ttf', name='Yrsa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-Regular.ttf', name='Liberation Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-Italic.otf', name='Nimbus Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-telu-extra/Pothana2000.ttf', name='Pothana2000', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa.ttf', name='Purisa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-orya-extra/utkal.ttf', name='ori1Uni', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-Regular.otf', name='Nimbus Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo-Oblique.ttf', name='Tlwg Typo', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-Roman.otf', name='P052', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Bold.ttf', name='Liberation Sans Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-LightItalic.otf', name='URW Bookman', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstLetter.ttf', name='KacstLetter', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst-one/KacstOne-Bold.ttf', name='KacstOne', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Manjari-Thin.otf', name='Manjari', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter-Oblique.ttf', name='Tlwg Typewriter', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/padmaa.ttf', name='padmaa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Gayathri-Bold.otf', name='Gayathri', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstBook.ttf', name='KacstBook', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/padmaa-Medium-0.5.ttf', name='padmaa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda-Oblique.ttf', name='Garuda', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/TenaliRamakrishna-Regular.ttf', name='TenaliRamakrishna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-BoldItalic.otf', name='Nimbus Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda-BoldOblique.ttf', name='Garuda', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/Padauk-Regular.ttf', name='Padauk', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa-Bold.ttf', name='Purisa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-RI.ttf', name='Ubuntu Mono', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-Bold.ttf', name='Liberation Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman-Bold.ttf', name='Laksaman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda.ttf', name='Garuda', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-L.ttf', name='Ubuntu', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf', name='Liberation Sans Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-Oblique.ttf', name='Umpush', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-guru-extra/Saab.ttf', name='Saab', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstScreen.ttf', name='KacstScreen', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak-fonts/Samyak-Malayalam.ttf', name='Samyak Malayalam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman.ttf', name='Laksaman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-BoldItalic.ttf', name='Yrsa', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/LakkiReddy.ttf', name='LakkiReddy', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree-BoldOblique.ttf', name='Waree', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/Z003-MediumItalic.otf', name='Z003', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa-BoldOblique.ttf', name='Purisa', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/SreeKrushnadevaraya.ttf', name='Sree Krushnadevaraya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstOffice.ttf', name='KacstOffice', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-Light.otf', name='URW Bookman', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-Regular.otf', name='Nimbus Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-SemiBoldItalic.ttf', name='Yrsa', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/JamrulNormal.ttf', name='Jamrul', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-MediumItalic.ttf', name='Yrsa', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstNaskh.ttf', name='KacstNaskh', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf', name='Droid Sans Fallback', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/dhurjati.ttf', name='Dhurjati', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Navilu/Navilu.ttf', name='Navilu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/LikhanNormal.ttf', name='Likhan', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-MI.ttf', name='Ubuntu', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-SemiBold.ttf', name='Yrsa', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/ramabhadra.ttf', name='Ramabhadra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstPen.ttf', name='KacstPen', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/mry_KacstQurn.ttf', name='mry_KacstQurn', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-tamil-classical/Lohit-Tamil-Classical.ttf', name='Lohit Tamil Classical', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Uroob-Regular.ttf', name='Uroob', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-oriya/Lohit-Odia.ttf', name='Lohit Odia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Light.ttf', name='Rasa', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/padmaa-Bold.1.1.ttf', name='padmaa-Bold.1.1', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Manjari-Regular.otf', name='Manjari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter-Bold.ttf', name='Tlwg Typewriter', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-Bold.ttf', name='Liberation Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 2.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMono-Bold.ttf', name='Noto Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/mallanna.ttf', name='Mallanna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-Oblique.ttf', name='Norasi', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-R.ttf', name='Ubuntu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist-Bold.ttf', name='Tlwg Typist', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-BoldItalic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-C.ttf', name='Ubuntu Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono-BoldOblique.ttf', name='Tlwg Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo-BoldOblique.ttf', name='Tlwg Typo', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-assamese/Lohit-Assamese.ttf', name='Lohit Assamese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman-BoldItalic.ttf', name='Laksaman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-bengali/Lohit-Bengali.ttf', name='Lohit Bengali', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc', name='Noto Sans CJK JP', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Gurajada.ttf', name='Gurajada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-BoldOblique.ttf', name='Kinnari', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Peddana-Regular.ttf', name='Peddana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/sinhala/lklug.ttf', name='LKLUG', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMono.ttf', name='FreeMono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Sarai/Sarai.ttf', name='Sarai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Gayathri-Regular.otf', name='Gayathri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstFarsi.ttf', name='KacstFarsi', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-BoldItalic.otf', name='P052', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/PadaukBook-Regular.ttf', name='Padauk Book', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-DemiItalic.otf', name='URW Bookman', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist-BoldOblique.ttf', name='Tlwg Typist', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Nakula/nakula.ttf', name='Nakula', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-BdIta.otf', name='C059', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-R.ttf', name='Ubuntu Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-BoldItalic.ttf', name='Liberation Sans Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-BoldOblique.ttf', name='Umpush', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo.ttf', name='Tlwg Typo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Gidugu.ttf', name='Gidugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-Italic.ttf', name='Kinnari', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Suravaram.ttf', name='Suravaram', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSansBold.ttf', name='FreeSans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Regular.ttf', name='Yrsa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Gayathri-Thin.otf', name='Gayathri', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-BoldItalic.otf', name='Nimbus Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari.ttf', name='Kinnari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Bold.ttf', name='Rasa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-Bold.otf', name='Nimbus Sans Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/libreoffice/opens___.ttf', name='OpenSymbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-RI.ttf', name='Ubuntu', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Ponnala.ttf', name='Ponnala', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSerifCJK-Bold.ttc', name='Noto Serif CJK JP', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Rachana-Bold.ttf', name='Rachana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstDecorative.ttf', name='KacstDecorative', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Bold.ttf', name='Yrsa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-Bold.otf', name='Nimbus Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-devanagari/Lohit-Devanagari.ttf', name='Lohit Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma-Oblique.ttf', name='Loma', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/TimmanaRegular.ttf', name='Timmana', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist-Oblique.ttf', name='Tlwg Typist', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-Roman.otf', name='C059', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee.ttf', name='Sawasdee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman-Italic.ttf', name='Laksaman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSerifCJK-Regular.ttc', name='Noto Serif CJK JP', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-Book.otf', name='URW Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-B.ttf', name='Ubuntu Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-Bold.ttf', name='Norasi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/SyamalaRamana.ttf', name='Syamala Ramana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-BoldItalic.ttf', name='Norasi', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSans.ttf', name='FreeSans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono-Oblique.ttf', name='Tlwg Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-BookOblique.otf', name='URW Gothic', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Medium.ttf', name='Rasa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-Italic.otf', name='Nimbus Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstArt.ttf', name='KacstArt', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-Regular.ttf', name='Liberation Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-Italic.otf', name='Nimbus Mono PS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-Regular.otf', name='Nimbus Mono PS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-punjabi/Lohit-Gurmukhi.ttf', name='Lohit Gurmukhi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstQurn.ttf', name='KacstQurn', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-kannada/Lohit-Kannada.ttf', name='Lohit Kannada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-Th.ttf', name='Ubuntu', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-B.ttf', name='Ubuntu', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstPoster.ttf', name='KacstPoster', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak-fonts/Samyak-Gujarati.ttf', name='Samyak Gujarati', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-Bold.ttf', name='Liberation Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-Bold.otf', name='Nimbus Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/Muktibold.ttf', name='Mukti', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono-Bold.ttf', name='Tlwg Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/AnjaliOldLipi-Regular.ttf', name='AnjaliOldLipi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-khmeros-core/KhmerOSsys.ttf', name='Khmer OS System', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-BoldOblique.ttf', name='Norasi', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-BoldItalic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-Italic.ttf', name='Norasi', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono.ttf', name='Tlwg Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-LI.ttf', name='Ubuntu', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree-Bold.ttf', name='Waree', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstDigital.ttf', name='KacstDigital', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-deva-extra/samanata.ttf', name='Samanata', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-BoldOblique.otf', name='Nimbus Sans Narrow', style='oblique', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Karumbi-Regular.ttf', name='Karumbi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-LightOblique.ttf', name='Umpush', style='oblique', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-Bold.otf', name='P052', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-Italic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-malayalam/Lohit-Malayalam.ttf', name='Lohit Malayalam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/aakar-medium.ttf', name='aakar', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerifBoldItalic.ttf', name='FreeSerif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-Bold.otf', name='Nimbus Mono PS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-BoldItalic.ttf', name='Kinnari', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Mandali-Regular.ttf', name='Mandali', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-Italic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/RaviPrakash.ttf', name='RaviPrakash', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-khmeros-core/KhmerOS.ttf', name='Khmer OS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak/Samyak-Devanagari.ttf', name='Samyak Devanagari', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-DemiOblique.otf', name='URW Gothic', style='oblique', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Italic.ttf', name='Yrsa', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-Bold.otf', name='C059', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Rachana-Regular.ttf', name='Rachana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-BoldItalic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-BoldItalic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-Italic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-Bold.ttf', name='Kinnari', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Light.ttf', name='Yrsa', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter.ttf', name='Tlwg Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lao/Phetsarath_OT.ttf', name='Phetsarath OT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-BI.ttf', name='Ubuntu', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-Regular.ttf', name='Liberation Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:49] [matplotlib.font_manager] [DEBUG] findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to Liberation Sans ('/usr/share/fonts/truetype/liberation2/LiberationSans-Regular.ttf') with score of 2.050000.
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=16.0.
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 5.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 5.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/StandardSymbolsPS.otf', name='Standard Symbols PS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Regular.ttf', name='Rasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-Bold.ttf', name='Liberation Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Manjari-Bold.otf', name='Manjari', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-tamil/Lohit-Tamil.ttf', name='Lohit Tamil', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/Rekha.ttf', name='Rekha', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-kalapi/Kalapi.ttf', name='Kalapi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMonoOblique.ttf', name='FreeMono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee-Bold.ttf', name='Sawasdee', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma-BoldOblique.ttf', name='Loma', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerifItalic.ttf', name='FreeSerif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush.ttf', name='Umpush', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf', name='Liberation Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-Italic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-Demi.otf', name='URW Gothic', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/MitraMono.ttf', name='Mitra ', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-Italic.otf', name='C059', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak-fonts/Samyak-Tamil.ttf', name='Samyak Tamil', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee-Oblique.ttf', name='Sawasdee', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Chilanka-Regular.otf', name='Chilanka', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Gubbi/Gubbi.ttf', name='Gubbi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-BoldItalic.otf', name='Nimbus Mono PS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc', name='Noto Sans CJK JP', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter-BoldOblique.ttf', name='Tlwg Typewriter', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst-one/KacstOne.ttf', name='KacstOne', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-gujarati/Lohit-Gujarati.ttf', name='Lohit Gujarati', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma-Bold.ttf', name='Loma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee-BoldOblique.ttf', name='Sawasdee', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/PadaukBook-Bold.ttf', name='Padauk Book', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-BI.ttf', name='Ubuntu Mono', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/NATS.ttf', name='NATS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Gargi/Gargi.ttf', name='Gargi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-LightItalic.ttf', name='Yrsa', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma.ttf', name='Loma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-BoldItalic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/abyssinica/AbyssinicaSIL-Regular.ttf', name='Abyssinica SIL', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-Demi.otf', name='URW Bookman', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tibetan-machine/TibetanMachineUni.ttf', name='Tibetan Machine Uni', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-Italic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf', name='Liberation Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 2.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSansOblique.ttf', name='FreeSans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/D050000L.otf', name='D050000L', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Italic.ttf', name='Liberation Sans Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerifBold.ttf', name='FreeSerif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-Italic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist.ttf', name='Tlwg Typist', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-deva-extra/chandas1-2.ttf', name='Chandas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-Light.ttf', name='Umpush', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Keraleeyam-Regular.ttf', name='Keraleeyam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMonoBoldOblique.ttf', name='FreeMono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoMono-Regular.ttf', name='Noto Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-Italic.otf', name='P052', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-M.ttf', name='Ubuntu', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-Regular.otf', name='Nimbus Sans Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/suranna.ttf', name='Suranna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSansBoldOblique.ttf', name='FreeSans', style='oblique', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-deva-extra/kalimati.ttf', name='Kalimati', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda-Bold.ttf', name='Garuda', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf', name='Liberation Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-telu-extra/vemana2000.ttf', name='Vemana2000', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-Regular.ttf', name='Liberation Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 2.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerif.ttf', name='FreeSerif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMonoBold.ttf', name='FreeMono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', name='Liberation Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 2.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-telugu/Lohit-Telugu.ttf', name='Lohit Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo-Bold.ttf', name='Tlwg Typo', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-Bold.ttf', name='Umpush', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Meera-Regular.ttf', name='Meera', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-SemiBold.ttf', name='Rasa', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree.ttf', name='Waree', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Sahadeva/sahadeva.ttf', name='Sahadeva', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/pagul/Pagul.ttf', name='Pagul', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Ramaraja-Regular.ttf', name='Ramaraja', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-BoldItalic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Suruma.ttf', name='Suruma', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree-Oblique.ttf', name='Waree', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/Ani.ttf', name='Ani', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/Mukti.ttf', name='Mukti', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstTitleL.ttf', name='KacstTitleL', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-Oblique.ttf', name='Kinnari', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/Padauk-Bold.ttf', name='Padauk', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Dyuthi-Regular.ttf', name='Dyuthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-Oblique.otf', name='Nimbus Sans Narrow', style='oblique', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/PottiSreeramulu.ttf', name='Potti Sreeramulu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMono-Regular.ttf', name='Noto Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa-Oblique.ttf', name='Purisa', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi.ttf', name='Norasi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstTitle.ttf', name='KacstTitle', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/RaghuMalayalamSans-Regular.ttf', name='RaghuMalayalamSans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/NTR.ttf', name='NTR', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Medium.ttf', name='Yrsa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-Regular.ttf', name='Liberation Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-Italic.otf', name='Nimbus Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-telu-extra/Pothana2000.ttf', name='Pothana2000', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa.ttf', name='Purisa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-orya-extra/utkal.ttf', name='ori1Uni', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-Regular.otf', name='Nimbus Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo-Oblique.ttf', name='Tlwg Typo', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-Roman.otf', name='P052', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Bold.ttf', name='Liberation Sans Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-LightItalic.otf', name='URW Bookman', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstLetter.ttf', name='KacstLetter', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst-one/KacstOne-Bold.ttf', name='KacstOne', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Manjari-Thin.otf', name='Manjari', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter-Oblique.ttf', name='Tlwg Typewriter', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/padmaa.ttf', name='padmaa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Gayathri-Bold.otf', name='Gayathri', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstBook.ttf', name='KacstBook', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/padmaa-Medium-0.5.ttf', name='padmaa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda-Oblique.ttf', name='Garuda', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/TenaliRamakrishna-Regular.ttf', name='TenaliRamakrishna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-BoldItalic.otf', name='Nimbus Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda-BoldOblique.ttf', name='Garuda', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/Padauk-Regular.ttf', name='Padauk', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa-Bold.ttf', name='Purisa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-RI.ttf', name='Ubuntu Mono', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSerif-Bold.ttf', name='Liberation Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman-Bold.ttf', name='Laksaman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Garuda.ttf', name='Garuda', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-L.ttf', name='Ubuntu', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf', name='Liberation Sans Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-Oblique.ttf', name='Umpush', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-guru-extra/Saab.ttf', name='Saab', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstScreen.ttf', name='KacstScreen', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak-fonts/Samyak-Malayalam.ttf', name='Samyak Malayalam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman.ttf', name='Laksaman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-BoldItalic.ttf', name='Yrsa', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/LakkiReddy.ttf', name='LakkiReddy', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree-BoldOblique.ttf', name='Waree', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/Z003-MediumItalic.otf', name='Z003', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Purisa-BoldOblique.ttf', name='Purisa', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/SreeKrushnadevaraya.ttf', name='Sree Krushnadevaraya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstOffice.ttf', name='KacstOffice', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-Light.otf', name='URW Bookman', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-Regular.otf', name='Nimbus Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-SemiBoldItalic.ttf', name='Yrsa', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/JamrulNormal.ttf', name='Jamrul', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-MediumItalic.ttf', name='Yrsa', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstNaskh.ttf', name='KacstNaskh', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf', name='Droid Sans Fallback', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/dhurjati.ttf', name='Dhurjati', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Navilu/Navilu.ttf', name='Navilu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/LikhanNormal.ttf', name='Likhan', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-MI.ttf', name='Ubuntu', style='italic', variant='normal', weight=500, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-SemiBold.ttf', name='Yrsa', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/ramabhadra.ttf', name='Ramabhadra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstPen.ttf', name='KacstPen', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/mry_KacstQurn.ttf', name='mry_KacstQurn', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-tamil-classical/Lohit-Tamil-Classical.ttf', name='Lohit Tamil Classical', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Uroob-Regular.ttf', name='Uroob', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-oriya/Lohit-Odia.ttf', name='Lohit Odia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Light.ttf', name='Rasa', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/padmaa-Bold.1.1.ttf', name='padmaa-Bold.1.1', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Manjari-Regular.otf', name='Manjari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter-Bold.ttf', name='Tlwg Typewriter', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-Bold.ttf', name='Liberation Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 2.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/noto/NotoSansMono-Bold.ttf', name='Noto Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/mallanna.ttf', name='Mallanna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-Oblique.ttf', name='Norasi', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-R.ttf', name='Ubuntu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist-Bold.ttf', name='Tlwg Typist', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSans-BoldItalic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-C.ttf', name='Ubuntu Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono-BoldOblique.ttf', name='Tlwg Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo-BoldOblique.ttf', name='Tlwg Typo', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-assamese/Lohit-Assamese.ttf', name='Lohit Assamese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman-BoldItalic.ttf', name='Laksaman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-bengali/Lohit-Bengali.ttf', name='Lohit Bengali', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc', name='Noto Sans CJK JP', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Gurajada.ttf', name='Gurajada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-BoldOblique.ttf', name='Kinnari', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Peddana-Regular.ttf', name='Peddana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/sinhala/lklug.ttf', name='LKLUG', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeMono.ttf', name='FreeMono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Sarai/Sarai.ttf', name='Sarai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Gayathri-Regular.otf', name='Gayathri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstFarsi.ttf', name='KacstFarsi', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-BoldItalic.otf', name='P052', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/padauk/PadaukBook-Regular.ttf', name='Padauk Book', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWBookman-DemiItalic.otf', name='URW Bookman', style='italic', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist-BoldOblique.ttf', name='Tlwg Typist', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/Nakula/nakula.ttf', name='Nakula', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-BdIta.otf', name='C059', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-R.ttf', name='Ubuntu Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationSansNarrow-BoldItalic.ttf', name='Liberation Sans Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-BoldOblique.ttf', name='Umpush', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypo.ttf', name='Tlwg Typo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Gidugu.ttf', name='Gidugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-Italic.ttf', name='Kinnari', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Suravaram.ttf', name='Suravaram', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSansBold.ttf', name='FreeSans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Regular.ttf', name='Yrsa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/malayalam/Gayathri-Thin.otf', name='Gayathri', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-BoldItalic.otf', name='Nimbus Sans', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari.ttf', name='Kinnari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Bold.ttf', name='Rasa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-Bold.otf', name='Nimbus Sans Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/libreoffice/opens___.ttf', name='OpenSymbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-RI.ttf', name='Ubuntu', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Ponnala.ttf', name='Ponnala', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSerifCJK-Bold.ttc', name='Noto Serif CJK JP', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Rachana-Bold.ttf', name='Rachana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstDecorative.ttf', name='KacstDecorative', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Bold.ttf', name='Yrsa', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSans-Bold.otf', name='Nimbus Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-devanagari/Lohit-Devanagari.ttf', name='Lohit Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Loma-Oblique.ttf', name='Loma', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/TimmanaRegular.ttf', name='Timmana', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypist-Oblique.ttf', name='Tlwg Typist', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-Roman.otf', name='C059', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Sawasdee.ttf', name='Sawasdee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Laksaman-Italic.ttf', name='Laksaman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/noto/NotoSerifCJK-Regular.ttc', name='Noto Serif CJK JP', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-Book.otf', name='URW Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/UbuntuMono-B.ttf', name='Ubuntu Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-Bold.ttf', name='Norasi', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/SyamalaRamana.ttf', name='Syamala Ramana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-BoldItalic.ttf', name='Norasi', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSans.ttf', name='FreeSans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono-Oblique.ttf', name='Tlwg Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-BookOblique.otf', name='URW Gothic', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Rasa-Medium.ttf', name='Rasa', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-Italic.otf', name='Nimbus Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstArt.ttf', name='KacstArt', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-Regular.ttf', name='Liberation Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-Italic.otf', name='Nimbus Mono PS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-Regular.otf', name='Nimbus Mono PS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-punjabi/Lohit-Gurmukhi.ttf', name='Lohit Gurmukhi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstQurn.ttf', name='KacstQurn', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-kannada/Lohit-Kannada.ttf', name='Lohit Kannada', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-Th.ttf', name='Ubuntu', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-B.ttf', name='Ubuntu', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstPoster.ttf', name='KacstPoster', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak-fonts/Samyak-Gujarati.ttf', name='Samyak Gujarati', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-Bold.ttf', name='Liberation Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusRoman-Bold.otf', name='Nimbus Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-beng-extra/Muktibold.ttf', name='Mukti', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono-Bold.ttf', name='Tlwg Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/AnjaliOldLipi-Regular.ttf', name='AnjaliOldLipi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-khmeros-core/KhmerOSsys.ttf', name='Khmer OS System', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-BoldOblique.ttf', name='Norasi', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationMono-BoldItalic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Norasi-Italic.ttf', name='Norasi', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgMono.ttf', name='Tlwg Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-LI.ttf', name='Ubuntu', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Waree-Bold.ttf', name='Waree', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/kacst/KacstDigital.ttf', name='KacstDigital', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-deva-extra/samanata.ttf', name='Samanata', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusSansNarrow-BoldOblique.otf', name='Nimbus Sans Narrow', style='oblique', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Karumbi-Regular.ttf', name='Karumbi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Umpush-LightOblique.ttf', name='Umpush', style='oblique', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/P052-Bold.otf', name='P052', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-Italic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lohit-malayalam/Lohit-Malayalam.ttf', name='Lohit Malayalam', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-gujr-extra/aakar-medium.ttf', name='aakar', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/freefont/FreeSerifBoldItalic.ttf', name='FreeSerif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/NimbusMonoPS-Bold.otf', name='Nimbus Mono PS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-BoldItalic.ttf', name='Kinnari', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/Mandali-Regular.ttf', name='Mandali', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-Italic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/teluguvijayam/RaviPrakash.ttf', name='RaviPrakash', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ttf-khmeros-core/KhmerOS.ttf', name='Khmer OS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/samyak/Samyak-Devanagari.ttf', name='Samyak Devanagari', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/URWGothic-DemiOblique.otf', name='URW Gothic', style='oblique', variant='normal', weight=600, stretch='normal', size='scalable')) = 11.24
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Italic.ttf', name='Yrsa', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/opentype/urw-base35/C059-Bold.otf', name='C059', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/malayalam/Rachana-Regular.ttf', name='Rachana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-BoldItalic.ttf', name='Liberation Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation/LiberationMono-BoldItalic.ttf', name='Liberation Mono', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSans-Italic.ttf', name='Liberation Sans', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/Kinnari-Bold.ttf', name='Kinnari', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/fonts-yrsa-rasa/Yrsa-Light.ttf', name='Yrsa', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/tlwg/TlwgTypewriter.ttf', name='Tlwg Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/lao/Phetsarath_OT.ttf', name='Phetsarath OT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/ubuntu/Ubuntu-BI.ttf', name='Ubuntu', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: score(FontEntry(fname='/usr/share/fonts/truetype/liberation2/LiberationSerif-Regular.ttf', name='Liberation Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
[2025-07-25 00:05:50] [matplotlib.font_manager] [DEBUG] findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=16.0 to Liberation Sans ('/usr/share/fonts/truetype/liberation2/LiberationSans-Regular.ttf') with score of 2.050000.
[2025-07-25 00:05:51] [matplotlib.colorbar] [DEBUG] locator: <matplotlib.ticker.AutoLocator object at 0x7f3abd5d4fd0>
[2025-07-25 00:05:52] [sglang_test_framework.core.result_manager] [INFO] Created 6 visualization plots in /home/lg/sglang/results/new_test/test_1
[2025-07-25 00:05:52] [sglang_test_framework.core.metrics_collector] [INFO] Generating metrics summary...

============================================================
                    METRICS SUMMARY
============================================================

=� Request Statistics:
  Total Requests: 1000
  Successful: 1000
  Failed: 0
  Success Rate: 100.0%

� Throughput Metrics:
  Request Throughput: 9.49 req/s
  Input Token Throughput: 9626 tok/s
  Output Token Throughput: 1223 tok/s
  Total Token Throughput: 10850 tok/s

�  Latency Metrics:
  Server Latency (ms):
    Mean: 0.0
    Median: 0.0
    P95: 0.0
    P99: 0.0
    Max: 0.0

  Total Latency (ms):
    Mean: 0.0
    Median: 0.0
    P95: 0.0
    P99: 0.0
    Max: 0.0

  Queue Time (ms):
    Mean: 42076.7
    Median: 42331.2
    P95: 80370.0
    P99: 83724.4

  Token Generation:
    Mean TTFT: 65.9 ms
    Mean ITL: 16.0 ms

=� Queue Metrics:
  Mean Queue Depth: 500.0
  Max Queue Depth: 1000
============================================================

[2025-07-25 00:05:52] [__main__] [INFO] Cleaning up...
[2025-07-25 00:05:52] [sglang_test_framework.core.server_manager] [INFO] Stopping server node_1
[2025-07-25 00:05:52] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:52] SIGTERM received. signum=None frame=None. Draining requests and shutting down...
[2025-07-25 00:05:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:56] Gracefully exiting... remaining number of requests 0
[2025-07-25 00:05:56] [sglang_test_framework.core.server_manager] [INFO] [node_1] [2025-07-25 00:05:56] Dumping requests before crash. self.crash_dump_folder=None
[2025-07-25 00:05:56] [__main__] [INFO] Test completed successfully!
