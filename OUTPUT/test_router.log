[2025-07-25 02:51:57] [sglang_test_framework] [INFO] SGLang Testing Framework v1.0.0 initialized with log level: DEBUG
[2025-07-25 02:52:00] [__main__] [INFO] ============================================================
[2025-07-25 02:52:00] [__main__] [INFO] SGLang Testing Framework - Routing Test
[2025-07-25 02:52:00] [__main__] [INFO] ============================================================
[2025-07-25 02:52:00] [asyncio] [DEBUG] Using selector: EpollSelector
[2025-07-25 02:52:00] [sglang_test_framework.tests.routing_test] [INFO] sglang-router is installed and available
[2025-07-25 02:52:00] [sglang_test_framework.tests.routing_test] [INFO] Launching 2 SGLang servers
[2025-07-25 02:52:00] [sglang_test_framework.core.server_manager] [INFO] Starting server worker_0 with command: python -m sglang.launch_server --model-path /data/pretrained_models/Llama-2-7b-hf --port 30001 --host 0.0.0.0 --mem-fraction-static 0.9 --max-running-requests 256 --chunked-prefill-size 8192 --max-prefill-tokens 16384 --schedule-conservativeness 1.0 --tp-size 1 --tokenizer-mode auto --dtype auto --load-format auto --log-level info --enable-metrics
[2025-07-25 02:52:00] [sglang_test_framework.core.server_manager] [INFO] Server logs will be displayed for worker_0
[2025-07-25 02:52:00] [sglang_test_framework.core.server_manager] [INFO] Starting server worker_1 with command: python -m sglang.launch_server --model-path /data/pretrained_models/Llama-2-7b-hf --port 30002 --host 0.0.0.0 --mem-fraction-static 0.9 --max-running-requests 256 --chunked-prefill-size 8192 --max-prefill-tokens 16384 --schedule-conservativeness 1.0 --tp-size 1 --tokenizer-mode auto --dtype auto --load-format auto --log-level info --enable-metrics
[2025-07-25 02:52:00] [sglang_test_framework.core.server_manager] [INFO] Server logs will be displayed for worker_1
[2025-07-25 02:52:07] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:07] server_args=ServerArgs(model_path='/data/pretrained_models/Llama-2-7b-hf', tokenizer_path='/data/pretrained_models/Llama-2-7b-hf', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=False, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='0.0.0.0', port=30001, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.9, max_running_requests=256, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=1, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=541756318, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=0, crash_dump_folder=None, show_time_cost=False, enable_metrics=True, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, api_key=None, served_model_name='/data/pretrained_models/Llama-2-7b-hf', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, dp_size=1, load_balance_method='round_robin', dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, ep_size=1, enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_moe=False, enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through_selective', hicache_io_backend='', hicache_storage_backend=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, cuda_graph_max_bs=None, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_nccl_nvls=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, enable_triton_kernel_moe=False, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, pdlb_url=None, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3)
[2025-07-25 02:52:07] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:07] server_args=ServerArgs(model_path='/data/pretrained_models/Llama-2-7b-hf', tokenizer_path='/data/pretrained_models/Llama-2-7b-hf', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=False, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='0.0.0.0', port=30002, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.9, max_running_requests=256, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=1, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=51913985, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=0, crash_dump_folder=None, show_time_cost=False, enable_metrics=True, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, api_key=None, served_model_name='/data/pretrained_models/Llama-2-7b-hf', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, dp_size=1, load_balance_method='round_robin', dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, ep_size=1, enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_moe=False, enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through_selective', hicache_io_backend='', hicache_storage_backend=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, cuda_graph_max_bs=None, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_nccl_nvls=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, enable_triton_kernel_moe=False, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, pdlb_url=None, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3)
[2025-07-25 02:52:13] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:13] Attention backend not explicitly specified. Use flashinfer backend by default.
[2025-07-25 02:52:13] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:13] Init torch distributed begin.
[2025-07-25 02:52:13] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:13] Attention backend not explicitly specified. Use flashinfer backend by default.
[2025-07-25 02:52:13] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:13] Init torch distributed begin.
[2025-07-25 02:52:14] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:14] Init torch distributed ends. mem usage=0.00 GB
[2025-07-25 02:52:14] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:14] Init torch distributed ends. mem usage=0.00 GB
[2025-07-25 02:52:14] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:14] Load weight begin. avail mem=78.64 GB
[2025-07-25 02:52:14] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:14] Load weight begin. avail mem=78.64 GB
[2025-07-25 02:52:14] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[2025-07-25 02:52:14] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[2025-07-25 02:52:15] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.74it/s]
[2025-07-25 02:52:15] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.45it/s]
[2025-07-25 02:52:16] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.19s/it]
[2025-07-25 02:52:16] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.10s/it]
[2025-07-25 02:52:17] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:17] Load weight end. type=LlamaForCausalLM, dtype=torch.float16, avail mem=66.07 GB, mem usage=12.57 GB.
[2025-07-25 02:52:17] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:17] KV Cache is allocated. #tokens: 119182, K size: 29.10 GB, V size: 29.10 GB
[2025-07-25 02:52:17] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:17] Memory pool end. avail mem=7.80 GB
[2025-07-25 02:52:17] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:17] Capture cuda graph begin. This can take up to several minutes. avail mem=7.30 GB
[2025-07-25 02:52:17] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:17] Capture cuda graph bs [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160]
[2025-07-25 02:52:17] [sglang_test_framework.core.server_manager] [INFO] [worker_0]   0%|          | 0/23 [00:00<?, ?it/s]
[2025-07-25 02:52:17] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.45s/it]
[2025-07-25 02:52:17] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.33s/it]
[2025-07-25 02:52:17] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:17] Load weight end. type=LlamaForCausalLM, dtype=torch.float16, avail mem=66.07 GB, mem usage=12.57 GB.
[2025-07-25 02:52:17] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:17] KV Cache is allocated. #tokens: 119182, K size: 29.10 GB, V size: 29.10 GB
[2025-07-25 02:52:17] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:17] Memory pool end. avail mem=7.80 GB
[2025-07-25 02:52:17] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:17] Capture cuda graph begin. This can take up to several minutes. avail mem=7.30 GB
[2025-07-25 02:52:18] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:18] Capture cuda graph bs [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160]
[2025-07-25 02:52:18] [sglang_test_framework.core.server_manager] [INFO] [worker_1]   0%|          | 0/23 [00:00<?, ?it/s]
[2025-07-25 02:52:18] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=160 avail_mem=7.30 GB):   0%|          | 0/23 [00:00<?, ?it/s]
[2025-07-25 02:52:18] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=160 avail_mem=7.30 GB):   4%|▍         | 1/23 [00:00<00:16,  1.34it/s]
[2025-07-25 02:52:18] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=152 avail_mem=7.21 GB):   4%|▍         | 1/23 [00:00<00:16,  1.34it/s]
[2025-07-25 02:52:18] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=152 avail_mem=7.21 GB):   9%|▊         | 2/23 [00:00<00:09,  2.22it/s]
[2025-07-25 02:52:18] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=144 avail_mem=7.19 GB):   9%|▊         | 2/23 [00:00<00:09,  2.22it/s]
[2025-07-25 02:52:18] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=144 avail_mem=7.19 GB):  13%|█▎        | 3/23 [00:01<00:07,  2.74it/s]
[2025-07-25 02:52:18] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=160 avail_mem=7.30 GB):   0%|          | 0/23 [00:00<?, ?it/s]
[2025-07-25 02:52:18] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=160 avail_mem=7.30 GB):   4%|▍         | 1/23 [00:00<00:17,  1.28it/s]
[2025-07-25 02:52:18] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=136 avail_mem=7.16 GB):  13%|█▎        | 3/23 [00:01<00:07,  2.74it/s]
[2025-07-25 02:52:18] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=136 avail_mem=7.16 GB):  17%|█▋        | 4/23 [00:01<00:06,  3.14it/s]
[2025-07-25 02:52:19] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=152 avail_mem=7.21 GB):   4%|▍         | 1/23 [00:00<00:17,  1.28it/s]
[2025-07-25 02:52:19] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=152 avail_mem=7.21 GB):   9%|▊         | 2/23 [00:01<00:09,  2.14it/s]
[2025-07-25 02:52:19] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=128 avail_mem=7.12 GB):  17%|█▋        | 4/23 [00:01<00:06,  3.14it/s]
[2025-07-25 02:52:19] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=128 avail_mem=7.12 GB):  22%|██▏       | 5/23 [00:01<00:05,  3.44it/s]
[2025-07-25 02:52:19] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=144 avail_mem=7.19 GB):   9%|▊         | 2/23 [00:01<00:09,  2.14it/s]
[2025-07-25 02:52:19] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=144 avail_mem=7.19 GB):  13%|█▎        | 3/23 [00:01<00:07,  2.73it/s]
[2025-07-25 02:52:19] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=120 avail_mem=7.09 GB):  22%|██▏       | 5/23 [00:01<00:05,  3.44it/s]
[2025-07-25 02:52:19] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=120 avail_mem=7.09 GB):  26%|██▌       | 6/23 [00:01<00:04,  3.66it/s]
[2025-07-25 02:52:19] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=136 avail_mem=7.16 GB):  13%|█▎        | 3/23 [00:01<00:07,  2.73it/s]
[2025-07-25 02:52:19] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=136 avail_mem=7.16 GB):  17%|█▋        | 4/23 [00:01<00:06,  3.13it/s]
[2025-07-25 02:52:19] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=112 avail_mem=7.05 GB):  26%|██▌       | 6/23 [00:01<00:04,  3.66it/s]
[2025-07-25 02:52:19] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=112 avail_mem=7.05 GB):  30%|███       | 7/23 [00:02<00:04,  3.82it/s]
[2025-07-25 02:52:19] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=128 avail_mem=7.12 GB):  17%|█▋        | 4/23 [00:01<00:06,  3.13it/s]
[2025-07-25 02:52:19] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=128 avail_mem=7.12 GB):  22%|██▏       | 5/23 [00:01<00:05,  3.43it/s]
[2025-07-25 02:52:19] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=104 avail_mem=7.03 GB):  30%|███       | 7/23 [00:02<00:04,  3.82it/s]
[2025-07-25 02:52:19] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=104 avail_mem=7.03 GB):  35%|███▍      | 8/23 [00:02<00:03,  3.94it/s]
[2025-07-25 02:52:20] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=120 avail_mem=7.09 GB):  22%|██▏       | 5/23 [00:01<00:05,  3.43it/s]
[2025-07-25 02:52:20] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=120 avail_mem=7.09 GB):  26%|██▌       | 6/23 [00:02<00:04,  3.64it/s]
[2025-07-25 02:52:20] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=96 avail_mem=7.00 GB):  35%|███▍      | 8/23 [00:02<00:03,  3.94it/s]
[2025-07-25 02:52:20] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=96 avail_mem=7.00 GB):  39%|███▉      | 9/23 [00:02<00:03,  4.02it/s]
[2025-07-25 02:52:20] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=112 avail_mem=7.05 GB):  26%|██▌       | 6/23 [00:02<00:04,  3.64it/s]
[2025-07-25 02:52:20] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=112 avail_mem=7.05 GB):  30%|███       | 7/23 [00:02<00:04,  3.79it/s]
[2025-07-25 02:52:20] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=88 avail_mem=6.98 GB):  39%|███▉      | 9/23 [00:02<00:03,  4.02it/s]
[2025-07-25 02:52:20] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=88 avail_mem=6.98 GB):  43%|████▎     | 10/23 [00:02<00:03,  4.05it/s]
[2025-07-25 02:52:20] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=104 avail_mem=7.03 GB):  30%|███       | 7/23 [00:02<00:04,  3.79it/s]
[2025-07-25 02:52:20] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=104 avail_mem=7.03 GB):  35%|███▍      | 8/23 [00:02<00:03,  3.90it/s]
[2025-07-25 02:52:20] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=80 avail_mem=6.94 GB):  43%|████▎     | 10/23 [00:02<00:03,  4.05it/s]
[2025-07-25 02:52:20] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=80 avail_mem=6.94 GB):  48%|████▊     | 11/23 [00:03<00:02,  4.10it/s]
[2025-07-25 02:52:20] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=96 avail_mem=7.00 GB):  35%|███▍      | 8/23 [00:02<00:03,  3.90it/s]
[2025-07-25 02:52:20] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=96 avail_mem=7.00 GB):  39%|███▉      | 9/23 [00:02<00:03,  3.97it/s]
[2025-07-25 02:52:20] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=72 avail_mem=6.91 GB):  48%|████▊     | 11/23 [00:03<00:02,  4.10it/s]
[2025-07-25 02:52:20] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=72 avail_mem=6.91 GB):  52%|█████▏    | 12/23 [00:03<00:02,  4.13it/s]
[2025-07-25 02:52:20] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=88 avail_mem=6.98 GB):  39%|███▉      | 9/23 [00:02<00:03,  3.97it/s]
[2025-07-25 02:52:20] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=88 avail_mem=6.98 GB):  43%|████▎     | 10/23 [00:02<00:03,  4.01it/s]
[2025-07-25 02:52:21] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=64 avail_mem=6.88 GB):  52%|█████▏    | 12/23 [00:03<00:02,  4.13it/s]
[2025-07-25 02:52:21] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=64 avail_mem=6.88 GB):  57%|█████▋    | 13/23 [00:03<00:02,  4.11it/s]
[2025-07-25 02:52:21] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=80 avail_mem=6.94 GB):  43%|████▎     | 10/23 [00:02<00:03,  4.01it/s]
[2025-07-25 02:52:21] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=80 avail_mem=6.94 GB):  48%|████▊     | 11/23 [00:03<00:02,  4.05it/s]
[2025-07-25 02:52:21] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=56 avail_mem=6.86 GB):  57%|█████▋    | 13/23 [00:03<00:02,  4.11it/s]
[2025-07-25 02:52:21] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=56 avail_mem=6.86 GB):  61%|██████    | 14/23 [00:03<00:02,  4.14it/s]
[2025-07-25 02:52:21] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=72 avail_mem=6.91 GB):  48%|████▊     | 11/23 [00:03<00:02,  4.05it/s]
[2025-07-25 02:52:21] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=72 avail_mem=6.91 GB):  52%|█████▏    | 12/23 [00:03<00:02,  4.08it/s]
[2025-07-25 02:52:21] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=48 avail_mem=6.84 GB):  61%|██████    | 14/23 [00:03<00:02,  4.14it/s]
[2025-07-25 02:52:21] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=48 avail_mem=6.84 GB):  65%|██████▌   | 15/23 [00:04<00:01,  4.18it/s]
[2025-07-25 02:52:21] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=64 avail_mem=6.88 GB):  52%|█████▏    | 12/23 [00:03<00:02,  4.08it/s]
[2025-07-25 02:52:21] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=64 avail_mem=6.88 GB):  57%|█████▋    | 13/23 [00:03<00:02,  4.05it/s]
[2025-07-25 02:52:21] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=40 avail_mem=6.83 GB):  65%|██████▌   | 15/23 [00:04<00:01,  4.18it/s]
[2025-07-25 02:52:21] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=40 avail_mem=6.83 GB):  70%|██████▉   | 16/23 [00:04<00:01,  4.20it/s]
[2025-07-25 02:52:21] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=56 avail_mem=6.86 GB):  57%|█████▋    | 13/23 [00:03<00:02,  4.05it/s]
[2025-07-25 02:52:21] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=56 avail_mem=6.86 GB):  61%|██████    | 14/23 [00:03<00:02,  4.10it/s]
[2025-07-25 02:52:22] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=32 avail_mem=6.78 GB):  70%|██████▉   | 16/23 [00:04<00:01,  4.20it/s]
[2025-07-25 02:52:22] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=32 avail_mem=6.78 GB):  74%|███████▍  | 17/23 [00:04<00:01,  4.22it/s]
[2025-07-25 02:52:22] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=48 avail_mem=6.84 GB):  61%|██████    | 14/23 [00:03<00:02,  4.10it/s]
[2025-07-25 02:52:22] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=48 avail_mem=6.84 GB):  65%|██████▌   | 15/23 [00:04<00:01,  4.13it/s]
[2025-07-25 02:52:22] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=24 avail_mem=6.78 GB):  74%|███████▍  | 17/23 [00:04<00:01,  4.22it/s]
[2025-07-25 02:52:22] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=24 avail_mem=6.78 GB):  78%|███████▊  | 18/23 [00:04<00:01,  4.23it/s]
[2025-07-25 02:52:22] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=40 avail_mem=6.83 GB):  65%|██████▌   | 15/23 [00:04<00:01,  4.13it/s]
[2025-07-25 02:52:22] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=40 avail_mem=6.83 GB):  70%|██████▉   | 16/23 [00:04<00:01,  4.15it/s]
[2025-07-25 02:52:22] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=16 avail_mem=6.76 GB):  78%|███████▊  | 18/23 [00:04<00:01,  4.23it/s]
[2025-07-25 02:52:22] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=16 avail_mem=6.76 GB):  83%|████████▎ | 19/23 [00:05<00:00,  4.24it/s]
[2025-07-25 02:52:22] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=32 avail_mem=6.78 GB):  70%|██████▉   | 16/23 [00:04<00:01,  4.15it/s]
[2025-07-25 02:52:22] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=32 avail_mem=6.78 GB):  74%|███████▍  | 17/23 [00:04<00:01,  4.17it/s]
[2025-07-25 02:52:22] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=8 avail_mem=6.75 GB):  83%|████████▎ | 19/23 [00:05<00:00,  4.24it/s]
[2025-07-25 02:52:22] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=8 avail_mem=6.75 GB):  87%|████████▋ | 20/23 [00:05<00:00,  4.22it/s]
[2025-07-25 02:52:22] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=24 avail_mem=6.78 GB):  74%|███████▍  | 17/23 [00:04<00:01,  4.17it/s]
[2025-07-25 02:52:22] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=24 avail_mem=6.78 GB):  78%|███████▊  | 18/23 [00:04<00:01,  4.18it/s]
[2025-07-25 02:52:22] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=4 avail_mem=6.73 GB):  87%|████████▋ | 20/23 [00:05<00:00,  4.22it/s]
[2025-07-25 02:52:22] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=4 avail_mem=6.73 GB):  91%|█████████▏| 21/23 [00:05<00:00,  4.21it/s]
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=16 avail_mem=6.76 GB):  78%|███████▊  | 18/23 [00:04<00:01,  4.18it/s]
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=16 avail_mem=6.76 GB):  83%|████████▎ | 19/23 [00:05<00:00,  4.11it/s]
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=2 avail_mem=6.72 GB):  91%|█████████▏| 21/23 [00:05<00:00,  4.21it/s]
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=2 avail_mem=6.72 GB):  96%|█████████▌| 22/23 [00:05<00:00,  4.22it/s]
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=8 avail_mem=6.75 GB):  83%|████████▎ | 19/23 [00:05<00:00,  4.11it/s]
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=8 avail_mem=6.75 GB):  87%|████████▋ | 20/23 [00:05<00:00,  4.14it/s]
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=1 avail_mem=6.70 GB):  96%|█████████▌| 22/23 [00:05<00:00,  4.22it/s]
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=1 avail_mem=6.70 GB): 100%|██████████| 23/23 [00:06<00:00,  4.23it/s]
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_0] Capturing batches (bs=1 avail_mem=6.70 GB): 100%|██████████| 23/23 [00:06<00:00,  3.82it/s]
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:23] Capture cuda graph end. Time elapsed: 6.05 s. mem usage=0.61 GB. avail mem=6.69 GB.
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:23] max_total_num_tokens=119182, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=256, context_len=4096, available_gpu_mem=6.69 GB
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=4 avail_mem=6.73 GB):  87%|████████▋ | 20/23 [00:05<00:00,  4.14it/s]
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=4 avail_mem=6.73 GB):  91%|█████████▏| 21/23 [00:05<00:00,  4.16it/s]
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:23] INFO:     Started server process [2025273]
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:23] INFO:     Waiting for application startup.
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:23] INFO:     Application startup complete.
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:23] INFO:     Uvicorn running on http://0.0.0.0:30001 (Press CTRL+C to quit)
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=2 avail_mem=6.72 GB):  91%|█████████▏| 21/23 [00:05<00:00,  4.16it/s]
[2025-07-25 02:52:23] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=2 avail_mem=6.72 GB):  96%|█████████▌| 22/23 [00:05<00:00,  4.11it/s]
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=1 avail_mem=6.70 GB):  96%|█████████▌| 22/23 [00:05<00:00,  4.11it/s]
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=1 avail_mem=6.70 GB): 100%|██████████| 23/23 [00:06<00:00,  4.11it/s]
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] [worker_1] Capturing batches (bs=1 avail_mem=6.70 GB): 100%|██████████| 23/23 [00:06<00:00,  3.76it/s]
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:24] Capture cuda graph end. Time elapsed: 6.16 s. mem usage=0.61 GB. avail mem=6.69 GB.
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:24] max_total_num_tokens=119182, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=256, context_len=4096, available_gpu_mem=6.69 GB
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:24] INFO:     Started server process [2025275]
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:24] INFO:     Waiting for application startup.
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:24] INFO:     Application startup complete.
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:24] INFO:     Uvicorn running on http://0.0.0.0:30002 (Press CTRL+C to quit)
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:24] INFO:     127.0.0.1:48142 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:24] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0,
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:24] INFO:     127.0.0.1:48168 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:24] INFO:     127.0.0.1:60420 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] Server worker_0 started successfully in 24.0s
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] Server worker_1 started successfully in 24.0s
[2025-07-25 02:52:24] [sglang_test_framework.tests.routing_test] [INFO] Mapped worker http://0.0.0.0:30001 to GPU 0
[2025-07-25 02:52:24] [sglang_test_framework.tests.routing_test] [INFO] Mapped worker http://0.0.0.0:30002 to GPU 1
[2025-07-25 02:52:24] [sglang_test_framework.tests.routing_test] [INFO] Launching router with policy: cache_aware
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] Starting router with command: python -m sglang_router.launch_router --worker-urls http://0.0.0.0:30001 http://0.0.0.0:30002 --port 30000 --host 0.0.0.0 --policy cache_aware --cache-threshold 0.5 --balance-abs-threshold 32 --balance-rel-threshold 1.0001 --eviction-interval 60 --max-tree-size 16777216
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:24] INFO:     127.0.0.1:48174 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:24] INFO:     127.0.0.1:60428 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:24] INFO:     127.0.0.1:60436 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:52:24] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:24] INFO:     127.0.0.1:48184 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:25] INFO:     127.0.0.1:48154 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:25] The server is fired up and ready to roll!
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:25] INFO:     127.0.0.1:60450 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:25] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0,
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] Router started successfully in 1.0s
[2025-07-25 02:52:25] [sglang_test_framework.tests.routing_test] [INFO] Warming up servers with 10 requests
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] RequestSender session created with connection pool limit=100
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [INFO] Generating 10 requests from dataset 'random'...
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [INFO] Generating random requests with input_len=128, output_len=16, range_ratio=0.1
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [INFO] Successfully generated 10 random requests
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [INFO] Setting all requests to arrive immediately (infinite rate)
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_0 to http://0.0.0.0:30000/generate at 1753383145.7850258
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_0 with payload: {'text': 'Random prompt 0 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 14, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_1 to http://0.0.0.0:30000/generate at 1753383145.7861304
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_1 with payload: {'text': 'Random prompt 1 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 17, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_2 to http://0.0.0.0:30000/generate at 1753383145.7869866
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_2 with payload: {'text': 'Random prompt 2 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 16, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_3 to http://0.0.0.0:30000/generate at 1753383145.7877624
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_3 with payload: {'text': 'Random prompt 3 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 15, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_4 to http://0.0.0.0:30000/generate at 1753383145.788494
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_4 with payload: {'text': 'Random prompt 4 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 15, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_5 to http://0.0.0.0:30000/generate at 1753383145.7892087
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_5 with payload: {'text': 'Random prompt 5 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 15, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_6 to http://0.0.0.0:30000/generate at 1753383145.7899258
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_6 with payload: {'text': 'Random prompt 6 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 15, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_7 to http://0.0.0.0:30000/generate at 1753383145.7906437
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_7 with payload: {'text': 'Random prompt 7 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 16, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_8 to http://0.0.0.0:30000/generate at 1753383145.7913413
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_8 with payload: {'text': 'Random prompt 8 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 15, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_9 to http://0.0.0.0:30000/generate at 1753383145.792384
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_9 with payload: {'text': 'Random prompt 9 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 15, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:25] INFO:     127.0.0.1:48188 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:25] INFO:     127.0.0.1:60466 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_0
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:25] Prefill batch. #new-seq: 1, #new-token: 31, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0,
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_0
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_2
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_2
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:25] INFO:     127.0.0.1:48202 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:25] INFO:     127.0.0.1:60476 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_1
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_1
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:25] Prefill batch. #new-seq: 1, #new-token: 35, #cached-token: 1, token usage: 0.00, #running-req: 1, #queue-req: 0,
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:25] INFO:     127.0.0.1:48210 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_4
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_4
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:25] INFO:     127.0.0.1:60486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_6
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_6
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:25] INFO:     127.0.0.1:48220 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_3
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_3
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:25] INFO:     127.0.0.1:60498 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_5
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_5
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:25] INFO:     127.0.0.1:48228 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_7
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_7
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_8
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_8
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:25] INFO:     127.0.0.1:60506 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_9
[2025-07-25 02:52:25] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_9
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:25] Prefill batch. #new-seq: 3, #new-token: 83, #cached-token: 12, token usage: 0.00, #running-req: 2, #queue-req: 0,
[2025-07-25 02:52:25] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:25] Prefill batch. #new-seq: 5, #new-token: 163, #cached-token: 5, token usage: 0.00, #running-req: 1, #queue-req: 0,
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_0 received DONE after 15 chunks
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_0 completed: 44 chars, 15 chunks, TTFT=116.7ms
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_8 received DONE after 16 chunks
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_8 completed: 45 chars, 16 chunks, TTFT=253.1ms
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_6 received DONE after 16 chunks
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_6 completed: 45 chars, 16 chunks, TTFT=254.6ms
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_5 received DONE after 16 chunks
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_5 completed: 47 chars, 16 chunks, TTFT=255.5ms
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_1 received DONE after 18 chunks
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_1 completed: 41 chars, 18 chunks, TTFT=143.0ms
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60456 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] The server is fired up and ready to roll!
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_3 received DONE after 16 chunks
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_3 completed: 45 chars, 16 chunks, TTFT=381.0ms
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_4 received DONE after 16 chunks
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_4 completed: 47 chars, 16 chunks, TTFT=380.2ms
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_9 received DONE after 16 chunks
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_9 completed: 60 chars, 16 chunks, TTFT=376.4ms
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_7 received DONE after 17 chunks
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_7 completed: 64 chars, 17 chunks, TTFT=378.1ms
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_2 received DONE after 17 chunks
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Request req_2 completed: 64 chars, 17 chunks, TTFT=381.7ms
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] RequestSender session closed
[2025-07-25 02:52:26] [sglang_test_framework.tests.routing_test] [INFO] Warmup complete: 10/10 successful
[2025-07-25 02:52:26] [sglang_test_framework.core.metrics_collector] [INFO] Started metrics collection
[2025-07-25 02:52:26] [sglang_test_framework.core.metrics_collector] [INFO] Started metrics collection
[2025-07-25 02:52:26] [sglang_test_framework.core.metrics_collector] [INFO] Started metrics collection
[2025-07-25 02:52:26] [sglang_test_framework.tests.routing_test] [INFO] Starting test with 1000 requests
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] RequestSender session created with connection pool limit=100
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [INFO] Generating 1000 requests from dataset 'random'...
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [INFO] Generating random requests with input_len=512, output_len=128, range_ratio=0.5
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [INFO] Generated 1000/1000 random requests
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [INFO] Successfully generated 1000 random requests
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [INFO] Generating Poisson arrivals with rate=50.0 req/s
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [INFO] Total test duration: 20.0 seconds
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_0 to http://0.0.0.0:30000/generate at 1753383146.6812377
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_0 with payload: {'text': 'Random prompt 0 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_1 to http://0.0.0.0:30000/generate at 1753383146.6818793
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_1 with payload: {'text': 'Random prompt 1 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_2 to http://0.0.0.0:30000/generate at 1753383146.682199
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_2 with payload: {'text': 'Random prompt 2 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_3 to http://0.0.0.0:30000/generate at 1753383146.6824782
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_3 with payload: {'text': 'Random prompt 3 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_4 to http://0.0.0.0:30000/generate at 1753383146.6827247
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_4 with payload: {'text': 'Random prompt 4 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_5 to http://0.0.0.0:30000/generate at 1753383146.6829634
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_5 with payload: {'text': 'Random prompt 5 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_6 to http://0.0.0.0:30000/generate at 1753383146.683323
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_6 with payload: {'text': 'Random prompt 6 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_7 to http://0.0.0.0:30000/generate at 1753383146.6836145
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_7 with payload: {'text': 'Random prompt 7 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 173, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_8 to http://0.0.0.0:30000/generate at 1753383146.6838815
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_8 with payload: {'text': 'Random prompt 8 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 96, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_9 to http://0.0.0.0:30000/generate at 1753383146.6841238
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_9 with payload: {'text': 'Random prompt 9 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_10 to http://0.0.0.0:30000/generate at 1753383146.6843743
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_10 with payload: {'text': 'Random prompt 10 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_11 to http://0.0.0.0:30000/generate at 1753383146.6846077
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_11 with payload: {'text': 'Random prompt 11 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_12 to http://0.0.0.0:30000/generate at 1753383146.6848304
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_12 with payload: {'text': 'Random prompt 12 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_13 to http://0.0.0.0:30000/generate at 1753383146.6851878
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_13 with payload: {'text': 'Random prompt 13 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_14 to http://0.0.0.0:30000/generate at 1753383146.6854324
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_14 with payload: {'text': 'Random prompt 14 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 154, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_15 to http://0.0.0.0:30000/generate at 1753383146.685663
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_15 with payload: {'text': 'Random prompt 15 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 182, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_16 to http://0.0.0.0:30000/generate at 1753383146.6858923
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_16 with payload: {'text': 'Random prompt 16 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_17 to http://0.0.0.0:30000/generate at 1753383146.6861227
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_17 with payload: {'text': 'Random prompt 17 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 137, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_18 to http://0.0.0.0:30000/generate at 1753383146.6863618
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_18 with payload: {'text': 'Random prompt 18 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 181, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_19 to http://0.0.0.0:30000/generate at 1753383146.6865945
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_19 with payload: {'text': 'Random prompt 19 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_20 to http://0.0.0.0:30000/generate at 1753383146.6868901
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_20 with payload: {'text': 'Random prompt 20 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_21 to http://0.0.0.0:30000/generate at 1753383146.687128
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_21 with payload: {'text': 'Random prompt 21 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 102, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_22 to http://0.0.0.0:30000/generate at 1753383146.6873605
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_22 with payload: {'text': 'Random prompt 22 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 182, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_23 to http://0.0.0.0:30000/generate at 1753383146.6875844
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_23 with payload: {'text': 'Random prompt 23 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_24 to http://0.0.0.0:30000/generate at 1753383146.687821
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_24 with payload: {'text': 'Random prompt 24 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_25 to http://0.0.0.0:30000/generate at 1753383146.688046
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_25 with payload: {'text': 'Random prompt 25 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_26 to http://0.0.0.0:30000/generate at 1753383146.68829
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_26 with payload: {'text': 'Random prompt 26 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 174, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_27 to http://0.0.0.0:30000/generate at 1753383146.689327
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_27 with payload: {'text': 'Random prompt 27 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_28 to http://0.0.0.0:30000/generate at 1753383146.6896229
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_28 with payload: {'text': 'Random prompt 28 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 105, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_29 to http://0.0.0.0:30000/generate at 1753383146.6898751
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_29 with payload: {'text': 'Random prompt 29 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_30 to http://0.0.0.0:30000/generate at 1753383146.69012
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_30 with payload: {'text': 'Random prompt 30 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_31 to http://0.0.0.0:30000/generate at 1753383146.69037
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_31 with payload: {'text': 'Random prompt 31 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_32 to http://0.0.0.0:30000/generate at 1753383146.6906
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_32 with payload: {'text': 'Random prompt 32 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_33 to http://0.0.0.0:30000/generate at 1753383146.6908329
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_33 with payload: {'text': 'Random prompt 33 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 79, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_34 to http://0.0.0.0:30000/generate at 1753383146.6911335
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_34 with payload: {'text': 'Random prompt 34 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_35 to http://0.0.0.0:30000/generate at 1753383146.6913764
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_35 with payload: {'text': 'Random prompt 35 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_36 to http://0.0.0.0:30000/generate at 1753383146.6916099
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_36 with payload: {'text': 'Random prompt 36 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_37 to http://0.0.0.0:30000/generate at 1753383146.6918378
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_37 with payload: {'text': 'Random prompt 37 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_38 to http://0.0.0.0:30000/generate at 1753383146.6920743
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_38 with payload: {'text': 'Random prompt 38 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_39 to http://0.0.0.0:30000/generate at 1753383146.6923132
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_39 with payload: {'text': 'Random prompt 39 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 104, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_40 to http://0.0.0.0:30000/generate at 1753383146.6926048
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_40 with payload: {'text': 'Random prompt 40 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_41 to http://0.0.0.0:30000/generate at 1753383146.6928444
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_41 with payload: {'text': 'Random prompt 41 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_42 to http://0.0.0.0:30000/generate at 1753383146.6930761
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_42 with payload: {'text': 'Random prompt 42 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 105, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_43 to http://0.0.0.0:30000/generate at 1753383146.6933136
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_43 with payload: {'text': 'Random prompt 43 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_44 to http://0.0.0.0:30000/generate at 1753383146.6935437
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_44 with payload: {'text': 'Random prompt 44 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_45 to http://0.0.0.0:30000/generate at 1753383146.6937757
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_45 with payload: {'text': 'Random prompt 45 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_46 to http://0.0.0.0:30000/generate at 1753383146.6940033
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_46 with payload: {'text': 'Random prompt 46 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_47 to http://0.0.0.0:30000/generate at 1753383146.694294
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_47 with payload: {'text': 'Random prompt 47 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_48 to http://0.0.0.0:30000/generate at 1753383146.694522
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_48 with payload: {'text': 'Random prompt 48 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_49 to http://0.0.0.0:30000/generate at 1753383146.694748
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_49 with payload: {'text': 'Random prompt 49 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_50 to http://0.0.0.0:30000/generate at 1753383146.6949768
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_50 with payload: {'text': 'Random prompt 50 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_51 to http://0.0.0.0:30000/generate at 1753383146.6952136
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_51 with payload: {'text': 'Random prompt 51 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 132, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_52 to http://0.0.0.0:30000/generate at 1753383146.6954403
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_52 with payload: {'text': 'Random prompt 52 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_53 to http://0.0.0.0:30000/generate at 1753383146.695727
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_53 with payload: {'text': 'Random prompt 53 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_54 to http://0.0.0.0:30000/generate at 1753383146.6959634
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_54 with payload: {'text': 'Random prompt 54 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_55 to http://0.0.0.0:30000/generate at 1753383146.6961915
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_55 with payload: {'text': 'Random prompt 55 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_56 to http://0.0.0.0:30000/generate at 1753383146.696445
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_56 with payload: {'text': 'Random prompt 56 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_57 to http://0.0.0.0:30000/generate at 1753383146.6966722
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_57 with payload: {'text': 'Random prompt 57 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_58 to http://0.0.0.0:30000/generate at 1753383146.6968966
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_58 with payload: {'text': 'Random prompt 58 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_59 to http://0.0.0.0:30000/generate at 1753383146.6971147
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_59 with payload: {'text': 'Random prompt 59 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_60 to http://0.0.0.0:30000/generate at 1753383146.6974225
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_60 with payload: {'text': 'Random prompt 60 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_61 to http://0.0.0.0:30000/generate at 1753383146.697665
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_61 with payload: {'text': 'Random prompt 61 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_62 to http://0.0.0.0:30000/generate at 1753383146.6978993
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_62 with payload: {'text': 'Random prompt 62 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_63 to http://0.0.0.0:30000/generate at 1753383146.6981359
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_63 with payload: {'text': 'Random prompt 63 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_64 to http://0.0.0.0:30000/generate at 1753383146.698373
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_64 with payload: {'text': 'Random prompt 64 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 118, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_65 to http://0.0.0.0:30000/generate at 1753383146.6986043
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_65 with payload: {'text': 'Random prompt 65 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_66 to http://0.0.0.0:30000/generate at 1753383146.6988842
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_66 with payload: {'text': 'Random prompt 66 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 95, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_67 to http://0.0.0.0:30000/generate at 1753383146.6991167
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_67 with payload: {'text': 'Random prompt 67 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_68 to http://0.0.0.0:30000/generate at 1753383146.699349
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_68 with payload: {'text': 'Random prompt 68 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_69 to http://0.0.0.0:30000/generate at 1753383146.6995745
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_69 with payload: {'text': 'Random prompt 69 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 101, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_70 to http://0.0.0.0:30000/generate at 1753383146.6997998
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_70 with payload: {'text': 'Random prompt 70 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 102, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_71 to http://0.0.0.0:30000/generate at 1753383146.7000217
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_71 with payload: {'text': 'Random prompt 71 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_72 to http://0.0.0.0:30000/generate at 1753383146.7002528
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_72 with payload: {'text': 'Random prompt 72 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_73 to http://0.0.0.0:30000/generate at 1753383146.7005339
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_73 with payload: {'text': 'Random prompt 73 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 66, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_74 to http://0.0.0.0:30000/generate at 1753383146.7007675
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_74 with payload: {'text': 'Random prompt 74 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_75 to http://0.0.0.0:30000/generate at 1753383146.7009885
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_75 with payload: {'text': 'Random prompt 75 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_76 to http://0.0.0.0:30000/generate at 1753383146.7012513
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_76 with payload: {'text': 'Random prompt 76 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 113, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_77 to http://0.0.0.0:30000/generate at 1753383146.701497
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_77 with payload: {'text': 'Random prompt 77 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_78 to http://0.0.0.0:30000/generate at 1753383146.7017245
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_78 with payload: {'text': 'Random prompt 78 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_79 to http://0.0.0.0:30000/generate at 1753383146.7020144
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_79 with payload: {'text': 'Random prompt 79 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_80 to http://0.0.0.0:30000/generate at 1753383146.7022517
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_80 with payload: {'text': 'Random prompt 80 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_81 to http://0.0.0.0:30000/generate at 1753383146.7024784
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_81 with payload: {'text': 'Random prompt 81 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_82 to http://0.0.0.0:30000/generate at 1753383146.7027082
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_82 with payload: {'text': 'Random prompt 82 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_83 to http://0.0.0.0:30000/generate at 1753383146.7029395
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_83 with payload: {'text': 'Random prompt 83 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_84 to http://0.0.0.0:30000/generate at 1753383146.703155
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_84 with payload: {'text': 'Random prompt 84 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_85 to http://0.0.0.0:30000/generate at 1753383146.703451
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_85 with payload: {'text': 'Random prompt 85 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 124, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_86 to http://0.0.0.0:30000/generate at 1753383146.7036786
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_86 with payload: {'text': 'Random prompt 86 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_87 to http://0.0.0.0:30000/generate at 1753383146.7039032
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_87 with payload: {'text': 'Random prompt 87 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_88 to http://0.0.0.0:30000/generate at 1753383146.7041287
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_88 with payload: {'text': 'Random prompt 88 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_89 to http://0.0.0.0:30000/generate at 1753383146.704379
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_89 with payload: {'text': 'Random prompt 89 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_90 to http://0.0.0.0:30000/generate at 1753383146.7046037
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_90 with payload: {'text': 'Random prompt 90 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_91 to http://0.0.0.0:30000/generate at 1753383146.7048218
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_91 with payload: {'text': 'Random prompt 91 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_92 to http://0.0.0.0:30000/generate at 1753383146.7051122
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_92 with payload: {'text': 'Random prompt 92 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_93 to http://0.0.0.0:30000/generate at 1753383146.7053826
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_93 with payload: {'text': 'Random prompt 93 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_94 to http://0.0.0.0:30000/generate at 1753383146.7056184
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_94 with payload: {'text': 'Random prompt 94 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_95 to http://0.0.0.0:30000/generate at 1753383146.7058506
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_95 with payload: {'text': 'Random prompt 95 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_96 to http://0.0.0.0:30000/generate at 1753383146.7060733
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_96 with payload: {'text': 'Random prompt 96 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_97 to http://0.0.0.0:30000/generate at 1753383146.7063088
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_97 with payload: {'text': 'Random prompt 97 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_98 to http://0.0.0.0:30000/generate at 1753383146.7065973
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_98 with payload: {'text': 'Random prompt 98 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_99 to http://0.0.0.0:30000/generate at 1753383146.7068417
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_99 with payload: {'text': 'Random prompt 99 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_100 to http://0.0.0.0:30000/generate at 1753383146.7070649
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_100 with payload: {'text': 'Random prompt 100 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_101 to http://0.0.0.0:30000/generate at 1753383146.7072208
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_101 with payload: {'text': 'Random prompt 101 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_102 to http://0.0.0.0:30000/generate at 1753383146.7073631
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_102 with payload: {'text': 'Random prompt 102 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_103 to http://0.0.0.0:30000/generate at 1753383146.7074938
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_103 with payload: {'text': 'Random prompt 103 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_104 to http://0.0.0.0:30000/generate at 1753383146.7076259
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_104 with payload: {'text': 'Random prompt 104 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_105 to http://0.0.0.0:30000/generate at 1753383146.707754
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_105 with payload: {'text': 'Random prompt 105 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_106 to http://0.0.0.0:30000/generate at 1753383146.7078793
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_106 with payload: {'text': 'Random prompt 106 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_107 to http://0.0.0.0:30000/generate at 1753383146.708006
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_107 with payload: {'text': 'Random prompt 107 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_108 to http://0.0.0.0:30000/generate at 1753383146.7081373
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_108 with payload: {'text': 'Random prompt 108 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_109 to http://0.0.0.0:30000/generate at 1753383146.7088704
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_109 with payload: {'text': 'Random prompt 109 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 84, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_110 to http://0.0.0.0:30000/generate at 1753383146.70901
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_110 with payload: {'text': 'Random prompt 110 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_111 to http://0.0.0.0:30000/generate at 1753383146.7091324
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_111 with payload: {'text': 'Random prompt 111 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_112 to http://0.0.0.0:30000/generate at 1753383146.7092738
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_112 with payload: {'text': 'Random prompt 112 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_113 to http://0.0.0.0:30000/generate at 1753383146.709407
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_113 with payload: {'text': 'Random prompt 113 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_114 to http://0.0.0.0:30000/generate at 1753383146.7095566
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_114 with payload: {'text': 'Random prompt 114 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_115 to http://0.0.0.0:30000/generate at 1753383146.709697
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_115 with payload: {'text': 'Random prompt 115 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 138, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_116 to http://0.0.0.0:30000/generate at 1753383146.7098303
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_116 with payload: {'text': 'Random prompt 116 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 76, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_117 to http://0.0.0.0:30000/generate at 1753383146.709958
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_117 with payload: {'text': 'Random prompt 117 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_118 to http://0.0.0.0:30000/generate at 1753383146.7100914
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_118 with payload: {'text': 'Random prompt 118 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 98, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_119 to http://0.0.0.0:30000/generate at 1753383146.71023
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_119 with payload: {'text': 'Random prompt 119 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_120 to http://0.0.0.0:30000/generate at 1753383146.7103608
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_120 with payload: {'text': 'Random prompt 120 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 178, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_121 to http://0.0.0.0:30000/generate at 1753383146.7105403
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_121 with payload: {'text': 'Random prompt 121 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_122 to http://0.0.0.0:30000/generate at 1753383146.7106693
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_122 with payload: {'text': 'Random prompt 122 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 174, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_123 to http://0.0.0.0:30000/generate at 1753383146.7107987
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_123 with payload: {'text': 'Random prompt 123 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_124 to http://0.0.0.0:30000/generate at 1753383146.7109227
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_124 with payload: {'text': 'Random prompt 124 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_125 to http://0.0.0.0:30000/generate at 1753383146.7110522
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_125 with payload: {'text': 'Random prompt 125 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 135, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_126 to http://0.0.0.0:30000/generate at 1753383146.711188
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_126 with payload: {'text': 'Random prompt 126 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_127 to http://0.0.0.0:30000/generate at 1753383146.7113252
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_127 with payload: {'text': 'Random prompt 127 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_128 to http://0.0.0.0:30000/generate at 1753383146.711458
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_128 with payload: {'text': 'Random prompt 128 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 112, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_129 to http://0.0.0.0:30000/generate at 1753383146.7115808
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_129 with payload: {'text': 'Random prompt 129 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_130 to http://0.0.0.0:30000/generate at 1753383146.7117047
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_130 with payload: {'text': 'Random prompt 130 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_131 to http://0.0.0.0:30000/generate at 1753383146.711834
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_131 with payload: {'text': 'Random prompt 131 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_132 to http://0.0.0.0:30000/generate at 1753383146.7119565
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_132 with payload: {'text': 'Random prompt 132 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_133 to http://0.0.0.0:30000/generate at 1753383146.7121315
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_133 with payload: {'text': 'Random prompt 133 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_134 to http://0.0.0.0:30000/generate at 1753383146.7122712
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_134 with payload: {'text': 'Random prompt 134 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_135 to http://0.0.0.0:30000/generate at 1753383146.7123952
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_135 with payload: {'text': 'Random prompt 135 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_136 to http://0.0.0.0:30000/generate at 1753383146.712518
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_136 with payload: {'text': 'Random prompt 136 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 173, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_137 to http://0.0.0.0:30000/generate at 1753383146.7126422
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_137 with payload: {'text': 'Random prompt 137 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_138 to http://0.0.0.0:30000/generate at 1753383146.7127686
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_138 with payload: {'text': 'Random prompt 138 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_139 to http://0.0.0.0:30000/generate at 1753383146.712897
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_139 with payload: {'text': 'Random prompt 139 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_140 to http://0.0.0.0:30000/generate at 1753383146.7130306
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_140 with payload: {'text': 'Random prompt 140 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_141 to http://0.0.0.0:30000/generate at 1753383146.713165
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_141 with payload: {'text': 'Random prompt 141 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_142 to http://0.0.0.0:30000/generate at 1753383146.7133036
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_142 with payload: {'text': 'Random prompt 142 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_143 to http://0.0.0.0:30000/generate at 1753383146.7134323
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_143 with payload: {'text': 'Random prompt 143 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 136, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_144 to http://0.0.0.0:30000/generate at 1753383146.7135584
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_144 with payload: {'text': 'Random prompt 144 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 98, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_145 to http://0.0.0.0:30000/generate at 1753383146.7137299
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_145 with payload: {'text': 'Random prompt 145 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_146 to http://0.0.0.0:30000/generate at 1753383146.7138567
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_146 with payload: {'text': 'Random prompt 146 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_147 to http://0.0.0.0:30000/generate at 1753383146.7139862
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_147 with payload: {'text': 'Random prompt 147 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_148 to http://0.0.0.0:30000/generate at 1753383146.714113
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_148 with payload: {'text': 'Random prompt 148 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 173, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_149 to http://0.0.0.0:30000/generate at 1753383146.7142487
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_149 with payload: {'text': 'Random prompt 149 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_150 to http://0.0.0.0:30000/generate at 1753383146.714375
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_150 with payload: {'text': 'Random prompt 150 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_151 to http://0.0.0.0:30000/generate at 1753383146.7145011
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_151 with payload: {'text': 'Random prompt 151 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 171, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_152 to http://0.0.0.0:30000/generate at 1753383146.7146285
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_152 with payload: {'text': 'Random prompt 152 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_153 to http://0.0.0.0:30000/generate at 1753383146.7147574
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_153 with payload: {'text': 'Random prompt 153 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_154 to http://0.0.0.0:30000/generate at 1753383146.7148786
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_154 with payload: {'text': 'Random prompt 154 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_155 to http://0.0.0.0:30000/generate at 1753383146.7150085
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_155 with payload: {'text': 'Random prompt 155 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 160, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_156 to http://0.0.0.0:30000/generate at 1753383146.7151506
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_156 with payload: {'text': 'Random prompt 156 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 84, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_157 to http://0.0.0.0:30000/generate at 1753383146.7153435
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_157 with payload: {'text': 'Random prompt 157 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_158 to http://0.0.0.0:30000/generate at 1753383146.7154713
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_158 with payload: {'text': 'Random prompt 158 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_159 to http://0.0.0.0:30000/generate at 1753383146.7156007
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_159 with payload: {'text': 'Random prompt 159 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_160 to http://0.0.0.0:30000/generate at 1753383146.7157278
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_160 with payload: {'text': 'Random prompt 160 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_161 to http://0.0.0.0:30000/generate at 1753383146.715854
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_161 with payload: {'text': 'Random prompt 161 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_162 to http://0.0.0.0:30000/generate at 1753383146.7159812
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_162 with payload: {'text': 'Random prompt 162 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_163 to http://0.0.0.0:30000/generate at 1753383146.716107
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_163 with payload: {'text': 'Random prompt 163 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 159, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_164 to http://0.0.0.0:30000/generate at 1753383146.7162464
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_164 with payload: {'text': 'Random prompt 164 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_165 to http://0.0.0.0:30000/generate at 1753383146.7163758
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_165 with payload: {'text': 'Random prompt 165 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_166 to http://0.0.0.0:30000/generate at 1753383146.7165265
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_166 with payload: {'text': 'Random prompt 166 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 171, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_167 to http://0.0.0.0:30000/generate at 1753383146.7166576
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_167 with payload: {'text': 'Random prompt 167 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 129, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_168 to http://0.0.0.0:30000/generate at 1753383146.716782
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_168 with payload: {'text': 'Random prompt 168 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_169 to http://0.0.0.0:30000/generate at 1753383146.7169566
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_169 with payload: {'text': 'Random prompt 169 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 101, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_170 to http://0.0.0.0:30000/generate at 1753383146.7170877
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_170 with payload: {'text': 'Random prompt 170 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_171 to http://0.0.0.0:30000/generate at 1753383146.7172256
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_171 with payload: {'text': 'Random prompt 171 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_172 to http://0.0.0.0:30000/generate at 1753383146.717355
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_172 with payload: {'text': 'Random prompt 172 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_173 to http://0.0.0.0:30000/generate at 1753383146.717484
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_173 with payload: {'text': 'Random prompt 173 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_174 to http://0.0.0.0:30000/generate at 1753383146.7176118
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_174 with payload: {'text': 'Random prompt 174 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_175 to http://0.0.0.0:30000/generate at 1753383146.7177389
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_175 with payload: {'text': 'Random prompt 175 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_176 to http://0.0.0.0:30000/generate at 1753383146.7178674
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_176 with payload: {'text': 'Random prompt 176 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_177 to http://0.0.0.0:30000/generate at 1753383146.7179947
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_177 with payload: {'text': 'Random prompt 177 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_178 to http://0.0.0.0:30000/generate at 1753383146.7181194
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_178 with payload: {'text': 'Random prompt 178 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_179 to http://0.0.0.0:30000/generate at 1753383146.7182598
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_179 with payload: {'text': 'Random prompt 179 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_180 to http://0.0.0.0:30000/generate at 1753383146.718384
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_180 with payload: {'text': 'Random prompt 180 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 187, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_181 to http://0.0.0.0:30000/generate at 1753383146.718557
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_181 with payload: {'text': 'Random prompt 181 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_182 to http://0.0.0.0:30000/generate at 1753383146.7186823
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_182 with payload: {'text': 'Random prompt 182 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_183 to http://0.0.0.0:30000/generate at 1753383146.718815
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_183 with payload: {'text': 'Random prompt 183 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_184 to http://0.0.0.0:30000/generate at 1753383146.7189393
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_184 with payload: {'text': 'Random prompt 184 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_185 to http://0.0.0.0:30000/generate at 1753383146.7190726
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_185 with payload: {'text': 'Random prompt 185 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_186 to http://0.0.0.0:30000/generate at 1753383146.7192116
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_186 with payload: {'text': 'Random prompt 186 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_187 to http://0.0.0.0:30000/generate at 1753383146.7193353
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_187 with payload: {'text': 'Random prompt 187 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_188 to http://0.0.0.0:30000/generate at 1753383146.7194648
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_188 with payload: {'text': 'Random prompt 188 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_189 to http://0.0.0.0:30000/generate at 1753383146.7195997
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_189 with payload: {'text': 'Random prompt 189 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_190 to http://0.0.0.0:30000/generate at 1753383146.719722
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_190 with payload: {'text': 'Random prompt 190 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_191 to http://0.0.0.0:30000/generate at 1753383146.7198474
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_191 with payload: {'text': 'Random prompt 191 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 139, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_192 to http://0.0.0.0:30000/generate at 1753383146.7199736
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_192 with payload: {'text': 'Random prompt 192 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_193 to http://0.0.0.0:30000/generate at 1753383146.7201488
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_193 with payload: {'text': 'Random prompt 193 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_194 to http://0.0.0.0:30000/generate at 1753383146.7202904
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_194 with payload: {'text': 'Random prompt 194 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 70, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_195 to http://0.0.0.0:30000/generate at 1753383146.7204144
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_195 with payload: {'text': 'Random prompt 195 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_196 to http://0.0.0.0:30000/generate at 1753383146.7205458
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_196 with payload: {'text': 'Random prompt 196 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_197 to http://0.0.0.0:30000/generate at 1753383146.7206748
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_197 with payload: {'text': 'Random prompt 197 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_198 to http://0.0.0.0:30000/generate at 1753383146.7208004
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_198 with payload: {'text': 'Random prompt 198 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 160, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_199 to http://0.0.0.0:30000/generate at 1753383146.7209265
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_199 with payload: {'text': 'Random prompt 199 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_200 to http://0.0.0.0:30000/generate at 1753383146.7210493
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_200 with payload: {'text': 'Random prompt 200 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_201 to http://0.0.0.0:30000/generate at 1753383146.7211745
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_201 with payload: {'text': 'Random prompt 201 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_202 to http://0.0.0.0:30000/generate at 1753383146.7213137
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_202 with payload: {'text': 'Random prompt 202 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_203 to http://0.0.0.0:30000/generate at 1753383146.7214444
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_203 with payload: {'text': 'Random prompt 203 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 105, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_204 to http://0.0.0.0:30000/generate at 1753383146.7215724
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_204 with payload: {'text': 'Random prompt 204 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_205 to http://0.0.0.0:30000/generate at 1753383146.721743
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_205 with payload: {'text': 'Random prompt 205 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_206 to http://0.0.0.0:30000/generate at 1753383146.7218695
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_206 with payload: {'text': 'Random prompt 206 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_207 to http://0.0.0.0:30000/generate at 1753383146.7219965
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_207 with payload: {'text': 'Random prompt 207 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 121, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_208 to http://0.0.0.0:30000/generate at 1753383146.7221274
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_208 with payload: {'text': 'Random prompt 208 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_209 to http://0.0.0.0:30000/generate at 1753383146.7222602
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_209 with payload: {'text': 'Random prompt 209 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_210 to http://0.0.0.0:30000/generate at 1753383146.7223904
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_210 with payload: {'text': 'Random prompt 210 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_211 to http://0.0.0.0:30000/generate at 1753383146.7225196
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_211 with payload: {'text': 'Random prompt 211 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_212 to http://0.0.0.0:30000/generate at 1753383146.7226448
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_212 with payload: {'text': 'Random prompt 212 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_213 to http://0.0.0.0:30000/generate at 1753383146.7227743
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_213 with payload: {'text': 'Random prompt 213 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_214 to http://0.0.0.0:30000/generate at 1753383146.7229025
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_214 with payload: {'text': 'Random prompt 214 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_215 to http://0.0.0.0:30000/generate at 1753383146.7230241
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_215 with payload: {'text': 'Random prompt 215 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_216 to http://0.0.0.0:30000/generate at 1753383146.7231457
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_216 with payload: {'text': 'Random prompt 216 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_217 to http://0.0.0.0:30000/generate at 1753383146.7233365
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_217 with payload: {'text': 'Random prompt 217 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_218 to http://0.0.0.0:30000/generate at 1753383146.7234635
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_218 with payload: {'text': 'Random prompt 218 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_219 to http://0.0.0.0:30000/generate at 1753383146.7235925
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_219 with payload: {'text': 'Random prompt 219 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_220 to http://0.0.0.0:30000/generate at 1753383146.7237198
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_220 with payload: {'text': 'Random prompt 220 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_221 to http://0.0.0.0:30000/generate at 1753383146.7238443
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_221 with payload: {'text': 'Random prompt 221 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_222 to http://0.0.0.0:30000/generate at 1753383146.7239676
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_222 with payload: {'text': 'Random prompt 222 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_223 to http://0.0.0.0:30000/generate at 1753383146.7240968
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_223 with payload: {'text': 'Random prompt 223 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_224 to http://0.0.0.0:30000/generate at 1753383146.7242277
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_224 with payload: {'text': 'Random prompt 224 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 118, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_225 to http://0.0.0.0:30000/generate at 1753383146.724364
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_225 with payload: {'text': 'Random prompt 225 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_226 to http://0.0.0.0:30000/generate at 1753383146.7244895
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_226 with payload: {'text': 'Random prompt 226 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_227 to http://0.0.0.0:30000/generate at 1753383146.724616
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_227 with payload: {'text': 'Random prompt 227 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_228 to http://0.0.0.0:30000/generate at 1753383146.7247458
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_228 with payload: {'text': 'Random prompt 228 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_229 to http://0.0.0.0:30000/generate at 1753383146.72492
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_229 with payload: {'text': 'Random prompt 229 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_230 to http://0.0.0.0:30000/generate at 1753383146.7250454
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_230 with payload: {'text': 'Random prompt 230 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 178, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_231 to http://0.0.0.0:30000/generate at 1753383146.7251704
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_231 with payload: {'text': 'Random prompt 231 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_232 to http://0.0.0.0:30000/generate at 1753383146.7253003
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_232 with payload: {'text': 'Random prompt 232 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 91, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_233 to http://0.0.0.0:30000/generate at 1753383146.725432
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_233 with payload: {'text': 'Random prompt 233 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_234 to http://0.0.0.0:30000/generate at 1753383146.7255585
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_234 with payload: {'text': 'Random prompt 234 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_235 to http://0.0.0.0:30000/generate at 1753383146.7256792
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_235 with payload: {'text': 'Random prompt 235 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_236 to http://0.0.0.0:30000/generate at 1753383146.7258039
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_236 with payload: {'text': 'Random prompt 236 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_237 to http://0.0.0.0:30000/generate at 1753383146.725927
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_237 with payload: {'text': 'Random prompt 237 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_238 to http://0.0.0.0:30000/generate at 1753383146.7260516
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_238 with payload: {'text': 'Random prompt 238 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_239 to http://0.0.0.0:30000/generate at 1753383146.7261848
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_239 with payload: {'text': 'Random prompt 239 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_240 to http://0.0.0.0:30000/generate at 1753383146.7263153
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_240 with payload: {'text': 'Random prompt 240 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_241 to http://0.0.0.0:30000/generate at 1753383146.7264924
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_241 with payload: {'text': 'Random prompt 241 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_242 to http://0.0.0.0:30000/generate at 1753383146.7266197
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_242 with payload: {'text': 'Random prompt 242 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_243 to http://0.0.0.0:30000/generate at 1753383146.726752
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_243 with payload: {'text': 'Random prompt 243 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_244 to http://0.0.0.0:30000/generate at 1753383146.726878
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_244 with payload: {'text': 'Random prompt 244 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_245 to http://0.0.0.0:30000/generate at 1753383146.7270007
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_245 with payload: {'text': 'Random prompt 245 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_246 to http://0.0.0.0:30000/generate at 1753383146.7271314
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_246 with payload: {'text': 'Random prompt 246 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_247 to http://0.0.0.0:30000/generate at 1753383146.7272632
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_247 with payload: {'text': 'Random prompt 247 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_248 to http://0.0.0.0:30000/generate at 1753383146.727389
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_248 with payload: {'text': 'Random prompt 248 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 182, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_249 to http://0.0.0.0:30000/generate at 1753383146.727524
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_249 with payload: {'text': 'Random prompt 249 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_250 to http://0.0.0.0:30000/generate at 1753383146.7276516
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_250 with payload: {'text': 'Random prompt 250 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_251 to http://0.0.0.0:30000/generate at 1753383146.727774
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_251 with payload: {'text': 'Random prompt 251 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_252 to http://0.0.0.0:30000/generate at 1753383146.7279096
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_252 with payload: {'text': 'Random prompt 252 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 79, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_253 to http://0.0.0.0:30000/generate at 1753383146.7286537
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_253 with payload: {'text': 'Random prompt 253 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_254 to http://0.0.0.0:30000/generate at 1753383146.7287912
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_254 with payload: {'text': 'Random prompt 254 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_255 to http://0.0.0.0:30000/generate at 1753383146.728919
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_255 with payload: {'text': 'Random prompt 255 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_256 to http://0.0.0.0:30000/generate at 1753383146.729045
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_256 with payload: {'text': 'Random prompt 256 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_257 to http://0.0.0.0:30000/generate at 1753383146.7291849
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_257 with payload: {'text': 'Random prompt 257 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_258 to http://0.0.0.0:30000/generate at 1753383146.7293112
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_258 with payload: {'text': 'Random prompt 258 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_259 to http://0.0.0.0:30000/generate at 1753383146.729434
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_259 with payload: {'text': 'Random prompt 259 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 138, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_260 to http://0.0.0.0:30000/generate at 1753383146.7295609
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_260 with payload: {'text': 'Random prompt 260 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 98, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_261 to http://0.0.0.0:30000/generate at 1753383146.7296922
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_261 with payload: {'text': 'Random prompt 261 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_262 to http://0.0.0.0:30000/generate at 1753383146.7298214
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_262 with payload: {'text': 'Random prompt 262 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 104, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_263 to http://0.0.0.0:30000/generate at 1753383146.729956
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_263 with payload: {'text': 'Random prompt 263 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_264 to http://0.0.0.0:30000/generate at 1753383146.7300828
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_264 with payload: {'text': 'Random prompt 264 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_265 to http://0.0.0.0:30000/generate at 1753383146.7302635
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_265 with payload: {'text': 'Random prompt 265 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_266 to http://0.0.0.0:30000/generate at 1753383146.7303903
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_266 with payload: {'text': 'Random prompt 266 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_267 to http://0.0.0.0:30000/generate at 1753383146.7305143
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_267 with payload: {'text': 'Random prompt 267 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_268 to http://0.0.0.0:30000/generate at 1753383146.730651
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_268 with payload: {'text': 'Random prompt 268 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_269 to http://0.0.0.0:30000/generate at 1753383146.7307765
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_269 with payload: {'text': 'Random prompt 269 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 101, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_270 to http://0.0.0.0:30000/generate at 1753383146.7309017
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_270 with payload: {'text': 'Random prompt 270 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_271 to http://0.0.0.0:30000/generate at 1753383146.7310388
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_271 with payload: {'text': 'Random prompt 271 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 174, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_272 to http://0.0.0.0:30000/generate at 1753383146.7311697
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_272 with payload: {'text': 'Random prompt 272 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_273 to http://0.0.0.0:30000/generate at 1753383146.7313085
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_273 with payload: {'text': 'Random prompt 273 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_274 to http://0.0.0.0:30000/generate at 1753383146.731435
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_274 with payload: {'text': 'Random prompt 274 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_275 to http://0.0.0.0:30000/generate at 1753383146.7315633
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_275 with payload: {'text': 'Random prompt 275 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_276 to http://0.0.0.0:30000/generate at 1753383146.7316895
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_276 with payload: {'text': 'Random prompt 276 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 95, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_277 to http://0.0.0.0:30000/generate at 1753383146.7318583
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_277 with payload: {'text': 'Random prompt 277 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_278 to http://0.0.0.0:30000/generate at 1753383146.7319877
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_278 with payload: {'text': 'Random prompt 278 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 82, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_279 to http://0.0.0.0:30000/generate at 1753383146.7321115
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_279 with payload: {'text': 'Random prompt 279 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_280 to http://0.0.0.0:30000/generate at 1753383146.7322476
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_280 with payload: {'text': 'Random prompt 280 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_281 to http://0.0.0.0:30000/generate at 1753383146.7323763
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_281 with payload: {'text': 'Random prompt 281 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 154, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_282 to http://0.0.0.0:30000/generate at 1753383146.7325017
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_282 with payload: {'text': 'Random prompt 282 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 136, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_283 to http://0.0.0.0:30000/generate at 1753383146.7326608
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_283 with payload: {'text': 'Random prompt 283 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_284 to http://0.0.0.0:30000/generate at 1753383146.7327855
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_284 with payload: {'text': 'Random prompt 284 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_285 to http://0.0.0.0:30000/generate at 1753383146.7329102
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_285 with payload: {'text': 'Random prompt 285 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_286 to http://0.0.0.0:30000/generate at 1753383146.7330396
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_286 with payload: {'text': 'Random prompt 286 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_287 to http://0.0.0.0:30000/generate at 1753383146.7331653
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_287 with payload: {'text': 'Random prompt 287 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_288 to http://0.0.0.0:30000/generate at 1753383146.7332969
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_288 with payload: {'text': 'Random prompt 288 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_289 to http://0.0.0.0:30000/generate at 1753383146.7334697
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_289 with payload: {'text': 'Random prompt 289 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_290 to http://0.0.0.0:30000/generate at 1753383146.7335954
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_290 with payload: {'text': 'Random prompt 290 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_291 to http://0.0.0.0:30000/generate at 1753383146.7337189
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_291 with payload: {'text': 'Random prompt 291 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_292 to http://0.0.0.0:30000/generate at 1753383146.7338462
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_292 with payload: {'text': 'Random prompt 292 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 137, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_293 to http://0.0.0.0:30000/generate at 1753383146.733974
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_293 with payload: {'text': 'Random prompt 293 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_294 to http://0.0.0.0:30000/generate at 1753383146.7341008
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_294 with payload: {'text': 'Random prompt 294 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_295 to http://0.0.0.0:30000/generate at 1753383146.7342303
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_295 with payload: {'text': 'Random prompt 295 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_296 to http://0.0.0.0:30000/generate at 1753383146.7343583
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_296 with payload: {'text': 'Random prompt 296 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_297 to http://0.0.0.0:30000/generate at 1753383146.7344832
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_297 with payload: {'text': 'Random prompt 297 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_298 to http://0.0.0.0:30000/generate at 1753383146.7346098
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_298 with payload: {'text': 'Random prompt 298 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_299 to http://0.0.0.0:30000/generate at 1753383146.7347314
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_299 with payload: {'text': 'Random prompt 299 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 154, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_300 to http://0.0.0.0:30000/generate at 1753383146.7348523
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_300 with payload: {'text': 'Random prompt 300 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_301 to http://0.0.0.0:30000/generate at 1753383146.735023
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_301 with payload: {'text': 'Random prompt 301 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_302 to http://0.0.0.0:30000/generate at 1753383146.7351499
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_302 with payload: {'text': 'Random prompt 302 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_303 to http://0.0.0.0:30000/generate at 1753383146.7352843
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_303 with payload: {'text': 'Random prompt 303 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_304 to http://0.0.0.0:30000/generate at 1753383146.7354121
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_304 with payload: {'text': 'Random prompt 304 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_305 to http://0.0.0.0:30000/generate at 1753383146.7355382
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_305 with payload: {'text': 'Random prompt 305 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_306 to http://0.0.0.0:30000/generate at 1753383146.7356665
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_306 with payload: {'text': 'Random prompt 306 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_307 to http://0.0.0.0:30000/generate at 1753383146.7357945
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_307 with payload: {'text': 'Random prompt 307 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_308 to http://0.0.0.0:30000/generate at 1753383146.7359197
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_308 with payload: {'text': 'Random prompt 308 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_309 to http://0.0.0.0:30000/generate at 1753383146.7360432
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_309 with payload: {'text': 'Random prompt 309 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_310 to http://0.0.0.0:30000/generate at 1753383146.7361815
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_310 with payload: {'text': 'Random prompt 310 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_311 to http://0.0.0.0:30000/generate at 1753383146.736307
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_311 with payload: {'text': 'Random prompt 311 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 179, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_312 to http://0.0.0.0:30000/generate at 1753383146.7364328
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_312 with payload: {'text': 'Random prompt 312 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_313 to http://0.0.0.0:30000/generate at 1753383146.736601
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_313 with payload: {'text': 'Random prompt 313 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_314 to http://0.0.0.0:30000/generate at 1753383146.7367249
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_314 with payload: {'text': 'Random prompt 314 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_315 to http://0.0.0.0:30000/generate at 1753383146.7368507
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_315 with payload: {'text': 'Random prompt 315 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_316 to http://0.0.0.0:30000/generate at 1753383146.736976
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_316 with payload: {'text': 'Random prompt 316 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 131, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_317 to http://0.0.0.0:30000/generate at 1753383146.7371008
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_317 with payload: {'text': 'Random prompt 317 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_318 to http://0.0.0.0:30000/generate at 1753383146.7372303
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_318 with payload: {'text': 'Random prompt 318 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_319 to http://0.0.0.0:30000/generate at 1753383146.7373583
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_319 with payload: {'text': 'Random prompt 319 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_320 to http://0.0.0.0:30000/generate at 1753383146.7374794
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_320 with payload: {'text': 'Random prompt 320 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 96, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_321 to http://0.0.0.0:30000/generate at 1753383146.7376077
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_321 with payload: {'text': 'Random prompt 321 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 84, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_322 to http://0.0.0.0:30000/generate at 1753383146.7377343
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_322 with payload: {'text': 'Random prompt 322 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_323 to http://0.0.0.0:30000/generate at 1753383146.7378614
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_323 with payload: {'text': 'Random prompt 323 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_324 to http://0.0.0.0:30000/generate at 1753383146.7379847
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_324 with payload: {'text': 'Random prompt 324 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_325 to http://0.0.0.0:30000/generate at 1753383146.7381568
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_325 with payload: {'text': 'Random prompt 325 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_326 to http://0.0.0.0:30000/generate at 1753383146.73829
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_326 with payload: {'text': 'Random prompt 326 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_327 to http://0.0.0.0:30000/generate at 1753383146.7384121
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_327 with payload: {'text': 'Random prompt 327 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_328 to http://0.0.0.0:30000/generate at 1753383146.7385406
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_328 with payload: {'text': 'Random prompt 328 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_329 to http://0.0.0.0:30000/generate at 1753383146.738665
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_329 with payload: {'text': 'Random prompt 329 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_330 to http://0.0.0.0:30000/generate at 1753383146.7387943
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_330 with payload: {'text': 'Random prompt 330 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 135, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_331 to http://0.0.0.0:30000/generate at 1753383146.7389216
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_331 with payload: {'text': 'Random prompt 331 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_332 to http://0.0.0.0:30000/generate at 1753383146.739048
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_332 with payload: {'text': 'Random prompt 332 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_333 to http://0.0.0.0:30000/generate at 1753383146.7391734
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_333 with payload: {'text': 'Random prompt 333 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_334 to http://0.0.0.0:30000/generate at 1753383146.7393055
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_334 with payload: {'text': 'Random prompt 334 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_335 to http://0.0.0.0:30000/generate at 1753383146.739427
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_335 with payload: {'text': 'Random prompt 335 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_336 to http://0.0.0.0:30000/generate at 1753383146.7395496
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_336 with payload: {'text': 'Random prompt 336 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_337 to http://0.0.0.0:30000/generate at 1753383146.7397225
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_337 with payload: {'text': 'Random prompt 337 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_338 to http://0.0.0.0:30000/generate at 1753383146.7398477
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_338 with payload: {'text': 'Random prompt 338 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_339 to http://0.0.0.0:30000/generate at 1753383146.7399728
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_339 with payload: {'text': 'Random prompt 339 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_340 to http://0.0.0.0:30000/generate at 1753383146.7401054
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_340 with payload: {'text': 'Random prompt 340 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_341 to http://0.0.0.0:30000/generate at 1753383146.7402382
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_341 with payload: {'text': 'Random prompt 341 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_342 to http://0.0.0.0:30000/generate at 1753383146.7403622
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_342 with payload: {'text': 'Random prompt 342 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_343 to http://0.0.0.0:30000/generate at 1753383146.7404857
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_343 with payload: {'text': 'Random prompt 343 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_344 to http://0.0.0.0:30000/generate at 1753383146.740611
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_344 with payload: {'text': 'Random prompt 344 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 159, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_345 to http://0.0.0.0:30000/generate at 1753383146.7407322
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_345 with payload: {'text': 'Random prompt 345 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 118, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_346 to http://0.0.0.0:30000/generate at 1753383146.740855
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_346 with payload: {'text': 'Random prompt 346 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_347 to http://0.0.0.0:30000/generate at 1753383146.7409854
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_347 with payload: {'text': 'Random prompt 347 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_348 to http://0.0.0.0:30000/generate at 1753383146.741109
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_348 with payload: {'text': 'Random prompt 348 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_349 to http://0.0.0.0:30000/generate at 1753383146.7412884
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_349 with payload: {'text': 'Random prompt 349 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_350 to http://0.0.0.0:30000/generate at 1753383146.7414138
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_350 with payload: {'text': 'Random prompt 350 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_351 to http://0.0.0.0:30000/generate at 1753383146.7415414
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_351 with payload: {'text': 'Random prompt 351 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 138, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_352 to http://0.0.0.0:30000/generate at 1753383146.7416694
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_352 with payload: {'text': 'Random prompt 352 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_353 to http://0.0.0.0:30000/generate at 1753383146.741814
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_353 with payload: {'text': 'Random prompt 353 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_354 to http://0.0.0.0:30000/generate at 1753383146.7419407
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_354 with payload: {'text': 'Random prompt 354 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_355 to http://0.0.0.0:30000/generate at 1753383146.7420728
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_355 with payload: {'text': 'Random prompt 355 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_356 to http://0.0.0.0:30000/generate at 1753383146.7422032
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_356 with payload: {'text': 'Random prompt 356 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 179, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_357 to http://0.0.0.0:30000/generate at 1753383146.7423263
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_357 with payload: {'text': 'Random prompt 357 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 118, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_358 to http://0.0.0.0:30000/generate at 1753383146.7424488
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_358 with payload: {'text': 'Random prompt 358 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_359 to http://0.0.0.0:30000/generate at 1753383146.74258
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_359 with payload: {'text': 'Random prompt 359 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_360 to http://0.0.0.0:30000/generate at 1753383146.7427049
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_360 with payload: {'text': 'Random prompt 360 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 181, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_361 to http://0.0.0.0:30000/generate at 1753383146.742877
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_361 with payload: {'text': 'Random prompt 361 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 91, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_362 to http://0.0.0.0:30000/generate at 1753383146.7430024
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_362 with payload: {'text': 'Random prompt 362 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_363 to http://0.0.0.0:30000/generate at 1753383146.743132
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_363 with payload: {'text': 'Random prompt 363 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_364 to http://0.0.0.0:30000/generate at 1753383146.7432709
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_364 with payload: {'text': 'Random prompt 364 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_365 to http://0.0.0.0:30000/generate at 1753383146.7434034
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_365 with payload: {'text': 'Random prompt 365 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_366 to http://0.0.0.0:30000/generate at 1753383146.7435286
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_366 with payload: {'text': 'Random prompt 366 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_367 to http://0.0.0.0:30000/generate at 1753383146.7436588
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_367 with payload: {'text': 'Random prompt 367 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 180, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_368 to http://0.0.0.0:30000/generate at 1753383146.7437816
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_368 with payload: {'text': 'Random prompt 368 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_369 to http://0.0.0.0:30000/generate at 1753383146.7439036
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_369 with payload: {'text': 'Random prompt 369 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_370 to http://0.0.0.0:30000/generate at 1753383146.744041
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_370 with payload: {'text': 'Random prompt 370 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_371 to http://0.0.0.0:30000/generate at 1753383146.7441666
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_371 with payload: {'text': 'Random prompt 371 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_372 to http://0.0.0.0:30000/generate at 1753383146.744294
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_372 with payload: {'text': 'Random prompt 372 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 173, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_373 to http://0.0.0.0:30000/generate at 1753383146.7444742
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_373 with payload: {'text': 'Random prompt 373 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_374 to http://0.0.0.0:30000/generate at 1753383146.744595
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_374 with payload: {'text': 'Random prompt 374 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 96, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_375 to http://0.0.0.0:30000/generate at 1753383146.7447152
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_375 with payload: {'text': 'Random prompt 375 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_376 to http://0.0.0.0:30000/generate at 1753383146.7448428
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_376 with payload: {'text': 'Random prompt 376 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 121, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_377 to http://0.0.0.0:30000/generate at 1753383146.74497
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_377 with payload: {'text': 'Random prompt 377 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_378 to http://0.0.0.0:30000/generate at 1753383146.7450974
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_378 with payload: {'text': 'Random prompt 378 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 110, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_379 to http://0.0.0.0:30000/generate at 1753383146.7452261
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_379 with payload: {'text': 'Random prompt 379 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_380 to http://0.0.0.0:30000/generate at 1753383146.7453504
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_380 with payload: {'text': 'Random prompt 380 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_381 to http://0.0.0.0:30000/generate at 1753383146.7454793
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_381 with payload: {'text': 'Random prompt 381 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_382 to http://0.0.0.0:30000/generate at 1753383146.7456243
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_382 with payload: {'text': 'Random prompt 382 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_383 to http://0.0.0.0:30000/generate at 1753383146.7457533
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_383 with payload: {'text': 'Random prompt 383 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_384 to http://0.0.0.0:30000/generate at 1753383146.745883
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_384 with payload: {'text': 'Random prompt 384 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_385 to http://0.0.0.0:30000/generate at 1753383146.746058
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_385 with payload: {'text': 'Random prompt 385 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_386 to http://0.0.0.0:30000/generate at 1753383146.7461872
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_386 with payload: {'text': 'Random prompt 386 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_387 to http://0.0.0.0:30000/generate at 1753383146.7463121
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_387 with payload: {'text': 'Random prompt 387 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_388 to http://0.0.0.0:30000/generate at 1753383146.7464356
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_388 with payload: {'text': 'Random prompt 388 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_389 to http://0.0.0.0:30000/generate at 1753383146.7465615
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_389 with payload: {'text': 'Random prompt 389 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_390 to http://0.0.0.0:30000/generate at 1753383146.746713
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_390 with payload: {'text': 'Random prompt 390 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_391 to http://0.0.0.0:30000/generate at 1753383146.746846
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_391 with payload: {'text': 'Random prompt 391 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_392 to http://0.0.0.0:30000/generate at 1753383146.7469704
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_392 with payload: {'text': 'Random prompt 392 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_393 to http://0.0.0.0:30000/generate at 1753383146.7471037
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_393 with payload: {'text': 'Random prompt 393 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 131, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_394 to http://0.0.0.0:30000/generate at 1753383146.7472389
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_394 with payload: {'text': 'Random prompt 394 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_395 to http://0.0.0.0:30000/generate at 1753383146.7473698
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_395 with payload: {'text': 'Random prompt 395 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_396 to http://0.0.0.0:30000/generate at 1753383146.7474964
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_396 with payload: {'text': 'Random prompt 396 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_397 to http://0.0.0.0:30000/generate at 1753383146.7482314
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_397 with payload: {'text': 'Random prompt 397 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 96, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_398 to http://0.0.0.0:30000/generate at 1753383146.7483728
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_398 with payload: {'text': 'Random prompt 398 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_399 to http://0.0.0.0:30000/generate at 1753383146.7484956
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_399 with payload: {'text': 'Random prompt 399 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 154, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_400 to http://0.0.0.0:30000/generate at 1753383146.7486205
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_400 with payload: {'text': 'Random prompt 400 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_401 to http://0.0.0.0:30000/generate at 1753383146.7487495
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_401 with payload: {'text': 'Random prompt 401 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_402 to http://0.0.0.0:30000/generate at 1753383146.7488754
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_402 with payload: {'text': 'Random prompt 402 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_403 to http://0.0.0.0:30000/generate at 1753383146.7489972
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_403 with payload: {'text': 'Random prompt 403 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_404 to http://0.0.0.0:30000/generate at 1753383146.7491663
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_404 with payload: {'text': 'Random prompt 404 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_405 to http://0.0.0.0:30000/generate at 1753383146.7493045
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_405 with payload: {'text': 'Random prompt 405 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_406 to http://0.0.0.0:30000/generate at 1753383146.7494261
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_406 with payload: {'text': 'Random prompt 406 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_407 to http://0.0.0.0:30000/generate at 1753383146.7495515
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_407 with payload: {'text': 'Random prompt 407 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_408 to http://0.0.0.0:30000/generate at 1753383146.749675
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_408 with payload: {'text': 'Random prompt 408 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 139, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_409 to http://0.0.0.0:30000/generate at 1753383146.7498474
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_409 with payload: {'text': 'Random prompt 409 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_410 to http://0.0.0.0:30000/generate at 1753383146.749973
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_410 with payload: {'text': 'Random prompt 410 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_411 to http://0.0.0.0:30000/generate at 1753383146.7500944
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_411 with payload: {'text': 'Random prompt 411 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_412 to http://0.0.0.0:30000/generate at 1753383146.750224
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_412 with payload: {'text': 'Random prompt 412 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_413 to http://0.0.0.0:30000/generate at 1753383146.7503543
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_413 with payload: {'text': 'Random prompt 413 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_414 to http://0.0.0.0:30000/generate at 1753383146.7504814
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_414 with payload: {'text': 'Random prompt 414 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 132, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_415 to http://0.0.0.0:30000/generate at 1753383146.7506037
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_415 with payload: {'text': 'Random prompt 415 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_416 to http://0.0.0.0:30000/generate at 1753383146.7507298
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_416 with payload: {'text': 'Random prompt 416 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_417 to http://0.0.0.0:30000/generate at 1753383146.7508569
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_417 with payload: {'text': 'Random prompt 417 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_418 to http://0.0.0.0:30000/generate at 1753383146.7509773
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_418 with payload: {'text': 'Random prompt 418 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_419 to http://0.0.0.0:30000/generate at 1753383146.7511027
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_419 with payload: {'text': 'Random prompt 419 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_420 to http://0.0.0.0:30000/generate at 1753383146.7512307
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_420 with payload: {'text': 'Random prompt 420 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 104, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_421 to http://0.0.0.0:30000/generate at 1753383146.7514074
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_421 with payload: {'text': 'Random prompt 421 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 129, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_422 to http://0.0.0.0:30000/generate at 1753383146.7515366
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_422 with payload: {'text': 'Random prompt 422 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_423 to http://0.0.0.0:30000/generate at 1753383146.7516587
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_423 with payload: {'text': 'Random prompt 423 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_424 to http://0.0.0.0:30000/generate at 1753383146.751783
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_424 with payload: {'text': 'Random prompt 424 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_425 to http://0.0.0.0:30000/generate at 1753383146.7519097
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_425 with payload: {'text': 'Random prompt 425 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_426 to http://0.0.0.0:30000/generate at 1753383146.752031
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_426 with payload: {'text': 'Random prompt 426 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_427 to http://0.0.0.0:30000/generate at 1753383146.752152
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_427 with payload: {'text': 'Random prompt 427 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_428 to http://0.0.0.0:30000/generate at 1753383146.7522888
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_428 with payload: {'text': 'Random prompt 428 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_429 to http://0.0.0.0:30000/generate at 1753383146.7524085
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_429 with payload: {'text': 'Random prompt 429 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_430 to http://0.0.0.0:30000/generate at 1753383146.7525282
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_430 with payload: {'text': 'Random prompt 430 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_431 to http://0.0.0.0:30000/generate at 1753383146.752661
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_431 with payload: {'text': 'Random prompt 431 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_432 to http://0.0.0.0:30000/generate at 1753383146.7527833
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_432 with payload: {'text': 'Random prompt 432 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 127, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_433 to http://0.0.0.0:30000/generate at 1753383146.752959
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_433 with payload: {'text': 'Random prompt 433 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_434 to http://0.0.0.0:30000/generate at 1753383146.753092
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_434 with payload: {'text': 'Random prompt 434 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 82, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_435 to http://0.0.0.0:30000/generate at 1753383146.753221
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_435 with payload: {'text': 'Random prompt 435 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_436 to http://0.0.0.0:30000/generate at 1753383146.7533486
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_436 with payload: {'text': 'Random prompt 436 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_437 to http://0.0.0.0:30000/generate at 1753383146.7534764
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_437 with payload: {'text': 'Random prompt 437 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 154, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_438 to http://0.0.0.0:30000/generate at 1753383146.753603
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_438 with payload: {'text': 'Random prompt 438 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_439 to http://0.0.0.0:30000/generate at 1753383146.753726
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_439 with payload: {'text': 'Random prompt 439 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 150, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_440 to http://0.0.0.0:30000/generate at 1753383146.7538557
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_440 with payload: {'text': 'Random prompt 440 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_441 to http://0.0.0.0:30000/generate at 1753383146.7539778
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_441 with payload: {'text': 'Random prompt 441 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 76, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_442 to http://0.0.0.0:30000/generate at 1753383146.7541227
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_442 with payload: {'text': 'Random prompt 442 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 150, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_443 to http://0.0.0.0:30000/generate at 1753383146.7542608
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_443 with payload: {'text': 'Random prompt 443 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 121, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_444 to http://0.0.0.0:30000/generate at 1753383146.7543886
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_444 with payload: {'text': 'Random prompt 444 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_445 to http://0.0.0.0:30000/generate at 1753383146.7545662
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_445 with payload: {'text': 'Random prompt 445 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_446 to http://0.0.0.0:30000/generate at 1753383146.7546923
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_446 with payload: {'text': 'Random prompt 446 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_447 to http://0.0.0.0:30000/generate at 1753383146.7548215
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_447 with payload: {'text': 'Random prompt 447 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 171, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_448 to http://0.0.0.0:30000/generate at 1753383146.7549434
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_448 with payload: {'text': 'Random prompt 448 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_449 to http://0.0.0.0:30000/generate at 1753383146.7550695
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_449 with payload: {'text': 'Random prompt 449 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_450 to http://0.0.0.0:30000/generate at 1753383146.7551959
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_450 with payload: {'text': 'Random prompt 450 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_451 to http://0.0.0.0:30000/generate at 1753383146.755325
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_451 with payload: {'text': 'Random prompt 451 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_452 to http://0.0.0.0:30000/generate at 1753383146.7554507
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_452 with payload: {'text': 'Random prompt 452 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_453 to http://0.0.0.0:30000/generate at 1753383146.7555752
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_453 with payload: {'text': 'Random prompt 453 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 137, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_454 to http://0.0.0.0:30000/generate at 1753383146.7557006
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_454 with payload: {'text': 'Random prompt 454 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 68, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_455 to http://0.0.0.0:30000/generate at 1753383146.7558255
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_455 with payload: {'text': 'Random prompt 455 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_456 to http://0.0.0.0:30000/generate at 1753383146.755953
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_456 with payload: {'text': 'Random prompt 456 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_457 to http://0.0.0.0:30000/generate at 1753383146.7561233
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_457 with payload: {'text': 'Random prompt 457 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_458 to http://0.0.0.0:30000/generate at 1753383146.7562566
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_458 with payload: {'text': 'Random prompt 458 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_459 to http://0.0.0.0:30000/generate at 1753383146.7563763
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_459 with payload: {'text': 'Random prompt 459 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_460 to http://0.0.0.0:30000/generate at 1753383146.7565005
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_460 with payload: {'text': 'Random prompt 460 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_461 to http://0.0.0.0:30000/generate at 1753383146.7566218
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_461 with payload: {'text': 'Random prompt 461 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_462 to http://0.0.0.0:30000/generate at 1753383146.7567484
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_462 with payload: {'text': 'Random prompt 462 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_463 to http://0.0.0.0:30000/generate at 1753383146.7568803
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_463 with payload: {'text': 'Random prompt 463 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_464 to http://0.0.0.0:30000/generate at 1753383146.7570026
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_464 with payload: {'text': 'Random prompt 464 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_465 to http://0.0.0.0:30000/generate at 1753383146.757131
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_465 with payload: {'text': 'Random prompt 465 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 70, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_466 to http://0.0.0.0:30000/generate at 1753383146.7572682
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_466 with payload: {'text': 'Random prompt 466 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_467 to http://0.0.0.0:30000/generate at 1753383146.7573895
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_467 with payload: {'text': 'Random prompt 467 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_468 to http://0.0.0.0:30000/generate at 1753383146.757517
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_468 with payload: {'text': 'Random prompt 468 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_469 to http://0.0.0.0:30000/generate at 1753383146.7576888
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_469 with payload: {'text': 'Random prompt 469 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_470 to http://0.0.0.0:30000/generate at 1753383146.7578113
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_470 with payload: {'text': 'Random prompt 470 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 137, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_471 to http://0.0.0.0:30000/generate at 1753383146.7579322
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_471 with payload: {'text': 'Random prompt 471 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 159, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_472 to http://0.0.0.0:30000/generate at 1753383146.7580633
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_472 with payload: {'text': 'Random prompt 472 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_473 to http://0.0.0.0:30000/generate at 1753383146.758192
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_473 with payload: {'text': 'Random prompt 473 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_474 to http://0.0.0.0:30000/generate at 1753383146.7583246
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_474 with payload: {'text': 'Random prompt 474 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_475 to http://0.0.0.0:30000/generate at 1753383146.7584474
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_475 with payload: {'text': 'Random prompt 475 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_476 to http://0.0.0.0:30000/generate at 1753383146.7585683
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_476 with payload: {'text': 'Random prompt 476 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_477 to http://0.0.0.0:30000/generate at 1753383146.7586908
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_477 with payload: {'text': 'Random prompt 477 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_478 to http://0.0.0.0:30000/generate at 1753383146.758817
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_478 with payload: {'text': 'Random prompt 478 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_479 to http://0.0.0.0:30000/generate at 1753383146.7589488
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_479 with payload: {'text': 'Random prompt 479 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_480 to http://0.0.0.0:30000/generate at 1753383146.7590718
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_480 with payload: {'text': 'Random prompt 480 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_481 to http://0.0.0.0:30000/generate at 1753383146.7592468
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_481 with payload: {'text': 'Random prompt 481 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 79, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_482 to http://0.0.0.0:30000/generate at 1753383146.7593746
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_482 with payload: {'text': 'Random prompt 482 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_483 to http://0.0.0.0:30000/generate at 1753383146.7595003
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_483 with payload: {'text': 'Random prompt 483 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_484 to http://0.0.0.0:30000/generate at 1753383146.7596247
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_484 with payload: {'text': 'Random prompt 484 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_485 to http://0.0.0.0:30000/generate at 1753383146.7597463
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_485 with payload: {'text': 'Random prompt 485 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_486 to http://0.0.0.0:30000/generate at 1753383146.7598786
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_486 with payload: {'text': 'Random prompt 486 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_487 to http://0.0.0.0:30000/generate at 1753383146.7600014
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_487 with payload: {'text': 'Random prompt 487 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_488 to http://0.0.0.0:30000/generate at 1753383146.7601225
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_488 with payload: {'text': 'Random prompt 488 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_489 to http://0.0.0.0:30000/generate at 1753383146.7602587
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_489 with payload: {'text': 'Random prompt 489 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 121, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_490 to http://0.0.0.0:30000/generate at 1753383146.760385
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_490 with payload: {'text': 'Random prompt 490 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_491 to http://0.0.0.0:30000/generate at 1753383146.760507
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_491 with payload: {'text': 'Random prompt 491 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 112, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_492 to http://0.0.0.0:30000/generate at 1753383146.76064
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_492 with payload: {'text': 'Random prompt 492 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_493 to http://0.0.0.0:30000/generate at 1753383146.7608166
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_493 with payload: {'text': 'Random prompt 493 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_494 to http://0.0.0.0:30000/generate at 1753383146.7609417
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_494 with payload: {'text': 'Random prompt 494 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_495 to http://0.0.0.0:30000/generate at 1753383146.7610664
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_495 with payload: {'text': 'Random prompt 495 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 150, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_496 to http://0.0.0.0:30000/generate at 1753383146.7611945
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_496 with payload: {'text': 'Random prompt 496 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_497 to http://0.0.0.0:30000/generate at 1753383146.7613258
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_497 with payload: {'text': 'Random prompt 497 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_498 to http://0.0.0.0:30000/generate at 1753383146.7614617
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_498 with payload: {'text': 'Random prompt 498 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 113, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_499 to http://0.0.0.0:30000/generate at 1753383146.7615829
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_499 with payload: {'text': 'Random prompt 499 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_500 to http://0.0.0.0:30000/generate at 1753383146.7617135
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_500 with payload: {'text': 'Random prompt 500 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_501 to http://0.0.0.0:30000/generate at 1753383146.7618384
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_501 with payload: {'text': 'Random prompt 501 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_502 to http://0.0.0.0:30000/generate at 1753383146.7619588
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_502 with payload: {'text': 'Random prompt 502 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_503 to http://0.0.0.0:30000/generate at 1753383146.762087
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_503 with payload: {'text': 'Random prompt 503 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_504 to http://0.0.0.0:30000/generate at 1753383146.7622201
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_504 with payload: {'text': 'Random prompt 504 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 113, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_505 to http://0.0.0.0:30000/generate at 1753383146.7623904
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_505 with payload: {'text': 'Random prompt 505 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_506 to http://0.0.0.0:30000/generate at 1753383146.7625136
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_506 with payload: {'text': 'Random prompt 506 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 138, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_507 to http://0.0.0.0:30000/generate at 1753383146.7626398
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_507 with payload: {'text': 'Random prompt 507 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 132, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_508 to http://0.0.0.0:30000/generate at 1753383146.762762
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_508 with payload: {'text': 'Random prompt 508 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_509 to http://0.0.0.0:30000/generate at 1753383146.76289
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_509 with payload: {'text': 'Random prompt 509 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_510 to http://0.0.0.0:30000/generate at 1753383146.7630138
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_510 with payload: {'text': 'Random prompt 510 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_511 to http://0.0.0.0:30000/generate at 1753383146.7631426
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_511 with payload: {'text': 'Random prompt 511 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_512 to http://0.0.0.0:30000/generate at 1753383146.7632747
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_512 with payload: {'text': 'Random prompt 512 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_513 to http://0.0.0.0:30000/generate at 1753383146.763398
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_513 with payload: {'text': 'Random prompt 513 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 66, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_514 to http://0.0.0.0:30000/generate at 1753383146.7635198
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_514 with payload: {'text': 'Random prompt 514 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 89, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_515 to http://0.0.0.0:30000/generate at 1753383146.7636456
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_515 with payload: {'text': 'Random prompt 515 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_516 to http://0.0.0.0:30000/generate at 1753383146.763781
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_516 with payload: {'text': 'Random prompt 516 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_517 to http://0.0.0.0:30000/generate at 1753383146.7639542
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_517 with payload: {'text': 'Random prompt 517 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 179, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_518 to http://0.0.0.0:30000/generate at 1753383146.7640827
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_518 with payload: {'text': 'Random prompt 518 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 95, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_519 to http://0.0.0.0:30000/generate at 1753383146.7642183
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_519 with payload: {'text': 'Random prompt 519 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_520 to http://0.0.0.0:30000/generate at 1753383146.7643466
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_520 with payload: {'text': 'Random prompt 520 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_521 to http://0.0.0.0:30000/generate at 1753383146.7644725
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_521 with payload: {'text': 'Random prompt 521 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_522 to http://0.0.0.0:30000/generate at 1753383146.7646012
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_522 with payload: {'text': 'Random prompt 522 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_523 to http://0.0.0.0:30000/generate at 1753383146.7647336
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_523 with payload: {'text': 'Random prompt 523 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_524 to http://0.0.0.0:30000/generate at 1753383146.7648594
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_524 with payload: {'text': 'Random prompt 524 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_525 to http://0.0.0.0:30000/generate at 1753383146.764979
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_525 with payload: {'text': 'Random prompt 525 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_526 to http://0.0.0.0:30000/generate at 1753383146.7651002
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_526 with payload: {'text': 'Random prompt 526 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 100, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_527 to http://0.0.0.0:30000/generate at 1753383146.7652314
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_527 with payload: {'text': 'Random prompt 527 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_528 to http://0.0.0.0:30000/generate at 1753383146.7653558
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_528 with payload: {'text': 'Random prompt 528 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_529 to http://0.0.0.0:30000/generate at 1753383146.7655263
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_529 with payload: {'text': 'Random prompt 529 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_530 to http://0.0.0.0:30000/generate at 1753383146.7656553
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_530 with payload: {'text': 'Random prompt 530 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 104, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_531 to http://0.0.0.0:30000/generate at 1753383146.7657764
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_531 with payload: {'text': 'Random prompt 531 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_532 to http://0.0.0.0:30000/generate at 1753383146.7659066
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_532 with payload: {'text': 'Random prompt 532 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_533 to http://0.0.0.0:30000/generate at 1753383146.7660372
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_533 with payload: {'text': 'Random prompt 533 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_534 to http://0.0.0.0:30000/generate at 1753383146.766163
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_534 with payload: {'text': 'Random prompt 534 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_535 to http://0.0.0.0:30000/generate at 1753383146.766294
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_535 with payload: {'text': 'Random prompt 535 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_536 to http://0.0.0.0:30000/generate at 1753383146.7664154
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_536 with payload: {'text': 'Random prompt 536 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_537 to http://0.0.0.0:30000/generate at 1753383146.7665424
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_537 with payload: {'text': 'Random prompt 537 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_538 to http://0.0.0.0:30000/generate at 1753383146.7666674
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_538 with payload: {'text': 'Random prompt 538 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_539 to http://0.0.0.0:30000/generate at 1753383146.76679
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_539 with payload: {'text': 'Random prompt 539 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 131, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_540 to http://0.0.0.0:30000/generate at 1753383146.766914
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_540 with payload: {'text': 'Random prompt 540 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_541 to http://0.0.0.0:30000/generate at 1753383146.767649
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_541 with payload: {'text': 'Random prompt 541 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_542 to http://0.0.0.0:30000/generate at 1753383146.7677817
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_542 with payload: {'text': 'Random prompt 542 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 137, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_543 to http://0.0.0.0:30000/generate at 1753383146.7679052
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_543 with payload: {'text': 'Random prompt 543 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_544 to http://0.0.0.0:30000/generate at 1753383146.7680326
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_544 with payload: {'text': 'Random prompt 544 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 187, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_545 to http://0.0.0.0:30000/generate at 1753383146.7681506
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_545 with payload: {'text': 'Random prompt 545 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_546 to http://0.0.0.0:30000/generate at 1753383146.7682767
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_546 with payload: {'text': 'Random prompt 546 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_547 to http://0.0.0.0:30000/generate at 1753383146.7684045
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_547 with payload: {'text': 'Random prompt 547 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_548 to http://0.0.0.0:30000/generate at 1753383146.7685297
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_548 with payload: {'text': 'Random prompt 548 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 70, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_549 to http://0.0.0.0:30000/generate at 1753383146.7686546
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_549 with payload: {'text': 'Random prompt 549 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_550 to http://0.0.0.0:30000/generate at 1753383146.7687829
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_550 with payload: {'text': 'Random prompt 550 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_551 to http://0.0.0.0:30000/generate at 1753383146.7688997
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_551 with payload: {'text': 'Random prompt 551 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_552 to http://0.0.0.0:30000/generate at 1753383146.7690244
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_552 with payload: {'text': 'Random prompt 552 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_553 to http://0.0.0.0:30000/generate at 1753383146.7692058
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_553 with payload: {'text': 'Random prompt 553 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_554 to http://0.0.0.0:30000/generate at 1753383146.7693338
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_554 with payload: {'text': 'Random prompt 554 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_555 to http://0.0.0.0:30000/generate at 1753383146.7694569
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_555 with payload: {'text': 'Random prompt 555 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 91, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_556 to http://0.0.0.0:30000/generate at 1753383146.7695808
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_556 with payload: {'text': 'Random prompt 556 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_557 to http://0.0.0.0:30000/generate at 1753383146.7697024
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_557 with payload: {'text': 'Random prompt 557 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_558 to http://0.0.0.0:30000/generate at 1753383146.7698267
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_558 with payload: {'text': 'Random prompt 558 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_559 to http://0.0.0.0:30000/generate at 1753383146.7699518
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_559 with payload: {'text': 'Random prompt 559 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 179, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_560 to http://0.0.0.0:30000/generate at 1753383146.770079
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_560 with payload: {'text': 'Random prompt 560 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_561 to http://0.0.0.0:30000/generate at 1753383146.7702088
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_561 with payload: {'text': 'Random prompt 561 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_562 to http://0.0.0.0:30000/generate at 1753383146.7703378
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_562 with payload: {'text': 'Random prompt 562 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_563 to http://0.0.0.0:30000/generate at 1753383146.7704587
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_563 with payload: {'text': 'Random prompt 563 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_564 to http://0.0.0.0:30000/generate at 1753383146.7705855
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_564 with payload: {'text': 'Random prompt 564 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_565 to http://0.0.0.0:30000/generate at 1753383146.7707572
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_565 with payload: {'text': 'Random prompt 565 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 118, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_566 to http://0.0.0.0:30000/generate at 1753383146.7708862
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_566 with payload: {'text': 'Random prompt 566 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_567 to http://0.0.0.0:30000/generate at 1753383146.7710116
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_567 with payload: {'text': 'Random prompt 567 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 76, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_568 to http://0.0.0.0:30000/generate at 1753383146.771132
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_568 with payload: {'text': 'Random prompt 568 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_569 to http://0.0.0.0:30000/generate at 1753383146.771264
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_569 with payload: {'text': 'Random prompt 569 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_570 to http://0.0.0.0:30000/generate at 1753383146.7713957
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_570 with payload: {'text': 'Random prompt 570 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 139, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_571 to http://0.0.0.0:30000/generate at 1753383146.7715156
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_571 with payload: {'text': 'Random prompt 571 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_572 to http://0.0.0.0:30000/generate at 1753383146.771641
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_572 with payload: {'text': 'Random prompt 572 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_573 to http://0.0.0.0:30000/generate at 1753383146.7717645
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_573 with payload: {'text': 'Random prompt 573 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 174, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_574 to http://0.0.0.0:30000/generate at 1753383146.7718878
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_574 with payload: {'text': 'Random prompt 574 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_575 to http://0.0.0.0:30000/generate at 1753383146.7720053
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_575 with payload: {'text': 'Random prompt 575 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 76, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_576 to http://0.0.0.0:30000/generate at 1753383146.77213
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_576 with payload: {'text': 'Random prompt 576 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_577 to http://0.0.0.0:30000/generate at 1753383146.7723029
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_577 with payload: {'text': 'Random prompt 577 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_578 to http://0.0.0.0:30000/generate at 1753383146.7724345
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_578 with payload: {'text': 'Random prompt 578 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_579 to http://0.0.0.0:30000/generate at 1753383146.7725604
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_579 with payload: {'text': 'Random prompt 579 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_580 to http://0.0.0.0:30000/generate at 1753383146.7726917
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_580 with payload: {'text': 'Random prompt 580 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_581 to http://0.0.0.0:30000/generate at 1753383146.7728174
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_581 with payload: {'text': 'Random prompt 581 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_582 to http://0.0.0.0:30000/generate at 1753383146.7729433
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_582 with payload: {'text': 'Random prompt 582 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_583 to http://0.0.0.0:30000/generate at 1753383146.773068
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_583 with payload: {'text': 'Random prompt 583 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_584 to http://0.0.0.0:30000/generate at 1753383146.7731934
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_584 with payload: {'text': 'Random prompt 584 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_585 to http://0.0.0.0:30000/generate at 1753383146.77332
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_585 with payload: {'text': 'Random prompt 585 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_586 to http://0.0.0.0:30000/generate at 1753383146.773444
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_586 with payload: {'text': 'Random prompt 586 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_587 to http://0.0.0.0:30000/generate at 1753383146.7735636
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_587 with payload: {'text': 'Random prompt 587 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_588 to http://0.0.0.0:30000/generate at 1753383146.7736843
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_588 with payload: {'text': 'Random prompt 588 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_589 to http://0.0.0.0:30000/generate at 1753383146.7738516
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_589 with payload: {'text': 'Random prompt 589 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_590 to http://0.0.0.0:30000/generate at 1753383146.7739768
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_590 with payload: {'text': 'Random prompt 590 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_591 to http://0.0.0.0:30000/generate at 1753383146.774099
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_591 with payload: {'text': 'Random prompt 591 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_592 to http://0.0.0.0:30000/generate at 1753383146.7742314
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_592 with payload: {'text': 'Random prompt 592 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_593 to http://0.0.0.0:30000/generate at 1753383146.7743647
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_593 with payload: {'text': 'Random prompt 593 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_594 to http://0.0.0.0:30000/generate at 1753383146.774484
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_594 with payload: {'text': 'Random prompt 594 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_595 to http://0.0.0.0:30000/generate at 1753383146.7746093
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_595 with payload: {'text': 'Random prompt 595 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 138, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_596 to http://0.0.0.0:30000/generate at 1753383146.7747355
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_596 with payload: {'text': 'Random prompt 596 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_597 to http://0.0.0.0:30000/generate at 1753383146.7748585
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_597 with payload: {'text': 'Random prompt 597 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_598 to http://0.0.0.0:30000/generate at 1753383146.774981
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_598 with payload: {'text': 'Random prompt 598 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_599 to http://0.0.0.0:30000/generate at 1753383146.7751043
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_599 with payload: {'text': 'Random prompt 599 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 178, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_600 to http://0.0.0.0:30000/generate at 1753383146.7752352
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_600 with payload: {'text': 'Random prompt 600 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 89, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_601 to http://0.0.0.0:30000/generate at 1753383146.7754076
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_601 with payload: {'text': 'Random prompt 601 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 105, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_602 to http://0.0.0.0:30000/generate at 1753383146.7755723
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_602 with payload: {'text': 'Random prompt 602 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_603 to http://0.0.0.0:30000/generate at 1753383146.7756941
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_603 with payload: {'text': 'Random prompt 603 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_604 to http://0.0.0.0:30000/generate at 1753383146.7758133
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_604 with payload: {'text': 'Random prompt 604 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_605 to http://0.0.0.0:30000/generate at 1753383146.775941
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_605 with payload: {'text': 'Random prompt 605 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_606 to http://0.0.0.0:30000/generate at 1753383146.7760656
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_606 with payload: {'text': 'Random prompt 606 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_607 to http://0.0.0.0:30000/generate at 1753383146.77619
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_607 with payload: {'text': 'Random prompt 607 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_608 to http://0.0.0.0:30000/generate at 1753383146.7763186
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_608 with payload: {'text': 'Random prompt 608 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_609 to http://0.0.0.0:30000/generate at 1753383146.776439
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_609 with payload: {'text': 'Random prompt 609 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_610 to http://0.0.0.0:30000/generate at 1753383146.7765603
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_610 with payload: {'text': 'Random prompt 610 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_611 to http://0.0.0.0:30000/generate at 1753383146.776685
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_611 with payload: {'text': 'Random prompt 611 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_612 to http://0.0.0.0:30000/generate at 1753383146.7768087
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_612 with payload: {'text': 'Random prompt 612 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 132, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_613 to http://0.0.0.0:30000/generate at 1753383146.7769854
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_613 with payload: {'text': 'Random prompt 613 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_614 to http://0.0.0.0:30000/generate at 1753383146.7771087
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_614 with payload: {'text': 'Random prompt 614 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_615 to http://0.0.0.0:30000/generate at 1753383146.7772362
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_615 with payload: {'text': 'Random prompt 615 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 150, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_616 to http://0.0.0.0:30000/generate at 1753383146.7773724
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_616 with payload: {'text': 'Random prompt 616 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_617 to http://0.0.0.0:30000/generate at 1753383146.7774916
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_617 with payload: {'text': 'Random prompt 617 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_618 to http://0.0.0.0:30000/generate at 1753383146.7776134
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_618 with payload: {'text': 'Random prompt 618 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 135, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_619 to http://0.0.0.0:30000/generate at 1753383146.777739
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_619 with payload: {'text': 'Random prompt 619 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_620 to http://0.0.0.0:30000/generate at 1753383146.7778583
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_620 with payload: {'text': 'Random prompt 620 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 124, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_621 to http://0.0.0.0:30000/generate at 1753383146.7779782
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_621 with payload: {'text': 'Random prompt 621 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_622 to http://0.0.0.0:30000/generate at 1753383146.7780967
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_622 with payload: {'text': 'Random prompt 622 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 136, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_623 to http://0.0.0.0:30000/generate at 1753383146.7782228
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_623 with payload: {'text': 'Random prompt 623 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 187, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_624 to http://0.0.0.0:30000/generate at 1753383146.778352
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_624 with payload: {'text': 'Random prompt 624 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_625 to http://0.0.0.0:30000/generate at 1753383146.7785282
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_625 with payload: {'text': 'Random prompt 625 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_626 to http://0.0.0.0:30000/generate at 1753383146.7786498
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_626 with payload: {'text': 'Random prompt 626 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_627 to http://0.0.0.0:30000/generate at 1753383146.7787747
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_627 with payload: {'text': 'Random prompt 627 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_628 to http://0.0.0.0:30000/generate at 1753383146.7789028
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_628 with payload: {'text': 'Random prompt 628 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 76, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_629 to http://0.0.0.0:30000/generate at 1753383146.7790236
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_629 with payload: {'text': 'Random prompt 629 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_630 to http://0.0.0.0:30000/generate at 1753383146.7791462
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_630 with payload: {'text': 'Random prompt 630 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_631 to http://0.0.0.0:30000/generate at 1753383146.779286
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_631 with payload: {'text': 'Random prompt 631 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_632 to http://0.0.0.0:30000/generate at 1753383146.7794106
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_632 with payload: {'text': 'Random prompt 632 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_633 to http://0.0.0.0:30000/generate at 1753383146.7795353
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_633 with payload: {'text': 'Random prompt 633 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_634 to http://0.0.0.0:30000/generate at 1753383146.7796602
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_634 with payload: {'text': 'Random prompt 634 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_635 to http://0.0.0.0:30000/generate at 1753383146.7797909
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_635 with payload: {'text': 'Random prompt 635 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 94, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_636 to http://0.0.0.0:30000/generate at 1753383146.7799141
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_636 with payload: {'text': 'Random prompt 636 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_637 to http://0.0.0.0:30000/generate at 1753383146.7800891
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_637 with payload: {'text': 'Random prompt 637 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 84, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_638 to http://0.0.0.0:30000/generate at 1753383146.7802227
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_638 with payload: {'text': 'Random prompt 638 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_639 to http://0.0.0.0:30000/generate at 1753383146.7803457
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_639 with payload: {'text': 'Random prompt 639 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_640 to http://0.0.0.0:30000/generate at 1753383146.7804718
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_640 with payload: {'text': 'Random prompt 640 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_641 to http://0.0.0.0:30000/generate at 1753383146.7805908
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_641 with payload: {'text': 'Random prompt 641 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_642 to http://0.0.0.0:30000/generate at 1753383146.780712
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_642 with payload: {'text': 'Random prompt 642 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 131, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_643 to http://0.0.0.0:30000/generate at 1753383146.7808328
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_643 with payload: {'text': 'Random prompt 643 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_644 to http://0.0.0.0:30000/generate at 1753383146.7809522
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_644 with payload: {'text': 'Random prompt 644 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_645 to http://0.0.0.0:30000/generate at 1753383146.7810764
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_645 with payload: {'text': 'Random prompt 645 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_646 to http://0.0.0.0:30000/generate at 1753383146.781209
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_646 with payload: {'text': 'Random prompt 646 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_647 to http://0.0.0.0:30000/generate at 1753383146.7813342
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_647 with payload: {'text': 'Random prompt 647 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_648 to http://0.0.0.0:30000/generate at 1753383146.7814667
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_648 with payload: {'text': 'Random prompt 648 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_649 to http://0.0.0.0:30000/generate at 1753383146.7816386
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_649 with payload: {'text': 'Random prompt 649 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_650 to http://0.0.0.0:30000/generate at 1753383146.7817702
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_650 with payload: {'text': 'Random prompt 650 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_651 to http://0.0.0.0:30000/generate at 1753383146.7818937
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_651 with payload: {'text': 'Random prompt 651 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_652 to http://0.0.0.0:30000/generate at 1753383146.782014
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_652 with payload: {'text': 'Random prompt 652 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 98, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_653 to http://0.0.0.0:30000/generate at 1753383146.7821383
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_653 with payload: {'text': 'Random prompt 653 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 110, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_654 to http://0.0.0.0:30000/generate at 1753383146.7822702
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_654 with payload: {'text': 'Random prompt 654 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_655 to http://0.0.0.0:30000/generate at 1753383146.7823908
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_655 with payload: {'text': 'Random prompt 655 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_656 to http://0.0.0.0:30000/generate at 1753383146.7825212
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_656 with payload: {'text': 'Random prompt 656 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 135, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_657 to http://0.0.0.0:30000/generate at 1753383146.7826421
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_657 with payload: {'text': 'Random prompt 657 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_658 to http://0.0.0.0:30000/generate at 1753383146.7827628
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_658 with payload: {'text': 'Random prompt 658 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_659 to http://0.0.0.0:30000/generate at 1753383146.782882
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_659 with payload: {'text': 'Random prompt 659 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 121, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_660 to http://0.0.0.0:30000/generate at 1753383146.7830098
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_660 with payload: {'text': 'Random prompt 660 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_661 to http://0.0.0.0:30000/generate at 1753383146.783184
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_661 with payload: {'text': 'Random prompt 661 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_662 to http://0.0.0.0:30000/generate at 1753383146.783313
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_662 with payload: {'text': 'Random prompt 662 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 182, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_663 to http://0.0.0.0:30000/generate at 1753383146.7834432
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_663 with payload: {'text': 'Random prompt 663 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_664 to http://0.0.0.0:30000/generate at 1753383146.7835624
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_664 with payload: {'text': 'Random prompt 664 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_665 to http://0.0.0.0:30000/generate at 1753383146.783681
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_665 with payload: {'text': 'Random prompt 665 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 173, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_666 to http://0.0.0.0:30000/generate at 1753383146.783803
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_666 with payload: {'text': 'Random prompt 666 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 91, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_667 to http://0.0.0.0:30000/generate at 1753383146.7839246
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_667 with payload: {'text': 'Random prompt 667 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_668 to http://0.0.0.0:30000/generate at 1753383146.7840514
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_668 with payload: {'text': 'Random prompt 668 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 79, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_669 to http://0.0.0.0:30000/generate at 1753383146.7841878
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_669 with payload: {'text': 'Random prompt 669 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_670 to http://0.0.0.0:30000/generate at 1753383146.7843173
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_670 with payload: {'text': 'Random prompt 670 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 113, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_671 to http://0.0.0.0:30000/generate at 1753383146.7844424
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_671 with payload: {'text': 'Random prompt 671 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_672 to http://0.0.0.0:30000/generate at 1753383146.7845645
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_672 with payload: {'text': 'Random prompt 672 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 175, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_673 to http://0.0.0.0:30000/generate at 1753383146.7847323
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_673 with payload: {'text': 'Random prompt 673 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_674 to http://0.0.0.0:30000/generate at 1753383146.7848568
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_674 with payload: {'text': 'Random prompt 674 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_675 to http://0.0.0.0:30000/generate at 1753383146.7849784
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_675 with payload: {'text': 'Random prompt 675 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_676 to http://0.0.0.0:30000/generate at 1753383146.7851112
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_676 with payload: {'text': 'Random prompt 676 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_677 to http://0.0.0.0:30000/generate at 1753383146.7852454
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_677 with payload: {'text': 'Random prompt 677 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_678 to http://0.0.0.0:30000/generate at 1753383146.7853675
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_678 with payload: {'text': 'Random prompt 678 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_679 to http://0.0.0.0:30000/generate at 1753383146.7854903
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_679 with payload: {'text': 'Random prompt 679 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_680 to http://0.0.0.0:30000/generate at 1753383146.7856236
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_680 with payload: {'text': 'Random prompt 680 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 108, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_681 to http://0.0.0.0:30000/generate at 1753383146.7857504
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_681 with payload: {'text': 'Random prompt 681 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_682 to http://0.0.0.0:30000/generate at 1753383146.7858775
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_682 with payload: {'text': 'Random prompt 682 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_683 to http://0.0.0.0:30000/generate at 1753383146.786003
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_683 with payload: {'text': 'Random prompt 683 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_684 to http://0.0.0.0:30000/generate at 1753383146.786127
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_684 with payload: {'text': 'Random prompt 684 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_685 to http://0.0.0.0:30000/generate at 1753383146.786861
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_685 with payload: {'text': 'Random prompt 685 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 174, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_686 to http://0.0.0.0:30000/generate at 1753383146.7870045
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_686 with payload: {'text': 'Random prompt 686 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 182, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_687 to http://0.0.0.0:30000/generate at 1753383146.787128
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_687 with payload: {'text': 'Random prompt 687 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_688 to http://0.0.0.0:30000/generate at 1753383146.787256
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_688 with payload: {'text': 'Random prompt 688 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_689 to http://0.0.0.0:30000/generate at 1753383146.7873805
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_689 with payload: {'text': 'Random prompt 689 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_690 to http://0.0.0.0:30000/generate at 1753383146.787501
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_690 with payload: {'text': 'Random prompt 690 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_691 to http://0.0.0.0:30000/generate at 1753383146.7876244
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_691 with payload: {'text': 'Random prompt 691 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_692 to http://0.0.0.0:30000/generate at 1753383146.7877586
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_692 with payload: {'text': 'Random prompt 692 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_693 to http://0.0.0.0:30000/generate at 1753383146.7878892
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_693 with payload: {'text': 'Random prompt 693 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_694 to http://0.0.0.0:30000/generate at 1753383146.78801
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_694 with payload: {'text': 'Random prompt 694 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_695 to http://0.0.0.0:30000/generate at 1753383146.788135
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_695 with payload: {'text': 'Random prompt 695 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_696 to http://0.0.0.0:30000/generate at 1753383146.7882588
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_696 with payload: {'text': 'Random prompt 696 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_697 to http://0.0.0.0:30000/generate at 1753383146.7884316
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_697 with payload: {'text': 'Random prompt 697 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_698 to http://0.0.0.0:30000/generate at 1753383146.7885585
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_698 with payload: {'text': 'Random prompt 698 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 187, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_699 to http://0.0.0.0:30000/generate at 1753383146.7886832
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_699 with payload: {'text': 'Random prompt 699 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_700 to http://0.0.0.0:30000/generate at 1753383146.7888112
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_700 with payload: {'text': 'Random prompt 700 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_701 to http://0.0.0.0:30000/generate at 1753383146.7889347
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_701 with payload: {'text': 'Random prompt 701 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_702 to http://0.0.0.0:30000/generate at 1753383146.789057
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_702 with payload: {'text': 'Random prompt 702 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 104, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_703 to http://0.0.0.0:30000/generate at 1753383146.7891874
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_703 with payload: {'text': 'Random prompt 703 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 129, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_704 to http://0.0.0.0:30000/generate at 1753383146.7893195
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_704 with payload: {'text': 'Random prompt 704 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_705 to http://0.0.0.0:30000/generate at 1753383146.7894456
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_705 with payload: {'text': 'Random prompt 705 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_706 to http://0.0.0.0:30000/generate at 1753383146.78957
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_706 with payload: {'text': 'Random prompt 706 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_707 to http://0.0.0.0:30000/generate at 1753383146.7896953
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_707 with payload: {'text': 'Random prompt 707 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_708 to http://0.0.0.0:30000/generate at 1753383146.7898161
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_708 with payload: {'text': 'Random prompt 708 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_709 to http://0.0.0.0:30000/generate at 1753383146.7899847
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_709 with payload: {'text': 'Random prompt 709 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_710 to http://0.0.0.0:30000/generate at 1753383146.7901094
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_710 with payload: {'text': 'Random prompt 710 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_711 to http://0.0.0.0:30000/generate at 1753383146.7902436
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_711 with payload: {'text': 'Random prompt 711 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_712 to http://0.0.0.0:30000/generate at 1753383146.7903695
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_712 with payload: {'text': 'Random prompt 712 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_713 to http://0.0.0.0:30000/generate at 1753383146.790497
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_713 with payload: {'text': 'Random prompt 713 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_714 to http://0.0.0.0:30000/generate at 1753383146.7906215
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_714 with payload: {'text': 'Random prompt 714 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_715 to http://0.0.0.0:30000/generate at 1753383146.7907445
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_715 with payload: {'text': 'Random prompt 715 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_716 to http://0.0.0.0:30000/generate at 1753383146.7908704
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_716 with payload: {'text': 'Random prompt 716 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_717 to http://0.0.0.0:30000/generate at 1753383146.7909951
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_717 with payload: {'text': 'Random prompt 717 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_718 to http://0.0.0.0:30000/generate at 1753383146.7911212
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_718 with payload: {'text': 'Random prompt 718 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_719 to http://0.0.0.0:30000/generate at 1753383146.7912517
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_719 with payload: {'text': 'Random prompt 719 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 95, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_720 to http://0.0.0.0:30000/generate at 1753383146.7913778
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_720 with payload: {'text': 'Random prompt 720 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 82, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_721 to http://0.0.0.0:30000/generate at 1753383146.791551
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_721 with payload: {'text': 'Random prompt 721 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_722 to http://0.0.0.0:30000/generate at 1753383146.7916756
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_722 with payload: {'text': 'Random prompt 722 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_723 to http://0.0.0.0:30000/generate at 1753383146.7918015
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_723 with payload: {'text': 'Random prompt 723 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_724 to http://0.0.0.0:30000/generate at 1753383146.7919302
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_724 with payload: {'text': 'Random prompt 724 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_725 to http://0.0.0.0:30000/generate at 1753383146.7920535
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_725 with payload: {'text': 'Random prompt 725 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_726 to http://0.0.0.0:30000/generate at 1753383146.792182
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_726 with payload: {'text': 'Random prompt 726 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 129, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_727 to http://0.0.0.0:30000/generate at 1753383146.7923076
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_727 with payload: {'text': 'Random prompt 727 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_728 to http://0.0.0.0:30000/generate at 1753383146.7924278
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_728 with payload: {'text': 'Random prompt 728 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_729 to http://0.0.0.0:30000/generate at 1753383146.792555
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_729 with payload: {'text': 'Random prompt 729 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_730 to http://0.0.0.0:30000/generate at 1753383146.792673
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_730 with payload: {'text': 'Random prompt 730 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_731 to http://0.0.0.0:30000/generate at 1753383146.7927914
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_731 with payload: {'text': 'Random prompt 731 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_732 to http://0.0.0.0:30000/generate at 1753383146.7929177
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_732 with payload: {'text': 'Random prompt 732 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 131, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_733 to http://0.0.0.0:30000/generate at 1753383146.7930923
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_733 with payload: {'text': 'Random prompt 733 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_734 to http://0.0.0.0:30000/generate at 1753383146.7932208
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_734 with payload: {'text': 'Random prompt 734 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_735 to http://0.0.0.0:30000/generate at 1753383146.7933462
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_735 with payload: {'text': 'Random prompt 735 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_736 to http://0.0.0.0:30000/generate at 1753383146.793473
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_736 with payload: {'text': 'Random prompt 736 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_737 to http://0.0.0.0:30000/generate at 1753383146.7935967
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_737 with payload: {'text': 'Random prompt 737 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 89, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_738 to http://0.0.0.0:30000/generate at 1753383146.7937229
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_738 with payload: {'text': 'Random prompt 738 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_739 to http://0.0.0.0:30000/generate at 1753383146.7938504
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_739 with payload: {'text': 'Random prompt 739 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_740 to http://0.0.0.0:30000/generate at 1753383146.7939808
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_740 with payload: {'text': 'Random prompt 740 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_741 to http://0.0.0.0:30000/generate at 1753383146.7941103
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_741 with payload: {'text': 'Random prompt 741 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_742 to http://0.0.0.0:30000/generate at 1753383146.7942302
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_742 with payload: {'text': 'Random prompt 742 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_743 to http://0.0.0.0:30000/generate at 1753383146.7943568
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_743 with payload: {'text': 'Random prompt 743 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_744 to http://0.0.0.0:30000/generate at 1753383146.7944798
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_744 with payload: {'text': 'Random prompt 744 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_745 to http://0.0.0.0:30000/generate at 1753383146.794647
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_745 with payload: {'text': 'Random prompt 745 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_746 to http://0.0.0.0:30000/generate at 1753383146.7947745
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_746 with payload: {'text': 'Random prompt 746 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 66, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_747 to http://0.0.0.0:30000/generate at 1753383146.7948997
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_747 with payload: {'text': 'Random prompt 747 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_748 to http://0.0.0.0:30000/generate at 1753383146.795023
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_748 with payload: {'text': 'Random prompt 748 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_749 to http://0.0.0.0:30000/generate at 1753383146.7951474
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_749 with payload: {'text': 'Random prompt 749 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 82, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_750 to http://0.0.0.0:30000/generate at 1753383146.7952812
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_750 with payload: {'text': 'Random prompt 750 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_751 to http://0.0.0.0:30000/generate at 1753383146.7954009
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_751 with payload: {'text': 'Random prompt 751 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_752 to http://0.0.0.0:30000/generate at 1753383146.7955253
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_752 with payload: {'text': 'Random prompt 752 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 66, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_753 to http://0.0.0.0:30000/generate at 1753383146.7956529
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_753 with payload: {'text': 'Random prompt 753 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 95, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_754 to http://0.0.0.0:30000/generate at 1753383146.795773
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_754 with payload: {'text': 'Random prompt 754 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_755 to http://0.0.0.0:30000/generate at 1753383146.7958994
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_755 with payload: {'text': 'Random prompt 755 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_756 to http://0.0.0.0:30000/generate at 1753383146.7960203
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_756 with payload: {'text': 'Random prompt 756 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 187, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_757 to http://0.0.0.0:30000/generate at 1753383146.7961943
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_757 with payload: {'text': 'Random prompt 757 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_758 to http://0.0.0.0:30000/generate at 1753383146.7963233
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_758 with payload: {'text': 'Random prompt 758 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 78, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_759 to http://0.0.0.0:30000/generate at 1753383146.7964487
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_759 with payload: {'text': 'Random prompt 759 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_760 to http://0.0.0.0:30000/generate at 1753383146.796572
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_760 with payload: {'text': 'Random prompt 760 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 122, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_761 to http://0.0.0.0:30000/generate at 1753383146.7966914
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_761 with payload: {'text': 'Random prompt 761 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_762 to http://0.0.0.0:30000/generate at 1753383146.7968147
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_762 with payload: {'text': 'Random prompt 762 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_763 to http://0.0.0.0:30000/generate at 1753383146.7969375
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_763 with payload: {'text': 'Random prompt 763 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_764 to http://0.0.0.0:30000/generate at 1753383146.7970605
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_764 with payload: {'text': 'Random prompt 764 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_765 to http://0.0.0.0:30000/generate at 1753383146.79719
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_765 with payload: {'text': 'Random prompt 765 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_766 to http://0.0.0.0:30000/generate at 1753383146.797312
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_766 with payload: {'text': 'Random prompt 766 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_767 to http://0.0.0.0:30000/generate at 1753383146.7974327
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_767 with payload: {'text': 'Random prompt 767 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 125, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_768 to http://0.0.0.0:30000/generate at 1753383146.797556
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_768 with payload: {'text': 'Random prompt 768 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 112, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_769 to http://0.0.0.0:30000/generate at 1753383146.797731
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_769 with payload: {'text': 'Random prompt 769 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_770 to http://0.0.0.0:30000/generate at 1753383146.7978542
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_770 with payload: {'text': 'Random prompt 770 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_771 to http://0.0.0.0:30000/generate at 1753383146.7979758
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_771 with payload: {'text': 'Random prompt 771 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_772 to http://0.0.0.0:30000/generate at 1753383146.7981083
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_772 with payload: {'text': 'Random prompt 772 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 178, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_773 to http://0.0.0.0:30000/generate at 1753383146.798239
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_773 with payload: {'text': 'Random prompt 773 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_774 to http://0.0.0.0:30000/generate at 1753383146.7983603
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_774 with payload: {'text': 'Random prompt 774 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_775 to http://0.0.0.0:30000/generate at 1753383146.798481
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_775 with payload: {'text': 'Random prompt 775 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 104, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_776 to http://0.0.0.0:30000/generate at 1753383146.798608
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_776 with payload: {'text': 'Random prompt 776 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_777 to http://0.0.0.0:30000/generate at 1753383146.798735
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_777 with payload: {'text': 'Random prompt 777 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_778 to http://0.0.0.0:30000/generate at 1753383146.7988603
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_778 with payload: {'text': 'Random prompt 778 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_779 to http://0.0.0.0:30000/generate at 1753383146.7989862
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_779 with payload: {'text': 'Random prompt 779 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_780 to http://0.0.0.0:30000/generate at 1753383146.79911
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_780 with payload: {'text': 'Random prompt 780 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_781 to http://0.0.0.0:30000/generate at 1753383146.7992852
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_781 with payload: {'text': 'Random prompt 781 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 179, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_782 to http://0.0.0.0:30000/generate at 1753383146.7994106
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_782 with payload: {'text': 'Random prompt 782 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_783 to http://0.0.0.0:30000/generate at 1753383146.799577
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_783 with payload: {'text': 'Random prompt 783 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_784 to http://0.0.0.0:30000/generate at 1753383146.7997098
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_784 with payload: {'text': 'Random prompt 784 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_785 to http://0.0.0.0:30000/generate at 1753383146.7998335
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_785 with payload: {'text': 'Random prompt 785 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 179, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_786 to http://0.0.0.0:30000/generate at 1753383146.7999563
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_786 with payload: {'text': 'Random prompt 786 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_787 to http://0.0.0.0:30000/generate at 1753383146.8000789
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_787 with payload: {'text': 'Random prompt 787 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_788 to http://0.0.0.0:30000/generate at 1753383146.8002057
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_788 with payload: {'text': 'Random prompt 788 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_789 to http://0.0.0.0:30000/generate at 1753383146.8003292
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_789 with payload: {'text': 'Random prompt 789 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_790 to http://0.0.0.0:30000/generate at 1753383146.8004553
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_790 with payload: {'text': 'Random prompt 790 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_791 to http://0.0.0.0:30000/generate at 1753383146.8005824
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_791 with payload: {'text': 'Random prompt 791 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_792 to http://0.0.0.0:30000/generate at 1753383146.800703
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_792 with payload: {'text': 'Random prompt 792 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_793 to http://0.0.0.0:30000/generate at 1753383146.8008823
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_793 with payload: {'text': 'Random prompt 793 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_794 to http://0.0.0.0:30000/generate at 1753383146.8010073
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_794 with payload: {'text': 'Random prompt 794 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_795 to http://0.0.0.0:30000/generate at 1753383146.8011262
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_795 with payload: {'text': 'Random prompt 795 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_796 to http://0.0.0.0:30000/generate at 1753383146.801256
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_796 with payload: {'text': 'Random prompt 796 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_797 to http://0.0.0.0:30000/generate at 1753383146.8013813
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_797 with payload: {'text': 'Random prompt 797 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_798 to http://0.0.0.0:30000/generate at 1753383146.801505
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_798 with payload: {'text': 'Random prompt 798 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_799 to http://0.0.0.0:30000/generate at 1753383146.8016298
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_799 with payload: {'text': 'Random prompt 799 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 66, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_800 to http://0.0.0.0:30000/generate at 1753383146.801758
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_800 with payload: {'text': 'Random prompt 800 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_801 to http://0.0.0.0:30000/generate at 1753383146.8018851
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_801 with payload: {'text': 'Random prompt 801 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_802 to http://0.0.0.0:30000/generate at 1753383146.8020084
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_802 with payload: {'text': 'Random prompt 802 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_803 to http://0.0.0.0:30000/generate at 1753383146.8021333
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_803 with payload: {'text': 'Random prompt 803 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 102, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_804 to http://0.0.0.0:30000/generate at 1753383146.8022614
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_804 with payload: {'text': 'Random prompt 804 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_805 to http://0.0.0.0:30000/generate at 1753383146.8024354
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_805 with payload: {'text': 'Random prompt 805 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_806 to http://0.0.0.0:30000/generate at 1753383146.8025563
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_806 with payload: {'text': 'Random prompt 806 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_807 to http://0.0.0.0:30000/generate at 1753383146.8026795
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_807 with payload: {'text': 'Random prompt 807 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_808 to http://0.0.0.0:30000/generate at 1753383146.8028169
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_808 with payload: {'text': 'Random prompt 808 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 86, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_809 to http://0.0.0.0:30000/generate at 1753383146.8029387
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_809 with payload: {'text': 'Random prompt 809 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_810 to http://0.0.0.0:30000/generate at 1753383146.8030608
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_810 with payload: {'text': 'Random prompt 810 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 149, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_811 to http://0.0.0.0:30000/generate at 1753383146.803191
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_811 with payload: {'text': 'Random prompt 811 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_812 to http://0.0.0.0:30000/generate at 1753383146.803314
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_812 with payload: {'text': 'Random prompt 812 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 98, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_813 to http://0.0.0.0:30000/generate at 1753383146.803442
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_813 with payload: {'text': 'Random prompt 813 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_814 to http://0.0.0.0:30000/generate at 1753383146.8035688
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_814 with payload: {'text': 'Random prompt 814 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_815 to http://0.0.0.0:30000/generate at 1753383146.8036954
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_815 with payload: {'text': 'Random prompt 815 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_816 to http://0.0.0.0:30000/generate at 1753383146.8038204
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_816 with payload: {'text': 'Random prompt 816 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 102, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_817 to http://0.0.0.0:30000/generate at 1753383146.803988
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_817 with payload: {'text': 'Random prompt 817 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_818 to http://0.0.0.0:30000/generate at 1753383146.804112
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_818 with payload: {'text': 'Random prompt 818 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 144, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_819 to http://0.0.0.0:30000/generate at 1753383146.804243
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_819 with payload: {'text': 'Random prompt 819 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 113, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_820 to http://0.0.0.0:30000/generate at 1753383146.8043702
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_820 with payload: {'text': 'Random prompt 820 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_821 to http://0.0.0.0:30000/generate at 1753383146.8044918
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_821 with payload: {'text': 'Random prompt 821 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_822 to http://0.0.0.0:30000/generate at 1753383146.8046196
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_822 with payload: {'text': 'Random prompt 822 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_823 to http://0.0.0.0:30000/generate at 1753383146.8047423
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_823 with payload: {'text': 'Random prompt 823 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_824 to http://0.0.0.0:30000/generate at 1753383146.804864
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_824 with payload: {'text': 'Random prompt 824 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_825 to http://0.0.0.0:30000/generate at 1753383146.8049872
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_825 with payload: {'text': 'Random prompt 825 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 132, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_826 to http://0.0.0.0:30000/generate at 1753383146.805113
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_826 with payload: {'text': 'Random prompt 826 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_827 to http://0.0.0.0:30000/generate at 1753383146.8052387
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_827 with payload: {'text': 'Random prompt 827 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 188, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_828 to http://0.0.0.0:30000/generate at 1753383146.8053608
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_828 with payload: {'text': 'Random prompt 828 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_829 to http://0.0.0.0:30000/generate at 1753383146.8060703
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_829 with payload: {'text': 'Random prompt 829 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 101, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_830 to http://0.0.0.0:30000/generate at 1753383146.8062177
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_830 with payload: {'text': 'Random prompt 830 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 189, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_831 to http://0.0.0.0:30000/generate at 1753383146.8063428
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_831 with payload: {'text': 'Random prompt 831 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_832 to http://0.0.0.0:30000/generate at 1753383146.8064675
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_832 with payload: {'text': 'Random prompt 832 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 139, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_833 to http://0.0.0.0:30000/generate at 1753383146.8066018
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_833 with payload: {'text': 'Random prompt 833 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 160, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_834 to http://0.0.0.0:30000/generate at 1753383146.8067236
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_834 with payload: {'text': 'Random prompt 834 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_835 to http://0.0.0.0:30000/generate at 1753383146.8068519
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_835 with payload: {'text': 'Random prompt 835 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_836 to http://0.0.0.0:30000/generate at 1753383146.8069732
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_836 with payload: {'text': 'Random prompt 836 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_837 to http://0.0.0.0:30000/generate at 1753383146.807096
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_837 with payload: {'text': 'Random prompt 837 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_838 to http://0.0.0.0:30000/generate at 1753383146.8072238
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_838 with payload: {'text': 'Random prompt 838 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_839 to http://0.0.0.0:30000/generate at 1753383146.8073459
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_839 with payload: {'text': 'Random prompt 839 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 93, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_840 to http://0.0.0.0:30000/generate at 1753383146.807472
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_840 with payload: {'text': 'Random prompt 840 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 112, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_841 to http://0.0.0.0:30000/generate at 1753383146.8076472
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_841 with payload: {'text': 'Random prompt 841 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_842 to http://0.0.0.0:30000/generate at 1753383146.80778
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_842 with payload: {'text': 'Random prompt 842 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_843 to http://0.0.0.0:30000/generate at 1753383146.8079
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_843 with payload: {'text': 'Random prompt 843 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_844 to http://0.0.0.0:30000/generate at 1753383146.8080275
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_844 with payload: {'text': 'Random prompt 844 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 185, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_845 to http://0.0.0.0:30000/generate at 1753383146.8081644
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_845 with payload: {'text': 'Random prompt 845 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 95, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_846 to http://0.0.0.0:30000/generate at 1753383146.8082922
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_846 with payload: {'text': 'Random prompt 846 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 80, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_847 to http://0.0.0.0:30000/generate at 1753383146.808416
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_847 with payload: {'text': 'Random prompt 847 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 89, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_848 to http://0.0.0.0:30000/generate at 1753383146.8085423
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_848 with payload: {'text': 'Random prompt 848 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 178, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_849 to http://0.0.0.0:30000/generate at 1753383146.8086615
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_849 with payload: {'text': 'Random prompt 849 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 147, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_850 to http://0.0.0.0:30000/generate at 1753383146.8087847
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_850 with payload: {'text': 'Random prompt 850 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 101, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_851 to http://0.0.0.0:30000/generate at 1753383146.8089058
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_851 with payload: {'text': 'Random prompt 851 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 168, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_852 to http://0.0.0.0:30000/generate at 1753383146.8090336
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_852 with payload: {'text': 'Random prompt 852 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 174, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_853 to http://0.0.0.0:30000/generate at 1753383146.809205
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_853 with payload: {'text': 'Random prompt 853 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_854 to http://0.0.0.0:30000/generate at 1753383146.8093348
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_854 with payload: {'text': 'Random prompt 854 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 182, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_855 to http://0.0.0.0:30000/generate at 1753383146.8094547
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_855 with payload: {'text': 'Random prompt 855 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 96, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_856 to http://0.0.0.0:30000/generate at 1753383146.8095803
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_856 with payload: {'text': 'Random prompt 856 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_857 to http://0.0.0.0:30000/generate at 1753383146.809706
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_857 with payload: {'text': 'Random prompt 857 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_858 to http://0.0.0.0:30000/generate at 1753383146.8098264
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_858 with payload: {'text': 'Random prompt 858 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_859 to http://0.0.0.0:30000/generate at 1753383146.80995
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_859 with payload: {'text': 'Random prompt 859 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_860 to http://0.0.0.0:30000/generate at 1753383146.810072
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_860 with payload: {'text': 'Random prompt 860 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 163, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_861 to http://0.0.0.0:30000/generate at 1753383146.810203
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_861 with payload: {'text': 'Random prompt 861 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_862 to http://0.0.0.0:30000/generate at 1753383146.8103337
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_862 with payload: {'text': 'Random prompt 862 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 87, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_863 to http://0.0.0.0:30000/generate at 1753383146.810456
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_863 with payload: {'text': 'Random prompt 863 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 134, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_864 to http://0.0.0.0:30000/generate at 1753383146.8105764
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_864 with payload: {'text': 'Random prompt 864 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 190, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_865 to http://0.0.0.0:30000/generate at 1753383146.8107457
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_865 with payload: {'text': 'Random prompt 865 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_866 to http://0.0.0.0:30000/generate at 1753383146.8108716
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_866 with payload: {'text': 'Random prompt 866 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 70, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_867 to http://0.0.0.0:30000/generate at 1753383146.8109968
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_867 with payload: {'text': 'Random prompt 867 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 85, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_868 to http://0.0.0.0:30000/generate at 1753383146.8111281
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_868 with payload: {'text': 'Random prompt 868 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_869 to http://0.0.0.0:30000/generate at 1753383146.8112557
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_869 with payload: {'text': 'Random prompt 869 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_870 to http://0.0.0.0:30000/generate at 1753383146.8113792
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_870 with payload: {'text': 'Random prompt 870 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 169, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_871 to http://0.0.0.0:30000/generate at 1753383146.811501
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_871 with payload: {'text': 'Random prompt 871 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 91, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_872 to http://0.0.0.0:30000/generate at 1753383146.81162
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_872 with payload: {'text': 'Random prompt 872 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 129, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_873 to http://0.0.0.0:30000/generate at 1753383146.8117433
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_873 with payload: {'text': 'Random prompt 873 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_874 to http://0.0.0.0:30000/generate at 1753383146.8118696
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_874 with payload: {'text': 'Random prompt 874 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_875 to http://0.0.0.0:30000/generate at 1753383146.811988
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_875 with payload: {'text': 'Random prompt 875 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 133, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_876 to http://0.0.0.0:30000/generate at 1753383146.812105
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_876 with payload: {'text': 'Random prompt 876 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_877 to http://0.0.0.0:30000/generate at 1753383146.8122845
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_877 with payload: {'text': 'Random prompt 877 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 129, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_878 to http://0.0.0.0:30000/generate at 1753383146.8124058
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_878 with payload: {'text': 'Random prompt 878 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 102, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_879 to http://0.0.0.0:30000/generate at 1753383146.812529
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_879 with payload: {'text': 'Random prompt 879 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 136, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_880 to http://0.0.0.0:30000/generate at 1753383146.8126564
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_880 with payload: {'text': 'Random prompt 880 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 152, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_881 to http://0.0.0.0:30000/generate at 1753383146.812779
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_881 with payload: {'text': 'Random prompt 881 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_882 to http://0.0.0.0:30000/generate at 1753383146.8129082
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_882 with payload: {'text': 'Random prompt 882 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_883 to http://0.0.0.0:30000/generate at 1753383146.8130302
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_883 with payload: {'text': 'Random prompt 883 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_884 to http://0.0.0.0:30000/generate at 1753383146.8131523
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_884 with payload: {'text': 'Random prompt 884 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 84, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_885 to http://0.0.0.0:30000/generate at 1753383146.8132808
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_885 with payload: {'text': 'Random prompt 885 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_886 to http://0.0.0.0:30000/generate at 1753383146.813408
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_886 with payload: {'text': 'Random prompt 886 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_887 to http://0.0.0.0:30000/generate at 1753383146.8135245
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_887 with payload: {'text': 'Random prompt 887 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 96, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_888 to http://0.0.0.0:30000/generate at 1753383146.8136451
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_888 with payload: {'text': 'Random prompt 888 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_889 to http://0.0.0.0:30000/generate at 1753383146.8138206
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_889 with payload: {'text': 'Random prompt 889 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 191, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_890 to http://0.0.0.0:30000/generate at 1753383146.813948
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_890 with payload: {'text': 'Random prompt 890 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 77, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_891 to http://0.0.0.0:30000/generate at 1753383146.8140674
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_891 with payload: {'text': 'Random prompt 891 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 115, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_892 to http://0.0.0.0:30000/generate at 1753383146.8142045
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_892 with payload: {'text': 'Random prompt 892 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_893 to http://0.0.0.0:30000/generate at 1753383146.8143244
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_893 with payload: {'text': 'Random prompt 893 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_894 to http://0.0.0.0:30000/generate at 1753383146.8144486
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_894 with payload: {'text': 'Random prompt 894 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 135, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_895 to http://0.0.0.0:30000/generate at 1753383146.8145714
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_895 with payload: {'text': 'Random prompt 895 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_896 to http://0.0.0.0:30000/generate at 1753383146.814689
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_896 with payload: {'text': 'Random prompt 896 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_897 to http://0.0.0.0:30000/generate at 1753383146.814811
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_897 with payload: {'text': 'Random prompt 897 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_898 to http://0.0.0.0:30000/generate at 1753383146.8149316
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_898 with payload: {'text': 'Random prompt 898 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 109, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_899 to http://0.0.0.0:30000/generate at 1753383146.815053
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_899 with payload: {'text': 'Random prompt 899 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_900 to http://0.0.0.0:30000/generate at 1753383146.8151991
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_900 with payload: {'text': 'Random prompt 900 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 135, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_901 to http://0.0.0.0:30000/generate at 1753383146.8153744
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_901 with payload: {'text': 'Random prompt 901 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 65, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_902 to http://0.0.0.0:30000/generate at 1753383146.815496
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_902 with payload: {'text': 'Random prompt 902 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 161, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_903 to http://0.0.0.0:30000/generate at 1753383146.8156252
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_903 with payload: {'text': 'Random prompt 903 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 69, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_904 to http://0.0.0.0:30000/generate at 1753383146.8157544
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_904 with payload: {'text': 'Random prompt 904 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 159, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_905 to http://0.0.0.0:30000/generate at 1753383146.8158796
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_905 with payload: {'text': 'Random prompt 905 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 90, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_906 to http://0.0.0.0:30000/generate at 1753383146.8160079
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_906 with payload: {'text': 'Random prompt 906 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 187, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_907 to http://0.0.0.0:30000/generate at 1753383146.8161306
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_907 with payload: {'text': 'Random prompt 907 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_908 to http://0.0.0.0:30000/generate at 1753383146.8162558
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_908 with payload: {'text': 'Random prompt 908 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_909 to http://0.0.0.0:30000/generate at 1753383146.8163772
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_909 with payload: {'text': 'Random prompt 909 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_910 to http://0.0.0.0:30000/generate at 1753383146.8164978
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_910 with payload: {'text': 'Random prompt 910 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 103, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_911 to http://0.0.0.0:30000/generate at 1753383146.8166258
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_911 with payload: {'text': 'Random prompt 911 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_912 to http://0.0.0.0:30000/generate at 1753383146.816753
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_912 with payload: {'text': 'Random prompt 912 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_913 to http://0.0.0.0:30000/generate at 1753383146.816917
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_913 with payload: {'text': 'Random prompt 913 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 111, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_914 to http://0.0.0.0:30000/generate at 1753383146.81704
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_914 with payload: {'text': 'Random prompt 914 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 121, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_915 to http://0.0.0.0:30000/generate at 1753383146.8171637
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_915 with payload: {'text': 'Random prompt 915 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 156, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_916 to http://0.0.0.0:30000/generate at 1753383146.817289
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_916 with payload: {'text': 'Random prompt 916 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 177, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_917 to http://0.0.0.0:30000/generate at 1753383146.8174157
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_917 with payload: {'text': 'Random prompt 917 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 140, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_918 to http://0.0.0.0:30000/generate at 1753383146.8175445
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_918 with payload: {'text': 'Random prompt 918 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 114, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_919 to http://0.0.0.0:30000/generate at 1753383146.8176672
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_919 with payload: {'text': 'Random prompt 919 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 117, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_920 to http://0.0.0.0:30000/generate at 1753383146.8178017
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_920 with payload: {'text': 'Random prompt 920 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 153, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_921 to http://0.0.0.0:30000/generate at 1753383146.817926
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_921 with payload: {'text': 'Random prompt 921 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 64, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_922 to http://0.0.0.0:30000/generate at 1753383146.8180535
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_922 with payload: {'text': 'Random prompt 922 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 143, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_923 to http://0.0.0.0:30000/generate at 1753383146.818183
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_923 with payload: {'text': 'Random prompt 923 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 110, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_924 to http://0.0.0.0:30000/generate at 1753383146.8183103
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_924 with payload: {'text': 'Random prompt 924 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 166, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_925 to http://0.0.0.0:30000/generate at 1753383146.8184795
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_925 with payload: {'text': 'Random prompt 925 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 76, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_926 to http://0.0.0.0:30000/generate at 1753383146.8186007
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_926 with payload: {'text': 'Random prompt 926 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 139, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_927 to http://0.0.0.0:30000/generate at 1753383146.8187218
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_927 with payload: {'text': 'Random prompt 927 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_928 to http://0.0.0.0:30000/generate at 1753383146.8188436
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_928 with payload: {'text': 'Random prompt 928 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_929 to http://0.0.0.0:30000/generate at 1753383146.818968
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_929 with payload: {'text': 'Random prompt 929 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 72, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_930 to http://0.0.0.0:30000/generate at 1753383146.8190904
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_930 with payload: {'text': 'Random prompt 930 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 138, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_931 to http://0.0.0.0:30000/generate at 1753383146.8192155
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_931 with payload: {'text': 'Random prompt 931 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 136, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_932 to http://0.0.0.0:30000/generate at 1753383146.8193452
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_932 with payload: {'text': 'Random prompt 932 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 136, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_933 to http://0.0.0.0:30000/generate at 1753383146.8194702
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_933 with payload: {'text': 'Random prompt 933 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_934 to http://0.0.0.0:30000/generate at 1753383146.819593
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_934 with payload: {'text': 'Random prompt 934 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 151, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_935 to http://0.0.0.0:30000/generate at 1753383146.8197186
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_935 with payload: {'text': 'Random prompt 935 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_936 to http://0.0.0.0:30000/generate at 1753383146.8198423
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_936 with payload: {'text': 'Random prompt 936 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_937 to http://0.0.0.0:30000/generate at 1753383146.820012
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_937 with payload: {'text': 'Random prompt 937 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_938 to http://0.0.0.0:30000/generate at 1753383146.820141
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_938 with payload: {'text': 'Random prompt 938 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_939 to http://0.0.0.0:30000/generate at 1753383146.8228426
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_939 with payload: {'text': 'Random prompt 939 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_940 to http://0.0.0.0:30000/generate at 1753383146.8231144
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_940 with payload: {'text': 'Random prompt 940 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_941 to http://0.0.0.0:30000/generate at 1753383146.8233159
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_941 with payload: {'text': 'Random prompt 941 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_942 to http://0.0.0.0:30000/generate at 1753383146.8234754
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_942 with payload: {'text': 'Random prompt 942 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 164, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_943 to http://0.0.0.0:30000/generate at 1753383146.8236203
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_943 with payload: {'text': 'Random prompt 943 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 155, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_944 to http://0.0.0.0:30000/generate at 1753383146.8237624
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_944 with payload: {'text': 'Random prompt 944 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_945 to http://0.0.0.0:30000/generate at 1753383146.8239162
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_945 with payload: {'text': 'Random prompt 945 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_946 to http://0.0.0.0:30000/generate at 1753383146.8240736
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_946 with payload: {'text': 'Random prompt 946 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_947 to http://0.0.0.0:30000/generate at 1753383146.8242373
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_947 with payload: {'text': 'Random prompt 947 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 83, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_948 to http://0.0.0.0:30000/generate at 1753383146.8243828
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_948 with payload: {'text': 'Random prompt 948 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 106, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_949 to http://0.0.0.0:30000/generate at 1753383146.824605
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_949 with payload: {'text': 'Random prompt 949 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_950 to http://0.0.0.0:30000/generate at 1753383146.8247442
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_950 with payload: {'text': 'Random prompt 950 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 75, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_951 to http://0.0.0.0:30000/generate at 1753383146.8248794
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_951 with payload: {'text': 'Random prompt 951 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 92, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_952 to http://0.0.0.0:30000/generate at 1753383146.8250253
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_952 with payload: {'text': 'Random prompt 952 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 141, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_953 to http://0.0.0.0:30000/generate at 1753383146.8251622
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_953 with payload: {'text': 'Random prompt 953 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 158, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_954 to http://0.0.0.0:30000/generate at 1753383146.825315
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_954 with payload: {'text': 'Random prompt 954 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 192, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_955 to http://0.0.0.0:30000/generate at 1753383146.8254514
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_955 with payload: {'text': 'Random prompt 955 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 183, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_956 to http://0.0.0.0:30000/generate at 1753383146.825602
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_956 with payload: {'text': 'Random prompt 956 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 146, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_957 to http://0.0.0.0:30000/generate at 1753383146.8257434
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_957 with payload: {'text': 'Random prompt 957 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 118, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_958 to http://0.0.0.0:30000/generate at 1753383146.8258803
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_958 with payload: {'text': 'Random prompt 958 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 145, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_959 to http://0.0.0.0:30000/generate at 1753383146.8260272
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_959 with payload: {'text': 'Random prompt 959 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 165, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_960 to http://0.0.0.0:30000/generate at 1753383146.8261676
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_960 with payload: {'text': 'Random prompt 960 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 79, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_961 to http://0.0.0.0:30000/generate at 1753383146.8263717
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_961 with payload: {'text': 'Random prompt 961 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 116, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_962 to http://0.0.0.0:30000/generate at 1753383146.8265114
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_962 with payload: {'text': 'Random prompt 962 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 171, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_963 to http://0.0.0.0:30000/generate at 1753383146.8266456
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_963 with payload: {'text': 'Random prompt 963 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 113, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_964 to http://0.0.0.0:30000/generate at 1753383146.8267848
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_964 with payload: {'text': 'Random prompt 964 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 137, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_965 to http://0.0.0.0:30000/generate at 1753383146.8269184
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_965 with payload: {'text': 'Random prompt 965 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 139, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_966 to http://0.0.0.0:30000/generate at 1753383146.827061
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_966 with payload: {'text': 'Random prompt 966 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_967 to http://0.0.0.0:30000/generate at 1753383146.8272033
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_967 with payload: {'text': 'Random prompt 967 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 110, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_968 to http://0.0.0.0:30000/generate at 1753383146.8273406
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_968 with payload: {'text': 'Random prompt 968 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 107, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_969 to http://0.0.0.0:30000/generate at 1753383146.8274763
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_969 with payload: {'text': 'Random prompt 969 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_970 to http://0.0.0.0:30000/generate at 1753383146.8276255
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_970 with payload: {'text': 'Random prompt 970 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 67, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_971 to http://0.0.0.0:30000/generate at 1753383146.8277693
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_971 with payload: {'text': 'Random prompt 971 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 170, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_972 to http://0.0.0.0:30000/generate at 1753383146.8279073
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_972 with payload: {'text': 'Random prompt 972 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 99, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_973 to http://0.0.0.0:30000/generate at 1753383146.82928
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_973 with payload: {'text': 'Random prompt 973 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 130, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_974 to http://0.0.0.0:30000/generate at 1753383146.829432
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_974 with payload: {'text': 'Random prompt 974 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 102, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_975 to http://0.0.0.0:30000/generate at 1753383146.8295727
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_975 with payload: {'text': 'Random prompt 975 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 184, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_976 to http://0.0.0.0:30000/generate at 1753383146.829713
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_976 with payload: {'text': 'Random prompt 976 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 97, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_977 to http://0.0.0.0:30000/generate at 1753383146.8298562
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_977 with payload: {'text': 'Random prompt 977 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 119, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_978 to http://0.0.0.0:30000/generate at 1753383146.8299944
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_978 with payload: {'text': 'Random prompt 978 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 176, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_979 to http://0.0.0.0:30000/generate at 1753383146.8301303
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_979 with payload: {'text': 'Random prompt 979 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 172, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_980 to http://0.0.0.0:30000/generate at 1753383146.8302772
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_980 with payload: {'text': 'Random prompt 980 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 88, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_981 to http://0.0.0.0:30000/generate at 1753383146.8304222
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_981 with payload: {'text': 'Random prompt 981 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 167, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_982 to http://0.0.0.0:30000/generate at 1753383146.8305633
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_982 with payload: {'text': 'Random prompt 982 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 123, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_983 to http://0.0.0.0:30000/generate at 1753383146.8306973
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_983 with payload: {'text': 'Random prompt 983 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 126, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_984 to http://0.0.0.0:30000/generate at 1753383146.830861
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_984 with payload: {'text': 'Random prompt 984 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_985 to http://0.0.0.0:30000/generate at 1753383146.8310702
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_985 with payload: {'text': 'Random prompt 985 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 74, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_986 to http://0.0.0.0:30000/generate at 1753383146.8312159
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_986 with payload: {'text': 'Random prompt 986 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_987 to http://0.0.0.0:30000/generate at 1753383146.831358
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_987 with payload: {'text': 'Random prompt 987 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 128, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_988 to http://0.0.0.0:30000/generate at 1753383146.8314993
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_988 with payload: {'text': 'Random prompt 988 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 120, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_989 to http://0.0.0.0:30000/generate at 1753383146.8316379
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_989 with payload: {'text': 'Random prompt 989 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 157, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_990 to http://0.0.0.0:30000/generate at 1753383146.8317735
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_990 with payload: {'text': 'Random prompt 990 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 162, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_991 to http://0.0.0.0:30000/generate at 1753383146.8319032
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_991 with payload: {'text': 'Random prompt 991 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 84, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_992 to http://0.0.0.0:30000/generate at 1753383146.8320396
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_992 with payload: {'text': 'Random prompt 992 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 142, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_993 to http://0.0.0.0:30000/generate at 1753383146.8321812
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_993 with payload: {'text': 'Random prompt 993 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 81, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_994 to http://0.0.0.0:30000/generate at 1753383146.832319
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_994 with payload: {'text': 'Random prompt 994 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 160, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_995 to http://0.0.0.0:30000/generate at 1753383146.8324647
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_995 with payload: {'text': 'Random prompt 995 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 148, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_996 to http://0.0.0.0:30000/generate at 1753383146.8326013
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_996 with payload: {'text': 'Random prompt 996 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 186, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_997 to http://0.0.0.0:30000/generate at 1753383146.8327925
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_997 with payload: {'text': 'Random prompt 997 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 73, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_998 to http://0.0.0.0:30000/generate at 1753383146.8329298
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_998 with payload: {'text': 'Random prompt 998 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 71, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Sending request req_999 to http://0.0.0.0:30000/generate at 1753383146.8330636
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Posting request req_999 with payload: {'text': 'Random prompt 999 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', 'sampling_params': {'temperature': 0.0, 'max_new_tokens': 100, 'ignore_eos': True}, 'stream': True}
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48202 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0,
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60466 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48228 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60498 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0,
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48188 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_0
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_0
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60476 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] Prefill batch. #new-seq: 1, #new-token: 55, #cached-token: 30, token usage: 0.00, #running-req: 1, #queue-req: 0,
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48256 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_7
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_7
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_15
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_15
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48210 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_4
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_4
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60520 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_9
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_9
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_1
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_1
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_5
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_5
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_42
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_42
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_11
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_11
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_63
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_63
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60506 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48240 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48250 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60528 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48262 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_2
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_2
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_16
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_16
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48268 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60544 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_19
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_19
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_6
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_6
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_12
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_12
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_13
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_13
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_10
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_10
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60548 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] Prefill batch. #new-seq: 8, #new-token: 723, #cached-token: 87, token usage: 0.00, #running-req: 1, #queue-req: 0,
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48220 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48278 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_8
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_8
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60558 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_20
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_20
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_17
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_17
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48294 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_22
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_22
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_18
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_18
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48302 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_21
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_21
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_23
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_23
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48310 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_27
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_27
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60578 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_24
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_24
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48326 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_25
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_25
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60592 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_28
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_28
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48336 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_29
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_29
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60606 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_26
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_26
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48350 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_33
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_33
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60612 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_30
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_30
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48354 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_79
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_79
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_31
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_31
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48370 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_35
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_35
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60636 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_32
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_32
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48384 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_36
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_36
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60648 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_38
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_38
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48394 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_39
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_39
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_40
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_40
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48408 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_41
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_41
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_37
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_37
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48420 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_46
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_46
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60672 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_44
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_44
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_45
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_45
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] Prefill batch. #new-seq: 14, #new-token: 1584, #cached-token: 58, token usage: 0.01, #running-req: 9, #queue-req: 0,
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48434 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_87
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_87
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48436 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_49
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_49
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] Prefill batch. #new-seq: 21, #new-token: 2445, #cached-token: 192, token usage: 0.00, #running-req: 2, #queue-req: 0,
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_3
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_3
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48446 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_47
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_47
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_52
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_52
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48462 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_57
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_57
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60700 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_48
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_48
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48474 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_50
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_50
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_65
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_65
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48480 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_53
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_53
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60720 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_55
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_55
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48484 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_59
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_59
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_90
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_90
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_14
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_14
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60732 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_54
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_54
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_60
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_60
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48506 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_58
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_58
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_67
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_67
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48518 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60752 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_64
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_64
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_56
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_56
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_61
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_61
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48530 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60758 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_70
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_70
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_68
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_68
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60774 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_72
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_72
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_66
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_66
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_75
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_75
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_71
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_71
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60782 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48560 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_73
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_73
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_69
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_69
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60798 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48566 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_77
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_77
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_76
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_76
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_78
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_78
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48590 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_74
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_74
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_34
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_34
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_81
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_81
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_82
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_82
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48610 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_80
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_80
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60852 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_88
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_88
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_83
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_83
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60862 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_93
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_93
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_84
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_84
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_89
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_89
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_85
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_85
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60874 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_51
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_51
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48650 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_43
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_43
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60878 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_97
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_97
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48652 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_94
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60886 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_94
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_95
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_95
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48658 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_92
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_92
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_98
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_98
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60900 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_96
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_96
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_86
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_86
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60910 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_99
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_99
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] Prefill batch. #new-seq: 23, #new-token: 2856, #cached-token: 100, token usage: 0.02, #running-req: 23, #queue-req: 0,
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_62
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:26] INFO:     127.0.0.1:60922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_62
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_91
[2025-07-25 02:52:26] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_91
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:26] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:26] Prefill batch. #new-seq: 28, #new-token: 3603, #cached-token: 132, token usage: 0.02, #running-req: 23, #queue-req: 0,
[2025-07-25 02:52:27] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:27] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:27] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:27] Prefill batch. #new-seq: 3, #new-token: 447, #cached-token: 15, token usage: 0.05, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:27] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:27] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:27] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:27] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:27] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:27] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:27] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:27] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:27] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:27] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:27] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:27] Decode batch. #running-req: 51, #token: 6825, token usage: 0.06, cuda graph: True, gen throughput (token/s): 201.11, #queue-req: 0,
[2025-07-25 02:52:27] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:27] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:27] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:27] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:27] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:27] Decode batch. #running-req: 49, #token: 7271, token usage: 0.06, cuda graph: True, gen throughput (token/s): 357.30, #queue-req: 0,
[2025-07-25 02:52:27] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:27] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:27] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:27] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:27] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] Decode batch. #running-req: 51, #token: 8865, token usage: 0.07, cuda graph: True, gen throughput (token/s): 3868.59, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] Decode batch. #running-req: 49, #token: 9231, token usage: 0.08, cuda graph: True, gen throughput (token/s): 3710.14, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_73 received DONE after 66 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_73 completed: 255 chars, 66 chunks, TTFT=640.5ms
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48560 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_100
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_100
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_49 received DONE after 68 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_49 completed: 69 chars, 68 chunks, TTFT=419.6ms
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_47 received DONE after 68 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_47 completed: 265 chars, 68 chunks, TTFT=626.1ms
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_101
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_101
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_102
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_102
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 5, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_19 received DONE after 69 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_19 completed: 272 chars, 69 chunks, TTFT=429.0ms
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60544 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_103
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_103
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_30 received DONE after 70 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_30 completed: 71 chars, 70 chunks, TTFT=392.1ms
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_13 received DONE after 70 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_13 completed: 276 chars, 70 chunks, TTFT=275.7ms
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_72 received DONE after 69 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_72 completed: 191 chars, 69 chunks, TTFT=640.9ms
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_104
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_104
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_105
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_105
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60928 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_106
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_106
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_38 received DONE after 73 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_38 completed: 279 chars, 73 chunks, TTFT=390.9ms
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48384 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_107
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_107
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_34 received DONE after 74 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_34 completed: 286 chars, 74 chunks, TTFT=649.0ms
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60934 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_108
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_108
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_81 received DONE after 76 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_81 completed: 296 chars, 76 chunks, TTFT=619.2ms
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48590 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_109
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_109
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_67 received DONE after 78 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_67 completed: 301 chars, 78 chunks, TTFT=642.1ms
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_110
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_110
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_33 received DONE after 80 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_33 completed: 306 chars, 80 chunks, TTFT=424.4ms
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48506 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_111
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_111
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_87 received DONE after 85 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_87 completed: 331 chars, 85 chunks, TTFT=636.1ms
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60606 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_112
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_112
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_95 received DONE after 87 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_95 completed: 348 chars, 87 chunks, TTFT=633.9ms
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_0 received DONE after 89 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_0 completed: 90 chars, 89 chunks, TTFT=210.0ms
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48202 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60950 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_113
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_113
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_114
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_114
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_97 received DONE after 88 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_97 completed: 92 chars, 88 chunks, TTFT=633.6ms
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48650 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_115
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_115
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_16 received DONE after 88 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_16 completed: 87 chars, 88 chunks, TTFT=428.7ms
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60528 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_116
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_116
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_78 received DONE after 92 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_78 completed: 94 chars, 92 chunks, TTFT=638.4ms
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_10 received DONE after 93 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_10 completed: 257 chars, 93 chunks, TTFT=276.4ms
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48250 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_117
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_117
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_118
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_118
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] Prefill batch. #new-seq: 2, #new-token: 260, #cached-token: 12, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_32 received DONE after 94 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_32 completed: 372 chars, 94 chunks, TTFT=392.5ms
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60962 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_89 received DONE after 94 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_89 completed: 96 chars, 94 chunks, TTFT=635.5ms
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_119
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_119
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60978 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_96 received DONE after 93 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_96 completed: 365 chars, 93 chunks, TTFT=627.6ms
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_120
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_120
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_121
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_121
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] Decode batch. #running-req: 45, #token: 9067, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2636.65, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 5, token usage: 0.09, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_71 received DONE after 95 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_71 completed: 186 chars, 95 chunks, TTFT=620.4ms
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_94 received DONE after 95 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_94 completed: 365 chars, 95 chunks, TTFT=615.8ms
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_46 received DONE after 95 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_46 completed: 94 chars, 95 chunks, TTFT=420.5ms
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48370 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_122
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_122
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60878 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_66 received DONE after 96 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_66 completed: 188 chars, 96 chunks, TTFT=622.9ms
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_123
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_123
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_124
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_124
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48652 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_8 received DONE after 97 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_8 completed: 298 chars, 97 chunks, TTFT=431.7ms
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_125
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_125
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] Prefill batch. #new-seq: 2, #new-token: 165, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60548 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_126
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_126
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_70 received DONE after 102 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_70 completed: 397 chars, 102 chunks, TTFT=638.9ms
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] INFO:     127.0.0.1:48530 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:28] Prefill batch. #new-seq: 1, #new-token: 171, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_127
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_127
[2025-07-25 02:52:28] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:28] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_69 received DONE after 102 chunks
[2025-07-25 02:52:28] [sglang_test_framework.core.request_generator] [DEBUG] Request req_69 completed: 404 chars, 102 chunks, TTFT=622.0ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60782 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_21 received DONE after 103 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_21 completed: 203 chars, 103 chunks, TTFT=428.2ms
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_128
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_128
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_129
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_129
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] Decode batch. #running-req: 49, #token: 9849, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2331.82, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] Prefill batch. #new-seq: 2, #new-token: 189, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_28 received DONE after 106 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_28 completed: 416 chars, 106 chunks, TTFT=393.7ms
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_42 received DONE after 106 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_42 completed: 291 chars, 106 chunks, TTFT=267.9ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60648 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48210 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_39 received DONE after 105 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_39 completed: 416 chars, 105 chunks, TTFT=423.1ms
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_131
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_131
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_130
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_130
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48326 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_132
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_132
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] Prefill batch. #new-seq: 2, #new-token: 191, #cached-token: 12, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 5, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_55 received DONE after 109 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_55 completed: 426 chars, 109 chunks, TTFT=643.5ms
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_99 received DONE after 109 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_99 completed: 217 chars, 109 chunks, TTFT=633.4ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60774 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_133
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_133
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_134
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_134
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_36 received DONE after 109 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_36 completed: 108 chars, 109 chunks, TTFT=422.9ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48480 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_135
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_135
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_68 received DONE after 110 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_68 completed: 467 chars, 110 chunks, TTFT=622.9ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60758 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_136
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_136
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_76 received DONE after 114 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_76 completed: 441 chars, 114 chunks, TTFT=620.6ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48434 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_82 received DONE after 117 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_82 completed: 468 chars, 117 chunks, TTFT=637.8ms
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_137
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_137
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60798 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_138
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_138
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_57 received DONE after 116 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_57 completed: 115 chars, 116 chunks, TTFT=625.4ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_75 received DONE after 119 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_75 completed: 476 chars, 119 chunks, TTFT=639.4ms
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_139
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_139
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_140
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_140
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_63 received DONE after 118 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_63 completed: 233 chars, 118 chunks, TTFT=415.5ms
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_64 received DONE after 119 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_64 completed: 118 chars, 119 chunks, TTFT=623.1ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_141
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_141
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_142
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_142
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 6, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_9 received DONE after 128 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_9 completed: 498 chars, 128 chunks, TTFT=276.7ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48228 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 100, #cached-token: 6, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_85 received DONE after 125 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_85 completed: 246 chars, 125 chunks, TTFT=618.5ms
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_143
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_143
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_58 received DONE after 126 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_58 completed: 347 chars, 126 chunks, TTFT=625.1ms
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_25 received DONE after 126 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_25 completed: 491 chars, 126 chunks, TTFT=427.6ms
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_144
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_144
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48268 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_145
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_145
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48350 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_146
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_146
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] Prefill batch. #new-seq: 2, #new-token: 205, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_93 received DONE after 130 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_93 completed: 132 chars, 130 chunks, TTFT=632.8ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60578 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_147
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_147
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_51 received DONE after 132 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_51 completed: 528 chars, 132 chunks, TTFT=643.6ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_148
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_148
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_40 received DONE after 134 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_40 completed: 264 chars, 134 chunks, TTFT=390.5ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60732 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_149
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_149
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 6, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] Decode batch. #running-req: 49, #token: 10101, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2293.87, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_1 received DONE after 134 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_1 completed: 525 chars, 134 chunks, TTFT=235.4ms
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_17 received DONE after 138 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_17 completed: 548 chars, 138 chunks, TTFT=397.2ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48394 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_150
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_150
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60466 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_151
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_151
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 5, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_100 received DONE after 72 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_100 completed: 194 chars, 72 chunks, TTFT=1536.5ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60520 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_152
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_152
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 5, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_31 received DONE after 141 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_31 completed: 279 chars, 141 chunks, TTFT=392.5ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48354 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_153
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_153
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_86 received DONE after 143 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_86 completed: 562 chars, 143 chunks, TTFT=637.3ms
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_45 received DONE after 144 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_45 completed: 562 chars, 144 chunks, TTFT=389.4ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60636 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48420 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_154
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_154
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_155
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_155
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_92 received DONE after 143 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_92 completed: 559 chars, 143 chunks, TTFT=616.6ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_156
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_156
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] Decode batch. #running-req: 51, #token: 10349, token usage: 0.09, cuda graph: True, gen throughput (token/s): 2327.92, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_5 received DONE after 149 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_5 completed: 148 chars, 149 chunks, TTFT=278.0ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60720 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_43 received DONE after 145 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_43 completed: 491 chars, 145 chunks, TTFT=628.3ms
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_59 received DONE after 145 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_59 completed: 148 chars, 145 chunks, TTFT=625.2ms
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_157
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_157
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48188 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60874 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_158
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_158
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_159
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_159
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] Prefill batch. #new-seq: 2, #new-token: 313, #cached-token: 12, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_91 received DONE after 148 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_91 completed: 588 chars, 148 chunks, TTFT=629.0ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] INFO:     127.0.0.1:48560 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_160
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_160
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_77 received DONE after 151 chunks
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Request req_77 completed: 424 chars, 151 chunks, TTFT=638.1ms
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] INFO:     127.0.0.1:60922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_161
[2025-07-25 02:52:29] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_161
[2025-07-25 02:52:29] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:29] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_20 received DONE after 154 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_20 completed: 612 chars, 154 chunks, TTFT=395.2ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_6 received DONE after 154 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_6 completed: 427 chars, 154 chunks, TTFT=277.4ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60886 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48240 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_163
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_163
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_162
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_162
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_35 received DONE after 154 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_35 completed: 603 chars, 154 chunks, TTFT=422.9ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48278 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_164
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_164
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_37 received DONE after 158 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_37 completed: 442 chars, 158 chunks, TTFT=390.5ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_14 received DONE after 155 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_14 completed: 616 chars, 155 chunks, TTFT=635.1ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48408 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_3 received DONE after 158 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_3 completed: 160 chars, 158 chunks, TTFT=656.2ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_65 received DONE after 158 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_65 completed: 629 chars, 158 chunks, TTFT=642.5ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_165
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_165
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_166
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_166
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48474 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_167
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_167
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_168
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_168
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_105 received DONE after 87 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_105 completed: 86 chars, 87 chunks, TTFT=1633.4ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] Prefill batch. #new-seq: 2, #new-token: 234, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_169
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_169
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] Prefill batch. #new-seq: 2, #new-token: 222, #cached-token: 12, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_56 received DONE after 162 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_56 completed: 648 chars, 162 chunks, TTFT=642.2ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48518 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_170
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_170
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_109 received DONE after 85 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_109 completed: 231 chars, 85 chunks, TTFT=1780.2ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_171
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_171
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_98 received DONE after 164 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_98 completed: 656 chars, 164 chunks, TTFT=633.1ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48658 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_172
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_172
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 5, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_116 received DONE after 77 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_116 completed: 291 chars, 77 chunks, TTFT=1980.5ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_62 received DONE after 163 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_62 completed: 639 chars, 163 chunks, TTFT=635.7ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60910 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_173
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_173
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60528 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_174
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_174
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] Prefill batch. #new-seq: 2, #new-token: 236, #cached-token: 10, token usage: 0.09, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_41 received DONE after 166 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_41 completed: 167 chars, 166 chunks, TTFT=421.4ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_80 received DONE after 166 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_80 completed: 650 chars, 166 chunks, TTFT=619.9ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48590 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48436 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_53 received DONE after 167 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_53 completed: 654 chars, 167 chunks, TTFT=626.6ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_175
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_175
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_176
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_176
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_4 received DONE after 168 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_4 completed: 167 chars, 168 chunks, TTFT=260.1ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] Prefill batch. #new-seq: 2, #new-token: 233, #cached-token: 12, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_177
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_177
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48566 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_178
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_178
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_29 received DONE after 171 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_29 completed: 478 chars, 171 chunks, TTFT=425.2ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60592 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_179
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_179
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] Decode batch. #running-req: 50, #token: 9602, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2268.30, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_27 received DONE after 173 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_27 completed: 176 chars, 173 chunks, TTFT=425.3ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_126 received DONE after 76 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_126 completed: 286 chars, 76 chunks, TTFT=2220.3ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_26 received DONE after 175 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_26 completed: 346 chars, 175 chunks, TTFT=395.0ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_111 received DONE after 94 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_111 completed: 185 chars, 94 chunks, TTFT=1836.3ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60548 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48506 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_48 received DONE after 175 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_48 completed: 697 chars, 175 chunks, TTFT=645.9ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_180
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_180
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48336 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_182
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_182
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_183
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_183
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_181
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_181
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60498 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_184
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_184
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] Prefill batch. #new-seq: 2, #new-token: 286, #cached-token: 10, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] Prefill batch. #new-seq: 2, #new-token: 249, #cached-token: 12, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_60 received DONE after 176 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_60 completed: 180 chars, 176 chunks, TTFT=642.8ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_119 received DONE after 82 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_119 completed: 83 chars, 82 chunks, TTFT=2100.7ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_7 received DONE after 174 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_7 completed: 515 chars, 174 chunks, TTFT=431.9ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60476 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_186
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_186
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_185
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_185
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48462 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_187
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_187
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] Prefill batch. #new-seq: 2, #new-token: 262, #cached-token: 10, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] Prefill batch. #new-seq: 2, #new-token: 278, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_50 received DONE after 177 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_50 completed: 695 chars, 177 chunks, TTFT=626.8ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_2 received DONE after 177 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_2 completed: 696 chars, 177 chunks, TTFT=433.3ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60672 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_83 received DONE after 178 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_83 completed: 708 chars, 178 chunks, TTFT=619.2ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_44 received DONE after 178 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_44 completed: 177 chars, 178 chunks, TTFT=421.8ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48220 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_188
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_188
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_132 received DONE after 75 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_132 completed: 296 chars, 75 chunks, TTFT=2370.5ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_18 received DONE after 182 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_18 completed: 724 chars, 182 chunks, TTFT=396.6ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_189
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_189
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60852 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_190
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_190
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_191
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_191
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48294 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] Prefill batch. #new-seq: 2, #new-token: 202, #cached-token: 12, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60506 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48326 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_192
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_192
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] Prefill batch. #new-seq: 2, #new-token: 269, #cached-token: 11, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_193
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_193
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_15 received DONE after 183 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_15 completed: 362 chars, 183 chunks, TTFT=275.2ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_112 received DONE after 94 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_112 completed: 360 chars, 94 chunks, TTFT=1945.4ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60606 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48256 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_195
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_195
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_194
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_194
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] Prefill batch. #new-seq: 2, #new-token: 281, #cached-token: 12, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] Prefill batch. #new-seq: 2, #new-token: 250, #cached-token: 10, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_52 received DONE after 184 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_52 completed: 736 chars, 184 chunks, TTFT=645.0ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60700 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_196
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_196
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 6, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_12 received DONE after 186 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_12 completed: 730 chars, 186 chunks, TTFT=275.7ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_135 received DONE after 75 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_135 completed: 296 chars, 75 chunks, TTFT=2465.0ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_90 received DONE after 185 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_90 completed: 740 chars, 185 chunks, TTFT=635.2ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_24 received DONE after 186 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_24 completed: 187 chars, 186 chunks, TTFT=395.4ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48310 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.metrics_collector] [INFO] Completed 100 requests, success rate: 100.0%
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_197
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_197
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60962 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48484 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_198
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_198
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_199
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_199
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] Prefill batch. #new-seq: 2, #new-token: 337, #cached-token: 12, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_200
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_200
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] Prefill batch. #new-seq: 2, #new-token: 319, #cached-token: 11, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_22 received DONE after 183 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_22 completed: 182 chars, 183 chunks, TTFT=427.9ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48480 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_201
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_201
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_23 received DONE after 189 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_23 completed: 374 chars, 189 chunks, TTFT=395.3ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60558 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_202
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_202
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] Decode batch. #running-req: 51, #token: 9348, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2152.18, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_84 received DONE after 186 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_84 completed: 369 chars, 186 chunks, TTFT=618.7ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_106 received DONE after 116 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_106 completed: 117 chars, 116 chunks, TTFT=1635.9ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48610 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60928 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_88 received DONE after 191 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_88 completed: 683 chars, 191 chunks, TTFT=636.2ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_203
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_203
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_204
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_204
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48302 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_54 received DONE after 192 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_54 completed: 192 chars, 192 chunks, TTFT=644.0ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_118 received DONE after 99 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_118 completed: 392 chars, 99 chunks, TTFT=2094.0ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_79 received DONE after 187 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_79 completed: 371 chars, 187 chunks, TTFT=412.4ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_205
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_205
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60612 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60862 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_206
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_206
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_207
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_207
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_208
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_208
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] Prefill batch. #new-seq: 2, #new-token: 136, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] Prefill batch. #new-seq: 2, #new-token: 208, #cached-token: 12, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_61 received DONE after 191 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_61 completed: 192 chars, 191 chunks, TTFT=623.8ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_11 received DONE after 191 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_11 completed: 760 chars, 191 chunks, TTFT=429.8ms
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_74 received DONE after 191 chunks
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Request req_74 completed: 751 chars, 191 chunks, TTFT=621.3ms
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] INFO:     127.0.0.1:48486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_209
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:30] INFO:     127.0.0.1:60486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_209
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_210
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_210
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_211
[2025-07-25 02:52:30] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_211
[2025-07-25 02:52:30] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:30] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 5, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 150, #cached-token: 6, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_133 received DONE after 93 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_133 completed: 368 chars, 93 chunks, TTFT=2459.5ms
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_212
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_212
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 145, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_129 received DONE after 98 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_129 completed: 99 chars, 98 chunks, TTFT=2361.3ms
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_213
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_213
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 6, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] Decode batch. #running-req: 49, #token: 9730, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2421.52, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_127 received DONE after 117 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_127 completed: 464 chars, 117 chunks, TTFT=2310.2ms
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60752 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_214
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_214
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_159 received DONE after 69 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_159 completed: 272 chars, 69 chunks, TTFT=3230.5ms
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48530 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_215
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_215
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 91, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_113 received DONE after 134 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_113 completed: 520 chars, 134 chunks, TTFT=1975.5ms
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48202 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_216
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_216
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_168 received DONE after 66 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_168 completed: 260 chars, 66 chunks, TTFT=3446.6ms
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60874 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_217
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_217
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 103, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_128 received DONE after 113 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_128 completed: 480 chars, 113 chunks, TTFT=2361.4ms
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48474 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_218
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_218
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_115 received DONE after 139 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_115 completed: 440 chars, 139 chunks, TTFT=1977.9ms
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60782 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_219
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_219
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] Decode batch. #running-req: 51, #token: 9968, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2803.43, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_144 received DONE after 99 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_144 completed: 98 chars, 99 chunks, TTFT=2842.1ms
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_141 received DONE after 110 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_141 completed: 436 chars, 110 chunks, TTFT=2706.4ms
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_156 received DONE after 85 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_156 completed: 333 chars, 85 chunks, TTFT=3211.4ms
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_220
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_220
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_221
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_221
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_222
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_222
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] Prefill batch. #new-seq: 2, #new-token: 220, #cached-token: 10, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_114 received DONE after 141 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_114 completed: 142 chars, 141 chunks, TTFT=1969.1ms
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48650 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_125 received DONE after 136 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_125 completed: 531 chars, 136 chunks, TTFT=2216.1ms
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_223
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_223
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60934 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_108 received DONE after 154 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_108 completed: 612 chars, 154 chunks, TTFT=1725.3ms
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_224
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_224
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48652 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_225
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_225
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] Prefill batch. #new-seq: 2, #new-token: 202, #cached-token: 10, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 95, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_107 received DONE after 162 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_107 completed: 630 chars, 162 chunks, TTFT=1694.5ms
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60950 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_226
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_226
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_161 received DONE after 81 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_161 completed: 82 chars, 81 chunks, TTFT=3325.1ms
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48384 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_131 received DONE after 128 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_131 completed: 252 chars, 128 chunks, TTFT=2362.7ms
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_227
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_227
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48262 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_228
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_228
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 175, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_164 received DONE after 86 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_164 completed: 238 chars, 86 chunks, TTFT=3438.5ms
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60648 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_229
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_229
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_137 received DONE after 128 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_137 completed: 127 chars, 128 chunks, TTFT=2613.2ms
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_230
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_230
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 5, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_138 received DONE after 127 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_138 completed: 126 chars, 127 chunks, TTFT=2607.0ms
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48434 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_231
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_231
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_187 received DONE after 74 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_187 completed: 75 chars, 74 chunks, TTFT=3848.6ms
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] INFO:     127.0.0.1:48462 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_232
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_232
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_124 received DONE after 149 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_124 completed: 592 chars, 149 chunks, TTFT=2217.5ms
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60878 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_233
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_233
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:31] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:31] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_102 received DONE after 178 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_102 completed: 708 chars, 178 chunks, TTFT=1582.4ms
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_177 received DONE after 79 chunks
[2025-07-25 02:52:31] [sglang_test_framework.core.request_generator] [DEBUG] Request req_177 completed: 154 chars, 79 chunks, TTFT=3710.9ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48278 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_110 received DONE after 169 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_110 completed: 168 chars, 169 chunks, TTFT=1815.2ms
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_235
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_235
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_234
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_234
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_236
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_236
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] Prefill batch. #new-seq: 2, #new-token: 183, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_201 received DONE after 68 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_201 completed: 188 chars, 68 chunks, TTFT=4098.8ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48480 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_237
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_237
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] Decode batch. #running-req: 49, #token: 9936, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2482.92, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_101 received DONE after 189 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_101 completed: 190 chars, 189 chunks, TTFT=1544.2ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_238
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_238
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_194 received DONE after 71 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_194 completed: 138 chars, 71 chunks, TTFT=4000.5ms
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_184 received DONE after 78 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_184 completed: 77 chars, 78 chunks, TTFT=3833.9ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_239
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_239
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48446 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_240
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_240
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] Prefill batch. #new-seq: 2, #new-token: 266, #cached-token: 12, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_202 received DONE after 68 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_202 completed: 133 chars, 68 chunks, TTFT=4139.0ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60558 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_241
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_241
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 5, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_103 received DONE after 184 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_103 completed: 185 chars, 184 chunks, TTFT=1582.3ms
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_190 received DONE after 74 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_190 completed: 312 chars, 74 chunks, TTFT=3973.0ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60852 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_243
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_243
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_242
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_242
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_139 received DONE after 141 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_139 completed: 548 chars, 141 chunks, TTFT=2614.8ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60544 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_244
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_244
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_162 received DONE after 108 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_162 completed: 425 chars, 108 chunks, TTFT=3362.8ms
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_104 received DONE after 192 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_104 completed: 764 chars, 192 chunks, TTFT=1626.7ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60606 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_246
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_246
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_245
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_245
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_130 received DONE after 158 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_130 completed: 312 chars, 158 chunks, TTFT=2370.8ms
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_143 received DONE after 137 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_143 completed: 136 chars, 137 chunks, TTFT=2822.4ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60498 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_247
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_247
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48228 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_248
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_248
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_169 received DONE after 102 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_169 completed: 105 chars, 102 chunks, TTFT=3461.4ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_249
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_249
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_199 received DONE after 82 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_199 completed: 310 chars, 82 chunks, TTFT=4088.9ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48484 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_250
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_250
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 100, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_173 received DONE after 98 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_173 completed: 97 chars, 98 chunks, TTFT=3596.6ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48210 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_117 received DONE after 177 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_117 completed: 350 chars, 177 chunks, TTFT=2094.1ms
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_251
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_251
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60774 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_134 received DONE after 152 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_134 completed: 591 chars, 152 chunks, TTFT=2476.2ms
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_252
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_252
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48250 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_253
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_253
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] Prefill batch. #new-seq: 2, #new-token: 214, #cached-token: 10, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] Decode batch. #running-req: 50, #token: 10239, token usage: 0.09, cuda graph: True, gen throughput (token/s): 2162.63, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_122 received DONE after 175 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_122 completed: 176 chars, 175 chunks, TTFT=2216.4ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60910 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_123 received DONE after 169 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_123 completed: 334 chars, 169 chunks, TTFT=2217.4ms
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_254
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_254
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48370 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 6, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_255
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_255
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_120 received DONE after 179 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_120 completed: 712 chars, 179 chunks, TTFT=2103.9ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60978 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_142 received DONE after 152 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_142 completed: 155 chars, 152 chunks, TTFT=2711.7ms
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_121 received DONE after 187 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_121 completed: 731 chars, 187 chunks, TTFT=2101.8ms
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_256
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_256
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_258
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_258
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_257
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_257
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 150, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_181 received DONE after 109 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_181 completed: 214 chars, 109 chunks, TTFT=3839.9ms
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_147 received DONE after 149 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_147 completed: 592 chars, 149 chunks, TTFT=2854.4ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48506 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48240 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_260
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_260
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_259
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_259
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] Prefill batch. #new-seq: 2, #new-token: 214, #cached-token: 12, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_212 received DONE after 86 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_212 completed: 337 chars, 86 chunks, TTFT=4436.1ms
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_188 received DONE after 104 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_188 completed: 107 chars, 104 chunks, TTFT=3973.5ms
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_136 received DONE after 174 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_136 completed: 175 chars, 174 chunks, TTFT=2479.5ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60758 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_261
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_261
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60672 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_262
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_262
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_263
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_263
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] Prefill batch. #new-seq: 2, #new-token: 317, #cached-token: 10, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_154 received DONE after 144 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_154 completed: 572 chars, 144 chunks, TTFT=3143.4ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_264
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_264
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_153 received DONE after 152 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_153 completed: 155 chars, 152 chunks, TTFT=3081.8ms
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_150 received DONE after 156 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_150 completed: 620 chars, 156 chunks, TTFT=2998.9ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48394 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60636 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_266
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_266
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_265
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_265
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] Prefill batch. #new-seq: 2, #new-token: 323, #cached-token: 12, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_167 received DONE after 130 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_167 completed: 257 chars, 130 chunks, TTFT=3461.6ms
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_140 received DONE after 171 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_140 completed: 680 chars, 171 chunks, TTFT=2617.2ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_268
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_268
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48354 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_267
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_267
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 6, token usage: 0.09, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] Decode batch. #running-req: 52, #token: 10288, token usage: 0.09, cuda graph: True, gen throughput (token/s): 2284.78, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_208 received DONE after 100 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_208 completed: 277 chars, 100 chunks, TTFT=4213.3ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60862 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_269
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_269
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_146 received DONE after 167 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_146 completed: 168 chars, 167 chunks, TTFT=2831.1ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 99, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:48350 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_192 received DONE after 109 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_192 completed: 432 chars, 109 chunks, TTFT=4001.0ms
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_270
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_270
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_152 received DONE after 154 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_152 completed: 304 chars, 154 chunks, TTFT=3027.4ms
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 5, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60506 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_271
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_271
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] INFO:     127.0.0.1:37002 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_272
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_272
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:32] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:32] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:32] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 5, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_203 received DONE after 106 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_203 completed: 407 chars, 106 chunks, TTFT=4213.8ms
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_216 received DONE after 76 chunks
[2025-07-25 02:52:32] [sglang_test_framework.core.request_generator] [DEBUG] Request req_216 completed: 77 chars, 76 chunks, TTFT=4736.6ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48202 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60520 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_274
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_274
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_273
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_273
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_175 received DONE after 134 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_175 completed: 532 chars, 134 chunks, TTFT=3726.9ms
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_155 received DONE after 161 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_155 completed: 160 chars, 161 chunks, TTFT=3138.7ms
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_145 received DONE after 177 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_145 completed: 495 chars, 177 chunks, TTFT=2823.6ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48268 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60578 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_275
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_275
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_276
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_276
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_277
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_277
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] Prefill batch. #new-seq: 2, #new-token: 269, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_170 received DONE after 144 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_170 completed: 449 chars, 144 chunks, TTFT=3567.3ms
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_148 received DONE after 174 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_148 completed: 748 chars, 174 chunks, TTFT=2921.8ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_279
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_279
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_278
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_278
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_172 received DONE after 146 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_172 completed: 147 chars, 146 chunks, TTFT=3569.0ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60798 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 5, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_280
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_280
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] Decode batch. #running-req: 52, #token: 10964, token usage: 0.09, cuda graph: True, gen throughput (token/s): 2312.46, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_207 received DONE after 122 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_207 completed: 472 chars, 122 chunks, TTFT=4216.9ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_281
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_281
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_215 received DONE after 93 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_215 completed: 368 chars, 93 chunks, TTFT=4713.8ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48530 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_179 received DONE after 134 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_179 completed: 264 chars, 134 chunks, TTFT=3796.9ms
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_282
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_282
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60592 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_151 received DONE after 172 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_151 completed: 341 chars, 172 chunks, TTFT=3021.0ms
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_283
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_283
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48658 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_284
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_284
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_174 received DONE after 146 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_174 completed: 577 chars, 146 chunks, TTFT=3596.4ms
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_149 received DONE after 176 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_149 completed: 177 chars, 176 chunks, TTFT=2943.7ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] Prefill batch. #new-seq: 2, #new-token: 244, #cached-token: 12, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60732 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60528 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_286
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_286
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_285
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_285
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_210 received DONE after 120 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_210 completed: 476 chars, 120 chunks, TTFT=4317.7ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_287
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_287
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] Prefill batch. #new-seq: 2, #new-token: 187, #cached-token: 12, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_221 received DONE after 84 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_221 completed: 87 chars, 84 chunks, TTFT=4933.3ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_288
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_288
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_163 received DONE after 160 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_163 completed: 161 chars, 160 chunks, TTFT=3372.0ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 6, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48560 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_160 received DONE after 171 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_160 completed: 170 chars, 171 chunks, TTFT=3288.4ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_289
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_289
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60886 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_191 received DONE after 140 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_191 completed: 542 chars, 140 chunks, TTFT=3980.5ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_290
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_290
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60466 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_291
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_291
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_211 received DONE after 123 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_211 completed: 124 chars, 123 chunks, TTFT=4322.9ms
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_204 received DONE after 128 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_204 completed: 505 chars, 128 chunks, TTFT=4208.0ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48294 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60928 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_292
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_292
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_293
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_293
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] Prefill batch. #new-seq: 2, #new-token: 173, #cached-token: 12, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_158 received DONE after 177 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_158 completed: 350 chars, 177 chunks, TTFT=3218.8ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_294
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_294
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_193 received DONE after 144 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_193 completed: 569 chars, 144 chunks, TTFT=3985.2ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48326 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_295
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_295
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_165 received DONE after 170 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_165 completed: 664 chars, 170 chunks, TTFT=3445.4ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60878 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_233 received DONE after 69 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_233 completed: 70 chars, 69 chunks, TTFT=5327.2ms
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_296
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48408 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_296
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_297
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_297
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_182 received DONE after 146 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_182 completed: 580 chars, 146 chunks, TTFT=3828.9ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_298
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_298
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 89, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_178 received DONE after 162 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_178 completed: 631 chars, 162 chunks, TTFT=3726.8ms
[2025-07-25 02:52:33] [sglang_test_framework.core.metrics_collector] [INFO] Completed 200 requests, success rate: 100.0%
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48566 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_299
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_299
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] Decode batch. #running-req: 47, #token: 9538, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2360.31, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_219 received DONE after 100 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_219 completed: 383 chars, 100 chunks, TTFT=4857.6ms
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_157 received DONE after 178 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_157 completed: 696 chars, 178 chunks, TTFT=3230.7ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48188 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_300
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60720 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_300
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_301
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_301
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_247 received DONE after 69 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_247 completed: 227 chars, 69 chunks, TTFT=5614.0ms
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_186 received DONE after 153 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_186 completed: 595 chars, 153 chunks, TTFT=3833.7ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60476 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48518 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_176 received DONE after 165 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_176 completed: 653 chars, 165 chunks, TTFT=3726.7ms
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_303
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_303
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_302
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_302
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48436 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_304
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_304
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] Prefill batch. #new-seq: 2, #new-token: 284, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_166 received DONE after 172 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_166 completed: 171 chars, 172 chunks, TTFT=3457.1ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_189 received DONE after 156 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_189 completed: 155 chars, 156 chunks, TTFT=3980.7ms
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_305
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_305
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48220 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_306
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_306
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_227 received DONE after 100 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_227 completed: 396 chars, 100 chunks, TTFT=5074.3ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48384 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_307
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_307
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_232 received DONE after 92 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_232 completed: 95 chars, 92 chunks, TTFT=5249.3ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] INFO:     127.0.0.1:60498 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_308
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_308
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:33] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_231 received DONE after 94 chunks
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Request req_231 completed: 372 chars, 94 chunks, TTFT=5245.3ms
[2025-07-25 02:52:33] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:33] INFO:     127.0.0.1:48434 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_309
[2025-07-25 02:52:33] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_309
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_239 received DONE after 89 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_239 completed: 175 chars, 89 chunks, TTFT=5433.7ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_310
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_310
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_246 received DONE after 82 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_246 completed: 85 chars, 82 chunks, TTFT=5588.2ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60606 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_311
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_311
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_206 received DONE after 152 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_206 completed: 300 chars, 152 chunks, TTFT=4211.2ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60612 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_312
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_312
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_253 received DONE after 81 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_253 completed: 80 chars, 81 chunks, TTFT=5715.7ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48250 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_313
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_313
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_252 received DONE after 80 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_252 completed: 304 chars, 80 chunks, TTFT=5728.6ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60774 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_314
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_314
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 168, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_226 received DONE after 116 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_226 completed: 448 chars, 116 chunks, TTFT=4963.9ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_198 received DONE after 161 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_198 completed: 628 chars, 161 chunks, TTFT=4080.6ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60962 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48462 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_316
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_316
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_200 received DONE after 162 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_200 completed: 644 chars, 162 chunks, TTFT=4080.4ms
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_315
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_315
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 150, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_317
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_317
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_222 received DONE after 120 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_222 completed: 236 chars, 120 chunks, TTFT=4933.8ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] Decode batch. #running-req: 48, #token: 9177, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2245.70, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_318
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] Prefill batch. #new-seq: 2, #new-token: 196, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_318
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_258 received DONE after 73 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_258 completed: 285 chars, 73 chunks, TTFT=5937.6ms
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_224 received DONE after 119 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_224 completed: 118 chars, 119 chunks, TTFT=4959.9ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48420 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_320
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60934 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_320
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_319
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_319
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_205 received DONE after 164 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_205 completed: 652 chars, 164 chunks, TTFT=4217.3ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_321
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_321
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_264 received DONE after 66 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_264 completed: 260 chars, 66 chunks, TTFT=6174.6ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_322
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_322
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 146, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_195 received DONE after 177 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_195 completed: 178 chars, 177 chunks, TTFT=3985.0ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60950 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_323
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_323
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_183 received DONE after 184 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_183 completed: 732 chars, 184 chunks, TTFT=3839.8ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48336 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_324
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_324
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_185 received DONE after 185 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_185 completed: 186 chars, 185 chunks, TTFT=3848.8ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60782 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_325
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_325
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_171 received DONE after 191 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_171 completed: 818 chars, 191 chunks, TTFT=3596.8ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_326
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_326
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_229 received DONE after 117 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_229 completed: 460 chars, 117 chunks, TTFT=5163.7ms
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_235 received DONE after 112 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_235 completed: 432 chars, 112 chunks, TTFT=5347.1ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48278 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60648 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_328
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_328
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_327
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_327
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_265 received DONE after 74 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_265 completed: 279 chars, 74 chunks, TTFT=6161.5ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60636 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_329
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_329
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_273 received DONE after 70 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_273 completed: 264 chars, 70 chunks, TTFT=6329.9ms
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_180 received DONE after 188 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_180 completed: 189 chars, 188 chunks, TTFT=3829.3ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60548 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48256 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_218 received DONE after 149 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_218 completed: 592 chars, 149 chunks, TTFT=4741.9ms
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_330
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_330
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_331
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_331
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60520 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_332
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_332
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] Decode batch. #running-req: 49, #token: 9526, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2133.54, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_197 received DONE after 189 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_197 completed: 739 chars, 189 chunks, TTFT=4089.3ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48310 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_333
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_333
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_256 received DONE after 91 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_256 completed: 347 chars, 91 chunks, TTFT=5934.3ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60978 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_334
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_334
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_237 received DONE after 126 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_237 completed: 537 chars, 126 chunks, TTFT=5350.5ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_335
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_335
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_225 received DONE after 147 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_225 completed: 584 chars, 147 chunks, TTFT=4936.5ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 6, token usage: 0.07, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48652 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_336
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_336
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_217 received DONE after 152 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_217 completed: 592 chars, 152 chunks, TTFT=4736.3ms
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_214 received DONE after 154 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_214 completed: 612 chars, 154 chunks, TTFT=4695.5ms
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_196 received DONE after 190 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_196 completed: 744 chars, 190 chunks, TTFT=4017.1ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 171, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60752 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48480 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_339
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_339
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60700 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_337
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_337
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_338
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_338
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] Prefill batch. #new-seq: 2, #new-token: 273, #cached-token: 12, token usage: 0.07, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_213 received DONE after 167 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_213 completed: 331 chars, 167 chunks, TTFT=4499.6ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48474 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_340
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_340
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:37018 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:51288 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_283 received DONE after 66 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_283 completed: 282 chars, 66 chunks, TTFT=6683.1ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60592 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_341
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_341
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_260 received DONE after 99 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_260 completed: 100 chars, 99 chunks, TTFT=6040.0ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48240 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_342
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_342
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:34] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_275 received DONE after 78 chunks
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Request req_275 completed: 308 chars, 78 chunks, TTFT=6492.5ms
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] INFO:     127.0.0.1:48302 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_343
[2025-07-25 02:52:34] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_343
[2025-07-25 02:52:34] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:34] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_278 received DONE after 83 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_278 completed: 315 chars, 83 chunks, TTFT=6492.4ms
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_288 received DONE after 69 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_288 completed: 70 chars, 69 chunks, TTFT=6798.7ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_344
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_344
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_345
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_345
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Prefill batch. #new-seq: 2, #new-token: 252, #cached-token: 12, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_286 received DONE after 76 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_286 completed: 77 chars, 76 chunks, TTFT=6684.8ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48590 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_346
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_346
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Decode batch. #running-req: 47, #token: 8654, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2268.15, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_255 received DONE after 120 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_255 completed: 476 chars, 120 chunks, TTFT=5821.2ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60528 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_347
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_347
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_209 received DONE after 193 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_209 completed: 382 chars, 193 chunks, TTFT=4320.1ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48370 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_348
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_348
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_251 received DONE after 127 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_251 completed: 504 chars, 127 chunks, TTFT=5709.6ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_349
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_349
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_262 received DONE after 105 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_262 completed: 206 chars, 105 chunks, TTFT=6142.8ms
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_289 received DONE after 75 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_289 completed: 292 chars, 75 chunks, TTFT=6806.7ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48560 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_350
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_350
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_351
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_351
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 171, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_269 received DONE after 102 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_269 completed: 101 chars, 102 chunks, TTFT=6267.7ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48268 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_276 received DONE after 96 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_276 completed: 380 chars, 96 chunks, TTFT=6480.7ms
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_352
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_352
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 145, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60862 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_353
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_353
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_300 received DONE after 69 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_300 completed: 188 chars, 69 chunks, TTFT=7095.6ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48188 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_354
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_354
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_291 received DONE after 82 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_291 completed: 356 chars, 82 chunks, TTFT=6846.4ms
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_234 received DONE after 148 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_234 completed: 292 chars, 148 chunks, TTFT=5331.1ms
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_297 received DONE after 78 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_297 completed: 79 chars, 78 chunks, TTFT=6936.3ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_356
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_356
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_355
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_355
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60466 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_357
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_357
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_302 received DONE after 72 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_302 completed: 284 chars, 72 chunks, TTFT=7103.2ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48518 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_358
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_358
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_266 received DONE after 115 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_266 completed: 456 chars, 115 chunks, TTFT=6174.2ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_359
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_359
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Prefill batch. #new-seq: 2, #new-token: 271, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_257 received DONE after 128 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_257 completed: 496 chars, 128 chunks, TTFT=5931.0ms
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_245 received DONE after 145 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_245 completed: 563 chars, 145 chunks, TTFT=5593.4ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_360
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_360
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60874 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_249 received DONE after 144 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_249 completed: 572 chars, 144 chunks, TTFT=5621.9ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_361
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_361
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_362
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_362
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_296 received DONE after 86 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_296 completed: 328 chars, 86 chunks, TTFT=6949.0ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60878 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_363
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_363
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] Decode batch. #running-req: 49, #token: 10121, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2231.79, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_263 received DONE after 123 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_263 completed: 488 chars, 123 chunks, TTFT=6138.1ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48394 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_364
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_364
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_295 received DONE after 91 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_295 completed: 94 chars, 91 chunks, TTFT=6936.5ms
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_267 received DONE after 126 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_267 completed: 488 chars, 126 chunks, TTFT=6174.3ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60672 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_223 received DONE after 186 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_223 completed: 185 chars, 186 chunks, TTFT=4936.7ms
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_310 received DONE after 75 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_310 completed: 296 chars, 75 chunks, TTFT=7324.9ms
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_365
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_365
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_366
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_366
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:51300 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_367
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_367
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_368
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_368
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Prefill batch. #new-seq: 3, #new-token: 381, #cached-token: 18, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_220 received DONE after 187 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_220 completed: 744 chars, 187 chunks, TTFT=4934.1ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_369
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_369
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_284 received DONE after 107 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_284 completed: 421 chars, 107 chunks, TTFT=6674.0ms
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_244 received DONE after 162 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_244 completed: 734 chars, 162 chunks, TTFT=5511.7ms
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_242 received DONE after 164 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_242 completed: 640 chars, 164 chunks, TTFT=5492.2ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60544 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48658 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:51306 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_371
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_371
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_370
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_370
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Prefill batch. #new-seq: 2, #new-token: 138, #cached-token: 10, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_372
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_372
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_274 received DONE after 127 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_274 completed: 128 chars, 127 chunks, TTFT=6330.0ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48202 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_241 received DONE after 164 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_241 completed: 640 chars, 164 chunks, TTFT=5477.8ms
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_373
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_373
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60558 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_374
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_374
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 149, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 5, token usage: 0.08, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_287 received DONE after 110 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_287 completed: 111 chars, 110 chunks, TTFT=6688.1ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:51320 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_375
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_375
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 6, token usage: 0.08, #running-req: 55, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_259 received DONE after 139 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_259 completed: 274 chars, 139 chunks, TTFT=6040.3ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48506 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_376
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_376
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 6, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_318 received DONE after 75 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_318 completed: 146 chars, 75 chunks, TTFT=7513.8ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:51324 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 6, token usage: 0.08, #running-req: 55, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_377
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_377
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_230 received DONE after 179 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_230 completed: 699 chars, 179 chunks, TTFT=5210.9ms
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_319 received DONE after 73 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_319 completed: 142 chars, 73 chunks, TTFT=7590.6ms
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_254 received DONE after 153 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_254 completed: 303 chars, 153 chunks, TTFT=5817.9ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60910 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_378
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_378
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_379
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_379
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_380
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_380
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] Prefill batch. #new-seq: 2, #new-token: 173, #cached-token: 12, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.08, #running-req: 56, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_228 received DONE after 191 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_228 completed: 760 chars, 191 chunks, TTFT=5076.3ms
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60934 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_240 received DONE after 176 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_240 completed: 688 chars, 176 chunks, TTFT=5433.6ms
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_381
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_381
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 5, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48446 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 6, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_236 received DONE after 176 chunks
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Request req_236 completed: 175 chars, 176 chunks, TTFT=5330.8ms
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_382
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_382
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] INFO:     127.0.0.1:60824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_383
[2025-07-25 02:52:35] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_383
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Decode batch. #running-req: 53, #token: 9863, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2240.65, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:35] Prefill batch. #new-seq: 1, #new-token: 174, #cached-token: 5, token usage: 0.08, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:35] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:35] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_279 received DONE after 129 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_279 completed: 499 chars, 129 chunks, TTFT=6484.1ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_384
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_384
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_250 received DONE after 167 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 6, token usage: 0.07, #running-req: 43, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_250 completed: 168 chars, 167 chunks, TTFT=5706.1ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48484 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_385
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_385
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_243 received DONE after 173 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_243 completed: 172 chars, 173 chunks, TTFT=5511.8ms
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_268 received DONE after 142 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_268 completed: 141 chars, 142 chunks, TTFT=6170.7ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60852 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 6, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_386
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_386
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_387
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_387
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] Prefill batch. #new-seq: 2, #new-token: 181, #cached-token: 12, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_290 received DONE after 116 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_290 completed: 491 chars, 116 chunks, TTFT=6822.3ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48262 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_388
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_388
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_321 received DONE after 85 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_321 completed: 333 chars, 85 chunks, TTFT=7593.3ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_389
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_389
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_248 received DONE after 183 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_248 completed: 728 chars, 183 chunks, TTFT=5595.1ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48228 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_238 received DONE after 189 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_238 completed: 749 chars, 189 chunks, TTFT=5396.6ms
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_390
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_390
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 5, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_285 received DONE after 131 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_285 completed: 587 chars, 131 chunks, TTFT=6684.9ms
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_391
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_391
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60732 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_392
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_392
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] Prefill batch. #new-seq: 2, #new-token: 223, #cached-token: 12, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_308 received DONE after 108 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_308 completed: 415 chars, 108 chunks, TTFT=7278.4ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_393
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_393
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_270 received DONE after 154 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_270 completed: 600 chars, 154 chunks, TTFT=6273.6ms
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_339 received DONE after 69 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_339 completed: 296 chars, 69 chunks, TTFT=8121.6ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60498 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48480 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_394
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_394
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_395
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_395
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] Prefill batch. #new-seq: 2, #new-token: 341, #cached-token: 12, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 6, token usage: 0.08, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_326 received DONE after 88 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_326 completed: 89 chars, 88 chunks, TTFT=7755.3ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60700 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_338 received DONE after 74 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_338 completed: 77 chars, 74 chunks, TTFT=8096.4ms
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_396
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_396
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60886 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_397
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_397
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] Prefill batch. #new-seq: 2, #new-token: 287, #cached-token: 12, token usage: 0.08, #running-req: 55, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_282 received DONE after 137 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_282 completed: 136 chars, 137 chunks, TTFT=6674.4ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48530 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_398
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_398
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_320 received DONE after 97 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_320 completed: 384 chars, 97 chunks, TTFT=7586.6ms
[2025-07-25 02:52:36] [sglang_test_framework.core.metrics_collector] [INFO] Completed 300 requests, success rate: 100.0%
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_399
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_399
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 6, token usage: 0.08, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_323 received DONE after 93 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_323 completed: 94 chars, 93 chunks, TTFT=7668.6ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48420 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_400
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_400
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] Decode batch. #running-req: 44, #token: 8692, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2072.84, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 6, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_280 received DONE after 144 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_280 completed: 559 chars, 144 chunks, TTFT=6569.5ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_401
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_401
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_261 received DONE after 167 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_261 completed: 651 chars, 167 chunks, TTFT=6138.3ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60758 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_402
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_402
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 5, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_272 received DONE after 165 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_272 completed: 644 chars, 165 chunks, TTFT=6281.0ms
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_292 received DONE after 138 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_292 completed: 548 chars, 138 chunks, TTFT=6840.8ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60798 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_403
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_403
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48294 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_404
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_404
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 6, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 168, #cached-token: 5, token usage: 0.08, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_332 received DONE after 94 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_332 completed: 259 chars, 94 chunks, TTFT=7923.4ms
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_349 received DONE after 70 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_349 completed: 69 chars, 70 chunks, TTFT=8421.6ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:37002 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_406
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_406
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.08, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_405
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_405
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_303 received DONE after 134 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_303 completed: 529 chars, 134 chunks, TTFT=7110.5ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_281 received DONE after 155 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_281 completed: 616 chars, 155 chunks, TTFT=6650.7ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60476 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_407
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_407
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_325 received DONE after 108 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_325 completed: 416 chars, 108 chunks, TTFT=7722.6ms
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_408
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_408
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60782 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_409
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_409
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_336 received DONE after 91 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_336 completed: 348 chars, 91 chunks, TTFT=8096.5ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60520 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_410
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_410
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] Prefill batch. #new-seq: 2, #new-token: 175, #cached-token: 12, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_271 received DONE after 175 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_271 completed: 683 chars, 175 chunks, TTFT=6268.0ms
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_298 received DONE after 146 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_298 completed: 149 chars, 146 chunks, TTFT=6956.3ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48652 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 5, token usage: 0.08, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] Decode batch. #running-req: 53, #token: 9670, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2550.18, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_411
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_411
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_412
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_412
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_314 received DONE after 123 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_314 completed: 476 chars, 123 chunks, TTFT=7491.5ms
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_293 received DONE after 153 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_293 completed: 152 chars, 153 chunks, TTFT=6846.3ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60928 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_414
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_414
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48350 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_413
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_413
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 6, token usage: 0.08, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_340 received DONE after 98 chunks
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Request req_340 completed: 99 chars, 98 chunks, TTFT=8124.2ms
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48474 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_415
[2025-07-25 02:52:36] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_415
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:36] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:36] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:36] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_312 received DONE after 135 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_312 completed: 536 chars, 135 chunks, TTFT=7393.1ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60612 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 99, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_316 received DONE after 132 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_316 completed: 524 chars, 132 chunks, TTFT=7495.7ms
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_416
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_416
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48650 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_417
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_417
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 103, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_299 received DONE after 155 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_299 completed: 665 chars, 155 chunks, TTFT=7070.9ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60962 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_418
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_418
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_304 received DONE after 156 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_304 completed: 608 chars, 156 chunks, TTFT=7109.0ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48436 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_419
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_419
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_294 received DONE after 167 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_294 completed: 664 chars, 167 chunks, TTFT=6853.3ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_420
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_420
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 5, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] Decode batch. #running-req: 47, #token: 9736, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2391.47, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_306 received DONE after 156 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_306 completed: 157 chars, 156 chunks, TTFT=7216.8ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48220 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_421
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_421
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 162, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_329 received DONE after 129 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_329 completed: 130 chars, 129 chunks, TTFT=7823.4ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60636 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_422
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_422
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_315 received DONE after 147 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_315 completed: 581 chars, 147 chunks, TTFT=7512.4ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60774 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_423
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_423
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 6, token usage: 0.09, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_346 received DONE after 109 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_346 completed: 432 chars, 109 chunks, TTFT=8385.6ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48590 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_424
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_424
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 6, token usage: 0.08, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_277 received DONE after 191 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_277 completed: 760 chars, 191 chunks, TTFT=6492.3ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48462 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_425
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_425
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_365 received DONE after 82 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_365 completed: 81 chars, 82 chunks, TTFT=8929.2ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60672 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_426
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_426
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 118, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_361 received DONE after 92 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_361 completed: 364 chars, 92 chunks, TTFT=8762.9ms
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_358 received DONE after 100 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_358 completed: 396 chars, 100 chunks, TTFT=8662.0ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48518 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60874 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_427
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_427
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_428
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_428
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 175, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_307 received DONE after 168 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_307 completed: 668 chars, 168 chunks, TTFT=7217.6ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60578 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_429
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_429
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 6, token usage: 0.09, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_347 received DONE after 112 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_347 completed: 311 chars, 112 chunks, TTFT=8421.8ms
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_330 received DONE after 136 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_330 completed: 135 chars, 136 chunks, TTFT=7920.6ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60548 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48384 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_431
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_431
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_430
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_430
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 5, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_368 received DONE after 88 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_368 completed: 172 chars, 88 chunks, TTFT=8928.7ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_309 received DONE after 169 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_309 completed: 170 chars, 169 chunks, TTFT=7323.1ms
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_369 received DONE after 95 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_369 completed: 399 chars, 95 chunks, TTFT=8937.8ms
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_341 received DONE after 124 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_341 completed: 125 chars, 124 chunks, TTFT=8220.7ms
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_432
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_432
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60592 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48434 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_434
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_434
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_433
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_433
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:51300 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_435
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_435
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] Prefill batch. #new-seq: 2, #new-token: 214, #cached-token: 10, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] Prefill batch. #new-seq: 2, #new-token: 225, #cached-token: 12, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_328 received DONE after 149 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_328 completed: 152 chars, 149 chunks, TTFT=7817.1ms
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_380 received DONE after 86 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_380 completed: 340 chars, 86 chunks, TTFT=9188.6ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_436
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_436
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48278 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_437
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_437
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] Prefill batch. #new-seq: 2, #new-token: 236, #cached-token: 12, token usage: 0.08, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_345 received DONE after 119 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_345 completed: 468 chars, 119 chunks, TTFT=8353.3ms
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_317 received DONE after 159 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_317 completed: 632 chars, 159 chunks, TTFT=7502.1ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_438
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48566 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_438
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_439
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_439
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_371 received DONE after 88 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_371 completed: 348 chars, 88 chunks, TTFT=9057.0ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] Decode batch. #running-req: 51, #token: 9321, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2523.09, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60544 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_440
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_440
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_305 received DONE after 176 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_305 completed: 688 chars, 176 chunks, TTFT=7198.1ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48354 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_441
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_441
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 188, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_313 received DONE after 170 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_313 completed: 676 chars, 170 chunks, TTFT=7461.8ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_442
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_442
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_387 received DONE after 82 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_387 completed: 161 chars, 82 chunks, TTFT=9373.5ms
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_301 received DONE after 185 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_301 completed: 186 chars, 185 chunks, TTFT=7107.0ms
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_352 received DONE after 121 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48268 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_352 completed: 480 chars, 121 chunks, TTFT=8561.1ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60720 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_444
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_444
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60852 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_443
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_443
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_445
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_445
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] Prefill batch. #new-seq: 2, #new-token: 291, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_374 received DONE after 97 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_374 completed: 429 chars, 97 chunks, TTFT=9080.2ms
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48250 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_391 received DONE after 74 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_391 completed: 145 chars, 74 chunks, TTFT=9594.4ms
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_354 received DONE after 127 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_354 completed: 355 chars, 127 chunks, TTFT=8565.6ms
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_331 received DONE after 157 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_331 completed: 612 chars, 157 chunks, TTFT=7920.2ms
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_446
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_446
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48256 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] Prefill batch. #new-seq: 2, #new-token: 296, #cached-token: 12, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60466 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_357 received DONE after 119 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_357 completed: 469 chars, 119 chunks, TTFT=8664.8ms
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_448
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_448
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_447
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_447
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_449
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_449
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48188 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] Prefill batch. #new-seq: 2, #new-token: 230, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_335 received DONE after 148 chunks
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Request req_335 completed: 588 chars, 148 chunks, TTFT=8091.9ms
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_450
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_450
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_451
[2025-07-25 02:52:37] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_451
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 161, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:37] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:37] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:37] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_311 received DONE after 180 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_311 completed: 500 chars, 180 chunks, TTFT=7392.4ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48326 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Decode batch. #running-req: 49, #token: 10486, token usage: 0.09, cuda graph: True, gen throughput (token/s): 2240.01, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_452
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_452
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 6, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_337 received DONE after 152 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_337 completed: 601 chars, 152 chunks, TTFT=8096.5ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60752 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_383 received DONE after 98 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_383 completed: 388 chars, 98 chunks, TTFT=9273.1ms
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_453
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_453
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48408 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_454
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_454
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_402 received DONE after 70 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_402 completed: 73 chars, 70 chunks, TTFT=9862.9ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60758 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_455
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_455
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_322 received DONE after 177 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_322 completed: 701 chars, 177 chunks, TTFT=7662.5ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_456
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_456
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_327 received DONE after 166 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_327 completed: 660 chars, 166 chunks, TTFT=7823.5ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48210 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_457
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_457
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_351 received DONE after 139 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_351 completed: 538 chars, 139 chunks, TTFT=8471.9ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_458
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_458
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_392 received DONE after 87 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_392 completed: 86 chars, 87 chunks, TTFT=9594.2ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60732 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_459
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_459
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_400 received DONE after 86 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_400 completed: 340 chars, 86 chunks, TTFT=9723.7ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48420 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_460
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_460
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 5, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_378 received DONE after 111 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_378 completed: 440 chars, 111 chunks, TTFT=9174.3ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60910 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_461
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_461
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_385 received DONE after 107 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_385 completed: 411 chars, 107 chunks, TTFT=9342.5ms
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_390 received DONE after 95 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_390 completed: 363 chars, 95 chunks, TTFT=9561.6ms
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_401 received DONE after 86 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_401 completed: 328 chars, 86 chunks, TTFT=9781.9ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60648 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_463
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_463
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_462
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_462
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_464
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_464
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48228 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 2, #new-token: 341, #cached-token: 12, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_343 received DONE after 158 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_343 completed: 159 chars, 158 chunks, TTFT=8286.1ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_465
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_465
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_376 received DONE after 122 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_376 completed: 484 chars, 122 chunks, TTFT=9138.9ms
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_324 received DONE after 190 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_324 completed: 756 chars, 190 chunks, TTFT=7668.5ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48336 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60606 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_466
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_466
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_467
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_467
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_413 received DONE after 72 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_413 completed: 73 chars, 72 chunks, TTFT=10186.8ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 6, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48350 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_468
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_468
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_397 received DONE after 97 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_397 completed: 98 chars, 97 chunks, TTFT=9627.2ms
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_359 received DONE after 141 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_359 completed: 144 chars, 141 chunks, TTFT=8664.4ms
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_373 received DONE after 128 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_373 completed: 393 chars, 128 chunks, TTFT=9050.2ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48202 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_469
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_469
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_470
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_470
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60886 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_471
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_471
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] Prefill batch. #new-seq: 2, #new-token: 248, #cached-token: 12, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 2, #new-token: 274, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_381 received DONE after 115 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_381 completed: 456 chars, 115 chunks, TTFT=9273.2ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48506 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_472
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_472
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_411 received DONE after 79 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_411 completed: 300 chars, 79 chunks, TTFT=10128.6ms
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_362 received DONE after 145 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_362 completed: 148 chars, 145 chunks, TTFT=8768.5ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_344 received DONE after 160 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_344 completed: 161 chars, 160 chunks, TTFT=8353.5ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_474
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_474
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_473
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_473
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60934 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_475
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_475
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] Decode batch. #running-req: 49, #token: 8953, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2187.80, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 175, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] Prefill batch. #new-seq: 2, #new-token: 317, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_416 received DONE after 70 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_416 completed: 69 chars, 70 chunks, TTFT=10325.5ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48652 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_476
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_476
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_394 received DONE after 108 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_394 completed: 212 chars, 108 chunks, TTFT=9622.5ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48302 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_477
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_477
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_363 received DONE after 146 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_363 completed: 149 chars, 146 chunks, TTFT=8825.3ms
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_353 received DONE after 158 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_353 completed: 313 chars, 158 chunks, TTFT=8565.7ms
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_377 received DONE after 131 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_377 completed: 559 chars, 131 chunks, TTFT=9167.3ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48484 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:51324 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:37034 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_410 received DONE after 91 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_410 completed: 92 chars, 91 chunks, TTFT=10050.5ms
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_479
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_479
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_478
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_478
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_480
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_480
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60520 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_481
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_481
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 2, #new-token: 270, #cached-token: 12, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] Prefill batch. #new-seq: 2, #new-token: 336, #cached-token: 11, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_342 received DONE after 176 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_342 completed: 700 chars, 176 chunks, TTFT=8235.1ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48240 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_482
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_482
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_334 received DONE after 190 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_334 completed: 529 chars, 190 chunks, TTFT=8022.2ms
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_483
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_483
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60978 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_422 received DONE after 70 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_422 completed: 137 chars, 70 chunks, TTFT=10561.9ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:37048 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_484
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_484
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 6, token usage: 0.09, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_389 received DONE after 123 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_389 completed: 488 chars, 123 chunks, TTFT=9490.8ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_485
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_485
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_426 received DONE after 66 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_426 completed: 67 chars, 66 chunks, TTFT=10708.0ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:37058 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_486
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_486
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 6, token usage: 0.09, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_417 received DONE after 81 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_417 completed: 80 chars, 81 chunks, TTFT=10347.7ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48650 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_396 received DONE after 120 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_396 completed: 464 chars, 120 chunks, TTFT=9628.0ms
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_487
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_487
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60700 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_488
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_488
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 6, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 6, token usage: 0.09, #running-req: 55, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_333 received DONE after 193 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_333 completed: 383 chars, 193 chunks, TTFT=7997.2ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48310 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_489
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_489
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 175, #cached-token: 6, token usage: 0.09, #running-req: 56, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_412 received DONE after 100 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_412 completed: 383 chars, 100 chunks, TTFT=10155.2ms
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] INFO:     127.0.0.1:60576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_379 received DONE after 141 chunks
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Request req_379 completed: 140 chars, 141 chunks, TTFT=9188.6ms
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_490
[2025-07-25 02:52:38] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_490
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 6, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:38] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] INFO:     127.0.0.1:48552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:38] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 5, token usage: 0.09, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_491
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_491
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_366 received DONE after 157 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_366 completed: 612 chars, 157 chunks, TTFT=8929.0ms
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_435 received DONE after 69 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_435 completed: 259 chars, 69 chunks, TTFT=10846.1ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:51300 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:37064 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_493
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_493
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_492
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_492
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 86, #cached-token: 5, token usage: 0.09, #running-req: 55, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] Decode batch. #running-req: 56, #token: 10762, token usage: 0.09, cuda graph: True, gen throughput (token/s): 1927.20, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_350 received DONE after 176 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_350 completed: 177 chars, 176 chunks, TTFT=8476.9ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 6, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_494
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_494
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_423 received DONE after 84 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_423 completed: 332 chars, 84 chunks, TTFT=10605.7ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48560 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_364 received DONE after 159 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_364 completed: 620 chars, 159 chunks, TTFT=8914.9ms
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_495
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_495
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60774 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_496
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_496
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 6, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 6, token usage: 0.09, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_356 received DONE after 180 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_356 completed: 500 chars, 180 chunks, TTFT=8652.1ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48394 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_497
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_497
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_393 received DONE after 132 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_393 completed: 512 chars, 132 chunks, TTFT=9611.9ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 6, token usage: 0.09, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_498
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_498
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_355 received DONE after 177 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_355 completed: 704 chars, 177 chunks, TTFT=8660.1ms
[2025-07-25 02:52:39] [sglang_test_framework.core.metrics_collector] [INFO] Completed 400 requests, success rate: 100.0%
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_499
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_499
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 186, #cached-token: 6, token usage: 0.09, #running-req: 55, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_384 received DONE after 149 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_384 completed: 580 chars, 149 chunks, TTFT=9342.3ms
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_348 received DONE after 191 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_348 completed: 190 chars, 191 chunks, TTFT=8398.3ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48370 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_500
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60672 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_500
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_501
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_501
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 5, token usage: 0.09, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_420 received DONE after 105 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_420 completed: 416 chars, 105 chunks, TTFT=10418.1ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_502
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_502
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] Decode batch. #running-req: 45, #token: 8839, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2292.92, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_405 received DONE after 126 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_405 completed: 486 chars, 126 chunks, TTFT=9945.0ms
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_360 received DONE after 182 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_360 completed: 185 chars, 182 chunks, TTFT=8768.6ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60636 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_503
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_503
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_504
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_504
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 149, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_441 received DONE after 77 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_441 completed: 304 chars, 77 chunks, TTFT=10985.1ms
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_372 received DONE after 174 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48354 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_372 completed: 791 chars, 174 chunks, TTFT=9056.7ms
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_505
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_505
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:51306 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_506
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_506
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_434 received DONE after 83 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_434 completed: 226 chars, 83 chunks, TTFT=10843.3ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48434 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_507
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_507
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 6, token usage: 0.08, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_375 received DONE after 176 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_375 completed: 177 chars, 176 chunks, TTFT=9084.7ms
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_386 received DONE after 164 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_386 completed: 163 chars, 164 chunks, TTFT=9373.5ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:37002 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_508
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_508
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_509
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_509
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 6, token usage: 0.08, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_398 received DONE after 144 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_398 completed: 560 chars, 144 chunks, TTFT=9673.9ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:51320 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_510
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_510
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 5, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_438 received DONE after 91 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_438 completed: 348 chars, 91 chunks, TTFT=10967.3ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48530 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_511
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_511
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_367 received DONE after 181 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_367 completed: 552 chars, 181 chunks, TTFT=8936.3ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_512
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_512
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 6, token usage: 0.08, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_399 received DONE after 155 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_399 completed: 604 chars, 155 chunks, TTFT=9700.7ms
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_414 received DONE after 133 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_414 completed: 525 chars, 133 chunks, TTFT=10157.9ms
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_445 received DONE after 88 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_445 completed: 348 chars, 88 chunks, TTFT=11105.2ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60852 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_515
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_515
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60928 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_513
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_513
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_514
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_514
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 6, token usage: 0.09, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] Prefill batch. #new-seq: 2, #new-token: 239, #cached-token: 12, token usage: 0.07, #running-req: 43, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_418 received DONE after 123 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_418 completed: 485 chars, 123 chunks, TTFT=10415.7ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60962 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_516
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_516
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 6, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_454 received DONE after 69 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_454 completed: 272 chars, 69 chunks, TTFT=11355.2ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48408 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_517
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_517
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.09, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_465 received DONE after 71 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_465 completed: 138 chars, 71 chunks, TTFT=11674.4ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_518
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_518
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_408 received DONE after 140 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_408 completed: 543 chars, 140 chunks, TTFT=10035.1ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_519
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_519
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_403 received DONE after 159 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_403 completed: 619 chars, 159 chunks, TTFT=9863.8ms
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_370 received DONE after 189 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_370 completed: 528 chars, 189 chunks, TTFT=9047.7ms
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_404 received DONE after 150 chunks
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Request req_404 completed: 296 chars, 150 chunks, TTFT=9872.1ms
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48294 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] INFO:     127.0.0.1:48658 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60798 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 5, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_520
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_520
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_521
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_521
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_522
[2025-07-25 02:52:39] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_522
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] Prefill batch. #new-seq: 2, #new-token: 322, #cached-token: 12, token usage: 0.09, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:39] Decode batch. #running-req: 55, #token: 10769, token usage: 0.09, cuda graph: True, gen throughput (token/s): 2391.61, #queue-req: 0,
[2025-07-25 02:52:39] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:39] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_458 received DONE after 93 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_458 completed: 368 chars, 93 chunks, TTFT=11477.4ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_523
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_523
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 6, token usage: 0.08, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_436 received DONE after 104 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_436 completed: 412 chars, 104 chunks, TTFT=10936.3ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_524
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_524
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 168, #cached-token: 6, token usage: 0.09, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_395 received DONE after 171 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_395 completed: 680 chars, 171 chunks, TTFT=9611.7ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_525
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_525
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 6, token usage: 0.08, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_483 received DONE after 66 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_483 completed: 260 chars, 66 chunks, TTFT=12106.5ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60978 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_526
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_526
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_382 received DONE after 189 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_382 completed: 749 chars, 189 chunks, TTFT=9266.1ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48446 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_527
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_527
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_462 received DONE after 79 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_462 completed: 300 chars, 79 chunks, TTFT=11581.9ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_528
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_528
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] Decode batch. #running-req: 47, #token: 9508, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2141.78, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_421 received DONE after 130 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_421 completed: 504 chars, 130 chunks, TTFT=10513.6ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48220 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_388 received DONE after 189 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_388 completed: 740 chars, 189 chunks, TTFT=9407.5ms
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_529
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_529
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60862 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_530
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_530
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 165, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_407 received DONE after 168 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_407 completed: 716 chars, 168 chunks, TTFT=10039.3ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48262 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_531
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_531
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 190, #cached-token: 5, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_406 received DONE after 173 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_406 completed: 176 chars, 173 chunks, TTFT=9950.8ms
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_431 received DONE after 131 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_431 completed: 508 chars, 131 chunks, TTFT=10839.1ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60548 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_532
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_532
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_533
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_533
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 6, token usage: 0.09, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 6, token usage: 0.08, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_481 received DONE after 80 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_481 completed: 79 chars, 80 chunks, TTFT=11993.9ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_443 received DONE after 122 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_443 completed: 240 chars, 122 chunks, TTFT=11105.6ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60720 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_535
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_535
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48480 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_534
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_534
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 6, token usage: 0.08, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 6, token usage: 0.09, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_430 received DONE after 123 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_430 completed: 488 chars, 123 chunks, TTFT=10836.2ms
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_409 received DONE after 176 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_409 completed: 349 chars, 176 chunks, TTFT=10042.2ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48384 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60782 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 6, token usage: 0.08, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_537
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_537
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_536
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_536
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 6, token usage: 0.09, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_428 received DONE after 147 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_428 completed: 290 chars, 147 chunks, TTFT=10712.3ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48664 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_538
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_538
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 6, token usage: 0.09, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_432 received DONE after 128 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_432 completed: 508 chars, 128 chunks, TTFT=10836.5ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60874 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_539
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_539
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 6, token usage: 0.08, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_493 received DONE after 74 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_493 completed: 144 chars, 74 chunks, TTFT=12302.2ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60520 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_540
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_540
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 5, token usage: 0.08, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_433 received DONE after 150 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_433 completed: 418 chars, 150 chunks, TTFT=10844.4ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:37064 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_541
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_541
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 6, token usage: 0.10, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_502 received DONE after 68 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_502 completed: 67 chars, 68 chunks, TTFT=12631.4ms
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_474 received DONE after 107 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_474 completed: 108 chars, 107 chunks, TTFT=11858.1ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_543
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_543
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_542
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_542
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_467 received DONE after 117 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_467 completed: 464 chars, 117 chunks, TTFT=11703.3ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 6, token usage: 0.10, #running-req: 55, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:37074 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 6, token usage: 0.08, #running-req: 42, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_544
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_544
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 140, #cached-token: 6, token usage: 0.10, #running-req: 56, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] Decode batch. #running-req: 57, #token: 12090, token usage: 0.10, cuda graph: True, gen throughput (token/s): 2617.03, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_453 received DONE after 138 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_453 completed: 536 chars, 138 chunks, TTFT=11348.1ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_451 received DONE after 144 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_451 completed: 145 chars, 144 chunks, TTFT=11234.0ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60752 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_492 received DONE after 94 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_492 completed: 93 chars, 94 chunks, TTFT=12293.7ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48420 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_460 received DONE after 115 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_460 completed: 226 chars, 115 chunks, TTFT=11518.4ms
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_545
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_545
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_442 received DONE after 151 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_442 completed: 152 chars, 151 chunks, TTFT=11097.0ms
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_490 received DONE after 95 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_490 completed: 376 chars, 95 chunks, TTFT=12289.6ms
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_546
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_546
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] Prefill batch. #new-seq: 2, #new-token: 254, #cached-token: 12, token usage: 0.07, #running-req: 38, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_547
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_547
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 6, token usage: 0.10, #running-req: 56, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_549
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_549
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:37086 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:37094 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_548
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_548
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_550
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_550
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 6, token usage: 0.07, #running-req: 40, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] Prefill batch. #new-seq: 2, #new-token: 256, #cached-token: 12, token usage: 0.10, #running-req: 57, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_450 received DONE after 129 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_450 completed: 500 chars, 129 chunks, TTFT=11229.5ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] INFO:     127.0.0.1:48188 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_551
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_551
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:40] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 6, token usage: 0.10, #running-req: 59, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] Decode batch. #running-req: 41, #token: 8867, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2354.51, #queue-req: 0,
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_513 received DONE after 67 chunks
[2025-07-25 02:52:40] [sglang_test_framework.core.request_generator] [DEBUG] Request req_513 completed: 251 chars, 67 chunks, TTFT=12987.8ms
[2025-07-25 02:52:40] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:40] INFO:     127.0.0.1:60852 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_552
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_552
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 133, #cached-token: 5, token usage: 0.07, #running-req: 39, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_449 received DONE after 152 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_449 completed: 688 chars, 152 chunks, TTFT=11231.2ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60466 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_553
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_553
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_485 received DONE after 112 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_485 completed: 444 chars, 112 chunks, TTFT=12106.4ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:37100 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_554
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_554
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 6, token usage: 0.10, #running-req: 58, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_415 received DONE after 185 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_415 completed: 186 chars, 185 chunks, TTFT=10188.2ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_555
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_555
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 2, #new-token: 248, #cached-token: 10, token usage: 0.07, #running-req: 40, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_429 received DONE after 176 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_429 completed: 348 chars, 176 chunks, TTFT=10767.5ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_515 received DONE after 66 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_515 completed: 260 chars, 66 chunks, TTFT=12982.5ms
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_556
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_556
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60578 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_557
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_557
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 6, token usage: 0.07, #running-req: 40, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 6, token usage: 0.10, #running-req: 57, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_439 received DONE after 151 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_439 completed: 685 chars, 151 chunks, TTFT=10944.6ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48566 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_470 received DONE after 138 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_470 completed: 495 chars, 138 chunks, TTFT=11708.5ms
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_558
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_558
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_559
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_559
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 6, token usage: 0.07, #running-req: 41, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 158, #cached-token: 6, token usage: 0.10, #running-req: 58, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_488 received DONE after 115 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_488 completed: 442 chars, 115 chunks, TTFT=12181.0ms
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_459 received DONE after 149 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_459 completed: 592 chars, 149 chunks, TTFT=11478.0ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:37048 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60732 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_437 received DONE after 155 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_437 completed: 616 chars, 155 chunks, TTFT=10936.1ms
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_484 received DONE after 107 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_484 completed: 420 chars, 107 chunks, TTFT=12095.9ms
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_560
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_560
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_561
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_561
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48278 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60700 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_563
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] Prefill batch. #new-seq: 2, #new-token: 214, #cached-token: 12, token usage: 0.10, #running-req: 57, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 2, #new-token: 169, #cached-token: 10, token usage: 0.07, #running-req: 39, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_563
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_562
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_562
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_461 received DONE after 148 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_461 completed: 585 chars, 148 chunks, TTFT=11574.5ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60910 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_473 received DONE after 117 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_473 completed: 452 chars, 117 chunks, TTFT=11867.7ms
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_564
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_564
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_565
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_565
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 5, token usage: 0.07, #running-req: 41, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 6, token usage: 0.10, #running-req: 59, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_463 received DONE after 149 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_463 completed: 152 chars, 149 chunks, TTFT=11575.7ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60648 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_566
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_566
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 6, token usage: 0.07, #running-req: 42, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_419 received DONE after 185 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_419 completed: 736 chars, 185 chunks, TTFT=10415.4ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48436 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_567
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_567
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 6, token usage: 0.10, #running-req: 58, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_447 received DONE after 172 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_447 completed: 672 chars, 172 chunks, TTFT=11231.3ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_479 received DONE after 121 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_479 completed: 477 chars, 121 chunks, TTFT=11980.6ms
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_568
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_568
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 6, token usage: 0.07, #running-req: 40, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48484 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_569
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_569
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 6, token usage: 0.10, #running-req: 58, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_514 received DONE after 90 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_514 completed: 397 chars, 90 chunks, TTFT=12987.7ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60928 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_570
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_570
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_486 received DONE after 116 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_486 completed: 519 chars, 116 chunks, TTFT=12175.7ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:37058 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_571
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_571
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 6, token usage: 0.07, #running-req: 41, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 162, #cached-token: 5, token usage: 0.10, #running-req: 59, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_491 received DONE after 113 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_491 completed: 445 chars, 113 chunks, TTFT=12302.4ms
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_446 received DONE after 154 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_446 completed: 612 chars, 154 chunks, TTFT=11225.4ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48250 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:51300 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_573
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_573
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_572
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_572
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 6, token usage: 0.07, #running-req: 41, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 5, token usage: 0.10, #running-req: 60, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_440 received DONE after 189 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_440 completed: 859 chars, 189 chunks, TTFT=10970.3ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60544 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_574
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_574
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_520 received DONE after 73 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_520 completed: 285 chars, 73 chunks, TTFT=13216.0ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48294 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 6, token usage: 0.07, #running-req: 40, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_475 received DONE after 150 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_475 completed: 584 chars, 150 chunks, TTFT=11858.1ms
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_575
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_575
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_471 received DONE after 160 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_471 completed: 636 chars, 160 chunks, TTFT=11710.4ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60934 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_457 received DONE after 152 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_457 completed: 153 chars, 152 chunks, TTFT=11384.3ms
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_576
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_576
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 6, token usage: 0.10, #running-req: 56, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_577
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_577
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60886 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_578
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_578
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_456 received DONE after 153 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_456 completed: 426 chars, 153 chunks, TTFT=11378.8ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 2, #new-token: 204, #cached-token: 12, token usage: 0.07, #running-req: 41, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_579
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_579
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 6, token usage: 0.10, #running-req: 57, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 6, token usage: 0.07, #running-req: 43, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_489 received DONE after 122 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_489 completed: 471 chars, 122 chunks, TTFT=12206.4ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48310 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_580
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_580
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 121, #cached-token: 5, token usage: 0.10, #running-req: 56, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_523 received DONE after 78 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_523 completed: 295 chars, 78 chunks, TTFT=13364.3ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_581
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_581
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.07, #running-req: 42, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_427 received DONE after 187 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_427 completed: 572 chars, 187 chunks, TTFT=10709.8ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48518 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_582
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_582
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_425 received DONE after 189 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_425 completed: 752 chars, 189 chunks, TTFT=10658.5ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 6, token usage: 0.10, #running-req: 55, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60606 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_583
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_583
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_504 received DONE after 114 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_504 completed: 439 chars, 114 chunks, TTFT=12751.2ms
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_518 received DONE after 96 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_518 completed: 380 chars, 96 chunks, TTFT=13123.6ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 103, #cached-token: 6, token usage: 0.07, #running-req: 41, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48462 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_584
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_584
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_585
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_585
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] Decode batch. #running-req: 55, #token: 11463, token usage: 0.10, cuda graph: True, gen throughput (token/s): 2331.47, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 6, token usage: 0.10, #running-req: 56, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_424 received DONE after 191 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_424 completed: 760 chars, 191 chunks, TTFT=10657.7ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48590 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_586
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_586
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Decode batch. #running-req: 41, #token: 7794, token usage: 0.07, cuda graph: True, gen throughput (token/s): 1871.95, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 6, token usage: 0.07, #running-req: 42, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_455 received DONE after 184 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_455 completed: 729 chars, 184 chunks, TTFT=11351.3ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60758 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_587
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_587
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 6, token usage: 0.10, #running-req: 57, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 6, token usage: 0.07, #running-req: 43, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_498 received DONE after 114 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_498 completed: 439 chars, 114 chunks, TTFT=12528.8ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_588
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_588
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 6, token usage: 0.10, #running-req: 56, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_482 received DONE after 135 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_482 completed: 536 chars, 135 chunks, TTFT=12080.9ms
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_501 received DONE after 126 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_501 completed: 127 chars, 126 chunks, TTFT=12625.7ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60672 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_589
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_589
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48240 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_590
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_590
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 6, token usage: 0.07, #running-req: 42, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 5, token usage: 0.09, #running-req: 57, #queue-req: 0,
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_444 received DONE after 176 chunks
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Request req_444 completed: 688 chars, 176 chunks, TTFT=11103.4ms
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] INFO:     127.0.0.1:60636 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_591
[2025-07-25 02:52:41] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_591
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:41] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:41] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:41] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 6, token usage: 0.07, #running-req: 43, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_503 received DONE after 109 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_503 completed: 432 chars, 109 chunks, TTFT=12754.5ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_494 received DONE after 142 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_494 completed: 564 chars, 142 chunks, TTFT=12384.9ms
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_535 received DONE after 81 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_535 completed: 308 chars, 81 chunks, TTFT=13634.4ms
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_592
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_592
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 6, token usage: 0.09, #running-req: 55, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48268 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60720 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_593
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_593
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.07, #running-req: 42, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_594
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_594
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 6, token usage: 0.09, #running-req: 56, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_496 received DONE after 144 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_496 completed: 568 chars, 144 chunks, TTFT=12419.6ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_595
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_595
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 122, #cached-token: 6, token usage: 0.10, #running-req: 57, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_497 received DONE after 124 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_497 completed: 343 chars, 124 chunks, TTFT=12528.6ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60774 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_596
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_596
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 6, token usage: 0.06, #running-req: 40, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_525 received DONE after 98 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_525 completed: 99 chars, 98 chunks, TTFT=13388.8ms
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_478 received DONE after 167 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_478 completed: 652 chars, 167 chunks, TTFT=11994.3ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48394 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_597
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_597
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48210 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_598
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] Prefill batch. #new-seq: 2, #new-token: 169, #cached-token: 12, token usage: 0.10, #running-req: 58, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_598
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_526 received DONE after 101 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_526 completed: 102 chars, 101 chunks, TTFT=13397.3ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60978 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.metrics_collector] [INFO] Completed 500 requests, success rate: 100.0%
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_599
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_599
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 6, token usage: 0.06, #running-req: 40, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_505 received DONE after 116 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_505 completed: 229 chars, 116 chunks, TTFT=12774.8ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48354 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_600
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_600
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 6, token usage: 0.10, #running-req: 57, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_452 received DONE after 176 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_452 completed: 700 chars, 176 chunks, TTFT=11331.4ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:51324 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_601
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_601
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 5, token usage: 0.06, #running-req: 40, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_536 received DONE after 88 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_536 completed: 334 chars, 88 chunks, TTFT=13728.6ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48326 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_602
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_602
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 6, token usage: 0.10, #running-req: 58, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_506 received DONE after 139 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_506 completed: 539 chars, 139 chunks, TTFT=12755.9ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:51306 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_603
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_603
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 6, token usage: 0.06, #running-req: 40, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_469 received DONE after 165 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_469 completed: 656 chars, 165 chunks, TTFT=11717.7ms
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_448 received DONE after 186 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_448 completed: 740 chars, 186 chunks, TTFT=11225.2ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48256 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_604
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_604
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60782 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_500 received DONE after 131 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_500 completed: 520 chars, 131 chunks, TTFT=12617.6ms
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_605
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_605
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 6, token usage: 0.06, #running-req: 41, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48370 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 6, token usage: 0.09, #running-req: 56, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_606
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_606
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 88, #cached-token: 6, token usage: 0.09, #running-req: 57, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_530 received DONE after 105 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_530 completed: 404 chars, 105 chunks, TTFT=13525.9ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60862 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_607
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_607
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 6, token usage: 0.06, #running-req: 41, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_487 received DONE after 154 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_487 completed: 153 chars, 154 chunks, TTFT=12199.9ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48650 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_522 received DONE after 110 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_522 completed: 436 chars, 110 chunks, TTFT=13215.8ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_608
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_608
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 149, #cached-token: 6, token usage: 0.06, #running-req: 42, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_609
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_609
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 126, #cached-token: 6, token usage: 0.09, #running-req: 55, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_477 received DONE after 163 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_477 completed: 162 chars, 163 chunks, TTFT=11971.7ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48302 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_476 received DONE after 168 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_476 completed: 765 chars, 168 chunks, TTFT=11871.8ms
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_610
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_610
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48652 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_611
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_611
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] Prefill batch. #new-seq: 2, #new-token: 231, #cached-token: 10, token usage: 0.09, #running-req: 56, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_468 received DONE after 176 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_468 completed: 175 chars, 176 chunks, TTFT=11717.8ms
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_507 received DONE after 133 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_507 completed: 528 chars, 133 chunks, TTFT=12783.5ms
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_541 received DONE after 79 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_541 completed: 80 chars, 79 chunks, TTFT=13927.7ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_612
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_612
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:37064 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_527 received DONE after 104 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_527 completed: 103 chars, 104 chunks, TTFT=13429.0ms
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_614
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_614
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_613
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_613
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] Decode batch. #running-req: 43, #token: 8164, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2088.13, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] Prefill batch. #new-seq: 2, #new-token: 314, #cached-token: 12, token usage: 0.07, #running-req: 43, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48446 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_538 received DONE after 88 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_538 completed: 91 chars, 88 chunks, TTFT=13807.2ms
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_548 received DONE after 71 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_548 completed: 72 chars, 71 chunks, TTFT=14185.3ms
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_615
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_615
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60592 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:37086 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_533 received DONE after 100 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_533 completed: 393 chars, 100 chunks, TTFT=13578.8ms
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_495 received DONE after 151 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_495 completed: 600 chars, 151 chunks, TTFT=12430.4ms
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_616
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_616
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_617
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_617
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48560 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_618
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_618
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_619
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_619
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] Prefill batch. #new-seq: 2, #new-token: 226, #cached-token: 12, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] Prefill batch. #new-seq: 3, #new-token: 440, #cached-token: 18, token usage: 0.07, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_472 received DONE after 177 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_472 completed: 807 chars, 177 chunks, TTFT=11794.9ms
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_480 received DONE after 170 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_480 completed: 528 chars, 170 chunks, TTFT=11980.6ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60476 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_620
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60878 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_620
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_621
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_621
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] Prefill batch. #new-seq: 2, #new-token: 173, #cached-token: 12, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] Decode batch. #running-req: 51, #token: 9537, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2328.27, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_543 received DONE after 98 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_543 completed: 376 chars, 98 chunks, TTFT=13993.2ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48506 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_516 received DONE after 148 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_516 completed: 588 chars, 148 chunks, TTFT=13041.9ms
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_622
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_622
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 5, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60962 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_623
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_623
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_464 received DONE after 193 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_464 completed: 768 chars, 193 chunks, TTFT=11581.6ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48228 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_624
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_624
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 5, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_508 received DONE after 143 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_508 completed: 555 chars, 143 chunks, TTFT=12842.3ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_625
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_625
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_499 received DONE after 176 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_499 completed: 700 chars, 176 chunks, TTFT=12536.2ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:37002 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_626
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_626
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_466 received DONE after 190 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_466 completed: 189 chars, 190 chunks, TTFT=11711.0ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_509 received DONE after 163 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_509 completed: 636 chars, 163 chunks, TTFT=12851.0ms
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_627
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_627
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48336 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_628
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_628
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:42] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_555 received DONE after 92 chunks
[2025-07-25 02:52:42] [sglang_test_framework.core.request_generator] [DEBUG] Request req_555 completed: 95 chars, 92 chunks, TTFT=14309.3ms
[2025-07-25 02:52:42] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:42] INFO:     127.0.0.1:37034 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_629
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_629
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_510 received DONE after 169 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_510 completed: 170 chars, 169 chunks, TTFT=12861.9ms
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_576 received DONE after 68 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_576 completed: 133 chars, 68 chunks, TTFT=14896.7ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60934 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_631
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_631
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_630
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_630
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 152, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 5, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_524 received DONE after 127 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_524 completed: 504 chars, 127 chunks, TTFT=13363.0ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:51320 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_632
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_632
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 127, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_534 received DONE after 118 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_534 completed: 456 chars, 118 chunks, TTFT=13656.5ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48480 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_633
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_633
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_561 received DONE after 95 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_561 completed: 376 chars, 95 chunks, TTFT=14523.3ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60732 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_634
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_634
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_567 received DONE after 77 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_567 completed: 78 chars, 77 chunks, TTFT=14656.4ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_511 received DONE after 157 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_511 completed: 310 chars, 157 chunks, TTFT=12921.1ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48530 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_635
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_635
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_636
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_636
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_539 received DONE after 132 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_539 completed: 260 chars, 132 chunks, TTFT=13828.8ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60874 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_554 received DONE after 94 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_554 completed: 372 chars, 94 chunks, TTFT=14309.2ms
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_637
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_637
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:37100 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_638
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_638
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] Prefill batch. #new-seq: 2, #new-token: 210, #cached-token: 12, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_529 received DONE after 134 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_529 completed: 518 chars, 134 chunks, TTFT=13532.3ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_575 received DONE after 77 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_575 completed: 291 chars, 77 chunks, TTFT=14889.7ms
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_639
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_639
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48294 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_640
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_640
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] Decode batch. #running-req: 49, #token: 9435, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2363.52, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_585 received DONE after 82 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_585 completed: 161 chars, 82 chunks, TTFT=15103.1ms
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_641
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_641
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48220 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 102, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_574 received DONE after 93 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_574 completed: 355 chars, 93 chunks, TTFT=14868.7ms
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_532 received DONE after 157 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_532 completed: 612 chars, 157 chunks, TTFT=13584.2ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:37058 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_571 received DONE after 87 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_571 completed: 344 chars, 87 chunks, TTFT=14778.8ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60548 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_643
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_643
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_642
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_642
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 88, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60544 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_545 received DONE after 127 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_545 completed: 251 chars, 127 chunks, TTFT=14154.1ms
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_644
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_644
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60752 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_645
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_645
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 103, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] Prefill batch. #new-seq: 2, #new-token: 251, #cached-token: 12, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_528 received DONE after 168 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_528 completed: 668 chars, 168 chunks, TTFT=13441.5ms
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_557 received DONE after 118 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_557 completed: 327 chars, 118 chunks, TTFT=14394.6ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48436 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_646
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_646
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_647
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_647
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] Prefill batch. #new-seq: 2, #new-token: 285, #cached-token: 12, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_531 received DONE after 143 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_531 completed: 556 chars, 143 chunks, TTFT=13539.7ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60578 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_563 received DONE after 100 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_563 completed: 424 chars, 100 chunks, TTFT=14527.6ms
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_648
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_648
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48278 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_649
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_649
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 162, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] Decode batch. #running-req: 53, #token: 9755, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2397.42, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_547 received DONE after 135 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_547 completed: 524 chars, 135 chunks, TTFT=14153.7ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_650
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_650
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 73, #cached-token: 5, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_521 received DONE after 185 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_521 completed: 186 chars, 185 chunks, TTFT=13207.6ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60798 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_651
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_651
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 5, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_597 received DONE after 75 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_597 completed: 146 chars, 75 chunks, TTFT=15418.5ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48394 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_598 received DONE after 76 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_598 completed: 148 chars, 76 chunks, TTFT=15420.4ms
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_593 received DONE after 78 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_593 completed: 308 chars, 78 chunks, TTFT=15335.3ms
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_652
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_652
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48268 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_653
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_653
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_654
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_654
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] Prefill batch. #new-seq: 2, #new-token: 252, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_560 received DONE after 110 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_560 completed: 424 chars, 110 chunks, TTFT=14528.1ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:37048 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_655
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_655
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_592 received DONE after 81 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_592 completed: 320 chars, 81 chunks, TTFT=15335.4ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_656
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_656
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_540 received DONE after 156 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_540 completed: 608 chars, 156 chunks, TTFT=13903.4ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_512 received DONE after 187 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_512 completed: 732 chars, 187 chunks, TTFT=12921.0ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_517 received DONE after 180 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_517 completed: 703 chars, 180 chunks, TTFT=13073.7ms
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_580 received DONE after 95 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_580 completed: 98 chars, 95 chunks, TTFT=14991.4ms
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_657
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_657
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60520 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_658
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_658
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_659
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_659
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:33930 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_660
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_660
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] Prefill batch. #new-seq: 2, #new-token: 251, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_542 received DONE after 138 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_542 completed: 548 chars, 138 chunks, TTFT=14014.8ms
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_549 received DONE after 146 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_549 completed: 567 chars, 146 chunks, TTFT=14156.1ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_537 received DONE after 152 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_537 completed: 153 chars, 152 chunks, TTFT=13747.0ms
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_662
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_662
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_661
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_661
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:33942 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] Prefill batch. #new-seq: 1, #new-token: 188, #cached-token: 5, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_663
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_663
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_565 received DONE after 119 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_565 completed: 469 chars, 119 chunks, TTFT=14531.0ms
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_606 received DONE after 74 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_606 completed: 73 chars, 74 chunks, TTFT=15667.4ms
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_604 received DONE after 74 chunks
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Request req_604 completed: 144 chars, 74 chunks, TTFT=15665.1ms
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:33946 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48256 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_666
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_666
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_664
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_664
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] INFO:     127.0.0.1:48370 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_665
[2025-07-25 02:52:43] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_665
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] Prefill batch. #new-seq: 2, #new-token: 184, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:43] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:43] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:43] Prefill batch. #new-seq: 2, #new-token: 157, #cached-token: 10, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_519 received DONE after 184 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_519 completed: 732 chars, 184 chunks, TTFT=13207.9ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_581 received DONE after 115 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_581 completed: 444 chars, 115 chunks, TTFT=15002.8ms
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_667
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_667
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_668
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_668
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_621 received DONE after 73 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_621 completed: 74 chars, 73 chunks, TTFT=15943.9ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_669
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_669
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_551 received DONE after 142 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_551 completed: 551 chars, 142 chunks, TTFT=14197.5ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60878 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_670
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_670
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 5, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_596 received DONE after 100 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_596 completed: 384 chars, 100 chunks, TTFT=15413.4ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48188 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_671
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_671
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_600 received DONE after 90 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_600 completed: 176 chars, 90 chunks, TTFT=15512.0ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60774 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_672
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_672
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 5, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_587 received DONE after 117 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_587 completed: 230 chars, 117 chunks, TTFT=15106.3ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60758 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_673
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_673
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_569 received DONE after 123 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_569 completed: 242 chars, 123 chunks, TTFT=14754.7ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48484 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_674
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_674
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_602 received DONE after 94 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_602 completed: 185 chars, 94 chunks, TTFT=15564.7ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:33954 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_675
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_675
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] Decode batch. #running-req: 52, #token: 10061, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2207.49, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_556 received DONE after 143 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_556 completed: 568 chars, 143 chunks, TTFT=14403.7ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_676
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_676
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_566 received DONE after 150 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_566 completed: 596 chars, 150 chunks, TTFT=14549.7ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48326 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_579 received DONE after 135 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_579 completed: 134 chars, 135 chunks, TTFT=14897.8ms
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_570 received DONE after 140 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_570 completed: 143 chars, 140 chunks, TTFT=14739.6ms
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_677
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_677
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48354 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_679
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_679
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60928 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_678
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_678
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_601 received DONE after 106 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_601 completed: 107 chars, 106 chunks, TTFT=15532.5ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] Prefill batch. #new-seq: 2, #new-token: 284, #cached-token: 12, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:51324 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_680
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_680
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] Prefill batch. #new-seq: 2, #new-token: 351, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_583 received DONE after 129 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_583 completed: 128 chars, 129 chunks, TTFT=15080.2ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48384 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_681
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_681
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 95, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] Decode batch. #running-req: 49, #token: 9238, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2338.30, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_568 received DONE after 145 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_568 completed: 562 chars, 145 chunks, TTFT=14737.8ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48310 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_682
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_682
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_628 received DONE after 77 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_628 completed: 210 chars, 77 chunks, TTFT=16184.0ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_683
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_683
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_578 received DONE after 143 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_578 completed: 565 chars, 143 chunks, TTFT=14896.4ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48336 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_684
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_684
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 6, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_608 received DONE after 95 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_608 completed: 96 chars, 95 chunks, TTFT=15802.7ms
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_588 received DONE after 120 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_588 completed: 236 chars, 120 chunks, TTFT=15217.6ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60886 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_686
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_686
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_685
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_685
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 134, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_552 received DONE after 170 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_552 completed: 173 chars, 170 chunks, TTFT=14300.1ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60852 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_687
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_687
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 97, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_603 received DONE after 110 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_603 completed: 436 chars, 110 chunks, TTFT=15617.5ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:51306 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_688
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_688
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_624 received DONE after 87 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_624 completed: 344 chars, 87 chunks, TTFT=16086.6ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48228 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_689
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_689
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_546 received DONE after 168 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_546 completed: 332 chars, 168 chunks, TTFT=14162.2ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48420 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_690
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_690
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_562 received DONE after 165 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_562 completed: 326 chars, 165 chunks, TTFT=14523.1ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60700 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_691
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_691
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_553 received DONE after 178 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_553 completed: 704 chars, 178 chunks, TTFT=14300.5ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48650 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_692
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_692
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 126, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_564 received DONE after 170 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_564 completed: 336 chars, 170 chunks, TTFT=14549.9ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60910 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_626 received DONE after 91 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_626 completed: 360 chars, 91 chunks, TTFT=16167.8ms
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_693
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_693
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:37002 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_694
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_694
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_572 received DONE after 159 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_572 completed: 162 chars, 159 chunks, TTFT=14796.6ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:51300 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_695
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_695
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:54282 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:33958 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_577 received DONE after 147 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_577 completed: 571 chars, 147 chunks, TTFT=14892.5ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_614 received DONE after 108 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_614 completed: 415 chars, 108 chunks, TTFT=15915.4ms
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_559 received DONE after 180 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_559 completed: 179 chars, 180 chunks, TTFT=14397.6ms
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_696
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_696
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48518 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_582 received DONE after 141 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_582 completed: 142 chars, 141 chunks, TTFT=15067.8ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.metrics_collector] [INFO] Completed 600 requests, success rate: 100.0%
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_697
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_697
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_698
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_698
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_699
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_699
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_613 received DONE after 107 chunks
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Request req_613 completed: 452 chars, 107 chunks, TTFT=15917.8ms
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:37064 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_700
[2025-07-25 02:52:44] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_700
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] Prefill batch. #new-seq: 2, #new-token: 265, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:44] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] Prefill batch. #new-seq: 1, #new-token: 123, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:44] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:44] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_544 received DONE after 188 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_544 completed: 187 chars, 188 chunks, TTFT=14014.7ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60466 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_701
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_701
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_558 received DONE after 173 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_558 completed: 675 chars, 173 chunks, TTFT=14406.5ms
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_637 received DONE after 85 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_637 completed: 84 chars, 85 chunks, TTFT=16505.5ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60874 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48566 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_703
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_703
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_702
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_702
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_605 received DONE after 131 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_605 completed: 132 chars, 131 chunks, TTFT=15647.1ms
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_550 received DONE after 187 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_550 completed: 188 chars, 187 chunks, TTFT=14185.0ms
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_595 received DONE after 139 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_595 completed: 142 chars, 139 chunks, TTFT=15403.4ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60782 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:37094 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_704
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_704
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_705
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_705
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_706
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_706
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 188, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_644 received DONE after 76 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_644 completed: 300 chars, 76 chunks, TTFT=16768.0ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:37074 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_707
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_707
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] Prefill batch. #new-seq: 2, #new-token: 267, #cached-token: 12, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] Decode batch. #running-req: 49, #token: 9313, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2322.89, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_586 received DONE after 154 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_586 completed: 695 chars, 154 chunks, TTFT=15096.2ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60544 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_708
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_708
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_650 received DONE after 70 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_650 completed: 276 chars, 70 chunks, TTFT=16957.9ms
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_589 received DONE after 157 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_589 completed: 310 chars, 157 chunks, TTFT=15246.8ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48590 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60672 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_710
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_710
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_709
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_709
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 148, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 5, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_635 received DONE after 95 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_635 completed: 376 chars, 95 chunks, TTFT=16505.7ms
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_620 received DONE after 125 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_620 completed: 246 chars, 125 chunks, TTFT=15947.6ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60476 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_646 received DONE after 81 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_646 completed: 317 chars, 81 chunks, TTFT=16830.2ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48408 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_590 received DONE after 154 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_590 completed: 305 chars, 154 chunks, TTFT=15217.5ms
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_711
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_711
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_712
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_712
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48240 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_713
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_713
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_714
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_714
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] Prefill batch. #new-seq: 2, #new-token: 251, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] Prefill batch. #new-seq: 2, #new-token: 229, #cached-token: 10, token usage: 0.07, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_631 received DONE after 109 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_631 completed: 420 chars, 109 chunks, TTFT=16289.1ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_715
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_715
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] Decode batch. #running-req: 50, #token: 9043, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2282.38, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_609 received DONE after 134 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_609 completed: 532 chars, 134 chunks, TTFT=15781.8ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_594 received DONE after 158 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_594 completed: 614 chars, 158 chunks, TTFT=15328.0ms
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_716
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_716
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48436 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_573 received DONE after 175 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_573 completed: 176 chars, 175 chunks, TTFT=14782.6ms
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_717
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_717
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60720 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_654 received DONE after 76 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_654 completed: 300 chars, 76 chunks, TTFT=17028.2ms
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_718
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_718
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_719
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_719
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 185, #cached-token: 6, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_612 received DONE after 133 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_612 completed: 528 chars, 133 chunks, TTFT=15915.8ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48268 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 181, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_720
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_720
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_618 received DONE after 136 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_618 completed: 540 chars, 136 chunks, TTFT=15930.9ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_721
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_721
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 85, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_629 received DONE after 123 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_629 completed: 488 chars, 123 chunks, TTFT=16281.1ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60606 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_722
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_722
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 71, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_611 received DONE after 148 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_611 completed: 588 chars, 148 chunks, TTFT=15802.9ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48652 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_723
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_723
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_636 received DONE after 116 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_636 completed: 460 chars, 116 chunks, TTFT=16530.5ms
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_622 received DONE after 137 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_622 completed: 136 chars, 137 chunks, TTFT=16082.0ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48506 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_725
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_725
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_724
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_724
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_627 received DONE after 134 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_627 completed: 519 chars, 134 chunks, TTFT=16184.0ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_726
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_726
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_617 received DONE after 150 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_617 completed: 149 chars, 150 chunks, TTFT=15930.9ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60648 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_727
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_727
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_615 received DONE after 151 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_615 completed: 587 chars, 151 chunks, TTFT=15931.2ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48446 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_728
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_728
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 87, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_652 received DONE after 99 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_652 completed: 389 chars, 99 chunks, TTFT=17028.3ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:33960 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_729
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_729
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 6, token usage: 0.09, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_668 received DONE after 80 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_668 completed: 156 chars, 80 chunks, TTFT=17362.5ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48394 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_730
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_730
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_584 received DONE after 191 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_584 completed: 757 chars, 191 chunks, TTFT=15096.2ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_607 received DONE after 167 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_607 completed: 170 chars, 167 chunks, TTFT=15695.7ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_731
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_731
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:48462 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_732
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_732
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 5, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_666 received DONE after 92 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_666 completed: 91 chars, 92 chunks, TTFT=17227.7ms
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 146, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] INFO:     127.0.0.1:37086 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_651 received DONE after 104 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_651 completed: 107 chars, 104 chunks, TTFT=16962.7ms
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_733
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_733
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:60798 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_676 received DONE after 75 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_676 completed: 296 chars, 75 chunks, TTFT=17651.6ms
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_734
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_734
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] INFO:     127.0.0.1:33946 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_735
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_735
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:45] Prefill batch. #new-seq: 2, #new-token: 282, #cached-token: 10, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:45] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_599 received DONE after 179 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_599 completed: 712 chars, 179 chunks, TTFT=15495.2ms
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_591 received DONE after 192 chunks
[2025-07-25 02:52:45] [sglang_test_framework.core.request_generator] [DEBUG] Request req_591 completed: 761 chars, 192 chunks, TTFT=15248.3ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_736
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_736
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48530 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_737
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_737
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_619 received DONE after 159 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_619 completed: 618 chars, 159 chunks, TTFT=15940.1ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_738
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_738
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] Decode batch. #running-req: 50, #token: 9613, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2253.65, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_657 received DONE after 104 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_657 completed: 204 chars, 104 chunks, TTFT=17119.4ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 109, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_739
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_739
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_625 received DONE after 153 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_625 completed: 608 chars, 153 chunks, TTFT=16133.7ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_740
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_740
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Decode batch. #running-req: 49, #token: 9346, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2319.25, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_653 received DONE after 111 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_653 completed: 428 chars, 111 chunks, TTFT=17023.3ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:37034 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_741
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_741
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 101, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_684 received DONE after 82 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_684 completed: 312 chars, 82 chunks, TTFT=17797.5ms
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_640 received DONE after 134 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_640 completed: 569 chars, 134 chunks, TTFT=16657.5ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48294 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_742
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_742
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_743
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_743
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_658 received DONE after 116 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_658 completed: 447 chars, 116 chunks, TTFT=17102.0ms
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_632 received DONE after 150 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_632 completed: 151 chars, 150 chunks, TTFT=16381.2ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60928 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_678 received DONE after 87 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_678 completed: 332 chars, 87 chunks, TTFT=17680.9ms
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_610 received DONE after 178 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_610 completed: 495 chars, 178 chunks, TTFT=15803.0ms
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_744
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_744
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48302 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:51320 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_745
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_745
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60520 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] Prefill batch. #new-seq: 2, #new-token: 201, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_747
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_747
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_746
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_746
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_696 received DONE after 68 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_696 completed: 67 chars, 68 chunks, TTFT=18173.4ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_642 received DONE after 132 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_642 completed: 131 chars, 132 chunks, TTFT=16764.2ms
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_748
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_748
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60548 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_749
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_749
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] Prefill batch. #new-seq: 2, #new-token: 272, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 177, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_695 received DONE after 74 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_695 completed: 292 chars, 74 chunks, TTFT=18085.3ms
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_659 received DONE after 122 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_659 completed: 121 chars, 122 chunks, TTFT=17119.2ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:51300 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_751
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_751
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_750
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_750
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_630 received DONE after 162 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_630 completed: 644 chars, 162 chunks, TTFT=16297.8ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48336 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_752
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_752
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_675 received DONE after 104 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_675 completed: 399 chars, 104 chunks, TTFT=17559.7ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48560 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_753
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_753
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_690 received DONE after 87 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_690 completed: 170 chars, 87 chunks, TTFT=17952.0ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60878 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_670 received DONE after 114 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_670 completed: 452 chars, 114 chunks, TTFT=17424.2ms
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_754
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_754
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48420 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_755
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_755
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_693 received DONE after 84 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_693 completed: 83 chars, 84 chunks, TTFT=18082.4ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60910 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_643 received DONE after 145 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_643 completed: 144 chars, 145 chunks, TTFT=16741.0ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_756
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_756
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:33954 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_757
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_757
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] Prefill batch. #new-seq: 2, #new-token: 269, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_697 received DONE after 82 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_697 completed: 321 chars, 82 chunks, TTFT=18182.1ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48518 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_758
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_758
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_616 received DONE after 192 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_616 completed: 533 chars, 192 chunks, TTFT=15940.5ms
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_633 received DONE after 167 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_633 completed: 168 chars, 167 chunks, TTFT=16412.8ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60592 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_759
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_759
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48480 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_760
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_760
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 162, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_663 received DONE after 129 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_663 completed: 512 chars, 129 chunks, TTFT=17221.1ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:37058 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Prefill batch. #new-seq: 2, #new-token: 184, #cached-token: 10, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_656 received DONE after 136 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_656 completed: 540 chars, 136 chunks, TTFT=17088.9ms
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_761
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_761
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_762
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_762
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_661 received DONE after 130 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_661 completed: 520 chars, 130 chunks, TTFT=17228.5ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_763
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_763
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_623 received DONE after 188 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_623 completed: 189 chars, 188 chunks, TTFT=16086.7ms
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_680 received DONE after 109 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_680 completed: 420 chars, 109 chunks, TTFT=17680.6ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:51324 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_764
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_764
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60962 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_765
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_765
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] Prefill batch. #new-seq: 2, #new-token: 199, #cached-token: 12, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_711 received DONE after 73 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_711 completed: 288 chars, 73 chunks, TTFT=18526.1ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48250 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_766
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_766
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_705 received DONE after 79 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_705 completed: 299 chars, 79 chunks, TTFT=18397.0ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60782 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_767
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_767
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_714 received DONE after 71 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_714 completed: 73 chars, 71 chunks, TTFT=18534.5ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48240 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_768
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_768
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] Decode batch. #running-req: 48, #token: 8853, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2331.65, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_660 received DONE after 142 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_660 completed: 280 chars, 142 chunks, TTFT=17091.8ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:33930 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_769
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_769
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_649 received DONE after 155 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_649 completed: 159 chars, 155 chunks, TTFT=16831.5ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48278 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_770
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_770
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 75, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_716 received DONE after 71 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_716 completed: 284 chars, 71 chunks, TTFT=18664.9ms
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_677 received DONE after 116 chunks
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Request req_677 completed: 118 chars, 116 chunks, TTFT=17658.6ms
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] INFO:     127.0.0.1:60476 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] INFO:     127.0.0.1:48326 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_772
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_772
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_771
[2025-07-25 02:52:46] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_771
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:46] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:46] Prefill batch. #new-seq: 1, #new-token: 78, #cached-token: 5, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_645 received DONE after 162 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_645 completed: 632 chars, 162 chunks, TTFT=16767.9ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60752 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_773
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_773
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 113, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] Decode batch. #running-req: 51, #token: 9886, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2198.26, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_710 received DONE after 83 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_710 completed: 332 chars, 83 chunks, TTFT=18529.7ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48590 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_774
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_774
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 163, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_648 received DONE after 165 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_648 completed: 644 chars, 165 chunks, TTFT=16840.4ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60578 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_775
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_775
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_634 received DONE after 184 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_634 completed: 365 chars, 184 chunks, TTFT=16501.6ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60732 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_707 received DONE after 92 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_707 completed: 354 chars, 92 chunks, TTFT=18412.3ms
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_776
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_776
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:37074 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_777
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_777
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_694 received DONE after 111 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_694 completed: 221 chars, 111 chunks, TTFT=18064.3ms
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_641 received DONE after 172 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_641 completed: 688 chars, 172 chunks, TTFT=16740.0ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:33942 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_778
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_778
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48220 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_779
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_779
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 153, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 143, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_647 received DONE after 170 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_647 completed: 668 chars, 170 chunks, TTFT=16830.2ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60934 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_780
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_780
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_702 received DONE after 105 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_702 completed: 106 chars, 105 chunks, TTFT=18299.9ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_781
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_781
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 131, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_692 received DONE after 115 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_692 completed: 117 chars, 115 chunks, TTFT=18062.5ms
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_720 received DONE after 82 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_720 completed: 316 chars, 82 chunks, TTFT=18772.0ms
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_725 received DONE after 72 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_725 completed: 275 chars, 72 chunks, TTFT=18942.6ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60874 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60636 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_782
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48268 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_782
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_784
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_784
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] Prefill batch. #new-seq: 2, #new-token: 177, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_783
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_783
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_687 received DONE after 127 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_687 completed: 128 chars, 127 chunks, TTFT=17831.4ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48506 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_785
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_785
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] Prefill batch. #new-seq: 2, #new-token: 282, #cached-token: 12, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_721 received DONE after 81 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_721 completed: 320 chars, 81 chunks, TTFT=18857.6ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_786
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_786
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_639 received DONE after 184 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_639 completed: 732 chars, 184 chunks, TTFT=16645.7ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_787
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_787
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_638 received DONE after 191 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_638 completed: 191 chars, 191 chunks, TTFT=16530.3ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:37100 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_723 received DONE after 77 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_723 completed: 295 chars, 77 chunks, TTFT=18939.5ms
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_788
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_788
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60852 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_789
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_789
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 182, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_719 received DONE after 96 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_719 completed: 368 chars, 96 chunks, TTFT=18682.9ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48652 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_790
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_790
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_691 received DONE after 129 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_691 completed: 130 chars, 129 chunks, TTFT=17982.5ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48650 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_791
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_791
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 5, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_701 received DONE after 120 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_701 completed: 329 chars, 120 chunks, TTFT=18299.9ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60466 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_792
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_792
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 126, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_688 received DONE after 143 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_688 completed: 556 chars, 143 chunks, TTFT=17877.2ms
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_682 received DONE after 146 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_682 completed: 291 chars, 146 chunks, TTFT=17775.4ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48310 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:51306 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_793
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_793
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_794
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_794
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_665 received DONE after 173 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_665 completed: 344 chars, 173 chunks, TTFT=17230.7ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_734 received DONE after 82 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_734 completed: 160 chars, 82 chunks, TTFT=19229.6ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48370 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60798 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_743 received DONE after 65 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_743 completed: 260 chars, 65 chunks, TTFT=19537.4ms
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_796
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_796
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_795
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_795
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60700 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_797
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_797
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] Prefill batch. #new-seq: 2, #new-token: 306, #cached-token: 12, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_679 received DONE after 153 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_679 completed: 599 chars, 153 chunks, TTFT=17658.4ms
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_704 received DONE after 120 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_704 completed: 335 chars, 120 chunks, TTFT=18396.9ms
[2025-07-25 02:52:47] [sglang_test_framework.core.metrics_collector] [INFO] Completed 700 requests, success rate: 100.0%
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_798
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_798
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_799
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_799
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 150, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 179, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] Decode batch. #running-req: 52, #token: 9969, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2176.54, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_669 received DONE after 169 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_669 completed: 169 chars, 169 chunks, TTFT=17372.1ms
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_655 received DONE after 184 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_655 completed: 736 chars, 184 chunks, TTFT=17029.6ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60978 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:37048 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_801
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_801
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_800
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_800
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_746 received DONE after 67 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_746 completed: 264 chars, 67 chunks, TTFT=19605.1ms
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_673 received DONE after 168 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_673 completed: 668 chars, 168 chunks, TTFT=17454.7ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 153, #cached-token: 5, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60758 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_803
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_803
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_802
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_802
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 139, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_699 received DONE after 135 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_699 completed: 136 chars, 135 chunks, TTFT=18185.5ms
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_722 received DONE after 104 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_722 completed: 288 chars, 104 chunks, TTFT=18865.8ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48354 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60606 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_804
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_804
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_805
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_805
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_703 received DONE after 129 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_703 completed: 516 chars, 129 chunks, TTFT=18311.5ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48566 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_806
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_806
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] Prefill batch. #new-seq: 2, #new-token: 296, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_674 received DONE after 165 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_674 completed: 167 chars, 165 chunks, TTFT=17537.9ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] INFO:     127.0.0.1:60486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_807
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_807
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_662 received DONE after 183 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_662 completed: 725 chars, 183 chunks, TTFT=17217.7ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 180, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] INFO:     127.0.0.1:48484 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_713 received DONE after 124 chunks
[2025-07-25 02:52:47] [sglang_test_framework.core.request_generator] [DEBUG] Request req_713 completed: 245 chars, 124 chunks, TTFT=18531.9ms
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] Decode batch. #running-req: 48, #token: 9389, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2152.94, #queue-req: 0,
[2025-07-25 02:52:47] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:47] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_808
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_808
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48294 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_809
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_809
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_752 received DONE after 66 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_752 completed: 264 chars, 66 chunks, TTFT=19760.3ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_810
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_810
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 187, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_737 received DONE after 89 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_737 completed: 344 chars, 89 chunks, TTFT=19275.5ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48530 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_811
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_811
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 170, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_672 received DONE after 176 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_672 completed: 700 chars, 176 chunks, TTFT=17445.5ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60774 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_812
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_812
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 77, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_671 received DONE after 176 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_671 completed: 691 chars, 176 chunks, TTFT=17435.6ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48188 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_813
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_813
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 179, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_667 received DONE after 183 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_667 completed: 364 chars, 183 chunks, TTFT=17362.7ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_814
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_814
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_664 received DONE after 191 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_664 completed: 380 chars, 191 chunks, TTFT=17229.8ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48256 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_815
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_815
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 172, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_749 received DONE after 83 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_749 completed: 316 chars, 83 chunks, TTFT=19613.0ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60548 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_816
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_816
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_730 received DONE after 103 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_730 completed: 204 chars, 103 chunks, TTFT=19138.8ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48394 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_817
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_817
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_689 received DONE after 162 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_689 completed: 322 chars, 162 chunks, TTFT=17950.7ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:51320 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 68, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_818
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_818
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_683 received DONE after 170 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_683 completed: 664 chars, 170 chunks, TTFT=17781.8ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_819
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_819
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_706 received DONE after 146 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_706 completed: 584 chars, 146 chunks, TTFT=18404.2ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:37094 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_820
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_820
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_708 received DONE after 144 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_708 completed: 143 chars, 144 chunks, TTFT=18453.8ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60544 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_821
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_821
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 5, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_758 received DONE after 78 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_758 completed: 256 chars, 78 chunks, TTFT=19954.1ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60862 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 104, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_685 received DONE after 175 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_685 completed: 696 chars, 175 chunks, TTFT=17828.6ms
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_822
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_822
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48518 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_823
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_823
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_686 received DONE after 182 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_686 completed: 728 chars, 182 chunks, TTFT=17807.4ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60886 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_824
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_824
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 130, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_762 received DONE after 78 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_762 completed: 79 chars, 78 chunks, TTFT=19983.0ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_825
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_825
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 179, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_738 received DONE after 112 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_738 completed: 444 chars, 112 chunks, TTFT=19320.2ms
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_709 received DONE after 148 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_709 completed: 588 chars, 148 chunks, TTFT=18524.1ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48228 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60672 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_827
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_827
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_826
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_826
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 106, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_747 received DONE after 98 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_747 completed: 385 chars, 98 chunks, TTFT=19613.2ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60520 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_828
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_828
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_681 received DONE after 189 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_681 completed: 189 chars, 189 chunks, TTFT=17705.7ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48384 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_751 received DONE after 93 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 119, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_751 completed: 368 chars, 93 chunks, TTFT=19729.3ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_829
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_829
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:51300 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_830
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_830
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] Prefill batch. #new-seq: 2, #new-token: 246, #cached-token: 12, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_726 received DONE after 130 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_726 completed: 256 chars, 130 chunks, TTFT=18981.7ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_831
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_831
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 120, #cached-token: 5, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_753 received DONE after 95 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_753 completed: 189 chars, 95 chunks, TTFT=19773.7ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_832
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_832
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_733 received DONE after 119 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_733 completed: 119 chars, 119 chunks, TTFT=19251.7ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:37086 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_833
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_833
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_739 received DONE after 117 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_739 completed: 468 chars, 117 chunks, TTFT=19365.6ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_834
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_834
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] Decode batch. #running-req: 52, #token: 9725, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2210.99, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_764 received DONE after 84 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_764 completed: 332 chars, 84 chunks, TTFT=20081.2ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_736 received DONE after 122 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_736 completed: 488 chars, 122 chunks, TTFT=19274.6ms
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_835
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_835
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:51324 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_836
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_836
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_717 received DONE after 153 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_717 completed: 599 chars, 153 chunks, TTFT=18664.9ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48436 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_837
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_837
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 108, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] Decode batch. #running-req: 47, #token: 9249, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2161.98, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_780 received DONE after 70 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_780 completed: 263 chars, 70 chunks, TTFT=20517.6ms
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_712 received DONE after 164 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_712 completed: 656 chars, 164 chunks, TTFT=18534.6ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48546 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_838
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_838
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60934 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_839
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_839
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_732 received DONE after 131 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_732 completed: 524 chars, 131 chunks, TTFT=19222.7ms
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48462 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_840
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_840
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:48] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 5, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:48] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:48] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_744 received DONE after 118 chunks
[2025-07-25 02:52:48] [sglang_test_framework.core.request_generator] [DEBUG] Request req_744 completed: 119 chars, 118 chunks, TTFT=19605.5ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60928 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_841
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_841
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 146, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_729 received DONE after 144 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_729 completed: 284 chars, 144 chunks, TTFT=19095.7ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48408 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_842
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_842
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_700 received DONE after 188 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_700 completed: 752 chars, 188 chunks, TTFT=18181.6ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:37064 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_843
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_843
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 184, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_698 received DONE after 188 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_698 completed: 373 chars, 188 chunks, TTFT=18185.5ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60562 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_844
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_844
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 80, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_724 received DONE after 154 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_724 completed: 609 chars, 154 chunks, TTFT=18972.0ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_788 received DONE after 74 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_788 completed: 292 chars, 74 chunks, TTFT=20708.2ms
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_845
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_845
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:37100 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_846
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 72, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_846
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 114, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_731 received DONE after 145 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_731 completed: 576 chars, 145 chunks, TTFT=19220.8ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_847
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_847
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_745 received DONE after 126 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_745 completed: 504 chars, 126 chunks, TTFT=19610.2ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48302 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_848
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_848
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 189, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 125, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_765 received DONE after 107 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_765 completed: 106 chars, 107 chunks, TTFT=20081.0ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48560 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_799 received DONE after 67 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_799 completed: 252 chars, 67 chunks, TTFT=21001.2ms
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_849
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_849
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_768 received DONE after 113 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_768 completed: 223 chars, 113 chunks, TTFT=20088.8ms
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_850
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_850
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60962 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_794 received DONE after 70 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_794 completed: 276 chars, 70 chunks, TTFT=20970.1ms
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_851
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_851
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48240 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_852
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_852
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 89, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 157, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_798 received DONE after 74 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_798 completed: 292 chars, 74 chunks, TTFT=20999.9ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_790 received DONE after 84 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_790 completed: 165 chars, 84 chunks, TTFT=20792.5ms
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_853
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_853
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:51306 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_760 received DONE after 122 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_760 completed: 242 chars, 122 chunks, TTFT=19956.0ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_854
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_854
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:33960 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_797 received DONE after 74 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_797 completed: 292 chars, 74 chunks, TTFT=20999.8ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 87, #cached-token: 6, token usage: 0.09, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_855
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_855
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48480 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_856
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_856
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 86, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_750 received DONE after 133 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_750 completed: 133 chars, 133 chunks, TTFT=19738.6ms
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_795 received DONE after 76 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_795 completed: 286 chars, 76 chunks, TTFT=21000.0ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60798 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_857
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_857
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_858
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_858
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 122, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 133, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_778 received DONE after 98 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_778 completed: 388 chars, 98 chunks, TTFT=20514.5ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:33942 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_757 received DONE after 127 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_757 completed: 504 chars, 127 chunks, TTFT=19884.5ms
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_859
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_859
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 70, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48188 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_769 received DONE after 115 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_769 completed: 443 chars, 115 chunks, TTFT=20186.2ms
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_715 received DONE after 192 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_715 completed: 752 chars, 192 chunks, TTFT=18580.6ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_813 received DONE after 68 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_813 completed: 255 chars, 68 chunks, TTFT=21358.2ms
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_860
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_860
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60578 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48652 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_775 received DONE after 105 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_775 completed: 416 chars, 105 chunks, TTFT=20412.0ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 160, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_861
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_861
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_862
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_862
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_863
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_863
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:33930 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_864
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_864
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_763 received DONE after 127 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_763 completed: 504 chars, 127 chunks, TTFT=20056.6ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48662 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_865
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_865
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Prefill batch. #new-seq: 3, #new-token: 362, #cached-token: 15, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] Prefill batch. #new-seq: 2, #new-token: 251, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_728 received DONE after 168 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_728 completed: 170 chars, 168 chunks, TTFT=19082.3ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:33954 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_866
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_866
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Decode batch. #running-req: 51, #token: 9548, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2270.45, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_718 received DONE after 191 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_718 completed: 378 chars, 191 chunks, TTFT=18681.5ms
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_770 received DONE after 124 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_770 completed: 492 chars, 124 chunks, TTFT=20226.7ms
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_809 received DONE after 78 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_809 completed: 152 chars, 78 chunks, TTFT=21272.9ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48294 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60720 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_867
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_867
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48278 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_868
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_868
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_869
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_869
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 171, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_741 received DONE after 158 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_741 completed: 158 chars, 158 chunks, TTFT=19454.6ms
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_767 received DONE after 126 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_767 completed: 500 chars, 126 chunks, TTFT=20085.1ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:37034 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60782 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_871
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_871
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_870
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_870
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] Decode batch. #running-req: 46, #token: 9074, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2218.46, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] Prefill batch. #new-seq: 2, #new-token: 278, #cached-token: 12, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 5, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_759 received DONE after 135 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_759 completed: 524 chars, 135 chunks, TTFT=19983.2ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60592 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_872
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_872
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 144, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_777 received DONE after 121 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_777 completed: 468 chars, 121 chunks, TTFT=20440.2ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:37074 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_808 received DONE after 87 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_808 completed: 90 chars, 87 chunks, TTFT=21251.8ms
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_873
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_873
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 113, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60700 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_874
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_874
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 64, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_748 received DONE after 161 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_748 completed: 631 chars, 161 chunks, TTFT=19609.9ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_875
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_875
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 81, #cached-token: 6, token usage: 0.08, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_814 received DONE after 76 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_814 completed: 300 chars, 76 chunks, TTFT=21453.7ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_876
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_876
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_735 received DONE after 178 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_735 completed: 708 chars, 178 chunks, TTFT=19229.3ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48484 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_877
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_877
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 153, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_742 received DONE after 163 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_742 completed: 635 chars, 163 chunks, TTFT=19537.4ms
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_740 received DONE after 171 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_740 completed: 680 chars, 171 chunks, TTFT=19394.8ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] INFO:     127.0.0.1:48446 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 145, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_879
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_879
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_878
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_878
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 65, #cached-token: 6, token usage: 0.07, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:49] Prefill batch. #new-seq: 1, #new-token: 90, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_807 received DONE after 89 chunks
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Request req_807 completed: 339 chars, 89 chunks, TTFT=21227.1ms
[2025-07-25 02:52:49] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:49] INFO:     127.0.0.1:60486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_880
[2025-07-25 02:52:49] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_880
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 5, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_782 received DONE after 124 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_782 completed: 492 chars, 124 chunks, TTFT=20579.5ms
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_826 received DONE after 70 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_826 completed: 276 chars, 70 chunks, TTFT=21835.6ms
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_727 received DONE after 193 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_727 completed: 755 chars, 193 chunks, TTFT=19088.1ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48336 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_881
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_881
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60672 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60648 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_883
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_883
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_882
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_882
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] Prefill batch. #new-seq: 2, #new-token: 138, #cached-token: 12, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_803 received DONE after 103 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_803 completed: 404 chars, 103 chunks, TTFT=21126.9ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:37002 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_884
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_884
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_802 received DONE after 110 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_802 completed: 432 chars, 110 chunks, TTFT=21132.9ms
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_804 received DONE after 110 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_804 completed: 436 chars, 110 chunks, TTFT=21142.4ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60758 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60874 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_886
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_886
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_885
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_885
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] Prefill batch. #new-seq: 2, #new-token: 229, #cached-token: 12, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_821 received DONE after 81 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_821 completed: 222 chars, 81 chunks, TTFT=21665.6ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48354 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_887
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_887
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_766 received DONE after 159 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_766 completed: 620 chars, 159 chunks, TTFT=20080.1ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60544 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_888
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_888
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 74, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_812 received DONE after 99 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_812 completed: 194 chars, 99 chunks, TTFT=21322.1ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48250 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_889
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_889
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 92, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_755 received DONE after 167 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_755 completed: 655 chars, 167 chunks, TTFT=19864.0ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60774 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_890
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_890
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 155, #cached-token: 5, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_820 received DONE after 91 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_820 completed: 347 chars, 91 chunks, TTFT=21628.3ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:37094 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_891
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_891
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 171, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_789 received DONE after 131 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_789 completed: 520 chars, 131 chunks, TTFT=20703.6ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60852 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_892
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_892
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_761 received DONE after 172 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_761 completed: 172 chars, 172 chunks, TTFT=19967.7ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:37058 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_893
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_893
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 112, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_783 received DONE after 147 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_783 completed: 584 chars, 147 chunks, TTFT=20589.8ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48268 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_816 received DONE after 103 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_816 completed: 106 chars, 103 chunks, TTFT=21455.2ms
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_894
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_894
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60548 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_895
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_895
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] Decode batch. #running-req: 51, #token: 9010, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2443.06, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 87, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_836 received DONE after 81 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_836 completed: 257 chars, 81 chunks, TTFT=21999.3ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:51324 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_896
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_896
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_771 received DONE after 165 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_771 completed: 656 chars, 165 chunks, TTFT=20231.4ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48326 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_897
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_897
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 99, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] Decode batch. #running-req: 49, #token: 9825, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2274.20, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_787 received DONE after 144 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_787 completed: 572 chars, 144 chunks, TTFT=20646.0ms
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_792 received DONE after 131 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_792 completed: 134 chars, 131 chunks, TTFT=20893.5ms
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_776 received DONE after 153 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_776 completed: 608 chars, 153 chunks, TTFT=20415.1ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60732 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.metrics_collector] [INFO] Completed 800 requests, success rate: 100.0%
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_898
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_898
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48420 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60466 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 88, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_900
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_900
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_786 received DONE after 146 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_786 completed: 576 chars, 146 chunks, TTFT=20645.3ms
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_899
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_899
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_784 received DONE after 149 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_784 completed: 592 chars, 149 chunks, TTFT=20579.1ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_901
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_901
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60636 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_902
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_902
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] Prefill batch. #new-seq: 3, #new-token: 223, #cached-token: 16, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_774 received DONE after 166 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_774 completed: 648 chars, 166 chunks, TTFT=20373.1ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48590 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_903
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_903
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 136, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_829 received DONE after 102 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_829 completed: 103 chars, 102 chunks, TTFT=21845.0ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60704 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_904
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_904
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 6, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_846 received DONE after 81 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_846 completed: 222 chars, 81 chunks, TTFT=22356.4ms
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_819 received DONE after 114 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_819 completed: 113 chars, 114 chunks, TTFT=21562.0ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:37100 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_905
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_905
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60692 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 175, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_906
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_906
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 6, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_756 received DONE after 188 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_756 completed: 748 chars, 188 chunks, TTFT=19884.6ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48384 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_907
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_907
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 6, token usage: 0.09, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_754 received DONE after 190 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_754 completed: 377 chars, 190 chunks, TTFT=19875.0ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60878 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_908
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_908
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 94, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_791 received DONE after 159 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_791 completed: 629 chars, 159 chunks, TTFT=20805.8ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48650 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_839 received DONE after 94 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_839 completed: 93 chars, 94 chunks, TTFT=22143.1ms
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_909
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_909
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60934 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_910
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_910
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_779 received DONE after 173 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_779 completed: 676 chars, 173 chunks, TTFT=20508.2ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48220 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_793 received DONE after 152 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_793 completed: 604 chars, 152 chunks, TTFT=20970.1ms
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_911
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_911
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_772 received DONE after 179 chunks
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Request req_772 completed: 712 chars, 179 chunks, TTFT=20261.7ms
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] INFO:     127.0.0.1:60476 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_912
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_912
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] INFO:     127.0.0.1:48310 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_913
[2025-07-25 02:52:50] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_913
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:50] Prefill batch. #new-seq: 2, #new-token: 211, #cached-token: 10, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:50] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:50] Prefill batch. #new-seq: 1, #new-token: 141, #cached-token: 6, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_837 received DONE after 108 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_837 completed: 107 chars, 108 chunks, TTFT=22028.4ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_806 received DONE after 150 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_806 completed: 583 chars, 150 chunks, TTFT=21142.2ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60910 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_914
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_914
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48566 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 132, #cached-token: 6, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_915
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_915
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 117, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_796 received DONE after 157 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_796 completed: 624 chars, 157 chunks, TTFT=20990.9ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48370 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_916
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_916
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 99, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_866 received DONE after 71 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_866 completed: 139 chars, 71 chunks, TTFT=22865.7ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:33954 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_917
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_917
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 6, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_847 received DONE after 90 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_847 completed: 344 chars, 90 chunks, TTFT=22439.0ms
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_773 received DONE after 187 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_773 completed: 190 chars, 187 chunks, TTFT=20263.1ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60752 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48436 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_919
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_919
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 159, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_918
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_918
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 6, token usage: 0.07, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_785 received DONE after 180 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_785 completed: 716 chars, 180 chunks, TTFT=20589.5ms
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_781 received DONE after 180 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_781 completed: 181 chars, 180 chunks, TTFT=20580.5ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48506 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_920
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_920
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_921
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_921
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 5, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 124, #cached-token: 6, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_845 received DONE after 96 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_845 completed: 97 chars, 96 chunks, TTFT=22343.2ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60778 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_922
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_922
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_810 received DONE after 150 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_810 completed: 584 chars, 150 chunks, TTFT=21269.0ms
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_840 received DONE after 113 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_840 completed: 478 chars, 113 chunks, TTFT=22198.9ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60744 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_924
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_924
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48462 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_923
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_923
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] Decode batch. #running-req: 50, #token: 8747, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2310.85, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 116, #cached-token: 6, token usage: 0.07, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_825 received DONE after 133 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_825 completed: 515 chars, 133 chunks, TTFT=21801.0ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] Decode batch. #running-req: 48, #token: 9523, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2507.36, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 6, token usage: 0.08, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_801 received DONE after 159 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_801 completed: 314 chars, 159 chunks, TTFT=21101.8ms
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_925
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_925
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_926
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_926
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] Prefill batch. #new-seq: 2, #new-token: 160, #cached-token: 12, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_862 received DONE after 88 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_862 completed: 89 chars, 88 chunks, TTFT=22800.8ms
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_868 received DONE after 82 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_868 completed: 324 chars, 82 chunks, TTFT=22946.5ms
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_811 received DONE after 163 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_811 completed: 635 chars, 163 chunks, TTFT=21286.2ms
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_818 received DONE after 145 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_818 completed: 403 chars, 145 chunks, TTFT=21554.4ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60720 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48530 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 142, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_805 received DONE after 164 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_805 completed: 652 chars, 164 chunks, TTFT=21130.0ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48632 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_928
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_928
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_929
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_929
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_927
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_927
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_930
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_930
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60606 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] Prefill batch. #new-seq: 2, #new-token: 224, #cached-token: 12, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_931
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_931
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_867 received DONE after 86 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_867 completed: 340 chars, 86 chunks, TTFT=22934.9ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48294 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_932
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_932
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] Prefill batch. #new-seq: 2, #new-token: 266, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 169, #cached-token: 5, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_850 received DONE after 102 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_850 completed: 282 chars, 102 chunks, TTFT=22535.5ms
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_855 received DONE after 97 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_855 completed: 190 chars, 97 chunks, TTFT=22674.6ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:33960 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_933
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_933
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48496 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_934
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_934
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 83, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 129, #cached-token: 5, token usage: 0.07, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_842 received DONE after 121 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_842 completed: 239 chars, 121 chunks, TTFT=22280.4ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60922 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_822 received DONE after 144 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_822 completed: 563 chars, 144 chunks, TTFT=21711.3ms
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_935
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_935
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48408 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_936
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_936
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_886 received DONE after 66 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_886 completed: 248 chars, 66 chunks, TTFT=23452.5ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60874 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_871 received DONE after 92 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_871 completed: 93 chars, 92 chunks, TTFT=22943.9ms
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_937
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_937
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:37034 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_938
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_938
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 178, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 76, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_841 received DONE after 120 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_841 completed: 473 chars, 120 chunks, TTFT=22244.0ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:54294 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_831 received DONE after 142 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_831 completed: 143 chars, 142 chunks, TTFT=21890.3ms
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_939
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_939
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 135, #cached-token: 6, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60928 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_940
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_940
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_832 received DONE after 140 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_832 completed: 276 chars, 140 chunks, TTFT=21897.8ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_941
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_941
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 133, #cached-token: 5, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_824 received DONE after 147 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_824 completed: 150 chars, 147 chunks, TTFT=21761.0ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60886 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_942
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_942
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 145, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_817 received DONE after 163 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_817 completed: 322 chars, 163 chunks, TTFT=21525.3ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48394 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_943
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_943
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 167, #cached-token: 6, token usage: 0.09, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_800 received DONE after 187 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_800 completed: 732 chars, 187 chunks, TTFT=21108.1ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60696 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_890 received DONE after 78 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_890 completed: 296 chars, 78 chunks, TTFT=23536.9ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 88, #cached-token: 6, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_944
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_944
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_945
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_945
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60774 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_835 received DONE after 149 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_835 completed: 150 chars, 149 chunks, TTFT=22028.6ms
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] INFO:     127.0.0.1:48640 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_946
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_946
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 63, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:51] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 6, token usage: 0.09, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_823 received DONE after 164 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_823 completed: 324 chars, 164 chunks, TTFT=21722.7ms
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_884 received DONE after 85 chunks
[2025-07-25 02:52:51] [sglang_test_framework.core.request_generator] [DEBUG] Request req_884 completed: 324 chars, 85 chunks, TTFT=23406.4ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:51] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:37002 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_948
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_948
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_947
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_947
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60862 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 173, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 176, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_901 received DONE after 66 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_901 completed: 180 chars, 66 chunks, TTFT=23875.5ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_949
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_949
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_843 received DONE after 143 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_843 completed: 556 chars, 143 chunks, TTFT=22280.8ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:37064 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_950
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_950
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 138, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_857 received DONE after 124 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_857 completed: 125 chars, 124 chunks, TTFT=22682.8ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60798 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_951
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_951
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 147, #cached-token: 5, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_878 received DONE after 103 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_878 completed: 436 chars, 103 chunks, TTFT=23215.5ms
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_833 received DONE after 161 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_833 completed: 318 chars, 161 chunks, TTFT=21954.0ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:37086 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48518 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_952
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_952
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_953
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_953
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] Prefill batch. #new-seq: 2, #new-token: 262, #cached-token: 12, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_828 received DONE after 167 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_828 completed: 652 chars, 167 chunks, TTFT=21845.8ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] Decode batch. #running-req: 48, #token: 8753, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2283.79, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60520 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_954
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_954
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 115, #cached-token: 6, token usage: 0.07, #running-req: 47, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_815 received DONE after 189 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_815 completed: 190 chars, 189 chunks, TTFT=21450.6ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60840 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_955
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_955
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_903 received DONE after 70 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_903 completed: 272 chars, 70 chunks, TTFT=23955.2ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 110, #cached-token: 6, token usage: 0.07, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48590 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_956
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_956
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] Decode batch. #running-req: 50, #token: 9976, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2295.42, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 128, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_887 received DONE after 97 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_887 completed: 96 chars, 97 chunks, TTFT=23474.6ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:51320 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_957
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_957
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 67, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_897 received DONE after 89 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_897 completed: 339 chars, 89 chunks, TTFT=23742.6ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48326 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_958
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_958
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 82, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_849 received DONE after 148 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_849 completed: 588 chars, 148 chunks, TTFT=22494.3ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60810 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_834 received DONE after 169 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_834 completed: 172 chars, 169 chunks, TTFT=21996.2ms
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_959
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_959
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 156, #cached-token: 6, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48652 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_863 received DONE after 135 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_863 completed: 136 chars, 135 chunks, TTFT=22812.1ms
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_893 received DONE after 91 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_893 completed: 94 chars, 91 chunks, TTFT=23709.5ms
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_960
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_960
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_962
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_962
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:37058 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60978 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_961
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_961
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] Prefill batch. #new-seq: 2, #new-token: 212, #cached-token: 10, token usage: 0.08, #running-req: 49, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_827 received DONE after 189 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_827 completed: 374 chars, 189 chunks, TTFT=21804.2ms
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_963
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_963
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60870 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 111, #cached-token: 6, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_921 received DONE after 65 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_921 completed: 66 chars, 65 chunks, TTFT=24477.3ms
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_872 received DONE after 130 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_872 completed: 504 chars, 130 chunks, TTFT=23074.7ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48228 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60592 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_964
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_964
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_965
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_965
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 98, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 107, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_877 received DONE after 130 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_877 completed: 516 chars, 130 chunks, TTFT=23193.1ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48484 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_966
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_966
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 153, #cached-token: 6, token usage: 0.08, #running-req: 48, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_830 received DONE after 190 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_830 completed: 191 chars, 190 chunks, TTFT=21845.2ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:51300 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_909 received DONE after 84 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_909 completed: 85 chars, 84 chunks, TTFT=24201.6ms
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_875 received DONE after 134 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_875 completed: 264 chars, 134 chunks, TTFT=23169.5ms
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_905 received DONE after 91 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_905 completed: 360 chars, 91 chunks, TTFT=24055.3ms
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_967
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_967
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 99, #cached-token: 6, token usage: 0.08, #running-req: 50, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48552 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_838 received DONE after 184 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_838 completed: 732 chars, 184 chunks, TTFT=22136.5ms
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_969
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_969
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:37100 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_970
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_970
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_968
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_968
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_891 received DONE after 116 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_891 completed: 448 chars, 116 chunks, TTFT=23598.5ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] Prefill batch. #new-seq: 2, #new-token: 280, #cached-token: 12, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:33946 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:37094 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_971
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_971
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_972
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_972
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_856 received DONE after 162 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_856 completed: 449 chars, 162 chunks, TTFT=22645.9ms
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_879 received DONE after 137 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_879 completed: 136 chars, 137 chunks, TTFT=23197.4ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] Prefill batch. #new-seq: 2, #new-token: 304, #cached-token: 11, token usage: 0.08, #running-req: 51, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60824 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48446 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_974
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_974
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_973
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_973
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_861 received DONE after 149 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_861 completed: 150 chars, 149 chunks, TTFT=22800.8ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] Prefill batch. #new-seq: 2, #new-token: 220, #cached-token: 12, token usage: 0.07, #running-req: 46, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60578 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_975
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_975
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] Prefill batch. #new-seq: 2, #new-token: 186, #cached-token: 10, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_885 received DONE after 124 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_885 completed: 245 chars, 124 chunks, TTFT=23452.7ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48480 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_848 received DONE after 179 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_848 completed: 712 chars, 179 chunks, TTFT=22431.1ms
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_976
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_976
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60758 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_977
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_977
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_852 received DONE after 175 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_852 completed: 176 chars, 175 chunks, TTFT=22544.4ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 6, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:33976 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_978
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_978
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] Prefill batch. #new-seq: 2, #new-token: 193, #cached-token: 12, token usage: 0.09, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_869 received DONE after 158 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_869 completed: 616 chars, 158 chunks, TTFT=22944.0ms
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_860 received DONE after 164 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_860 completed: 652 chars, 164 chunks, TTFT=22807.9ms
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_925 received DONE after 77 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_925 completed: 208 chars, 77 chunks, TTFT=24598.3ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48622 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:33988 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] INFO:     127.0.0.1:48188 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_979
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_979
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_980
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_980
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_981
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_981
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:52] Prefill batch. #new-seq: 2, #new-token: 298, #cached-token: 12, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] Prefill batch. #new-seq: 1, #new-token: 105, #cached-token: 5, token usage: 0.08, #running-req: 55, #queue-req: 0,
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_876 received DONE after 141 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_876 completed: 547 chars, 141 chunks, TTFT=23192.7ms
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_859 received DONE after 158 chunks
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Request req_859 completed: 675 chars, 158 chunks, TTFT=22788.8ms
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:33942 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_982
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_982
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] INFO:     127.0.0.1:60722 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_983
[2025-07-25 02:52:52] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_983
[2025-07-25 02:52:52] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:52] Prefill batch. #new-seq: 2, #new-token: 148, #cached-token: 10, token usage: 0.08, #running-req: 56, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_853 received DONE after 173 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_853 completed: 676 chars, 173 chunks, TTFT=22646.2ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] INFO:     127.0.0.1:48602 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_984
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_984
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] Decode batch. #running-req: 43, #token: 7970, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2449.75, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] Prefill batch. #new-seq: 1, #new-token: 154, #cached-token: 6, token usage: 0.07, #running-req: 43, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_858 received DONE after 173 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_858 completed: 688 chars, 173 chunks, TTFT=22704.4ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_851 received DONE after 169 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_851 completed: 659 chars, 169 chunks, TTFT=22537.4ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] INFO:     127.0.0.1:60962 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_898 received DONE after 110 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_898 completed: 304 chars, 110 chunks, TTFT=23870.2ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_985
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_985
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] INFO:     127.0.0.1:60732 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_987
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_987
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] INFO:     127.0.0.1:48680 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] Prefill batch. #new-seq: 2, #new-token: 242, #cached-token: 12, token usage: 0.08, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_986
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_986
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] Prefill batch. #new-seq: 1, #new-token: 149, #cached-token: 6, token usage: 0.07, #running-req: 43, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] Decode batch. #running-req: 55, #token: 10172, token usage: 0.09, cuda graph: True, gen throughput (token/s): 2232.27, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_929 received DONE after 73 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_929 completed: 72 chars, 73 chunks, TTFT=24710.6ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] INFO:     127.0.0.1:60576 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_988
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_988
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] Prefill batch. #new-seq: 1, #new-token: 93, #cached-token: 6, token usage: 0.09, #running-req: 55, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_939 received DONE after 75 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_939 completed: 292 chars, 75 chunks, TTFT=24875.0ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] INFO:     127.0.0.1:54294 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_989
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_989
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] Prefill batch. #new-seq: 1, #new-token: 166, #cached-token: 6, token usage: 0.07, #running-req: 43, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_907 received DONE after 112 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_907 completed: 115 chars, 112 chunks, TTFT=24061.3ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] INFO:     127.0.0.1:55360 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_990
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_990
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] Prefill batch. #new-seq: 1, #new-token: 164, #cached-token: 5, token usage: 0.09, #running-req: 56, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_844 received DONE after 186 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_844 completed: 368 chars, 186 chunks, TTFT=22338.6ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] INFO:     127.0.0.1:48384 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] Prefill batch. #new-seq: 1, #new-token: 151, #cached-token: 5, token usage: 0.07, #running-req: 43, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_991
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_991
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_940 received DONE after 72 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_940 completed: 71 chars, 72 chunks, TTFT=24905.2ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] INFO:     127.0.0.1:60928 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_992
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_992
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_908 received DONE after 107 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_908 completed: 424 chars, 107 chunks, TTFT=24130.2ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] Prefill batch. #new-seq: 1, #new-token: 96, #cached-token: 6, token usage: 0.08, #running-req: 52, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_880 received DONE after 153 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_880 completed: 152 chars, 153 chunks, TTFT=23226.8ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] INFO:     127.0.0.1:48278 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_910 received DONE after 104 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_910 completed: 105 chars, 104 chunks, TTFT=24200.9ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_993
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_993
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] Prefill batch. #new-seq: 1, #new-token: 137, #cached-token: 6, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_874 received DONE after 159 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_874 completed: 632 chars, 159 chunks, TTFT=23085.8ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] INFO:     127.0.0.1:60934 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] INFO:     127.0.0.1:60486 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_995
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_995
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_994
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_994
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] INFO:     127.0.0.1:48240 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_996
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_996
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] Prefill batch. #new-seq: 2, #new-token: 180, #cached-token: 12, token usage: 0.08, #running-req: 53, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] Prefill batch. #new-seq: 1, #new-token: 179, #cached-token: 6, token usage: 0.07, #running-req: 45, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_913 received DONE after 112 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_913 completed: 220 chars, 112 chunks, TTFT=24201.3ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_894 received DONE after 136 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_894 completed: 528 chars, 136 chunks, TTFT=23728.6ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] INFO:     127.0.0.1:60700 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_997
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] INFO:     127.0.0.1:60878 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_997
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] Prefill batch. #new-seq: 1, #new-token: 79, #cached-token: 6, token usage: 0.08, #running-req: 54, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_998
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_998
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] Prefill batch. #new-seq: 1, #new-token: 183, #cached-token: 6, token usage: 0.08, #running-req: 55, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_882 received DONE after 146 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_882 completed: 408 chars, 146 chunks, TTFT=23382.1ms
[2025-07-25 02:52:53] [sglang_test_framework.core.metrics_collector] [INFO] Completed 900 requests, success rate: 100.0%
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] INFO:     127.0.0.1:48268 - "POST /generate HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Got response status 200 for request req_999
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Handling stream response for request req_999
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] Prefill batch. #new-seq: 1, #new-token: 118, #cached-token: 6, token usage: 0.07, #running-req: 44, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_865 received DONE after 185 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_865 completed: 732 chars, 185 chunks, TTFT=22812.0ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_870 received DONE after 170 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_870 completed: 173 chars, 170 chunks, TTFT=22948.8ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_854 received DONE after 183 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_854 completed: 728 chars, 183 chunks, TTFT=22655.2ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_873 received DONE after 173 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_873 completed: 688 chars, 173 chunks, TTFT=23085.9ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_900 received DONE after 136 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_900 completed: 135 chars, 136 chunks, TTFT=23862.4ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_918 received DONE after 115 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_918 completed: 442 chars, 115 chunks, TTFT=24389.6ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_950 received DONE after 76 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_950 completed: 77 chars, 76 chunks, TTFT=25310.3ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_896 received DONE after 144 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_896 completed: 143 chars, 144 chunks, TTFT=23733.1ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_936 received DONE after 100 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_936 completed: 396 chars, 100 chunks, TTFT=24850.9ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_888 received DONE after 158 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_888 completed: 313 chars, 158 chunks, TTFT=23489.4ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_883 received DONE after 162 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_883 completed: 644 chars, 162 chunks, TTFT=23382.0ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_923 received DONE after 111 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_923 completed: 428 chars, 111 chunks, TTFT=24597.0ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_864 received DONE after 191 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_864 completed: 760 chars, 191 chunks, TTFT=22800.6ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_919 received DONE after 118 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_919 completed: 232 chars, 118 chunks, TTFT=24380.9ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_914 received DONE after 122 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_914 completed: 125 chars, 122 chunks, TTFT=24285.7ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] Decode batch. #running-req: 38, #token: 7438, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2316.30, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_941 received DONE after 108 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_941 completed: 109 chars, 108 chunks, TTFT=24941.6ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_881 received DONE after 177 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_881 completed: 701 chars, 177 chunks, TTFT=23402.4ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_947 received DONE after 84 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_947 completed: 332 chars, 84 chunks, TTFT=25253.5ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_895 received DONE after 159 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_895 completed: 632 chars, 159 chunks, TTFT=23733.0ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] Decode batch. #running-req: 45, #token: 8965, token usage: 0.08, cuda graph: True, gen throughput (token/s): 2965.28, #queue-req: 0,
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_960 received DONE after 80 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_960 completed: 257 chars, 80 chunks, TTFT=25598.6ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_892 received DONE after 167 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_892 completed: 664 chars, 167 chunks, TTFT=23628.5ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_902 received DONE after 162 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_902 completed: 644 chars, 162 chunks, TTFT=23875.3ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_970 received DONE after 68 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_970 completed: 256 chars, 68 chunks, TTFT=25968.4ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_951 received DONE after 93 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_951 completed: 365 chars, 93 chunks, TTFT=25344.5ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_948 received DONE after 107 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_948 completed: 410 chars, 107 chunks, TTFT=25238.1ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:53] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_969 received DONE after 68 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_969 completed: 69 chars, 68 chunks, TTFT=25973.2ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_899 received DONE after 165 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_899 completed: 603 chars, 165 chunks, TTFT=23875.9ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_917 received DONE after 141 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_917 completed: 547 chars, 141 chunks, TTFT=24378.1ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_904 received DONE after 160 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_904 completed: 161 chars, 160 chunks, TTFT=23993.1ms
[2025-07-25 02:52:53] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:53] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_938 received DONE after 129 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_938 completed: 254 chars, 129 chunks, TTFT=24872.8ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_889 received DONE after 192 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_889 completed: 764 chars, 192 chunks, TTFT=23516.1ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_927 received DONE after 127 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_927 completed: 504 chars, 127 chunks, TTFT=24711.0ms
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_926 received DONE after 140 chunks
[2025-07-25 02:52:53] [sglang_test_framework.core.request_generator] [DEBUG] Request req_926 completed: 139 chars, 140 chunks, TTFT=24598.3ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_932 received DONE after 137 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_932 completed: 532 chars, 137 chunks, TTFT=24706.3ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_915 received DONE after 157 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_915 completed: 160 chars, 157 chunks, TTFT=24316.0ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_930 received DONE after 139 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_930 completed: 275 chars, 139 chunks, TTFT=24706.5ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_922 received DONE after 144 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_922 completed: 560 chars, 144 chunks, TTFT=24477.3ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:54] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_920 received DONE after 154 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_920 completed: 612 chars, 154 chunks, TTFT=24453.9ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_946 received DONE after 121 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_946 completed: 238 chars, 121 chunks, TTFT=25177.4ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:54] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_931 received DONE after 137 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_931 completed: 531 chars, 137 chunks, TTFT=24730.0ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_966 received DONE after 89 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_966 completed: 340 chars, 89 chunks, TTFT=25859.6ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_928 received DONE after 147 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_928 completed: 146 chars, 147 chunks, TTFT=24703.7ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:54] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_933 received DONE after 142 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_933 completed: 564 chars, 142 chunks, TTFT=24738.9ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_934 received DONE after 152 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_934 completed: 300 chars, 152 chunks, TTFT=24752.7ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:54] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_911 received DONE after 177 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_911 completed: 704 chars, 177 chunks, TTFT=24201.7ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_985 received DONE after 75 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_985 completed: 76 chars, 75 chunks, TTFT=26280.4ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:54] Decode batch. #running-req: 21, #token: 4876, token usage: 0.04, cuda graph: True, gen throughput (token/s): 2350.04, #queue-req: 0,
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_949 received DONE after 121 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_949 completed: 122 chars, 121 chunks, TTFT=25257.1ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_984 received DONE after 82 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_984 completed: 324 chars, 82 chunks, TTFT=26245.0ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_961 received DONE after 117 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_961 completed: 464 chars, 117 chunks, TTFT=25598.3ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_916 received DONE after 178 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_916 completed: 179 chars, 178 chunks, TTFT=24315.9ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:54] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_945 received DONE after 131 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_945 completed: 360 chars, 131 chunks, TTFT=25145.1ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_972 received DONE after 100 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_972 completed: 383 chars, 100 chunks, TTFT=25974.9ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_998 received DONE after 72 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_998 completed: 271 chars, 72 chunks, TTFT=26551.0ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:54] Decode batch. #running-req: 31, #token: 6559, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2858.83, #queue-req: 0,
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:54] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_997 received DONE after 74 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_997 completed: 144 chars, 74 chunks, TTFT=26547.4ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_980 received DONE after 89 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_980 completed: 92 chars, 89 chunks, TTFT=26171.6ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_974 received DONE after 103 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_974 completed: 359 chars, 103 chunks, TTFT=25973.3ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_906 received DONE after 188 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_906 completed: 734 chars, 188 chunks, TTFT=24047.0ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_957 received DONE after 119 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_957 completed: 326 chars, 119 chunks, TTFT=25516.6ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_993 received DONE after 82 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_993 completed: 321 chars, 82 chunks, TTFT=26498.3ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_943 received DONE after 156 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_943 completed: 620 chars, 156 chunks, TTFT=25024.9ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_976 received DONE after 98 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_976 completed: 388 chars, 98 chunks, TTFT=26140.2ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:54] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_991 received DONE after 85 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_991 completed: 258 chars, 85 chunks, TTFT=26449.6ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_968 received DONE after 108 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_968 completed: 107 chars, 108 chunks, TTFT=25968.7ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_924 received DONE after 167 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_924 completed: 168 chars, 167 chunks, TTFT=24576.7ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:54] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_952 received DONE after 142 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_952 completed: 280 chars, 142 chunks, TTFT=25382.2ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_963 received DONE after 114 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_963 completed: 117 chars, 114 chunks, TTFT=25775.1ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_967 received DONE after 111 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_967 completed: 110 chars, 111 chunks, TTFT=25947.9ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:54] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_912 received DONE after 193 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_912 completed: 194 chars, 193 chunks, TTFT=24203.4ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_956 received DONE after 147 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_956 completed: 148 chars, 147 chunks, TTFT=25463.3ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:54] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_935 received DONE after 168 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_935 completed: 169 chars, 168 chunks, TTFT=24847.8ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_937 received DONE after 171 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_937 completed: 668 chars, 171 chunks, TTFT=24848.2ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_942 received DONE after 165 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_942 completed: 644 chars, 165 chunks, TTFT=24975.3ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_958 received DONE after 146 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_958 completed: 580 chars, 146 chunks, TTFT=25593.6ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_953 received DONE after 159 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_953 completed: 620 chars, 159 chunks, TTFT=25382.3ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:54] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_964 received DONE after 138 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_964 completed: 137 chars, 138 chunks, TTFT=25795.1ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_999 received DONE after 101 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_999 completed: 102 chars, 101 chunks, TTFT=26604.3ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:54] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:54] Decode batch. #running-req: 5, #token: 1390, token usage: 0.01, cuda graph: True, gen throughput (token/s): 1088.17, #queue-req: 0,
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_977 received DONE after 120 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_977 completed: 330 chars, 120 chunks, TTFT=26147.5ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_944 received DONE after 166 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_944 completed: 165 chars, 166 chunks, TTFT=25143.2ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_973 received DONE after 131 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_973 completed: 130 chars, 131 chunks, TTFT=25977.7ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:54] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_982 received DONE after 124 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_982 completed: 245 chars, 124 chunks, TTFT=26183.9ms
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_965 received DONE after 140 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_965 completed: 276 chars, 140 chunks, TTFT=25778.4ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:54] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_983 received DONE after 127 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_983 completed: 570 chars, 127 chunks, TTFT=26185.7ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:54] Decode batch. #running-req: 14, #token: 3252, token usage: 0.03, cuda graph: True, gen throughput (token/s): 1834.83, #queue-req: 0,
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_988 received DONE after 121 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_988 completed: 120 chars, 121 chunks, TTFT=26354.3ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:54] INFO:     127.0.0.1:56456 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:54] INFO:     127.0.0.1:55370 - "GET /health HTTP/1.1" 200 OK
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:54] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_987 received DONE after 129 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_987 completed: 132 chars, 129 chunks, TTFT=26280.2ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:54] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_959 received DONE after 166 chunks
[2025-07-25 02:52:54] [sglang_test_framework.core.request_generator] [DEBUG] Request req_959 completed: 647 chars, 166 chunks, TTFT=25605.3ms
[2025-07-25 02:52:54] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:54] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:55] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_962 received DONE after 172 chunks
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_962 completed: 171 chars, 172 chunks, TTFT=25607.4ms
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_955 received DONE after 184 chunks
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_955 completed: 364 chars, 184 chunks, TTFT=25431.0ms
[2025-07-25 02:52:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:55] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_986 received DONE after 158 chunks
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_986 completed: 615 chars, 158 chunks, TTFT=26285.3ms
[2025-07-25 02:52:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:55] Decode batch. #running-req: 5, #token: 1283, token usage: 0.01, cuda graph: True, gen throughput (token/s): 474.69, #queue-req: 0,
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_992 received DONE after 143 chunks
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_992 completed: 144 chars, 143 chunks, TTFT=26493.4ms
[2025-07-25 02:52:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:55] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_989 received DONE after 158 chunks
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_989 completed: 615 chars, 158 chunks, TTFT=26350.6ms
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_981 received DONE after 168 chunks
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_981 completed: 655 chars, 168 chunks, TTFT=26150.2ms
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_954 received DONE after 193 chunks
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_954 completed: 194 chars, 193 chunks, TTFT=25430.6ms
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_971 received DONE after 171 chunks
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_971 completed: 668 chars, 171 chunks, TTFT=25972.9ms
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_995 received DONE after 149 chunks
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_995 completed: 295 chars, 149 chunks, TTFT=26496.6ms
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_979 received DONE after 173 chunks
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_979 completed: 682 chars, 173 chunks, TTFT=26150.4ms
[2025-07-25 02:52:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:55] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:55] Decode batch. #running-req: 4, #token: 1152, token usage: 0.01, cuda graph: True, gen throughput (token/s): 843.49, #queue-req: 0,
[2025-07-25 02:52:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:55] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_990 received DONE after 163 chunks
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_990 completed: 648 chars, 163 chunks, TTFT=26361.6ms
[2025-07-25 02:52:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:55] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_994 received DONE after 161 chunks
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_994 completed: 640 chars, 161 chunks, TTFT=26496.9ms
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_975 received DONE after 185 chunks
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_975 completed: 184 chars, 185 chunks, TTFT=25983.7ms
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_978 received DONE after 177 chunks
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_978 completed: 701 chars, 177 chunks, TTFT=26147.2ms
[2025-07-25 02:52:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:55] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:55] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:55] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_996 received DONE after 187 chunks
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] Request req_996 completed: 732 chars, 187 chunks, TTFT=26502.9ms
[2025-07-25 02:52:55] [sglang_test_framework.core.metrics_collector] [INFO] Completed 1000 requests, success rate: 100.0%
[2025-07-25 02:52:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:55] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:55] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:55] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:55] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:55] INFO:     127.0.0.1:48238 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:55] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:55] INFO:     127.0.0.1:60510 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-07-25 02:52:55] [sglang_test_framework.core.request_generator] [DEBUG] RequestSender session closed
[2025-07-25 02:52:55] [sglang_test_framework.core.metrics_collector] [INFO] Stopped metrics collection
[2025-07-25 02:52:55] [sglang_test_framework.core.metrics_collector] [INFO] Stopped metrics collection
[2025-07-25 02:52:55] [sglang_test_framework.core.metrics_collector] [INFO] Stopped metrics collection
[2025-07-25 02:52:55] [sglang_test_framework.core.metrics_collector] [INFO] Exported metrics to metrics_20250725_025255.csv
[2025-07-25 02:52:55] [sglang_test_framework.core.metrics_collector] [INFO] Exported metrics to metrics_20250725_025255.json
[2025-07-25 02:52:55] [sglang_test_framework.tests.routing_test] [ERROR] Test failed: "None of [Index(['req_id', 'input_length', 'decode_length', 'arrival_time',\n       'to_server_time', 'finish_time', 'server_latency', 'total_latency',\n       'ttft', 'queue_time', 'success', 'error', 'worker_url', 'gpu_id'],\n      dtype='object')] are in the [columns]"
[2025-07-25 02:52:55] [sglang_test_framework.core.metrics_collector] [WARNING] Metrics collection not started
[2025-07-25 02:52:55] [sglang_test_framework.core.metrics_collector] [WARNING] Metrics collection not started
[2025-07-25 02:52:55] [sglang_test_framework.core.metrics_collector] [WARNING] Metrics collection not started
[2025-07-25 02:52:55] [sglang_test_framework.core.server_manager] [INFO] Stopping router
[2025-07-25 02:52:56] [sglang_test_framework.core.server_manager] [INFO] Stopping server worker_0
[2025-07-25 02:52:56] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:56] SIGTERM received. signum=None frame=None. Draining requests and shutting down...
[2025-07-25 02:52:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:59] Gracefully exiting... remaining number of requests 0
[2025-07-25 02:52:59] [sglang_test_framework.core.server_manager] [INFO] [worker_0] [2025-07-25 02:52:59] Dumping requests before crash. self.crash_dump_folder=None
[2025-07-25 02:52:59] [sglang_test_framework.core.server_manager] [INFO] Stopping server worker_1
[2025-07-25 02:52:59] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:52:59] SIGTERM received. signum=None frame=None. Draining requests and shutting down...
[2025-07-25 02:53:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:53:00] Gracefully exiting... remaining number of requests 0
[2025-07-25 02:53:00] [sglang_test_framework.core.server_manager] [INFO] [worker_1] [2025-07-25 02:53:00] Dumping requests before crash. self.crash_dump_folder=None
[2025-07-25 02:53:00] [__main__] [ERROR] Test failed with error: "None of [Index(['req_id', 'input_length', 'decode_length', 'arrival_time',\n       'to_server_time', 'finish_time', 'server_latency', 'total_latency',\n       'ttft', 'queue_time', 'success', 'error', 'worker_url', 'gpu_id'],\n      dtype='object')] are in the [columns]"
Traceback (most recent call last):
  File "/home/lg/sglang/sglang_test_framework/test_route.py", line 281, in <module>
    asyncio.run(run_custom_test())
  File "/home/lg/.conda/envs/sglang_test/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/home/lg/.conda/envs/sglang_test/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/home/lg/sglang/sglang_test_framework/test_route.py", line 277, in run_custom_test
    results = await routing_test._run_async()
  File "/home/lg/sglang/sglang_test_framework/tests/routing_test.py", line 246, in _run_async
    server_csv = collector.export_metrics("csv",
  File "/home/lg/sglang/sglang_test_framework/core/metrics_collector.py", line 568, in export_metrics
    self._export_csv(path)
  File "/home/lg/sglang/sglang_test_framework/core/metrics_collector.py", line 645, in _export_csv
    df = df[columns]
  File "/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/pandas/core/frame.py", line 4113, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6212, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "/home/lg/.conda/envs/sglang_test/lib/python3.10/site-packages/pandas/core/indexes/base.py", line 6261, in _raise_if_missing
    raise KeyError(f"None of [{key}] are in the [{axis_name}]")
KeyError: "None of [Index(['req_id', 'input_length', 'decode_length', 'arrival_time',\n       'to_server_time', 'finish_time', 'server_latency', 'total_latency',\n       'ttft', 'queue_time', 'success', 'error', 'worker_url', 'gpu_id'],\n      dtype='object')] are in the [columns]"
