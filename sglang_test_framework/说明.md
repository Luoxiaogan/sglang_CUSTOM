# SGLang 测试框架详细说明文档

## 目录

1. [项目概述](#项目概述)
2. [文档体系说明](#文档体系说明)
3. [框架结构详解](#框架结构详解)
4. [核心模块使用指南](#核心模块使用指南)
5. [使用流程与最佳实践](#使用流程与最佳实践)
6. [与SGLang知识库的关系](#与sglang知识库的关系)
7. [扩展开发指南](#扩展开发指南)

## 项目概述

SGLang 测试框架是一个专门为 SGLang（大语言模型服务框架）设计的综合性能测试工具。该框架的设计初衷是提供一个标准化、可扩展的测试平台，用于评估 SGLang 在不同配置和负载条件下的性能表现。

### 核心设计理念

1. **双层测试架构**
   - **节点级测试（Node Level）**：单 GPU 上的性能测试，关注单个服务器实例的处理能力
   - **路由级测试（Routing Level）**：多 GPU 分布式测试，评估负载均衡和路由策略效果

2. **精确的时间测量**
   - **请求到达时间**：模拟用户请求到达路由器的时刻
   - **请求发送时间**：请求被发送到具体服务器的时刻
   - **请求完成时间**：服务器完成推理并返回结果的时刻

3. **灵活的策略支持**
   - 支持静态批处理和连续批处理
   - 多种路由策略（均匀随机、最短作业优先、参数感知等）
   - 动态参数调整能力

## 文档体系说明

### 1. `.claude_prompt_custom/demand_1_init.md`

这是项目需求文档，定义了测试框架的核心需求：

```
关键需求点：
1. SGLang知识库文档必须加入/memory
2. 支持两种测试模式：node level 和 routing level
3. 必须查询.DUCUMENT目录获取所有API使用方法
4. 记录三个关键时刻的延迟测量
5. 支持动态修改--max-running-requests参数
```

**使用考虑**：
- 开发新功能时必须参考此文档确保满足所有需求
- 特别注意延迟测量的定义差异（server_latency vs total_latency）
- 禁止使用防御性编程，要求及时报错

### 2. `CLAUDE.md`

这是框架的主要用户文档，提供了：

```
主要内容：
- 安装和配置指南
- API 参考文档
- 使用示例代码
- 性能优化建议
- 故障排查指南
```

**使用考虑**：
- 作为用户的第一参考文档
- 新功能必须在此文档中更新
- 保持示例代码的可运行性

### 3. `.DUCUMENT/` 目录

包含 SGLang 的核心知识库文档：

#### `.DUCUMENT/Server_Arguments.md`
- **内容**：SGLang 服务器的所有启动参数详解
- **重要参数**：
  - `--max-running-requests`：最大并发请求数
  - `--mem-fraction-static`：静态内存分配比例
  - `--chunked-prefill-size`：预填充批次大小
- **使用注意**：测试框架的 `ServerConfig` 类必须与此文档保持同步

#### `.DUCUMENT/Router_for_Data_Parallelism.md`
- **内容**：路由器的实现原理和配置方法
- **关键概念**：
  - Cache-aware routing（缓存感知路由）
  - Load balancing（负载均衡）
  - 动态切换策略的条件
- **使用注意**：实现自定义路由策略时必须参考此文档

#### `.DUCUMENT/Hyperparameter_Tuning.md`
- **内容**：性能调优指南
- **调优策略**：
  - 高吞吐量配置
  - 低延迟配置
  - 内存优化配置
- **使用注意**：测试场景设计应覆盖文档中提到的关键参数

#### `.DUCUMENT/Benchmark_and_Profiling.md`
- **内容**：基准测试和性能分析方法
- **工具介绍**：
  - `bench_serving.py`：在线服务测试
  - `bench_offline_throughput.py`：离线吞吐量测试
- **使用注意**：测试框架的指标收集应与官方基准测试兼容

#### `.DUCUMENT/Sampling_Parameters.md`
- **内容**：采样参数配置
- **重要参数**：
  - `temperature`：采样温度
  - `max_new_tokens`：最大生成长度
  - `ignore_eos`：是否忽略结束符
- **使用注意**：请求生成器应支持所有采样参数

## 框架结构详解

### 目录结构

```
sglang_test_framework/
├── config/               # 配置模块
│   ├── base.py          # 基础配置类
│   ├── node_config.py   # 节点测试配置
│   └── routing_config.py # 路由测试配置
├── core/                # 核心功能模块
│   ├── server_manager.py    # 服务器管理
│   ├── request_generator.py # 请求生成
│   ├── metrics_collector.py # 指标收集
│   └── result_manager.py    # 结果管理
├── strategies/          # 策略实现（待开发）
│   ├── batching/       # 批处理策略
│   └── routing/        # 路由策略
├── tests/              # 测试运行器（待开发）
├── utils/              # 工具函数（待开发）
└── requirements.txt    # 依赖列表
```

### 各模块详细说明

#### 1. 配置模块 (`config/`)

##### `base.py` - 基础配置类

```python
class BaseConfig:
    """所有配置的基类"""
    - 模型配置（model_path, tokenizer_path）
    - 测试配置（num_prompts, request_rate, dataset_name）
    - 输出配置（output_dir, output_format）
    - 验证逻辑和序列化方法

class ServerConfig:
    """服务器配置"""
    - 服务器标识（server_id, gpu_id, port）
    - 性能参数（max_running_requests, mem_fraction_static）
    - 优化选项（enable_torch_compile, quantization）
    
class MetricsConfig:
    """指标收集配置"""
    - 收集间隔和指标选择
    - 延迟百分位数设置
    - 导出格式配置
```

**使用注意事项**：
- 配置验证在 `__post_init__` 中自动执行
- 支持从 JSON 文件加载和保存配置
- GPU ID 必须正确设置以避免资源冲突

##### `node_config.py` - 单节点测试配置

```python
class NodeConfig(BaseConfig):
    """单GPU测试配置"""
    
主要特性：
- 批处理策略选择（continuous/static）
- 静态批处理的详细配置
- 动态参数更新调度
- 与ServerConfig的转换方法
```

**使用示例**：

```python
# 基础配置
config = NodeConfig(
    model_path="meta-llama/Llama-2-7b-hf",
    gpu_id=0,
    max_running_requests=256,
    batch_strategy="continuous"
)

# 带动态参数更新的配置
config = NodeConfig(
    model_path="meta-llama/Llama-2-7b-hf",
    enable_dynamic_params=True,
    param_update_schedule={
        60: {"max_running_requests": 512},    # 60秒后更新
        120: {"max_running_requests": 256}    # 120秒后恢复
    }
)
```

##### `routing_config.py` - 多节点路由测试配置

```python
class RoutingConfig(BaseConfig):
    """多GPU路由测试配置"""
    
主要特性：
- 多GPU配置（num_gpus, gpu_ids）
- 路由器配置（RouterConfig）
- 负载分布设置（uniform/skewed/pattern）
- 节点故障模拟
```

**使用示例**：

```python
# 基础路由配置
config = RoutingConfig(
    model_path="meta-llama/Llama-2-7b-hf",
    num_gpus=4,
    routing_policy="cache_aware",
    request_rate=40.0
)

# 带节点故障模拟的配置
config = RoutingConfig(
    model_path="meta-llama/Llama-2-7b-hf",
    num_gpus=4,
    enable_node_failures=True,
    failure_schedule={
        300: [1, 2],  # 300秒时节点1、2故障
        600: []       # 600秒时恢复
    }
)
```

#### 2. 核心模块 (`core/`)

##### `server_manager.py` - 服务器生命周期管理

```python
class SGLangServer:
    """单个服务器实例管理"""
    - 启动/停止服务器进程
    - 健康检查
    - 动态参数更新
    - 指标获取

class RouterManager:
    """路由器实例管理"""
    - 启动/停止路由器
    - 添加/移除工作节点
    - 健康检查

class ServerManager:
    """统一管理接口"""
    - 批量启动服务器
    - 协调路由器和服务器
    - 统一的参数更新接口
```

**关键实现细节**：

1. **进程管理**：
   ```python
   # 使用subprocess启动服务器
   self.process = subprocess.Popen(cmd, env=env, ...)
   
   # 优雅关闭
   self.process.terminate()
   self.process.wait(timeout=10)
   ```

2. **健康检查**：
   ```python
   # 通过HTTP endpoint检查
   async def health_check(self):
       response = await session.get(f"http://{host}:{port}/health")
       return response.status == 200
   ```

3. **动态参数更新**：
   ```python
   # 注意：需要服务器端支持相应的API
   async def update_param(self, param, value):
       url = f"http://{host}:{port}/update_{param}"
       response = await session.post(url, json={"value": value})
   ```

##### `request_generator.py` - 请求生成与发送

```python
class Request:
    """请求数据结构"""
    - 请求标识和内容
    - 三个关键时间戳
    - 输入输出长度

class RequestResult:
    """请求结果"""
    - 成功/失败状态
    - 各类延迟指标
    - 生成的文本内容

class RequestGenerator:
    """请求生成器"""
    - 支持多种数据集（ShareGPT, Random）
    - 泊松分布的到达时间生成
    - 长度分布生成

class RequestSender:
    """请求发送器"""
    - 异步HTTP请求
    - 流式/非流式响应处理
    - 并发控制
```

**核心算法**：

1. **泊松到达时间生成**：
   ```python
   def generate_poisson_arrivals(self, requests, request_rate):
       if request_rate == float('inf'):
           # 所有请求同时到达
           for req in requests:
               req.arrival_time = start_time
       else:
           # 泊松过程
           current_time = start_time
           for req in requests:
               interval = np.random.exponential(1.0 / request_rate)
               current_time += interval
               req.arrival_time = current_time
   ```

2. **延迟计算**：
   ```python
   # 三种延迟的精确定义
   server_latency = completion_time - send_time      # 服务器处理延迟
   total_latency = completion_time - arrival_time    # 端到端总延迟
   queue_time = send_time - arrival_time            # 排队等待时间
   ```

##### `metrics_collector.py` - 性能指标收集

```python
class MetricsCollector:
    """指标收集器"""
    
主要功能：
- 实时指标收集（后台线程）
- 请求级指标记录
- 系统级指标监控（GPU利用率等）
- 聚合指标计算

class AggregatedMetrics:
    """聚合指标数据结构"""
    - 吞吐量指标（请求/令牌）
    - 延迟指标（均值/中位数/百分位数）
    - 队列指标（深度/等待时间）
    - GPU指标（利用率/内存）
```

**指标计算方法**：

1. **吞吐量计算**：
   ```python
   request_throughput = completed_requests / duration
   token_throughput = total_tokens / duration
   ```

2. **百分位数计算**：
   ```python
   p95_latency = np.percentile(latencies, 95)
   p99_latency = np.percentile(latencies, 99)
   ```

3. **队列深度追踪**：
   ```python
   # 使用deque存储时间序列数据
   self.queue_depths.append((timestamp, active_requests_count))
   ```

##### `result_manager.py` - 结果管理与可视化

```python
class ResultManager:
    """结果管理器"""
    
主要功能：
- 结果持久化（JSON/CSV/Parquet）
- 可视化图表生成
- 多次测试对比分析
- 报告生成
```

**生成的可视化图表**：

1. **延迟分布图**：展示各类延迟的直方图分布
2. **吞吐量时序图**：展示吞吐量随时间的变化
3. **队列深度图**：展示系统负载情况
4. **请求时间线**：可视化请求的生命周期
5. **性能热力图**：综合展示各项指标
6. **GPU利用率图**：展示计算资源使用情况

## 核心模块使用指南

### 1. 快速开始 - 单节点测试

```python
import asyncio
from sglang_test_framework import (
    NodeConfig, ServerManager, RequestGenerator, 
    RequestSender, MetricsCollector, ResultManager
)

async def run_node_test():
    # 1. 配置测试
    config = NodeConfig(
        model_path="meta-llama/Llama-2-7b-hf",
        gpu_id=0,
        max_running_requests=256,
        request_rate=10.0,
        num_prompts=1000
    )
    
    # 2. 初始化组件
    server_manager = ServerManager()
    request_generator = RequestGenerator(config.tokenizer_path)
    metrics_collector = MetricsCollector()
    result_manager = ResultManager(config.output_dir)
    
    # 3. 启动服务器
    server_config = config.get_server_config()
    server = await server_manager.launch_server(server_config)
    
    # 4. 生成请求
    requests = request_generator.generate_requests(
        num_prompts=config.num_prompts,
        dataset_name=config.dataset_name,
        random_input_len=config.random_input_len,
        random_output_len=config.random_output_len
    )
    
    # 分配泊松到达时间
    requests = request_generator.generate_poisson_arrivals(
        requests, config.request_rate
    )
    
    # 5. 开始指标收集
    metrics_collector.start_collection()
    
    # 6. 发送请求并收集结果
    api_url = f"http://localhost:{server_config.port}/generate"
    
    async with RequestSender() as sender:
        tasks = []
        for request in requests:
            # 等待到达时间
            wait_time = request.arrival_time - asyncio.get_event_loop().time()
            if wait_time > 0:
                await asyncio.sleep(wait_time)
            
            # 记录请求开始
            metrics_collector.record_request_start(request.request_id)
            
            # 发送请求
            task = asyncio.create_task(sender.send_request(request, api_url))
            tasks.append(task)
        
        # 等待所有请求完成
        results = await asyncio.gather(*tasks)
        
        # 记录结果
        for result in results:
            metrics_collector.record_request_complete(result)
    
    # 7. 停止收集并生成报告
    metrics_collector.stop_collection()
    
    # 8. 保存结果和生成可视化
    test_dir = result_manager.save_results(
        metrics_collector, 
        config.to_dict(),
        "node_test_example"
    )
    
    plots = result_manager.create_visualizations(
        metrics_collector,
        test_dir
    )
    
    # 9. 打印摘要
    metrics_collector.print_summary()
    
    # 10. 清理
    server_manager.stop_all()

# 运行测试
asyncio.run(run_node_test())
```

### 2. 路由测试示例

```python
async def run_routing_test():
    # 1. 配置路由测试
    config = RoutingConfig(
        model_path="meta-llama/Llama-2-7b-hf",
        num_gpus=4,
        routing_policy="shortest_job",
        request_rate=40.0,
        num_prompts=5000
    )
    
    # 2. 启动多个服务器
    server_manager = ServerManager()
    servers = await server_manager.launch_multiple_servers(
        config.servers_config
    )
    
    # 3. 启动路由器
    worker_urls = config.get_worker_urls()
    router = await server_manager.launch_router(
        config.router_config,
        worker_urls
    )
    
    # 4. 执行测试（通过路由器发送请求）
    router_url = f"http://localhost:{config.router_config.port}/generate"
    
    # ... 后续步骤与单节点测试类似，但请求发送到路由器
```

### 3. 动态参数更新示例

```python
async def test_dynamic_updates():
    config = NodeConfig(
        model_path="meta-llama/Llama-2-7b-hf",
        enable_dynamic_params=True,
        param_update_schedule={
            60: {"max_running_requests": 512},
            120: {"max_running_requests": 256},
            180: {"max_running_requests": 384}
        }
    )
    
    # 启动服务器
    server_manager = ServerManager()
    server = await server_manager.launch_server(config.get_server_config())
    
    # 启动参数更新任务
    async def update_params():
        for time_point, params in config.param_update_schedule.items():
            await asyncio.sleep(time_point)
            for param, value in params.items():
                success = await server_manager.update_server_param(
                    server.config.server_id,
                    param,
                    value
                )
                print(f"Updated {param} to {value}: {success}")
    
    # 并行运行测试和参数更新
    await asyncio.gather(
        run_test_workload(),
        update_params()
    )
```

## 使用流程与最佳实践

### 1. 测试前准备

```bash
# 1. 安装依赖
cd sglang_test_framework
pip install -r requirements.txt

# 2. 确保SGLang已安装
pip install sglang sglang-router

# 3. 检查GPU可用性
nvidia-smi

# 4. 创建输出目录
mkdir -p results
```

### 2. 测试流程

```
1. 确定测试目标
   - 单节点性能极限？
   - 路由策略效果？
   - 参数敏感性分析？

2. 设计测试方案
   - 选择合适的数据集
   - 确定负载模式（请求速率、长度分布）
   - 设置测试时长

3. 配置测试参数
   - 根据.DUCUMENT/Hyperparameter_Tuning.md选择初始参数
   - 设置合理的预热请求数
   - 配置指标收集间隔

4. 执行测试
   - 监控系统资源
   - 观察实时指标
   - 记录异常情况

5. 分析结果
   - 查看生成的可视化图表
   - 对比预期性能目标
   - 识别性能瓶颈
```

### 3. 性能调优建议

基于 `.DUCUMENT/Hyperparameter_Tuning.md`：

```python
# 高吞吐量配置
high_throughput_config = NodeConfig(
    model_path="...",
    max_running_requests=512,
    mem_fraction_static=0.85,
    chunked_prefill_size=8192,
    schedule_conservativeness=0.8,  # 更激进的调度
    enable_torch_compile=True
)

# 低延迟配置
low_latency_config = NodeConfig(
    model_path="...",
    max_running_requests=32,
    mem_fraction_static=0.9,
    schedule_conservativeness=1.2,  # 更保守的调度
    chunked_prefill_size=2048
)

# 内存受限配置
memory_constrained_config = NodeConfig(
    model_path="...",
    max_running_requests=128,
    mem_fraction_static=0.7,  # 降低静态内存分配
    chunked_prefill_size=1024,
    quantization="fp8"  # 使用量化减少内存使用
)
```

### 4. 故障排查

常见问题及解决方案：

```python
# 1. 服务器启动失败
# 检查端口占用
# 解决：修改配置中的端口号

# 2. OOM错误
# 检查配置
if "CUDA out of memory" in error:
    # 减少max_running_requests
    # 降低mem_fraction_static
    # 减小chunked_prefill_size

# 3. 请求超时
# 增加客户端超时时间
# 检查服务器负载

# 4. 指标收集不完整
# 确保正确调用start/stop collection
# 检查是否所有请求都记录了完成状态
```

## 与SGLang知识库的关系

### 1. API使用规范

根据 `.claude_prompt_custom/demand_1_init.md` 的要求：

```
所有SGLang API的使用必须：
1. 查询.DUCUMENT目录中的相关文档
2. 确保参数名称和类型完全一致
3. 遵循官方推荐的最佳实践
```

### 2. 知识库文档映射

| 测试框架组件 | 对应知识库文档 | 关键依赖 |
|-------------|---------------|----------|
| ServerConfig | Server_Arguments.md | 启动参数定义 |
| RouterConfig | Router_for_Data_Parallelism.md | 路由策略参数 |
| 性能测试场景 | Hyperparameter_Tuning.md | 调优建议 |
| 指标定义 | Benchmark_and_Profiling.md | 指标计算方法 |
| 请求参数 | Sampling_Parameters.md | 采样参数 |

### 3. 版本兼容性

```python
# 检查SGLang版本兼容性
import sglang
assert sglang.__version__ >= "0.3.0", "需要SGLang 0.3.0或更高版本"

# 检查Router版本
import sglang_router
assert sglang_router.__version__ >= "0.1.0", "需要sglang-router 0.1.0或更高版本"
```

## 扩展开发指南

### 1. 添加新的批处理策略

```python
# strategies/batching/custom_batching.py
from .base import BaseBatchingStrategy

class CustomBatchingStrategy(BaseBatchingStrategy):
    def __init__(self, config):
        super().__init__(config)
        self.batch_size = config.get("batch_size", 32)
        self.timeout_ms = config.get("timeout_ms", 100)
    
    def should_process_batch(self, requests, current_time):
        """决定是否处理当前批次"""
        # 条件1：达到批次大小
        if len(requests) >= self.batch_size:
            return True
        
        # 条件2：超时
        if requests and (current_time - requests[0].arrival_time) * 1000 > self.timeout_ms:
            return True
            
        return False
    
    def select_requests_for_batch(self, pending_requests):
        """选择要处理的请求"""
        # 可以实现复杂的选择逻辑
        # 例如：基于请求长度的智能打包
        return pending_requests[:self.batch_size]
```

### 2. 实现自定义路由策略

```python
# strategies/routing/custom_routing.py
from .base import BaseRoutingPolicy

class PredictiveRoutingPolicy(BaseRoutingPolicy):
    """基于预测的路由策略"""
    
    def __init__(self, workers):
        super().__init__(workers)
        self.request_history = defaultdict(list)
    
    def route_request(self, request, server_metrics):
        """基于历史数据预测最佳服务器"""
        # 1. 预测请求处理时间
        predicted_times = {}
        for worker_id, metrics in server_metrics.items():
            # 基于当前负载和历史数据预测
            base_time = metrics['mean_latency']
            queue_penalty = metrics['queue_depth'] * 50  # ms per queued request
            predicted_time = base_time + queue_penalty
            predicted_times[worker_id] = predicted_time
        
        # 2. 选择预测时间最短的服务器
        best_worker = min(predicted_times.items(), key=lambda x: x[1])[0]
        
        # 3. 记录决策用于后续学习
        self.request_history[best_worker].append({
            'request_id': request.request_id,
            'predicted_time': predicted_times[best_worker],
            'timestamp': time.time()
        })
        
        return best_worker
    
    def update_with_result(self, request_id, actual_time):
        """根据实际结果更新模型"""
        # 可以实现在线学习逻辑
        pass
```

### 3. 创建测试运行器

```python
# tests/comprehensive_test.py
import asyncio
from typing import Dict, Any

class ComprehensiveTest:
    """综合测试运行器"""
    
    def __init__(self, base_config: Dict[str, Any]):
        self.base_config = base_config
        self.results = {}
    
    async def run_parameter_sweep(self, param_name: str, values: list):
        """参数扫描测试"""
        for value in values:
            # 创建配置副本
            config = self.base_config.copy()
            config[param_name] = value
            
            # 运行测试
            result = await self.run_single_test(config)
            self.results[f"{param_name}_{value}"] = result
            
            # 分析结果
            print(f"\n{param_name}={value}:")
            print(f"  Throughput: {result['throughput']:.1f} req/s")
            print(f"  P99 Latency: {result['p99_latency']:.1f} ms")
    
    async def run_stress_test(self, duration: int, ramp_up_time: int):
        """压力测试"""
        config = self.base_config.copy()
        
        # 阶段1：预热
        config['request_rate'] = 1.0
        await self.run_single_test(config, duration=30)
        
        # 阶段2：线性增加负载
        start_rate = 1.0
        end_rate = 100.0
        steps = 10
        
        for i in range(steps):
            rate = start_rate + (end_rate - start_rate) * i / steps
            config['request_rate'] = rate
            
            result = await self.run_single_test(
                config, 
                duration=ramp_up_time // steps
            )
            
            # 检查系统是否稳定
            if result['error_rate'] > 0.05:  # 5%错误率
                print(f"System unstable at {rate:.1f} req/s")
                break
```

### 4. 集成外部监控

```python
# utils/monitoring.py
import prometheus_client
from prometheus_client import Counter, Histogram, Gauge

class PrometheusExporter:
    """Prometheus指标导出器"""
    
    def __init__(self, port=8000):
        # 定义指标
        self.request_counter = Counter(
            'sglang_test_requests_total',
            'Total number of requests',
            ['status', 'test_id']
        )
        
        self.latency_histogram = Histogram(
            'sglang_test_latency_seconds',
            'Request latency',
            ['type', 'test_id'],
            buckets=(0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0)
        )
        
        self.queue_depth_gauge = Gauge(
            'sglang_test_queue_depth',
            'Current queue depth',
            ['server_id']
        )
        
        # 启动HTTP服务器
        prometheus_client.start_http_server(port)
    
    def record_request(self, result: RequestResult, test_id: str):
        """记录请求指标"""
        status = 'success' if result.success else 'failure'
        self.request_counter.labels(status=status, test_id=test_id).inc()
        
        if result.success:
            self.latency_histogram.labels(
                type='total', 
                test_id=test_id
            ).observe(result.total_latency)
            
            self.latency_histogram.labels(
                type='server',
                test_id=test_id
            ).observe(result.server_latency)
    
    def update_queue_depth(self, server_id: str, depth: int):
        """更新队列深度"""
        self.queue_depth_gauge.labels(server_id=server_id).set(depth)
```

## 注意事项与限制

### 1. 已知限制

1. **动态参数更新**：
   - 需要SGLang服务器端支持相应的API endpoint
   - 当前仅 `max_running_requests` 支持动态更新
   - 更新可能有延迟生效

2. **GPU指标收集**：
   - 需要安装 `pynvml` 库
   - 仅支持NVIDIA GPU
   - 多GPU环境下默认只收集GPU 0的指标

3. **路由策略**：
   - 自定义策略需要继承基类并实现接口
   - 策略切换需要重启路由器

### 2. 性能考虑

1. **请求生成开销**：
   - 大量请求时建议预生成并缓存
   - ShareGPT数据集会自动缓存到本地

2. **指标收集开销**：
   - 高频率收集可能影响性能
   - 建议生产测试时使用1秒或更长的收集间隔

3. **并发限制**：
   - 默认HTTP连接池限制为1000
   - 可通过 `aiohttp.TCPConnector(limit=N)` 调整

### 3. 安全注意事项

1. **端口冲突**：
   - 确保配置的端口未被占用
   - 使用 `netstat -tlnp | grep PORT` 检查

2. **资源清理**：
   - 测试结束后确保调用 `stop_all()`
   - 使用 `with` 语句或 `try-finally` 确保清理

3. **错误处理**：
   - 遵循"快速失败"原则
   - 不使用防御性编程
   - 详细记录错误信息

## 总结

SGLang测试框架提供了一个全面、灵活的性能测试解决方案。通过精确的时间测量、丰富的指标收集和可扩展的架构设计，能够满足从简单的单节点测试到复杂的分布式路由测试的各种需求。

关键要点：
1. 始终参考 `.DUCUMENT` 目录中的官方文档
2. 理解三种延迟（server/total/queue）的区别
3. 根据测试目标选择合适的配置
4. 充分利用可视化工具分析结果
5. 遵循框架的扩展接口进行二次开发

通过本框架，用户可以：
- 评估SGLang在不同配置下的性能表现
- 找出最优的参数组合
- 验证路由策略的效果
- 进行容量规划和性能调优