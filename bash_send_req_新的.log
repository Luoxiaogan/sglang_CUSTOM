==========================================
SGLang Router æµ‹è¯•é…ç½®
==========================================
è¯·æ±‚æ•°é‡: 200
è¯·æ±‚é€Ÿç‡: 50.0 req/s
æ•°æ®é›†: random
è¾“å…¥é•¿åº¦: 512 Â±256%
è¾“å‡ºé•¿åº¦: 128 Â±64%
è·¯ç”±å™¨åœ°å€: http://localhost:60009
==========================================

æ‰§è¡Œå‘½ä»¤:
python /nas/ganluo/sglang/send_req.py --num-requests 200 --request-rate 50.0 --dataset random --router-url http://localhost:60009 --input-len 512 --output-len 128 --range-ratio 0.5

é¢„è®¡æµ‹è¯•æ—¶é—´: 4.0ç§’ï¼ˆä¸å«å¤„ç†æ—¶é—´ï¼‰

Generating 200 random requests...
âœ… Router health check passed

Sending 200 requests at 50.0 req/s...
ğŸ“¤ Request 1/200 sent at 0.00s
ğŸ“¤ Request 2/200 sent at 0.01s
ğŸ“¤ Request 3/200 sent at 0.03s
ğŸ“¤ Request 4/200 sent at 0.03s
ğŸ“¤ Request 5/200 sent at 0.04s
ğŸ“¤ Request 6/200 sent at 0.05s
ğŸ“¤ Request 7/200 sent at 0.06s
ğŸ“¤ Request 8/200 sent at 0.06s
ğŸ“¤ Request 9/200 sent at 0.09s
ğŸ“¤ Request 10/200 sent at 0.10s
ğŸ“¤ Request 11/200 sent at 0.10s
ğŸ“¤ Request 12/200 sent at 0.12s
ğŸ“¤ Request 13/200 sent at 0.13s
ğŸ“¤ Request 14/200 sent at 0.13s
ğŸ“¤ Request 15/200 sent at 0.19s
ğŸ“¤ Request 16/200 sent at 0.21s
ğŸ“¤ Request 17/200 sent at 0.22s
ğŸ“¤ Request 18/200 sent at 0.25s
ğŸ“¤ Request 19/200 sent at 0.29s
ğŸ“¤ Request 20/200 sent at 0.29s
ğŸ“¤ Request 21/200 sent at 0.32s
ğŸ“¤ Request 22/200 sent at 0.35s
ğŸ“¤ Request 23/200 sent at 0.36s
ğŸ“¤ Request 24/200 sent at 0.37s
ğŸ“¤ Request 25/200 sent at 0.38s
ğŸ“¤ Request 26/200 sent at 0.40s
ğŸ“¤ Request 27/200 sent at 0.43s
ğŸ“¤ Request 28/200 sent at 0.46s
ğŸ“¤ Request 29/200 sent at 0.47s
ğŸ“¤ Request 30/200 sent at 0.51s
ğŸ“¤ Request 31/200 sent at 0.52s
ğŸ“¤ Request 32/200 sent at 0.53s
ğŸ“¤ Request 33/200 sent at 0.56s
ğŸ“¤ Request 34/200 sent at 0.60s
ğŸ“¤ Request 35/200 sent at 0.60s
ğŸ“¤ Request 36/200 sent at 0.65s
ğŸ“¤ Request 37/200 sent at 0.65s
ğŸ“¤ Request 38/200 sent at 0.68s
ğŸ“¤ Request 39/200 sent at 0.70s
ğŸ“¤ Request 40/200 sent at 0.72s
ğŸ“¤ Request 41/200 sent at 0.72s
ğŸ“¤ Request 42/200 sent at 0.72s
ğŸ“¤ Request 43/200 sent at 0.73s
ğŸ“¤ Request 44/200 sent at 0.82s
ğŸ“¤ Request 45/200 sent at 0.86s
ğŸ“¤ Request 46/200 sent at 0.87s
ğŸ“¤ Request 47/200 sent at 0.88s
ğŸ“¤ Request 48/200 sent at 0.92s
ğŸ“¤ Request 49/200 sent at 0.97s
ğŸ“¤ Request 50/200 sent at 1.01s
ğŸ“¤ Request 51/200 sent at 1.02s
ğŸ“¤ Request 52/200 sent at 1.03s
âœ… Request 30/200 completed
âœ… Request 16/200 completed
âœ… Request 2/200 completed
ğŸ“¤ Request 53/200 sent at 1.15s
ğŸ“¤ Request 54/200 sent at 1.16s
ğŸ“¤ Request 55/200 sent at 1.17s
ğŸ“¤ Request 56/200 sent at 1.17s
ğŸ“¤ Request 57/200 sent at 1.18s
ğŸ“¤ Request 58/200 sent at 1.21s
âœ… Request 5/200 completed
ğŸ“¤ Request 59/200 sent at 1.23s
âœ… Request 19/200 completed
ğŸ“¤ Request 60/200 sent at 1.25s
âœ… Request 9/200 completed
âœ… Request 1/200 completed
âœ… Request 42/200 completed
ğŸ“¤ Request 61/200 sent at 1.32s
âœ… Request 3/200 completed
ğŸ“¤ Request 62/200 sent at 1.34s
ğŸ“¤ Request 63/200 sent at 1.35s
ğŸ“¤ Request 64/200 sent at 1.40s
âœ… Request 24/200 completed
âœ… Request 35/200 completed
âœ… Request 10/200 completed
âœ… Request 21/200 completed
âœ… Request 45/200 completed
ğŸ“¤ Request 65/200 sent at 1.48s
ğŸ“¤ Request 66/200 sent at 1.50s
âœ… Request 6/200 completed
ğŸ“¤ Request 67/200 sent at 1.51s
âœ… Request 14/200 completed
ğŸ“¤ Request 68/200 sent at 1.52s
âœ… Request 27/200 completed
ğŸ“¤ Request 69/200 sent at 1.57s
ğŸ“¤ Request 70/200 sent at 1.59s
ğŸ“¤ Request 71/200 sent at 1.59s
ğŸ“¤ Request 72/200 sent at 1.60s
âœ… Request 17/200 completed
ğŸ“¤ Request 73/200 sent at 1.65s
âœ… Request 26/200 completed
âœ… Request 18/200 completed
ğŸ“¤ Request 74/200 sent at 1.69s
ğŸ“¤ Request 75/200 sent at 1.74s
ğŸ“¤ Request 76/200 sent at 1.77s
ğŸ“¤ Request 77/200 sent at 1.79s
âœ… Request 13/200 completed
ğŸ“¤ Request 78/200 sent at 1.79s
ğŸ“¤ Request 79/200 sent at 1.80s
âœ… Request 53/200 completed
âœ… Request 46/200 completed
âœ… Request 50/200 completed
âœ… Request 44/200 completed
ğŸ“¤ Request 80/200 sent at 1.86s
ğŸ“¤ Request 81/200 sent at 1.87s
âœ… Request 47/200 completed
âœ… Request 7/200 completed
âœ… Request 55/200 completed
âœ… Request 20/200 completed
âœ… Request 12/200 completed
âœ… Request 23/200 completed
âœ… Request 40/200 completed
ğŸ“¤ Request 82/200 sent at 1.93s
âœ… Request 41/200 completed
âœ… Request 48/200 completed
ğŸ“¤ Request 83/200 sent at 1.98s
âœ… Request 43/200 completed
ğŸ“¤ Request 84/200 sent at 2.01s
ğŸ“¤ Request 85/200 sent at 2.03s
ğŸ“¤ Request 86/200 sent at 2.04s
âœ… Request 63/200 completed
âœ… Request 22/200 completed
ğŸ“¤ Request 87/200 sent at 2.07s
âœ… Request 49/200 completed
ğŸ“¤ Request 88/200 sent at 2.08s
âœ… Request 52/200 completed
âœ… Request 15/200 completed
âœ… Request 37/200 completed
ğŸ“¤ Request 89/200 sent at 2.10s
ğŸ“¤ Request 90/200 sent at 2.10s
âœ… Request 28/200 completed
âœ… Request 32/200 completed
ğŸ“¤ Request 91/200 sent at 2.13s
âœ… Request 8/200 completed
âœ… Request 56/200 completed
âœ… Request 29/200 completed
âœ… Request 4/200 completed
ğŸ“¤ Request 92/200 sent at 2.19s
ğŸ“¤ Request 93/200 sent at 2.22s
âœ… Request 39/200 completed
ğŸ“¤ Request 94/200 sent at 2.24s
ğŸ“¤ Request 95/200 sent at 2.25s
âœ… Request 34/200 completed
âœ… Request 74/200 completed
âœ… Request 25/200 completed
âœ… Request 11/200 completed
âœ… Request 33/200 completed
âœ… Request 31/200 completed
ğŸ“¤ Request 96/200 sent at 2.38s
ğŸ“¤ Request 97/200 sent at 2.39s
âœ… Request 38/200 completed
âœ… Request 62/200 completed
âœ… Request 59/200 completed
âœ… Request 58/200 completed
âœ… Request 75/200 completed
ğŸ“¤ Request 98/200 sent at 2.46s
âœ… Request 67/200 completed
ğŸ“¤ Request 99/200 sent at 2.47s
âœ… Request 66/200 completed
ğŸ“¤ Request 100/200 sent at 2.47s
âœ… Request 36/200 completed
ğŸ“¤ Request 101/200 sent at 2.50s
ğŸ“¤ Request 102/200 sent at 2.51s
ğŸ“¤ Request 103/200 sent at 2.51s
ğŸ“¤ Request 104/200 sent at 2.54s
ğŸ“¤ Request 105/200 sent at 2.59s
ğŸ“¤ Request 106/200 sent at 2.60s
ğŸ“¤ Request 107/200 sent at 2.60s
ğŸ“¤ Request 108/200 sent at 2.60s
âœ… Request 78/200 completed
âœ… Request 79/200 completed
ğŸ“¤ Request 109/200 sent at 2.65s
âœ… Request 60/200 completed
âœ… Request 68/200 completed
âœ… Request 51/200 completed
âœ… Request 54/200 completed
ğŸ“¤ Request 110/200 sent at 2.72s
ğŸ“¤ Request 111/200 sent at 2.73s
ğŸ“¤ Request 112/200 sent at 2.73s
ğŸ“¤ Request 113/200 sent at 2.77s
ğŸ“¤ Request 114/200 sent at 2.79s
âœ… Request 57/200 completed
âœ… Request 64/200 completed
âœ… Request 69/200 completed
âœ… Request 87/200 completed
ğŸ“¤ Request 115/200 sent at 2.85s
ğŸ“¤ Request 116/200 sent at 2.86s
âœ… Request 84/200 completed
ğŸ“¤ Request 117/200 sent at 2.91s
ğŸ“¤ Request 118/200 sent at 2.91s
ğŸ“¤ Request 119/200 sent at 2.92s
ğŸ“¤ Request 120/200 sent at 2.93s
âœ… Request 70/200 completed
ğŸ“¤ Request 121/200 sent at 2.93s
ğŸ“¤ Request 122/200 sent at 2.98s
ğŸ“¤ Request 123/200 sent at 2.98s
ğŸ“¤ Request 124/200 sent at 3.00s
ğŸ“¤ Request 125/200 sent at 3.01s
ğŸ“¤ Request 126/200 sent at 3.02s
âœ… Request 92/200 completed
âœ… Request 65/200 completed
ğŸ“¤ Request 127/200 sent at 3.06s
ğŸ“¤ Request 128/200 sent at 3.07s
ğŸ“¤ Request 129/200 sent at 3.07s
ğŸ“¤ Request 130/200 sent at 3.07s
ğŸ“¤ Request 131/200 sent at 3.08s
ğŸ“¤ Request 132/200 sent at 3.09s
âœ… Request 72/200 completed
ğŸ“¤ Request 133/200 sent at 3.11s
âœ… Request 81/200 completed
âœ… Request 61/200 completed
ğŸ“¤ Request 134/200 sent at 3.14s
âœ… Request 89/200 completed
ğŸ“¤ Request 135/200 sent at 3.16s
âœ… Request 71/200 completed
ğŸ“¤ Request 136/200 sent at 3.24s
âœ… Request 100/200 completed
âœ… Request 91/200 completed
ğŸ“¤ Request 137/200 sent at 3.27s
ğŸ“¤ Request 138/200 sent at 3.29s
ğŸ“¤ Request 139/200 sent at 3.29s
ğŸ“¤ Request 140/200 sent at 3.30s
ğŸ“¤ Request 141/200 sent at 3.30s
ğŸ“¤ Request 142/200 sent at 3.32s
ğŸ“¤ Request 143/200 sent at 3.34s
âœ… Request 112/200 completed
ğŸ“¤ Request 144/200 sent at 3.34s
ğŸ“¤ Request 145/200 sent at 3.36s
âœ… Request 80/200 completed
âœ… Request 94/200 completed
âœ… Request 103/200 completed
ğŸ“¤ Request 146/200 sent at 3.39s
âœ… Request 76/200 completed
ğŸ“¤ Request 147/200 sent at 3.42s
âœ… Request 73/200 completed
âœ… Request 83/200 completed
ğŸ“¤ Request 148/200 sent at 3.44s
âœ… Request 114/200 completed
ğŸ“¤ Request 149/200 sent at 3.46s
ğŸ“¤ Request 150/200 sent at 3.46s
ğŸ“¤ Request 151/200 sent at 3.47s
ğŸ“¤ Request 152/200 sent at 3.47s
ğŸ“¤ Request 153/200 sent at 3.47s
ğŸ“¤ Request 154/200 sent at 3.47s
ğŸ“¤ Request 155/200 sent at 3.49s
ğŸ“¤ Request 156/200 sent at 3.50s
ğŸ“¤ Request 157/200 sent at 3.52s
ğŸ“¤ Request 158/200 sent at 3.53s
âœ… Request 95/200 completed
âœ… Request 88/200 completed
ğŸ“¤ Request 159/200 sent at 3.55s
ğŸ“¤ Request 160/200 sent at 3.56s
ğŸ“¤ Request 161/200 sent at 3.57s
ğŸ“¤ Request 162/200 sent at 3.58s
ğŸ“¤ Request 163/200 sent at 3.58s
âœ… Request 98/200 completed
ğŸ“¤ Request 164/200 sent at 3.59s
ğŸ“¤ Request 165/200 sent at 3.60s
ğŸ“¤ Request 166/200 sent at 3.62s
ğŸ“¤ Request 167/200 sent at 3.63s
ğŸ“¤ Request 168/200 sent at 3.63s
âœ… Request 77/200 completed
ğŸ“¤ Request 169/200 sent at 3.64s
ğŸ“¤ Request 170/200 sent at 3.68s
âœ… Request 82/200 completed
âœ… Request 99/200 completed
âœ… Request 110/200 completed
âœ… Request 85/200 completed
ğŸ“¤ Request 171/200 sent at 3.75s
ğŸ“¤ Request 172/200 sent at 3.76s
ğŸ“¤ Request 173/200 sent at 3.78s
ğŸ“¤ Request 174/200 sent at 3.78s
âœ… Request 144/200 completed
ğŸ“¤ Request 175/200 sent at 3.80s
ğŸ“¤ Request 176/200 sent at 3.80s
âœ… Request 111/200 completed
ğŸ“¤ Request 177/200 sent at 3.82s
ğŸ“¤ Request 178/200 sent at 3.83s
ğŸ“¤ Request 179/200 sent at 3.84s
ğŸ“¤ Request 180/200 sent at 3.84s
ğŸ“¤ Request 181/200 sent at 3.85s
ğŸ“¤ Request 182/200 sent at 3.85s
âœ… Request 107/200 completed
âœ… Request 104/200 completed
ğŸ“¤ Request 183/200 sent at 3.89s
ğŸ“¤ Request 184/200 sent at 3.91s
ğŸ“¤ Request 185/200 sent at 3.93s
ğŸ“¤ Request 186/200 sent at 3.93s
ğŸ“¤ Request 187/200 sent at 3.94s
ğŸ“¤ Request 188/200 sent at 3.94s
ğŸ“¤ Request 189/200 sent at 3.95s
ğŸ“¤ Request 190/200 sent at 3.96s
ğŸ“¤ Request 191/200 sent at 3.98s
ğŸ“¤ Request 192/200 sent at 3.99s
ğŸ“¤ Request 193/200 sent at 3.99s
âœ… Request 86/200 completed
ğŸ“¤ Request 194/200 sent at 4.00s
âœ… Request 131/200 completed
ğŸ“¤ Request 195/200 sent at 4.02s
âœ… Request 122/200 completed
âœ… Request 90/200 completed
ğŸ“¤ Request 196/200 sent at 4.08s
ğŸ“¤ Request 197/200 sent at 4.10s
ğŸ“¤ Request 198/200 sent at 4.11s
ğŸ“¤ Request 199/200 sent at 4.13s
ğŸ“¤ Request 200/200 sent at 4.14s

Waiting for all requests to complete...
âœ… Request 101/200 completed
âœ… Request 97/200 completed
âœ… Request 119/200 completed
âœ… Request 147/200 completed
âœ… Request 109/200 completed
âœ… Request 116/200 completed
âœ… Request 93/200 completed
âœ… Request 120/200 completed
âœ… Request 169/200 completed
âœ… Request 163/200 completed
âœ… Request 126/200 completed
âœ… Request 115/200 completed
âœ… Request 134/200 completed
âœ… Request 105/200 completed
âœ… Request 106/200 completed
âœ… Request 121/200 completed
âœ… Request 170/200 completed
âœ… Request 102/200 completed
âœ… Request 133/200 completed
âœ… Request 175/200 completed
âœ… Request 128/200 completed
âœ… Request 155/200 completed
âœ… Request 164/200 completed
âœ… Request 96/200 completed
âœ… Request 162/200 completed
âœ… Request 186/200 completed
âœ… Request 123/200 completed
âœ… Request 142/200 completed
âœ… Request 154/200 completed
âœ… Request 118/200 completed
âœ… Request 140/200 completed
âœ… Request 171/200 completed
âœ… Request 129/200 completed
âœ… Request 151/200 completed
âœ… Request 183/200 completed
âœ… Request 108/200 completed
âœ… Request 168/200 completed
âœ… Request 132/200 completed
âœ… Request 177/200 completed
âœ… Request 143/200 completed
âœ… Request 113/200 completed
âœ… Request 181/200 completed
âœ… Request 130/200 completed
âœ… Request 153/200 completed
âœ… Request 117/200 completed
âœ… Request 148/200 completed
âœ… Request 124/200 completed
âœ… Request 135/200 completed
âœ… Request 157/200 completed
âœ… Request 192/200 completed
âœ… Request 185/200 completed
âœ… Request 156/200 completed
âœ… Request 161/200 completed
âœ… Request 196/200 completed
âœ… Request 187/200 completed
âœ… Request 127/200 completed
âœ… Request 149/200 completed
âœ… Request 199/200 completed
âœ… Request 159/200 completed
âœ… Request 125/200 completed
âœ… Request 190/200 completed
âœ… Request 191/200 completed
âœ… Request 152/200 completed
âœ… Request 174/200 completed
âœ… Request 145/200 completed
âœ… Request 139/200 completed
âœ… Request 160/200 completed
âœ… Request 150/200 completed
âœ… Request 188/200 completed
âœ… Request 137/200 completed
âœ… Request 158/200 completed
âœ… Request 165/200 completed
âœ… Request 197/200 completed
âœ… Request 195/200 completed
âœ… Request 136/200 completed
âœ… Request 146/200 completed
âœ… Request 138/200 completed
âœ… Request 172/200 completed
âœ… Request 141/200 completed
âœ… Request 166/200 completed
âœ… Request 194/200 completed
âœ… Request 179/200 completed
âœ… Request 173/200 completed
âœ… Request 182/200 completed
âœ… Request 167/200 completed
âœ… Request 180/200 completed
âœ… Request 184/200 completed
âœ… Request 178/200 completed
âœ… Request 193/200 completed
âœ… Request 176/200 completed
âœ… Request 189/200 completed
âœ… Request 198/200 completed
âœ… Request 200/200 completed

âœ… All requests sent in 5.45s

Querying request tracking information...
âœ… Found tracking info for 200 requests

âœ… Results exported to: router_test_20250729_211857.csv

ğŸ“Š Summary Statistics:
Total requests: 200
Successful requests: 200
Failed requests: 0

Latency Statistics (successful requests):
  Server latency: mean=1.284s, p50=1.273s, p99=2.083s
  Total latency: mean=1.284s, p50=1.273s, p99=2.083s
  Queue time: mean=0.000s, p50=0.000s, p99=0.000s
  Server queue time (total): mean=0.568s, p50=0.518s, p99=1.016s

Host Distribution:
  http://localhost:60006: 100 requests (50.0%)
  http://localhost:60005: 100 requests (50.0%)

==========================================
æµ‹è¯•å®Œæˆï¼
ç»“æœå·²ä¿å­˜åˆ°: router_test_*.csv
==========================================


(lg) root:/nas/ganluo# python -m sglang.launch_server --model-path "/nas/models/Meta-Llama-3-8B-Instruct" --host "0.0.0.0" --port 60005 --base-gpu-id 2 --enable-metrics
[2025-07-29 21:12:05] server_args=ServerArgs(model_path='/nas/models/Meta-Llama-3-8B-Instruct', tokenizer_path='/nas/models/Meta-Llama-3-8B-Instruct', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=False, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='0.0.0.0', port=60005, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.874, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=1, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=859698659, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=2, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=0, crash_dump_folder=None, show_time_cost=False, enable_metrics=True, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, api_key=None, served_model_name='/nas/models/Meta-Llama-3-8B-Instruct', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, dp_size=1, load_balance_method='round_robin', dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, ep_size=1, enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_moe=False, enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through_selective', hicache_io_backend='', hicache_storage_backend=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, cuda_graph_max_bs=None, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_nccl_nvls=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, enable_triton_kernel_moe=False, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, pdlb_url=None, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3)
[2025-07-29 21:12:12] Scheduler initialized with enable_metrics=True
[2025-07-29 21:12:12] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-07-29 21:12:12] Init torch distributed begin.
[2025-07-29 21:12:13] Init torch distributed ends. mem usage=0.00 GB
[2025-07-29 21:12:13] Load weight begin. avail mem=78.49 GB
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.12it/s]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.07it/s]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.08it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.50it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.32it/s]

[2025-07-29 21:12:18] Load weight end. type=LlamaForCausalLM, dtype=torch.bfloat16, avail mem=63.52 GB, mem usage=14.98 GB.
[2025-07-29 21:12:19] KV Cache is allocated. #tokens: 439212, K size: 26.81 GB, V size: 26.81 GB
[2025-07-29 21:12:19] Memory pool end. avail mem=9.70 GB
[2025-07-29 21:12:20] Capture cuda graph begin. This can take up to several minutes. avail mem=9.60 GB
[2025-07-29 21:12:22] Capture cuda graph bs [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160]
Capturing batches (bs=1 avail_mem=8.53 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:10<00:00,  2.27it/s]
[2025-07-29 21:12:32] Capture cuda graph end. Time elapsed: 11.67 s. mem usage=1.07 GB. avail mem=8.53 GB.
[2025-07-29 21:12:32] max_total_num_tokens=439212, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=4096, context_len=8192, available_gpu_mem=8.53 GB
[2025-07-29 21:12:33] INFO:     Started server process [41843]
[2025-07-29 21:12:33] INFO:     Waiting for application startup.
[2025-07-29 21:12:33] INFO:     Application startup complete.
[2025-07-29 21:12:33] INFO:     Uvicorn running on http://0.0.0.0:60005 (Press CTRL+C to quit)
[2025-07-29 21:12:34] INFO:     127.0.0.1:32814 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-07-29 21:12:34] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-07-29 21:12:35] INFO:     127.0.0.1:32820 - "POST /generate HTTP/1.1" 200 OK
[2025-07-29 21:12:35] The server is fired up and ready to roll!
[2025-07-29 21:16:27] INFO:     127.0.0.1:56370 - "GET /health HTTP/1.1" 200 OK
[2025-07-29 21:16:27] INFO:     127.0.0.1:56384 - "GET /health HTTP/1.1" 200 OK
[2025-07-29 21:16:37] INFO:     127.0.0.1:56646 - "GET /health HTTP/1.1" 200 OK


(lg) root:/nas/ganluo# python -m sglang.launch_server --model-path "/nas/models/Meta-Llama-3-8B-Instruct" --host "0.0.0.0" --port 60006 --base-gpu-id 3 --enable-metrics
[2025-07-29 21:12:13] server_args=ServerArgs(model_path='/nas/models/Meta-Llama-3-8B-Instruct', tokenizer_path='/nas/models/Meta-Llama-3-8B-Instruct', tokenizer_mode='auto', skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=False, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='0.0.0.0', port=60006, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.874, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, cpu_offload_gb=0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=1, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=278511057, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=3, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=0, crash_dump_folder=None, show_time_cost=False, enable_metrics=True, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, api_key=None, served_model_name='/nas/models/Meta-Llama-3-8B-Instruct', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, dp_size=1, load_balance_method='round_robin', dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm=None, speculative_draft_model_path=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, ep_size=1, enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_moe=False, enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through_selective', hicache_io_backend='', hicache_storage_backend=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, cuda_graph_max_bs=None, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_nccl_nvls=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, enable_triton_kernel_moe=False, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, pdlb_url=None, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3)
[2025-07-29 21:12:22] Scheduler initialized with enable_metrics=True
[2025-07-29 21:12:22] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-07-29 21:12:22] Init torch distributed begin.
[2025-07-29 21:12:25] Init torch distributed ends. mem usage=0.00 GB
[2025-07-29 21:12:26] Load weight begin. avail mem=78.49 GB
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.21it/s]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.17it/s]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.14it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.53it/s]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.37it/s]

[2025-07-29 21:12:32] Load weight end. type=LlamaForCausalLM, dtype=torch.bfloat16, avail mem=63.50 GB, mem usage=14.99 GB.
[2025-07-29 21:12:32] KV Cache is allocated. #tokens: 439065, K size: 26.80 GB, V size: 26.80 GB
[2025-07-29 21:12:32] Memory pool end. avail mem=9.66 GB
[2025-07-29 21:12:32] Capture cuda graph begin. This can take up to several minutes. avail mem=9.60 GB
[2025-07-29 21:12:32] Capture cuda graph bs [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160]
Capturing batches (bs=1 avail_mem=8.53 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:06<00:00,  3.48it/s]
[2025-07-29 21:12:39] Capture cuda graph end. Time elapsed: 6.82 s. mem usage=1.07 GB. avail mem=8.53 GB.
[2025-07-29 21:12:39] max_total_num_tokens=439065, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=4096, context_len=8192, available_gpu_mem=8.53 GB
[2025-07-29 21:12:40] INFO:     Started server process [42324]
[2025-07-29 21:12:40] INFO:     Waiting for application startup.
[2025-07-29 21:12:40] INFO:     Application startup complete.
[2025-07-29 21:12:40] INFO:     Uvicorn running on http://0.0.0.0:60006 (Press CTRL+C to quit)
[2025-07-29 21:12:41] INFO:     127.0.0.1:52770 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-07-29 21:12:41] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-07-29 21:12:42] INFO:     127.0.0.1:52772 - "POST /generate HTTP/1.1" 200 OK
[2025-07-29 21:12:42] The server is fired up and ready to roll!
[2025-07-29 21:16:27] INFO:     127.0.0.1:48708 - "GET /health HTTP/1.1" 200 OK
[2025-07-29 21:16:27] INFO:     127.0.0.1:48714 - "GET /health HTTP/1.1" 200 OK
[2025-07-29 21:16:37] INFO:     127.0.0.1:58160 - "GET /health HTTP/1.1" 200 OK
[2025-07-29 21:16:47] INFO:     127.0.0.1:41056 - "GET /health HTTP/1.1" 200 OK


(lg) root:/nas/ganluo/sglang# bash /nas/ganluo/sglang/bash_start_router.sh
==========================================
SGLang Router å¯åŠ¨é…ç½®
==========================================
è·¯ç”±ç­–ç•¥: random
WorkerèŠ‚ç‚¹: http://localhost:60005 http://localhost:60006
è·¯ç”±å™¨åœ°å€: 0.0.0.0:60009
è¯·æ±‚è¿½è¸ª: true
æ—¥å¿—çº§åˆ«: INFO
==========================================

æ‰§è¡Œå‘½ä»¤:
python /nas/ganluo/sglang/start_router.py --policy random --host 0.0.0.0 --port 60009 --log-level INFO --workers http://localhost:60005 http://localhost:60006 --enable-tracking --max-trace-entries 100000 --trace-ttl 3600

Port-GPU mapping saved to: /tmp/sglang_port_gpu_mapping.json
Mapping:
  Port 60005 -> cuda:0
  Port 60006 -> cuda:1

Starting router with configuration:
  Policy: random
  Workers: ['http://localhost:60005', 'http://localhost:60006']
  Host: 0.0.0.0:60009
  Request tracking: Enabled
  Max trace entries: 100000
  Trace TTL: 3600s
  Log level: INFO

Router started successfully! Press Ctrl+C to stop.
2025-07-29 13:16:27  INFO sglang_router_rs::server: src/server.rs:331: ğŸš§ Initializing Prometheus metrics on 127.0.0.1:29000
2025-07-29 13:16:27  INFO sglang_router_rs::server: src/server.rs:340: ğŸš§ Initializing router on 0.0.0.0:60009
2025-07-29 13:16:27  INFO sglang_router_rs::server: src/server.rs:341: ğŸš§ Router mode: Regular { worker_urls: ["http://localhost:60005", "http://localhost:60006"] }
2025-07-29 13:16:27  INFO sglang_router_rs::server: src/server.rs:342: ğŸš§ Policy: Random
2025-07-29 13:16:27  INFO sglang_router_rs::server: src/server.rs:343: ğŸš§ Max payload size: 256 MB
2025-07-29 13:16:27  INFO sglang_router_rs::server: src/server.rs:353: ğŸš§ Service discovery disabled
2025-07-29 13:16:27  INFO sglang_router_rs::routers::router: src/routers/router.rs:181: All workers are healthy
2025-07-29 13:16:27  INFO sglang_router_rs::request_tracker: src/request_tracker.rs:65: Initializing request tracker with max_entries=100000, ttl=3600s
2025-07-29 13:16:27  INFO sglang_router_rs::server: src/server.rs:390: âœ… Serving router on 0.0.0.0:60009
2025-07-29 13:16:27  INFO sglang_router_rs::server: src/server.rs:391: âœ… Serving workers on ["http://localhost:60005", "http://localhost:60006"]


(lg) root:/nas/ganluo/sglang# python verify_queue_fix.py 2>&1 | tee verify_queue_fix_newlog_60005.log

ğŸš€ å¼€å§‹æµ‹è¯•Queueæ—¶é—´æˆ³ä¿®å¤
æ—¶é—´: 2025-07-29 21:21:10.730637
æœåŠ¡å™¨: http://localhost:60005

============================================================
æµ‹è¯•å•ä¸ªè¯·æ±‚çš„Queueæ—¶é—´æˆ³
============================================================

ğŸ“‹ å“åº”å†…å®¹:
{
  "error": {
    "message": "Either text, input_ids or input_embeds should be provided."
  }
}
âŒ å“åº”ä¸­æ²¡æœ‰meta_info

============================================================
æµ‹è¯•10ä¸ªå¹¶å‘è¯·æ±‚çš„Queueæ—¶é—´æˆ³
============================================================

âœ… æ‰€æœ‰è¯·æ±‚åœ¨ 0.01ç§’ å†…å®Œæˆ

  è¯·æ±‚ 0: âŒ æ²¡æœ‰meta_info
  è¯·æ±‚ 1: âŒ æ²¡æœ‰meta_info
  è¯·æ±‚ 2: âŒ æ²¡æœ‰meta_info
  è¯·æ±‚ 3: âŒ æ²¡æœ‰meta_info
  è¯·æ±‚ 4: âŒ æ²¡æœ‰meta_info
  è¯·æ±‚ 5: âŒ æ²¡æœ‰meta_info
  è¯·æ±‚ 6: âŒ æ²¡æœ‰meta_info
  è¯·æ±‚ 7: âŒ æ²¡æœ‰meta_info
  è¯·æ±‚ 8: âŒ æ²¡æœ‰meta_info
  è¯·æ±‚ 9: âŒ æ²¡æœ‰meta_info

============================================================
æµ‹è¯•æ€»ç»“
============================================================

âŒ æµ‹è¯•å¤±è´¥ï¼Queueæ—¶é—´æˆ³ä»ç„¶æœ‰é—®é¢˜

æ’æŸ¥å»ºè®®:
1. ç¡®è®¤ä»£ç å·²æ­£ç¡®éƒ¨ç½²åˆ°æœåŠ¡å™¨
2. æ£€æŸ¥æœåŠ¡å™¨å¯åŠ¨å‚æ•°æ˜¯å¦åŒ…å«--enable-metrics
3. æŸ¥çœ‹æœåŠ¡å™¨æ—¥å¿—ä¸­çš„enable_metricsçŠ¶æ€
4. ä½¿ç”¨--log-level debugæŸ¥çœ‹è¯¦ç»†çš„æ—¶é—´æˆ³è®¾ç½®æ—¥å¿—
(lg) root:/nas/ganluo/sglang# 


(lg) root:/nas/ganluo/sglang# python verify_queue_fix.py 2>&1 | tee verify_queue_fix_newlog_60006.log

ğŸš€ å¼€å§‹æµ‹è¯•Queueæ—¶é—´æˆ³ä¿®å¤
æ—¶é—´: 2025-07-29 21:21:28.232818
æœåŠ¡å™¨: http://localhost:60006

============================================================
æµ‹è¯•å•ä¸ªè¯·æ±‚çš„Queueæ—¶é—´æˆ³
============================================================

ğŸ“‹ å“åº”å†…å®¹:
{
  "error": {
    "message": "Either text, input_ids or input_embeds should be provided."
  }
}
âŒ å“åº”ä¸­æ²¡æœ‰meta_info

============================================================
æµ‹è¯•10ä¸ªå¹¶å‘è¯·æ±‚çš„Queueæ—¶é—´æˆ³
============================================================

âœ… æ‰€æœ‰è¯·æ±‚åœ¨ 0.01ç§’ å†…å®Œæˆ

  è¯·æ±‚ 0: âŒ æ²¡æœ‰meta_info
  è¯·æ±‚ 1: âŒ æ²¡æœ‰meta_info
  è¯·æ±‚ 2: âŒ æ²¡æœ‰meta_info
  è¯·æ±‚ 3: âŒ æ²¡æœ‰meta_info
  è¯·æ±‚ 4: âŒ æ²¡æœ‰meta_info
  è¯·æ±‚ 5: âŒ æ²¡æœ‰meta_info
  è¯·æ±‚ 6: âŒ æ²¡æœ‰meta_info
  è¯·æ±‚ 7: âŒ æ²¡æœ‰meta_info
  è¯·æ±‚ 8: âŒ æ²¡æœ‰meta_info
  è¯·æ±‚ 9: âŒ æ²¡æœ‰meta_info

============================================================
æµ‹è¯•æ€»ç»“
============================================================

âŒ æµ‹è¯•å¤±è´¥ï¼Queueæ—¶é—´æˆ³ä»ç„¶æœ‰é—®é¢˜

æ’æŸ¥å»ºè®®:
1. ç¡®è®¤ä»£ç å·²æ­£ç¡®éƒ¨ç½²åˆ°æœåŠ¡å™¨
2. æ£€æŸ¥æœåŠ¡å™¨å¯åŠ¨å‚æ•°æ˜¯å¦åŒ…å«--enable-metrics
3. æŸ¥çœ‹æœåŠ¡å™¨æ—¥å¿—ä¸­çš„enable_metricsçŠ¶æ€
4. ä½¿ç”¨--log-level debugæŸ¥çœ‹è¯¦ç»†çš„æ—¶é—´æˆ³è®¾ç½®æ—¥å¿—
(lg) root:/nas/ganluo/sglang# 
