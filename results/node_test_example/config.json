{
  "model_path": "/data/pretrained_models/Llama-2-7b-hf",
  "tokenizer_path": null,
  "num_prompts": 100,
  "request_rate": 10.0,
  "dataset_name": "random",
  "dataset_path": "",
  "output_dir": "./results",
  "output_format": "json",
  "save_detailed_results": true,
  "random_input_len": 1024,
  "random_output_len": 128,
  "random_range_ratio": 0.5,
  "seed": 42,
  "warmup_requests": 10,
  "timeout": 3600,
  "verbose": false,
  "gpu_id": 1,
  "port": 30000,
  "host": "0.0.0.0",
  "mem_fraction_static": 0.9,
  "max_running_requests": 256,
  "max_total_tokens": null,
  "chunked_prefill_size": 8192,
  "max_prefill_tokens": 16384,
  "tp_size": 1,
  "enable_torch_compile": false,
  "disable_radix_cache": false,
  "schedule_conservativeness": 1.0,
  "quantization": null,
  "attention_backend": null,
  "metrics_config": "MetricsConfig(collection_interval=1.0, collect_throughput=True, collect_latency=True, collect_queue_metrics=True, collect_resource_usage=True, collect_cache_metrics=True, latency_percentiles=[0.5, 0.9, 0.95, 0.99], export_format='json', export_interval=None, enable_dashboard=False, dashboard_port=8080)",
  "enable_dynamic_params": false,
  "param_update_schedule": null
}