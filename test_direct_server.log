SGLang 直连服务器测试
================================================================================


[22:58:41] 获取服务器信息
================================================================================
服务器信息:
{
  "model_path": "/nas/models/Meta-Llama-3-8B-Instruct",
  "tokenizer_path": "/nas/models/Meta-Llama-3-8B-Instruct",
  "tokenizer_mode": "auto",
  "skip_tokenizer_init": false,
  "load_format": "auto",
  "model_loader_extra_config": "{}",
  "trust_remote_code": false,
  "context_length": null,
  "is_embedding": false,
  "enable_multimodal": null,
  "revision": null,
  "model_impl": "auto",
  "host": "0.0.0.0",
  "port": 60005,
  "skip_server_warmup": false,
  "warmups": null,
  "nccl_port": null,
  "dtype": "auto",
  "quantization": null,
  "quantization_param_path": null,
  "kv_cache_dtype": "auto",
  "mem_fraction_static": 0.874,
  "max_running_requests": null,
  "max_total_tokens": null,
  "chunked_prefill_size": 8192,
  "max_prefill_tokens": 16384,
  "schedule_policy": "fcfs",
  "schedule_conservativeness": 1.0,
  "cpu_offload_gb": 0,
  "page_size": 1,
  "hybrid_kvcache_ratio": null,
  "swa_full_tokens_ratio": 0.8,
  "disable_hybrid_swa_memory": false,
  "device": "cuda",
  "tp_size": 1,
  "pp_size": 1,
  "max_micro_batch_size": null,
  "stream_interval": 1,
  "stream_output": false,
  "random_seed": 260055502,
  "constrained_json_whitespace_pattern": null,
  "watchdog_timeout": 300,
  "dist_timeout": null,
  "download_dir": null,
  "base_gpu_id": 2,
  "gpu_id_step": 1,
  "sleep_on_idle": false,
  "log_level": "debug",
  "log_level_http": null,
  "log_requests": false,
  "log_requests_level": 0,
  "crash_dump_folder": null,
  "show_time_cost": false,
  "enable_metrics": true,
  "enable_metrics_for_all_schedulers": false,
  "bucket_time_to_first_token": null,
  "bucket_inter_token_latency": null,
  "bucket_e2e_request_latency": null,
  "collect_tokens_histogram": false,
  "decode_log_interval": 40,
  "enable_request_time_stats_logging": false,
  "kv_events_config": null,
  "api_key": null,
  "served_model_name": "/nas/models/Meta-Llama-3-8B-Instruct",
  "chat_template": null,
  "completion_template": null,
  "file_storage_path": "sglang_storage",
  "enable_cache_report": false,
  "reasoning_parser": null,
  "tool_call_parser": null,
  "dp_size": 1,
  "load_balance_method": "round_robin",
  "dist_init_addr": null,
  "nnodes": 1,
  "node_rank": 0,
  "json_model_override_args": "{}",
  "preferred_sampling_params": null,
  "enable_lora": null,
  "max_lora_rank": null,
  "lora_target_modules": null,
  "lora_paths": null,
  "max_loras_per_batch": 8,
  "lora_backend": "triton",
  "attention_backend": null,
  "sampling_backend": "flashinfer",
  "grammar_backend": "xgrammar",
  "mm_attention_backend": null,
  "speculative_algorithm": null,
  "speculative_draft_model_path": null,
  "speculative_num_steps": null,
  "speculative_eagle_topk": null,
  "speculative_num_draft_tokens": null,
  "speculative_accept_threshold_single": 1.0,
  "speculative_accept_threshold_acc": 1.0,
  "speculative_token_map": null,
  "ep_size": 1,
  "enable_ep_moe": false,
  "enable_deepep_moe": false,
  "enable_flashinfer_moe": false,
  "enable_flashinfer_allreduce_fusion": false,
  "deepep_mode": "auto",
  "ep_num_redundant_experts": 0,
  "ep_dispatch_algorithm": "static",
  "init_expert_location": "trivial",
  "enable_eplb": false,
  "eplb_algorithm": "auto",
  "eplb_rebalance_num_iterations": 1000,
  "eplb_rebalance_layers_per_chunk": null,
  "expert_distribution_recorder_mode": null,
  "expert_distribution_recorder_buffer_size": 1000,
  "enable_expert_distribution_metrics": false,
  "deepep_config": null,
  "moe_dense_tp_size": null,
  "enable_hierarchical_cache": false,
  "hicache_ratio": 2.0,
  "hicache_size": 0,
  "hicache_write_policy": "write_through_selective",
  "hicache_io_backend": "",
  "hicache_storage_backend": null,
  "enable_double_sparsity": false,
  "ds_channel_config_path": null,
  "ds_heavy_channel_num": 32,
  "ds_heavy_token_num": 256,
  "ds_heavy_channel_type": "qk",
  "ds_sparse_decode_threshold": 4096,
  "disable_radix_cache": false,
  "cuda_graph_max_bs": null,
  "cuda_graph_bs": null,
  "disable_cuda_graph": false,
  "disable_cuda_graph_padding": false,
  "enable_profile_cuda_graph": false,
  "enable_nccl_nvls": false,
  "enable_tokenizer_batch_encode": false,
  "disable_outlines_disk_cache": false,
  "disable_custom_all_reduce": false,
  "enable_mscclpp": false,
  "disable_overlap_schedule": false,
  "enable_mixed_chunk": false,
  "enable_dp_attention": false,
  "enable_dp_lm_head": false,
  "enable_two_batch_overlap": false,
  "enable_torch_compile": false,
  "torch_compile_max_bs": 32,
  "torchao_config": "",
  "enable_nan_detection": false,
  "enable_p2p_check": false,
  "triton_attention_reduce_in_fp32": false,
  "triton_attention_num_kv_splits": 8,
  "num_continuous_decode_steps": 1,
  "delete_ckpt_after_loading": false,
  "enable_memory_saver": false,
  "allow_auto_truncate": false,
  "enable_custom_logit_processor": false,
  "flashinfer_mla_disable_ragged": false,
  "disable_shared_experts_fusion": false,
  "disable_chunked_prefix_cache": false,
  "disable_fast_image_processor": false,
  "enable_return_hidden_states": false,
  "enable_triton_kernel_moe": false,
  "debug_tensor_dump_output_folder": null,
  "debug_tensor_dump_input_file": null,
  "debug_tensor_dump_inject": false,
  "debug_tensor_dump_prefill_only": false,
  "disaggregation_mode": "null",
  "disaggregation_transfer_backend": "mooncake",
  "disaggregation_bootstrap_port": 8998,
  "disaggregation_decode_tp": null,
  "disaggregation_decode_dp": null,
  "disaggregation_prefill_pp": 1,
  "disaggregation_ib_device": null,
  "num_reserved_decode_tokens": 512,
  "pdlb_url": null,
  "custom_weight_loader": [],
  "weight_loader_disable_mmap": false,
  "enable_pdmux": false,
  "sm_group_num": 3,
  "status": "ready",
  "max_total_num_tokens": 439212,
  "max_req_input_len": 8186,
  "internal_states": [
    {
      "attention_backend": "fa3",
      "mm_attention_backend": null,
      "debug_tensor_dump_inject": false,
      "debug_tensor_dump_output_folder": null,
      "chunked_prefill_size": 8192,
      "device": "cuda",
      "disable_chunked_prefix_cache": true,
      "disable_radix_cache": false,
      "enable_dp_attention": false,
      "enable_two_batch_overlap": false,
      "enable_dp_lm_head": false,
      "enable_deepep_moe": false,
      "deepep_mode": "auto",
      "enable_ep_moe": false,
      "enable_flashinfer_moe": false,
      "enable_flashinfer_allreduce_fusion": false,
      "moe_dense_tp_size": null,
      "ep_dispatch_algorithm": "static",
      "deepep_config": null,
      "ep_num_redundant_experts": 0,
      "enable_nan_detection": false,
      "flashinfer_mla_disable_ragged": false,
      "max_micro_batch_size": 4096,
      "disable_shared_experts_fusion": false,
      "sampling_backend": "flashinfer",
      "speculative_accept_threshold_single": 1.0,
      "speculative_accept_threshold_acc": 1.0,
      "torchao_config": "",
      "triton_attention_reduce_in_fp32": false,
      "num_reserved_decode_tokens": 512,
      "weight_loader_disable_mmap": false,
      "enable_triton_kernel_moe": false,
      "enable_multimodal": null,
      "use_mla_backend": false,
      "speculative_algorithm": 1,
      "last_gen_throughput": 876.3516021938809,
      "memory_usage": {
        "weight": 14.98,
        "kvcache": 53.61,
        "token_capacity": 439212,
        "cuda_graph": 1.07
      },
      "load": 0
    }
  ],
  "version": "0.4.9.post3"
}
[22:58:41] 开始直连服务器测试
服务器地址: http://localhost:60005/generate
================================================================================

测试 1: Hello world...

完整响应 (耗时 0.079s):
{
  "text": "! I'm a new contributor to the Open Source",
  "meta_info": {
    "id": "2fcfff2f769443f6be94c92aa8dd0e21",
    "finish_reason": {
      "type": "length",
      "length": 10
    },
    "prompt_tokens": 3,
    "completion_tokens": 10,
    "cached_tokens": 2,
    "server_created_time": 1753801121.06221,
    "server_first_token_time": null,
    "queue_time_start": null,
    "queue_time_end": null,
    "e2e_latency": 0.07713890075683594
  }
}

✅ meta_info 字段存在

队列时间相关字段:
  ❌ queue_time_start: null
  ❌ queue_time_end: null
  ✅ server_created_time: 1753801121.06221
  ❌ server_first_token_time: null

其他字段:
  text: ! I'm a new contributor to the Open Source...
  usage: N/A
--------------------------------------------------------------------------------

测试 2: What is artificial intelligence?...

完整响应 (耗时 0.078s):
{
  "text": " Artificial intelligence (AI) refers to the development of",
  "meta_info": {
    "id": "a4a81bbf538d403990a29cddfa7d91f5",
    "finish_reason": {
      "type": "length",
      "length": 10
    },
    "prompt_tokens": 6,
    "completion_tokens": 10,
    "cached_tokens": 1,
    "server_created_time": 1753801122.1423225,
    "server_first_token_time": null,
    "queue_time_start": null,
    "queue_time_end": null,
    "e2e_latency": 0.07485127449035645
  }
}

✅ meta_info 字段存在

队列时间相关字段:
  ❌ queue_time_start: null
  ❌ queue_time_end: null
  ✅ server_created_time: 1753801122.1423225
  ❌ server_first_token_time: null

其他字段:
  text:  Artificial intelligence (AI) refers to the develo...
  usage: N/A
--------------------------------------------------------------------------------

测试 3: Explain quantum computing in simple terms...

完整响应 (耗时 0.076s):
{
  "text": "\nQuantum computing is a new way of processing",
  "meta_info": {
    "id": "08ff6deaf429469c9b87049f3d4dcf5b",
    "finish_reason": {
      "type": "length",
      "length": 10
    },
    "prompt_tokens": 8,
    "completion_tokens": 10,
    "cached_tokens": 1,
    "server_created_time": 1753801123.2212186,
    "server_first_token_time": null,
    "queue_time_start": null,
    "queue_time_end": null,
    "e2e_latency": 0.07313990592956543
  }
}

✅ meta_info 字段存在

队列时间相关字段:
  ❌ queue_time_start: null
  ❌ queue_time_end: null
  ✅ server_created_time: 1753801123.2212186
  ❌ server_first_token_time: null

其他字段:
  text: 
Quantum computing is a new way of processing...
  usage: N/A
--------------------------------------------------------------------------------


[22:58:44] 开始路由器测试（对比）
路由器地址: http://localhost:60009/generate
================================================================================

完整响应:
{
  "text": " and modem\nI'm trying to troubleshoot a",
  "meta_info": {
    "id": "3ce2e62e15624dd09edd777c951c59bc",
    "finish_reason": {
      "type": "length",
      "length": 10
    },
    "prompt_tokens": 5,
    "completion_tokens": 10,
    "cached_tokens": 1,
    "server_created_time": 1753801124.2992394,
    "server_first_token_time": null,
    "queue_time_start": null,
    "queue_time_end": null,
    "e2e_latency": 0.07870960235595703
  }
}

✅ meta_info 存在，包含字段:
  - id: 3ce2e62e15624dd09edd777c951c59bc
  - finish_reason: {'type': 'length', 'length': 10}
  - prompt_tokens: 5
  - completion_tokens: 10
  - cached_tokens: 1
  - server_created_time: 1753801124.2992394
  - server_first_token_time: None
  - queue_time_start: None
  - queue_time_end: None
  - e2e_latency: 0.07870960235595703


[22:58:44] 测试完成
